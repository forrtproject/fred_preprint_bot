<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Impact of Visual Imagery Absence on Fine-Grained Memory for Object Colour and Size: An Aphantasia Study</title>
				<funder ref="#_V8zruDf #_6X24Grx">
					<orgName type="full">National Natural Science Foundation of China</orgName>
				</funder>
				<funder ref="#_BDuhZeQ">
					<orgName type="full">Major Project of National Social Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Xiangqi</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Brain Research</orgName>
								<orgName type="laboratory">National Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country>McGovern, China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Language and Cognition</orgName>
								<orgName type="department" key="dep2">Division of Psychology and Language Sciences</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Minhong</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Brain Research</orgName>
								<orgName type="laboratory">National Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country>McGovern, China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory">South Railway Station Campus of Beijing No.12 High School Education Group</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhenjiang</forename><surname>Cui</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Brain Research</orgName>
								<orgName type="laboratory">National Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country>McGovern, China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Linguistics and Modern Languages</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<settlement>Hong Kong SAR</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">J</forename><forename type="middle">S H</forename><surname>Taylor</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Language and Cognition</orgName>
								<orgName type="department" key="dep2">Division of Psychology and Language Sciences</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Huafeng</forename><surname>Tang</surname></persName>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Institute of Developmental Psychology</orgName>
								<orgName type="department" key="dep2">Faculty of Psychology</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Zhiyun</forename><surname>Dai</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Brain Research</orgName>
								<orgName type="laboratory">National Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country>McGovern, China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xuliang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Brain Research</orgName>
								<orgName type="laboratory">National Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country>McGovern, China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yuxin</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institute for Brain Research</orgName>
								<orgName type="laboratory">National Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country>McGovern, China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Dorothy</forename><forename type="middle">Z</forename><surname>Gao</surname></persName>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Department of Experimental psychology</orgName>
								<orgName type="department" key="dep2">Division of Psychology and Language Sciences</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Zaizhu</forename><surname>Han</surname></persName>
							<email>zzhhan@bnu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Brain Research</orgName>
								<orgName type="laboratory">National Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG</orgName>
								<orgName type="institution">Beijing Normal University</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country>McGovern, China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="laboratory">National Key Laboratory of Cognitive Neuroscience and Learning &amp; IDG</orgName>
								<orgName type="institution" key="instit1">McGovern Institute for Brain Research</orgName>
								<orgName type="institution" key="instit2">Beijing Normal University</orgName>
								<address>
									<postCode>100875</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Impact of Visual Imagery Absence on Fine-Grained Memory for Object Colour and Size: An Aphantasia Study</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FC589AFFAF9D50D9101ABC5B21560076</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-21T13:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>aphantasia</term>
					<term>visual imagery</term>
					<term>fine-grained visual memory</term>
					<term>colour recall</term>
					<term>retrieval success</term>
					<term>retrieval precision</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Visual memory and visual imagery are closely intertwined cognitive functions, yet whether visual memory necessarily deteriorates when visual imagery is impaired remains unresolved. Aphantasia, the inability to voluntarily generate mental images, provides a compelling model to address this issue. However, previous reports of preserved or subtle deficits in aphantasia may have stemmed from tasks with low cognitive demands, coarse measures, and memory content lacking fine-grained demands, thereby limiting sensitivity to genuine impairments. Using high-load paradigms and continuous precision measures with mixture modelling, we tested colour memory, a domain requiring fine-grained representation, to examine whether these conditions would reveal pronounced impairments in aphantasia. Experiment 1 (20 aphantasic, 20 controls) tested colour memory for six sets of 20 objects (15 meaningful, 5 meaningless). Meaningless objects were included to further minimise verbal labelling. All object colours were sampled from the Hue-Saturation-Value (HSV) space, a perceptually uniform colour space. Recall was assessed using a continuous colour wheel, and performance was analysed with a computational mixture model that decomposed response errors into retrieval success (whether a colour was retrieved) and precision (how accurately it was remembered). Results revealed that aphantasic individuals showed markedly larger errors than controls, driven by reduced retrieval success rather than precision. Moreover, error magnitude and retrieval success correlated with several imagery dimensions (e.g., object imagery, spontaneous use of imagery), whereas retrieval precision was not. Experiment 2 (18 aphantasic, 20 controls) further tested whether deficits extend beyond colour using an analogous size-memory task with a slider. No group differences were observed in size error, retrieval success, or precision, and no correlations were observed between memory and several imagery-related aspects. Taken together, this study provides the first evidence that visual imagery is indispensable for retrieval success but not for precision when accessing visual memory traces for object colour, and that this indispensability may not extend to all object features.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Human cognition relies on visual memory-the system that retains and retrieves perceptual details to guide behaviour, shape decisions, and foster creativity <ref type="bibr" target="#b14">(Gerver et al., 2023;</ref><ref type="bibr" target="#b48">Schurgin, 2018)</ref>. Research suggests that visual memory is supported by at least two pathways: a vision-based route (e.g., visual imagery) and a languagebased route (e.g., verbal encoding) <ref type="bibr" target="#b0">(Baddeley, 2000;</ref><ref type="bibr" target="#b33">Paivio, 1990;</ref><ref type="bibr" target="#b35">Paivio, 2007)</ref>.</p><p>Visual imagery, the ability to generate sensory-like representations in the absence of visual input, has long been shown to facilitate memory by reinstating perceptual information during recall input <ref type="bibr" target="#b25">(Marks, 1973;</ref><ref type="bibr" target="#b38">Pearson, 2019;</ref><ref type="bibr" target="#b42">Reeder et al., 2024;</ref><ref type="bibr" target="#b52">Spagna et al., 2024)</ref>. In contrast, the language-based route supports memory by recoding perceptual details into verbal labels, which enables rehearsal and integration into semantic networks <ref type="bibr" target="#b1">(Baddeley, 2012;</ref><ref type="bibr" target="#b34">Paivio, 1991;</ref><ref type="bibr" target="#b51">Souza &amp; Skora, 2017</ref>). Yet a fundamental question persists: when the visual imagery route is impaired, does visual memory inevitably decline, or can language-based strategies fully compensate to preserve performance? Aphantasia, the inability to voluntarily generate visual mental images, offers an ideal model to address this question <ref type="bibr" target="#b12">(Dawes et al., 2020;</ref><ref type="bibr" target="#b56">Zeman et al., 2015)</ref>.</p><p>Intriguingly, despite this introspective absence, empirical studies generally find largely intact memory performance. Individuals with aphantasia exhibit no significant deficits in visual pattern recognition, memory updating, verbal memory, spatial short-term memory, or orientation and number working memory tasks <ref type="bibr" target="#b15">(Jacobs et al., 2018;</ref><ref type="bibr" target="#b20">Keogh et al., 2021;</ref><ref type="bibr" target="#b37">Pauly-Takacs et al., 2025;</ref><ref type="bibr" target="#b49">Siena &amp; Simons, 2024;</ref><ref type="bibr" target="#b54">Weber et al., 2024)</ref>. Some studies have reported impairments in more demanding short-term, long-term, verbal, or visual memory tasks <ref type="bibr" target="#b2">(Bainbridge et al., 2021;</ref><ref type="bibr" target="#b5">Beran et al., 2023;</ref><ref type="bibr" target="#b15">Jacobs et al., 2018;</ref><ref type="bibr" target="#b30">Monzel et al., 2022;</ref><ref type="bibr" target="#b40">Pounder et al., 2022)</ref> and autobiographical/episodic memory has also been shown to be affected <ref type="bibr" target="#b12">(Dawes et al., 2020;</ref><ref type="bibr" target="#b13">Dawes et al., 2022;</ref><ref type="bibr" target="#b28">Monzel et al., 2024)</ref>. However, overall, these impairments are usually subtle or, at most, moderate. Three broad explanations have been proposed for the generally preserved or subtle deficits reported in aphantasia. First, aphantasia may not entail a complete absence of imagery but rather reflect a "blindsight of the mind's eye", in which imagination operates without metacognitive awareness <ref type="bibr" target="#b23">(Liu &amp; Bartolomeo, 2023</ref><ref type="bibr">, 2025;</ref><ref type="bibr" target="#b26">Michel et al., 2025;</ref><ref type="bibr" target="#b31">Nanay, 2021)</ref>. Second, aphantasia may involve a genuine deficit in visual imagery that affects visual memory, but individuals can compensate for these impairments through alternative language-based strategies <ref type="bibr" target="#b17">(Kay et al., 2022;</ref><ref type="bibr" target="#b19">Keogh &amp; Pearson, 2024;</ref><ref type="bibr" target="#b20">Keogh et al., 2021;</ref><ref type="bibr" target="#b41">Purkart et al., 2025;</ref><ref type="bibr" target="#b55">Wicken et al., 2021)</ref>. Finally, it is also possible that such imagery deficits give rise to genuine visual memory impairments that alternative strategies cannot fully compensate for. However, these impairments may have gone undetected in previous studies due to the nature of the memory content examined and the limited sensitivity of the experimental designs and measures <ref type="bibr" target="#b40">(Pounder et al., 2022;</ref><ref type="bibr" target="#b47">Scholz et al., 2025)</ref>.</p><p>The type of memory content may influence whether deficits emerge. First, imagery impairment in aphantasia is typically stronger for object than for spatial imagery, so tasks relying primarily on spatial memory, such as location recall or navigation-based paradigms, may reveal minimal differences <ref type="bibr" target="#b2">(Bainbridge et al., 2021;</ref><ref type="bibr" target="#b7">Blazhenkova &amp; Pechenkova, 2019;</ref><ref type="bibr" target="#b36">Palermo et al., 2022;</ref><ref type="bibr" target="#b39">Phillips, 2025)</ref>. Second, when memory contents afford multiple encoding pathways <ref type="bibr">(e.g., verbal, spatial, tactile)</ref>, the absence of imagery may be more easily and effectively compensated by alternative pathways <ref type="bibr" target="#b12">(Dawes et al., 2020;</ref><ref type="bibr" target="#b32">Nanay, 2025;</ref><ref type="bibr" target="#b46">Savarimuthu &amp; Ponniah, 2024)</ref>. Finally, the granularity of the memory matters <ref type="bibr" target="#b2">(Bainbridge et al., 2021;</ref><ref type="bibr" target="#b40">Pounder et al., 2022)</ref>.</p><p>Coarse memory representations (e.g., recalling that something was "red") place relatively weak demands on imagery, whereas fine-grained memory (e.g., remembering the exact shade of red) is more likely to expose impairments. Therefore, studies that employ predominantly spatial, multimodally rich, or low-granularity memory tasks may fail to reveal the full extent of imagery deficits in aphantasia.</p><p>Object colour memory provides a compelling test case. Colour is a high-granularity, non-spatial feature that exists on a continuous spectrum, and although it can be encoded through visual imagery or verbal labels, the latter is insufficient to capture its subtle variations. A few initial investigations into colour memory deficits in aphantasia have been conducted. One study found no group differences in judging which of two vegetables (spinach vs. lettuce) had a deeper green colour when presented with their written names <ref type="bibr" target="#b23">(Liu &amp; Bartolomeo, 2023)</ref>. Another study found that aphantasic participants applied less colour when drawing remembered scenes compared to controls <ref type="bibr" target="#b2">(Bainbridge et al., 2021)</ref>. However, this may reflect impoverished object memory rather than a primary colour memory deficit, since aphantasic participants also recalled fewer objects, thereby naturally limiting colour usage. More recently, a study using continuous colour-wheel adjustments and computational mixture modelling to assess retrieval success and retrieval precision also found no deficits in either colour or location memory <ref type="bibr" target="#b49">(Siena &amp; Simons, 2024)</ref>. In sum, although several studies have examined colour memory in aphantasia, they have generally not identified robust deficits.</p><p>A more plausible explanation for the lack of robust evidence of colour memory deficits in aphantasia may lie in the experimental designs and measurement methods employed, which could inadvertently mask imagery-related impairments. First, tasks with relatively low memory loads may lack the resolution to reveal impairments; for example, previous studies have typically required participants to remember only a few items, potentially underestimating the contribution of imagery <ref type="bibr" target="#b40">(Pounder et al., 2022;</ref><ref type="bibr" target="#b49">Siena &amp; Simons, 2024)</ref>. Second, when multiple features are encoded simultaneously (e.g., colour and location), individuals with aphantasia may draw on compensatory strategies, such as spatial grouping (e.g., mentally "placing two colours in each corner"), thereby obscuring imagery-dependent impairments <ref type="bibr" target="#b46">(Savarimuthu &amp; Ponniah, 2024;</ref><ref type="bibr" target="#b49">Siena &amp; Simons, 2024)</ref>. Third, conventional measures (e.g., accuracy, reaction times) lack the sensitivity to detect subtle performance differences <ref type="bibr" target="#b15">(Jacobs et al., 2018;</ref><ref type="bibr" target="#b40">Pounder et al., 2022)</ref>. Finally, previous studies have often relied on relatively simple analytical approaches, which may be insufficient to pinpoint deficits in specific components of memory <ref type="bibr" target="#b4">(Bays et al., 2009;</ref><ref type="bibr" target="#b57">Zhang &amp; Luck, 2008)</ref>.</p><p>Against this backdrop, the present study revisits this question by introducing several key advancements in experimental design, measurement, and analysis to examine object colour memory performance in individuals with aphantasia more rigorously. First, we implemented three experimental design improvements over previous studies: (a) increased memory load, with participants required to memorize 20 items, substantially raising task demands; (b) isolated feature encoding, with object colour memorized independently of other attributes (e.g., spatial location), thereby limiting opportunities for chunking or multimodal encoding; and (c) inclusion of hardto-name objects, with a small set of meaningless stimuli added alongside the primary set of meaningful objects to serve as a control condition, minimizing verbal or semantic labelling and guarding against confounding effects of real-world colour associations that could otherwise facilitate memory. Second, we utilized precision colour measurement. Object colours were sampled from the Hue-Saturation-Value (HSV) colour space. Colour memory was assessed via a continuous colour-wheel selection task, with performance quantified by the error angle (angular difference between target and selected colours). This continuous approach was used to detect subtle differences in memory fidelity. Third, we conducted refined statistical analyses involving both memory decomposition and additional imagery assessments. With regards to memory decomposition, computational mixture modelling dissected memory performance into retrieval success (whether an item was present in memory) and retrieval precision (feature accuracy for retrieved items, e.g., recalling "bright" colour but not distinguishing red/orange). This approach enables more precise identification of the specific memory components that are affected <ref type="bibr" target="#b4">(Bays et al., 2009;</ref><ref type="bibr" target="#b54">Weber et al., 2024;</ref><ref type="bibr" target="#b57">Zhang &amp; Luck, 2008)</ref>. Concerning imagery assessment, in addition to Vividness of Visual Imagery Questionnaire (VVIQ) used by many studies on aphantasia, we incorporated the Object-Spatial Imagery and Verbal Questionnaire (OSIVQ), the Internal Representations Questionnaire (IRQ) and the Spontaneous Use of Imagery Scale (SUIS) <ref type="bibr" target="#b6">(Blazhenkova &amp; Kozhevnikov, 2008;</ref><ref type="bibr" target="#b25">Marks, 1973;</ref><ref type="bibr" target="#b43">Reisberg et al., 2002;</ref><ref type="bibr" target="#b45">Roebuck &amp; Lupyan, 2020)</ref>. This provides granular profiling of distinct abilities: visual object, verbal, and spatial imagery, plus daily-life imagery frequency, and allows us to see how these relate to each other. We anticipate that these refinements will better enable us to reveal memory impairments in aphantasia compared to previous studies.</p><p>In addition to examining object colour memory (Experiment 1), we conducted a control experiment on object size memory (Experiment 2) to determine whether any observed deficits were specific to colour processing. The experimental design of the size-memory task closely paralleled that of the colour-memory task, with comparable task demands and measurement precision. Previous research indicates that individuals with aphantasia generally retain intact spatial imagery <ref type="bibr" target="#b7">(Blazhenkova &amp; Pechenkova, 2019;</ref><ref type="bibr" target="#b12">Dawes et al., 2020)</ref>, suggesting that size memory performance should be preserved. Moreover, object size memory can draw on a wide range of compensatory cues in daily life, including: (1) spatial reasoning (e.g., relative comparisons such as "a mouse is smaller than a keyboard"); (2) verbal strategies that allow precise size discrimination (e.g., "A is five times larger than B" or "C occupied about half of the screen"); and (3) tactile-kinesthetic experience (e.g., grasping objects to encode size). These alternative sources of information may offer robust support for size encoding, even when vivid imagery is absent. For these reasons, we predict that individuals with aphantasia will show either preserved or only minimally impaired size memory performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1: Object Colour Memory</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>A total of 84 participants took part in the experiment. Of these, 40 participated in the main object colour-memory experiment, and an additional 44 participated in the evaluation of the degree of meaningfulness of the stimuli.</p><p>Participants for the main experiment were primarily recruited online via social media posts advertising a study on visual imagery. Posts targeted at individuals who self-identified as having little or no visual imagery were used to recruit the aphantasia group, while general calls for volunteers were used to recruit controls. All respondents completed the Vividness of Visual Imagery Questionnaire <ref type="bibr" target="#b25">(Marks, 1973)</ref>. Following established cut-offs <ref type="bibr" target="#b11">(Dance et al., 2022;</ref><ref type="bibr" target="#b13">Dawes et al., 2022;</ref><ref type="bibr" target="#b17">Kay et al., 2022)</ref>, 20 participants with VVIQ scores ≤ 32 were classified as aphantasic (mean [M] = 19.80, standard deviation [SD] = 5.11, range: 16-32). and 20 participants with scores &gt; 32 were selected as controls with typical imagery (M = 65.45, SD = 8.64, range: 49-80).</p><p>The two groups differed significantly in VVIQ scores (t(38) = 20.34, p &lt; 0.001, Cohen's d = 6.43). The two groups were also matched in demographic characteristics, showing no significant differences in gender, age or education (Table <ref type="table" target="#tab_0">1</ref>). Written informed consent was obtained from all participants prior to the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questionnaires</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VVIQ</head><p>The questionnaire includes four distinct scenes (e.g., 'Think of the front of a shop you often visit"), and for each scene, four specific aspects are described (e.g., "A window display with colours, shapes, and details of individual items for sale"), yielding a total of 16 items. Participants rate the vividness of their mental imagery for each item on a 5-point scale: from 1 (No image at all) to 5 (Perfectly clear, as vivid as normal vision). Total scores range from 16 to 80, with higher values indicating stronger visual imagery <ref type="bibr">(Dance et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Other Relevant Questionnaires</head><p>To assess multiple dimensions of mental imagery ability, participants additionally completed three self-report questionnaires: the OSIVQ <ref type="bibr" target="#b6">(Blazhenkova &amp; Kozhevnikov, 2008)</ref> , the IRQ <ref type="bibr" target="#b45">(Roebuck &amp; Lupyan, 2020)</ref>, and the SUIS <ref type="bibr" target="#b43">(Reisberg et al., 2002)</ref>.</p><p>The OSIVQ is a 45-item multidimensional assessment tool designed to evaluate three distinct cognitive domains: (a) object imagery, the ability to visualize detailed visual characteristics such as shapes, colours, and textures (e.g., "When I imagine the face of a friend, I have a perfectly clear and bright image"); (b) spatial imagery, the capacity to mentally represent and manipulate spatial relationships and movements (e.g., "I can easily sketch a blueprint for a building I am familiar with"); and (c) verbal ability, proficiency in comprehending and producing verbal and written language (e.g., "My verbal skills are excellent"). Each domain contains 15 items rated on a 5-point Likert scale ranging from 1 (totally disagree) to 5 (totally agree).</p><p>The IRQ assessed individual differences in internal cognitive representations. This 36-item measure evaluates four distinct dimensions: (a) internal verbalization (12 items), the tendency to engage in language-based thinking (e.g., "I often talk to myself internally while watching TV"); (b) visual imagery (10 items), the ability to generate and maintain vivid mental images (e.g., "I can close my eyes and easily picture a scene I have experienced"); (c) orthographic imagery (6 items), the mental visualization of written language (e.g., "When I hear someone talking, I see words written down in my mind"); and (d) representational manipulation (8 items), the capacity to dynamically transform mental representations, such as rotating shapes or modifying sounds (e.g., "I can easily imagine the sound of a trumpet getting louder"). All items were rated on a 5-point Likert scale ranging from 1 (strongly disagree) to 5 (strongly agree).</p><p>The To ensure attentiveness, we inserted infrequent attention-check items within the questionnaires. These items used the same response format as regular questions but instructed participants to select a specific option (e.g., "Please choose the 'medium' option"). Participants were unaware of the number or placement of these checks. All questionnaires were administered in validated Chinese versions following standard procedures <ref type="bibr" target="#b10">(Cui et al., 2025)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimuli</head><p>The main colour memory experiment comprised 120 colourful stimulus images (Figure <ref type="figure" target="#fig_2">1A</ref>), including 90 meaningful images (easy-to-name objects) and 30 meaningless images (difficult-to-name objects). These 120 images were randomly divided into six sets, each containing 20 images (15 meaningful and 5 meaningless).</p><p>Colours were assigned using a continuous wheel constructed in the Hue-Saturation-Value (HSV) colour space <ref type="bibr" target="#b50">(Smith, 1978)</ref>, from which 120 hues were selected at 3° intervals. For each participant, these 120 colours were randomly assigned to the images. These colours were hard to discriminate effectively with words since many objects were assigned the same broad colour category (e.g., purple).</p><p>Regarding image content, the meaningful images consisted of animal figures sourced from online royalty-free clip art. To reduce semantic or verbal labeling and to eliminate real-world colour associations, we also included meaningless images that were created by cutting, rotating, and morphing the meaningful images to generate irregular, unrecognizable shapes. As the primary aim of this experiment was to examine participants' ability to memorise the colours of meaningful objects, fewer meaningless stimuli were included. To validate the meaningfulness manipulation, 44 healthy participants were instructed to evaluate the degree to which each image could be regarded as a meaningful object. The evaluation was administered via the Wenjuanxing online platform (https://www.wjx.cn). Participants were asked to rate each of the 120 images on a 5-point Likert scale (1 = not meaningful at all, 5 = completely meaningful). The presentation order was pseudo-randomized. Results</p><p>showed that images categorized as meaningful received significantly higher meaningfulness ratings than meaningless images (Meaningful: M = 4.83, SD = 0.22;</p><p>Meaningless: M = 2.28, SD = 0.92; t(43) = 17.38, p &lt; .001, Cohen's d = 2.62). Given the unequal number of meaningful and meaningless stimuli, we conducted a bootstrap analysis (30 vs. 30 resampling; B = 5000) to assess the robustness of the meaningfulness difference. In each iteration, 30 meaningful items were randomly sampled without replacement and compared to the 30 meaningless items using a paired t-test across participants. Across these resamples, 100% of the tests were significant at both the p &lt; .05 and p &lt; .01 levels, confirming the effectiveness of the manipulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design and Procedure</head><p>The experiment comprised six blocks, with each block utilizing one of six distinct stimulus sets. Each block was divided into two key phases: an encoding phase followed by a recall phase. The procedure details are as follows and are depicted in Figure <ref type="figure" target="#fig_2">1B</ref>.</p><p>During the encoding phase, participants passively viewed images from a single stimulus set while intentionally memorizing each image's colour. Specifically, the encoding phase began with a central fixation cross displayed for 750 ms, followed by a coloured image displayed at the centre of the screen against a grey background (RGB = [128, 128, 128]) for 6 s during which participants were instructed to remember the colour-shape association. The images automatically disappeared at trial offset, immediately triggering the next trial's onset. The stimulus sequence was pseudorandomised, with the constraint that one meaningless image followed every three meaningful images to balance cognitive load and to avoid extended sequences of only meaningful trials, which might encourage semantic strategies, or only meaningless trials, which could be overly difficult. After viewing all 20 images in the set, participants completed a 10-second retention interval before proceeding to the recall phase, a delay period designed to assess longer-term colour memory representations.</p><p>In the recall phase, participants were asked to accurately recall and reproduce the colour corresponding to each image. Each trial commenced with a 1000-ms central fixation cross, followed by presentation of a colourless shape outline at screen centre surrounded by a continuous colour wheel. Participants selected a hue by moving the cursor around a colour wheel; the outline dynamically filled with the currently selected colour, allowing continuous adjustment until a final choice was confirmed with a mouse click. The recall phase was self-paced, with no time limits or feedback. This procedure was repeated until all 20 items had been recalled. Trial order during recall was fully randomised to prevent order effects relative to encoding.</p><p>The entire experiment was programmed and run using PsychoPy version 2021.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Analysis</head><p>Angular Error. Response error was defined as the angular deviation (0°-±180°)</p><p>between the target hue at encoding and the hue reproduced at recall. An error of 0° indicated perfect accuracy, while ±180° represented the maximum deviation. For each trial, the error was converted to an absolute value. These trial-level values were then averaged within each condition (meaningful, meaningless) to yield a mean error score for each participant, which was submitted to group-level analyses. Trial-level angular errors were also retained for linear mixed-effects modelling (LMM), which better accounts for subject-and item-level variance. Because the number of meaningless trials was too small, LMMs were applied only to the meaningful condition (see</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Analysis section below).</head><p>Retrieval Success and Retrieval Precision. For each participant, the signed angular deviations across trials (i.e., not converted to absolute values) form a distribution that can be modelled as a mixture of two components: random guessing and imprecise memory <ref type="bibr" target="#b4">(Bays et al., 2009;</ref><ref type="bibr" target="#b8">Brady et al., 2013;</ref><ref type="bibr" target="#b57">Zhang &amp; Luck, 2008)</ref>.</p><p>On some trials, participants may fail to recall the colour associated with the shape cue, leading to random guesses in which all colours are equally likely. These guesses produce a uniform distribution of response errors <ref type="bibr" target="#b21">(Korkki et al., 2020)</ref>. On other trials, participants may successfully retrieve the target colour but with reduced precision-e.g., knowing it was a bright colour but being unsure whether it was red or orange. In such cases, their responses tend to cluster around the correct value, with some variability. This pattern of noisy yet centred responses is well captured by a von Mises distribution, the circular analogue of a Gaussian distribution, appropriate for the circular nature of the colour space <ref type="bibr" target="#b57">(Zhang &amp; Luck, 2008)</ref>. This mixture modelling approach allows for a dissociation between whether an object colour was successfully retrieved (i.e. retrieval success) and how accurately it was remembered (i.e. retrieval precision).</p><p>In this study, response errors were entered into the MATLAB MemToolbox for the above mixture modelling analysis <ref type="bibr" target="#b53">(Suchow et al., 2013)</ref>. A Markov Chain Monte Carlo (MCMC) approach was used. The MCMC algorithm iteratively samples parameter values based on how well they account for the observed data while incorporating prior distributions. This procedure yielded Maximum A Posteriori (MAP) estimates for two key parameters: Pmem, representing the inverse of the height of the uniform distribution (i.e., 1 minus the proportion of random guesses), and kappa (ĸ), the concentration parameter of the von Mises distribution. Pmem captures the probability that participants successfully retrieved the target colour-higher values indicate greater memory accessibility (i.e. retrieval success). In contrast, κ quantifies the concentration of the recalled hue distribution, with higher values reflecting more precise memory (i.e., retrieval precision). We conducted this analysis separately for each experimental condition (meaningful and meaningless) and for each participant. The resulting individual Pmem and κ estimates were then submitted to group-level statistical analyses.</p><p>Statistical Analysis. To examine potential differences in memory performance between the aphantasia and control groups, we analysed three dependent variablesangular error, Pmem (retrieval success), and κ (retrieval precision)-separately for the meaningful and meaningless conditions. Within each group, Distributional normality was assessed using the Shapiro-Wilk test. For data that did not significantly deviate from normality, two-tailed independent-samples t-tests were used, and t, df, p, and Cohen's d were reported. For data violating the normality assumption, Mann-Whitney U (Wilcoxon rank-sum) tests were used. We reported the U statistic, p value, and the rank-biserial correlation (rrb) as an effect size measure.</p><p>In addition, for the meaningful condition we conducted linear mixed-effects modelling (LMM) to further assess group differences in angular error. LMMs were chosen because they account for both subject-and item-level variance, providing a more robust estimate of group effects than analyses based solely on aggregated scores. The meaningless condition was not subjected to LMM analysis, as the small number of items precluded reliable estimation. Angle data were analysed in R (version 4.4.3) using the lme4, lmerTest, car, and emmeans packages <ref type="bibr" target="#b3">(Bates et al., 2015;</ref><ref type="bibr" target="#b22">Kuznetsova et al., 2017)</ref>.The model included group (aphantasia vs. control) as a fixed effect, with random intercepts for subjects and random intercepts and slopes for items:</p><p>Post-hoc pairwise comparisons were conducted using the emmeans package with pvalues adjusted via the Bonferroni method. The syntax for the models is as follows:</p><p>Angle ~ group +(1|subject) + (1+group|item).</p><p>By contrast, Pmem (retrieval success) and κ (retrieval precision) were not analysed with LMMs, as these parameters are estimated at the participant level from computational mixture modelling and thus lack trial-level values. Instead, group differences for these measures were assessed using the statistical tests described above.</p><p>Finally, to explore which types of imagery are associated with different aspects of memory, we computed Pearson correlations between participants' questionnaire scores and each memory measure (angular error, Pmem, and κ). To control for multiple comparisons, p values were adjusted using the Benjamini-Hochberg false discovery rate (FDR) procedure (applied within each memory measure; two-tailed, α = .05).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group Differences in Visual Object Colour Memory Performance</head><p>Colour memory performance was evaluated separately in meaningful and meaningless conditions, with between-group comparisons (aphantasia vs. control) conducted for angular error, retrieval success, and retrieval precision (Figure <ref type="figure" target="#fig_4">2</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Angular</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group Differences Across Imagery-related Questionnaires</head><p>To comprehensively assess different facets of mental imagery, participants completed the VVIQ together with several additional validated questionnaires (Figure <ref type="figure" target="#fig_6">3</ref>). Relative to the control group, the aphantasia group scored significantly lower not only on the VVIQ but also on measures of object imagery (OSIVQ_object; aphantasia:  </p><formula xml:id="formula_0">M =</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Relationship Between Visual Colour Memory Performance and Various Visual Imagery Aspects</head><p>Correlations were computed between imagery questionnaire scores and memory performance (angular error, retrieval success, and retrieval precision) under both meaningful and meaningless conditions (Table <ref type="table" target="#tab_1">2</ref>; Figure <ref type="figure" target="#fig_8">4</ref>).</p><p>Angular Error. In the meaningful condition, poorer colour memory was associated with weaker general imagery vividness (VVIQ) and reduced representational manipulation ability (IRQ_manipulation) (all pFDR &lt; .01). In the meaningless condition, poorer colour memory was associated with multiple imagery dimensions, including vividness (VVIQ), reliance on object imagery (OSIVQ_object), representational manipulation (IRQ_manipulation), visual imagery tendencies (IRQ_visual), and spontaneous use of imagery in everyday life (SUIS) (all pFDR &lt; .005).</p><p>Retrieval Success and Retrieval Precision. Across both conditions, higher retrieval success was consistently associated with stronger imagery vividness (VVIQ), object imagery (OSIVQ_object), representational manipulation (IRQ_manipulation), visual imagery tendencies (IRQ_visual), and spontaneous use of imagery (SUIS) (all pFDR &lt; .05). Under meaningless conditions, additional associations emerged with orthographic imagery (IRQ_orthographic) and inner verbalization (IRQ_verbal), suggesting that some individuals may impose symbolic or language-like labels on otherwise non-semantic stimuli.</p><p>No imagery measures significantly correlated with retrieval precision (all pFDR &gt; .05) in either condition, indicating that imagery ability primarily influences the likelihood of successful retrieval rather than the fidelity of recalled representations.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2 Object Size Memory</head><p>Experiment 1 revealed that individuals with aphantasia exhibited impairments in object colour memory compared to controls. To determine whether these deficits are specific to colour processing, Experiment 2 examined object size memory under parallel task conditions. This design allows us to test whether aphantasia-related impairments are feature-specific or generalize across different object features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Participants</head><p>A total of 40 participants were recruited online for Experiment 2, including 20 individuals with congenital aphantasia and 20 visually unimpaired controls with typical imagery ability. Of these, 13 aphantasic participants and 7 controls also took part in Experiment 1. Two individuals with aphantasia were excluded from all analyses-one due to a history of brain injury and the other due to psychiatric disorders-resulting in a final sample of 38 participants (18 aphantasic, 20 controls). Aphantasia status was assessed using the same VVIQ criteria as in Experiment 1. The aphantasia group (M = 19.56, SD = 6.06, range: 16-32) and control group (M = 62.90, SD = 8.67, range: 48-80) again showed a highly significant difference in VVIQ scores (t(36) = -17.66, p &lt; 0.001, Cohen's d = -5.74). The two groups were comparable in demographic characteristics, with no differences in gender, age, or years of education (see Table <ref type="table">3</ref>).</p><p>Furthermore, comparisons between participants in Experiments 1 and 2 indicated no significant differences within either the aphantasia or control groups in gender Note. The procedure was identical to Experiment 1 except that participants memorized and reproduced object sizes using a continuous slider during recall instead of reporting colours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Analysis</head><p>As in Experiment 1, memory performance was evaluated using three dependent variables: size error, retrieval success (Pmem), and retrieval precision (κ).</p><p>Size Error. Response error was defined as the deviation between the reproduced and true size. For each trial, this deviation was converted to an absolute value. These trial-level values were averaged within each condition (meaningful, meaningless) to yield a mean error score per participant, which was submitted to group-level analyses.</p><p>Trial-level size errors were also analysed with linear mixed-effects models (LMMs), but only for the meaningful condition due to the small number of meaningless trials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval Success and Retrieval Precision. To parallel the analysis in</head><p>Experiment 1, we again estimated retrieval success and retrieval precision. However, because the response space in the current task was defined by a linear slider rather than a circular colour wheel, we fitted a two-component truncated normal mixture model instead of the von Mises-uniform mixture model. This model preserves the same logic as the circular case but is adapted to the linear, bounded nature of the size slider. For each participant and condition, two parameters were estimated using Maximum A Posteriori (MAP) estimation in MATLAB: (i) retrieval success (Pmem), the mixture weight parameter indexing the probability that the target size was successfully retrieved, and (ii) retrieval precision, defined as the inverse of the standard deviation of the truncated normal distribution, indexing the fidelity of size memory. To prevent boundary solutions with small sample sizes, we incorporated weakly informative priors: a Beta(2,2) prior on Pmem, which discourages estimates at 0 and 1, and a log-normal prior on σ, which avoids degenerate estimates approaching zero variance. Parameter estimation was performed using the fmincon routine (sequential quadratic programming algorithm) with multiple random restarts and appropriate parameter bounds, yielding stable posterior-mode estimates for both parameters.</p><p>Statistical Analysis. The data analysis for Experiment 2 followed the same procedure as in Experiment 1. We examined group differences in size memory performance (size error, retrieval success, retrieval precision) across meaningful and meaningless conditions, using parametric or non-parametric tests depending on the outcome of assumption checks. Trial-level size errors were also analysed with linear mixed-effects models (LMMs), applied only to the meaningful condition due to the small number of meaningless trials. Apart from replacing the dependent variable with size error, the model specification was identical to that used for angular error.</p><p>Correlations between questionnaire scores and memory measures were also computed. For all analyses, p values were corrected for multiple comparisons using the Benjamini-Hochberg FDR procedure (two-tailed, α = .05).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group Differences in Visual Size Memory Performance</head><p>Size memory performance was analysed separately for meaningful and meaningless conditions, with between-group comparisons (aphantasia vs. control) conducted for size error, retrieval success, and retrieval precision (Figure <ref type="figure" target="#fig_11">6</ref>).</p><p>Size Error. In the meaningful condition, no significant group differences were observed (aphantasia: M = 0.14, SD = 0.03; control: M = 0.13, SD = 0.03; t(36) = 1.40, pFDR = 0.17, Cohen's d = 0.46), and consistent with this, the LMM also revealed no significant main effect of group (χ²(1) = 1.96, p = 0.16). Similarly, in the meaningless condition, no significant group differences emerged (aphantasia: M = 0.17, SD = 0.03; control: M = 0.16, SD = 0.05; t(36) = 0.74, pFDR = 0.46, Cohen's d = 0.24). These results suggest that aphantasic individuals performed comparably to controls in reproducing object sizes.</p><p>Retrieval Success and Retrieval Precision. Consistent with the size error results, no significant group differences were found for retrieval success in either the Overall, the results of Experiment 2 indicate that, unlike colour memory, object size memory is preserved in aphantasia, with no evidence of impairments in either accuracy, retrieval success, or retrieval precision, suggesting that visual imagery is critical for colour representations but may play a less essential role for size.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Relationship Between Visual Size Memory Performance and Various Visual Imagery Aspects</head><p>Correlations between imagery questionnaire scores and memory performance (size error, retrieval success, and retrieval precision) were examined under both meaningful and meaningless conditions (Figure <ref type="figure" target="#fig_13">8</ref>).</p><p>Across all measures, no significant correlations emerged between imagery questionnaire scores and any of the three memory measures (all pFDR &gt; .05).</p><p>Specifically, neither size error, retrieval success, nor retrieval precision was reliably associated with participants' reported imagery vividness, preference for object versus spatial imagery, manipulation ability, or other imagery-related tendencies. These results further support the interpretation that imagery ability plays a critical role in colour memory but may be less essential for size memory. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Employing a paradigm with high memory load, isolated feature encoding, and finegrained continuous measures analysed with mixture modelling, the present study aimed to examine whether visual imagery impairments (e.g., in aphantasia) necessarily lead to deficits in visual memory. Three main findings emerged. First, individuals with aphantasia showed robust deficits in object colour memory across both meaningful (easy-to-name) and meaningless (difficult-to-name) conditions, whereas, object size memory remained largely intact. Second, these colour memory deficits were specific to retrieval success rather than retrieval precision, indicating difficulties in accessing stored representations rather than in the fidelity of retrieved traces. Finally, individual differences in various imagery dimensions correlated with colour memory performance. Together, these results demonstrate that visual imagery is critical for certain forms of visual memory and that compensatory strategies cannot fully substitute for imagery, at least for fine-grained memory information such as colour.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Purely Metacognitive Account May Be Incomplete</head><p>According to the meta-cognitive view of aphantasia that has recently gained traction, individuals with aphantasia may in fact generate visual images but fail to introspectively access or report them, leading to an underestimation of their imagery abilities <ref type="bibr" target="#b26">(Michel et al., 2025;</ref><ref type="bibr" target="#b31">Nanay, 2021)</ref>. Our findings are inconsistent with this account. If aphantasia merely reflected a metacognitive blind spot, memory performance should be preserved. Instead, participants with aphantasia showed clear behavioral impairments in colour memory, particularly in retrieval success, across both meaningful and meaningless conditions. These results converge with physiological evidence indicating that individuals with aphantasia show reduced visual priming <ref type="bibr" target="#b18">(Keogh &amp; Pearson, 2018</ref><ref type="bibr" target="#b27">, 2024)</ref>, attenuated skin conductance responses to imagined threats <ref type="bibr" target="#b55">(Wicken et al., 2021)</ref>, and diminished pupil dilation to imagined brightness <ref type="bibr" target="#b17">(Kay et al., 2022)</ref>. Collectively, converging behavioural and physiological data support the view that aphantasia involves a genuine disruption in the generation of visual imagery rather than a failure of self-awareness <ref type="bibr" target="#b9">(Chang et al., 2025;</ref><ref type="bibr" target="#b18">Keogh &amp; Pearson, 2018;</ref><ref type="bibr" target="#b41">Purkart et al., 2025;</ref><ref type="bibr" target="#b47">Scholz et al., 2025)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aphantasia Deficits Localised More in Retrieval Success Than in Precision</head><p>By decomposing memory performance, we found that colour memory impairments in individuals with aphantasia are localised to retrieval success, not precision. This dissociation extends prior reports of subtle or task-dependent deficits in aphantasia <ref type="bibr" target="#b30">(Monzel et al., 2022;</ref><ref type="bibr" target="#b40">Pounder et al., 2022)</ref> and indicates that the core difficulty lies in accessing or reinstating representations rather than in maintaining their fine-grained quality. Analyses of individual differences reinforce this interpretation: retrieval success, but not retrieval precision, was significantly correlated with imagery vividness, object imagery, representational manipulation, and spontaneous imagery use, particularly with broader associations emerging under meaningless conditions. The additional involvement of orthographic and verbal imagery under the meaningless condition suggests that, in the absence of semantic content, some individuals impose symbolic or linguistic codes to aid retrieval <ref type="bibr" target="#b20">(Keogh et al., 2021;</ref><ref type="bibr" target="#b42">Reeder et al., 2024)</ref>. By contrast, no imagery dimensions correlated with retrieval precision, underscoring that imagery determines whether information is accessible rather than the fidelity of its representation.</p><p>Our finding that colour memory deficits in aphantasia were driven by reduced retrieval success rather than precision aligns with evidence that these two components of episodic retrieval rely on distinct neural mechanisms <ref type="bibr" target="#b8">(Brady et al., 2013;</ref><ref type="bibr" target="#b44">Richter et al., 2016)</ref>. Retrieval success is linked to hippocampal activity and cue-driven reinstatement, whereas precision depends on neocortical regions such as the angular gyrus, reflecting the fidelity of stored representations and attentional modulation experience <ref type="bibr" target="#b4">(Bays et al., 2009;</ref><ref type="bibr" target="#b21">Korkki et al., 2020)</ref>. Imagery may facilitate retrieval by providing reinstatement signals that engage hippocampal mechanisms, increasing the likelihood of accessing stored traces. In contrast, precision is thought to rely on the integrity of perceptual encoding and the stability of neocortical representations, which are relatively preserved in individuals with aphantasia given their intact perceptual <ref type="bibr" target="#b17">(Kay et al., 2022;</ref><ref type="bibr" target="#b55">Wicken et al., 2021)</ref>. However, direct evidence for these mechanisms is limited, future work combining fine-grained behavioural modelling with neural measures will be essential to test these proposed mechanisms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Differential Effects of Aphantasia on Colour and Size Memory</head><p>The contrasting findings across our two experiments suggest that memory impairments in aphantasia are feature-specific rather than domain-general. Two possible explanations for this phenomenon are as follows.</p><p>One plausible explanation lies in the nature of the features themselves. Colour is a purely perceptual attribute with limited semantic or motor associations, making it particularly vulnerable when visual imagery is absent. By contrast, size can be encoded and retrieved through multiple alternative routes, including spatial reasoning (e.g., relative comparisons such as 'it occupied about half of the screen'), verbal strategies, and tactile-motor experience. These compensatory pathways may allow individuals with aphantasia to achieve performance comparable to controls in size memory tasks <ref type="bibr" target="#b27">(Milton, 2024)</ref>. Furthermore, prior work suggests that spatial imagery remains relatively preserved in aphantasia <ref type="bibr" target="#b2">(Bainbridge et al., 2021;</ref><ref type="bibr" target="#b7">Blazhenkova &amp; Pechenkova, 2019)</ref>, implying that size memory might benefit from intact spatial mechanisms even when object imagery is compromised.</p><p>An additional consideration is task difficulty. In the size experiment, 120 stimuli were distributed across only 20 size levels, whereas in the colour experiment, each of the 120 stimuli was uniquely paired with a different colour. This mismatch in difficulty could partly contribute to the divergent findings. However, this factor is unlikely to be decisive: even in the more challenging meaningless condition of the size task, no group differences were observed, whereas in the colour task, significant deficits emerged for the aphantasia group even under the relatively easier meaningful condition. Nevertheless, future research should refine the experimental design to better match task demands across features and shed light on the cognitive and neural mechanisms underlying preserved versus impaired memory performance in aphantasia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In sum, our findings highlight that visual imagery is indispensable for retrieval success but not for precision when accessing object colour representations, suggesting that imagery contributes selectively to the accessibility, rather than the fidelity, of certain visual memory traces. Moreover, this indispensability may not extend to all object features, indicating that imagery's contribution to memory is featuredependent rather than domain-general.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>SUIS assessed the degree to which one spontaneously uses of mental imagery in a particular situation. It consists of 12 items (e.g. If I am looking for new furniture in a store, I always visualize what the furniture would look like in particular places in my home). Participants rated the appropriateness of spontaneous mental imagery use from 1 (never) to 5 (completely appropriate), with total scores ranging from 12-60. Together, we employed multiple standardized measures to assess distinct dimensions of imagery. The OSIVQ provided indices of object (OSIVQ_object) and spatial (OSIVQ_spatial) imagery; the IRQ assessed orthographic imagery (IRQ_orthographic) and visual imagery tendencies (IRQ_visual); and the SUIS measured the frequency of spontaneous image use. Additionally, we included verbal processing measures (OSIVQ_verbal, IRQ_verbal) and a representational manipulation assessment (IRQ_manipulation) to examine potential non-visual cognitive contributions. This multidimensional approach enables a fine-grained examination of how imagery subcomponents relate to visual memory, while accounting for potential contributions from verbal and other non-visual processes.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>2.3    (Peirce, 2007). All participants completed this experiment remotely via Tencent Meeting, a secure videoconferencing platform.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Experimental Stimuli and Procedure for the Colour-Memory Task</figDesc><graphic coords="15,107.64,508.56,380.04,212.64" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Error. In the meaningful condition, aphantasic individuals exhibited significantly greater angular errors than controls (aphantasia: M = 59.74, SD = 12.74; control: M = 46.95, SD = 14.30; t(38) = 2.99, p = 0.005, Cohen's d = 0.94). Consistent with these results, LMMs conducted for the meaningful condition also revealed a significant main effect of group (χ²(1) = 8.76, p = 0.003), with post-hoc tests indicating larger errors in the aphantasia group compared to controls (β = 12.80, SE = 4.32, Z = 2.96, p = 0.003). In the meaningless condition, aphantasic individuals likewise showed greater angular errors than controls (aphantasia: M = 72.97, SD = 14.65; control: M = 54.40, SD = 18.03; t(38) = 3.57, p &lt; 0.001, Cohen's d = 1.13). Together, these results suggest impaired memory for object colour in aphantasia.Retrieval Success and Retrieval Precision. Retrieval success was significantly reduced in the aphantasia group compared to controls in both the meaningful condition (aphantasia: M = 0.41, SD = 0.17; control: M = 0.62, SD = 0.16; t(38) = -3.84, p &lt; 0.001, Cohen's d = -1.22) and the meaningless condition (aphantasia: M = 0.32, SD = 0.16; control: M = 0.59, SD = 0.24; Mann-Whitney U = 327, p &lt; 0.001, rrb = -0.64).In contrast, no group differences were observed for retrieval precision in either the meaningful (aphantasia: M = 8.98, SD = 6.19; control: M = 8.12, SD = 4.82; Mann-Whitney U = 202, p = 0.97, rrb = -0.01) or meaningless condition(aphantasia: M = 8.23, SD = 6.66; control: M = 5.86, SD = 4.56; Mann-Whitney U = 237, p = 0.32, rrb = -0.19), indicating a potential dissociation whereby aphantasia impairs the likelihood of successful memory retrieval but spares the precision of spatial details once retrieval occurs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2</head><label>2</label><figDesc>Figure 2 Colour Memory Performance in Aphantasia and Control Groups Note. Violin plots show group differences between individuals with aphantasia (blue) and controls (purple) on three measures of colour memory performance: angular error, retrieval success, and retrieval precision. Results are presented separately for the meaningful condition (top row) and the meaningless condition (bottom row). Lower angular error and higher retrieval success and precision indicate better colour memory performance. Statistical significance is indicated as follows: *p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001, ns = not significant.</figDesc><graphic coords="20,73.20,266.40,446.40,356.88" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>24, SD = 5.25; control: M = 53.40, SD = 7.17; t(38) = -14.79, pFDR &lt; 0.001, Cohen's d = -4.68), visual imagery tendencies (IRQ_visual; aphantasia: M = 16.90, SD = 5.13; control: M = 37.05, SD = 5.20; Mann-Whitney U = 397, pFDR &lt; 0.001, rrb = -0.99), orthographic imagery (IRQ_orthographic; aphantasia: M = 10.85, SD = 3.90; control: M = 18.25, SD = 3.80; t(38) = -6.08, pFDR &lt; 0.001, Cohen's d = -1.92), and spontaneous use of imagery (SUIS; aphantasia: M = 23.60, SD = 7.34; control: M = 43.85, SD = 6.18; t(38) = -9.44, pFDR &lt; 0.001, Cohen's d = -2.98). In contrast, no group difference was observed for spatial imagery (OSVIQ_spatial; aphantasia: M = 46.85, SD = 7.16; control: M = 44.20, SD = 8.46; Mann-Whitney U = 155, pFDR = 0.23, rrb = 0.23). Together, these findings suggest that individuals with aphantasia show broad difficulties across multiple imagery-related domains (e.g., object, orthographic, and spontaneous use of imagery), while their spatial imagery abilities remain intact. Additionally, some aspects of these questionnaires also assessed verbal processing (OSIVQ_verbal; IRQ_verbal) and representational manipulation (IRQ_manipulation). OSIVQ_verbal focuses on verbal abilities such as using language to reason, describe, and remember. Interestingly, individuals with aphantasia scored significantly higher on this dimension than controls (aphantasia: M = 53.80, SD = 9.89; control: M = 47.35, SD = 7.91; t(38) = 2.28, pFDR = 0.04, Cohen's d = 0.72). By contrast, IRQ_verbal, which captures how often and how vividly people experience inner speech, showed the opposite pattern, with the aphantasia group scoring lower than controls (aphantasia: M = 35.7, SD = 13.73; control: M = 44.50, SD = 8.77; t(38) = -2.42, pFDR = 0.02, Cohen's d = -0.76). These findings indicate a dissociation between verbal cognitive style and the phenomenology of inner speech, suggesting that greater reliance on verbal strategies does not necessarily entail more frequent or vivid inner speech. Finally, in representational manipulation (IRQ_manipulation), aphantasic individuals scored lower than controls (aphantasia: M = 21.15, SD = 7.11; control: M = 29.05, SD = 4.07; t(38) = -4.31, pFDR &lt; 0.001, Cohen's d =-1.36), indicating a reduced capacity to dynamically transform internal representations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3</head><label>3</label><figDesc>Figure 3 Group Comparisons on Imagery-related Questionnaires Note. Violin plots show score distributions for the aphantasia (blue) and control (purple) groups across nine measures: VVIQ (visual imagery vividness), OSIVQ_object (object imagery), OSIVQ_spatial (spatial imagery), OSIVQ_verbal (verbal strategy use), IRQ_manipulation (representational manipulation), IRQ_orthographic (orthographic imagery), IRQ_visual (visual imagery tendencies), IRQ_verbal (inner speech), and SUIS (spontaneous use of imagery). Asterisks indicate significance after FDR correction (*pFDR &lt; .05, **pFDR &lt; .01, ***pFDR &lt; .001).</figDesc><graphic coords="22,115.92,292.56,362.52,326.16" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Table2shows correlations between imagery questionnaire scores and memory performance (angular error, retrieval success, retrieval precision) in the meaningful (MF) and meaningless (ML) conditions. The meanings of the imagery-related measures are the same as in Figure3. Asterisks indicate significance after FDR correction (*pFDR &lt; .05, **pFDR &lt; .01, ***pFDR &lt; .001) and n.s. denotes non-significant correlations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4</head><label>4</label><figDesc>Figure 4 Correlations Between Imagery Measures and Colour Memory Performance Note. Panels show correlations between imagery measures and size memory performance for the meaningful condition (top) and the meaningless condition (bottom). Angular error is shown in pink, retrieval success in yellow, and retrieval precision in green. The meanings of the imagery-related measures are the same as in Figure 3. Asterisks indicate significance after FDR correction (*pFDR &lt; .05, **pFDR &lt; .01, ***pFDR &lt; .001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>(Figure 5</head><label>5</label><figDesc>Figure 5 Experimental Procedure for the Size Memory Task</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>meaningful condition (aphantasia: M = 0.93, SD = 0.05; control: M = 0.94, SD = 0.03; Mann-Whitney U = 205, pFDR = 0.48, rrb = -0.14) or the meaningless condition (aphantasia: M = 0.91, SD = 0.05; control: M = 0.93, SD = 0.05; Mann-Whitney U = 210, pFDR = 0.39, rrb = -0.17). Likewise, retrieval precision did not differ significantly between groups in the meaningful (aphantasia: M = 11.17, SD = 3.03; control: M = 11.88, SD = 3.08; t(36) = -0.72, pFDR = 0.48, Cohen's d = -0.23) or meaningless condition (aphantasia: M = 9.12, SD = 1.76; control: M = 10.12, SD = 3.53; t(36) = -1.09, pFDR = 0.29, Cohen's d = -0.35).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 6</head><label>6</label><figDesc>Figure 6 Size Memory Performance in Aphantasia and Control Groups Note. Violin plots show group differences between individuals with aphantasia (blue) and controls (purple) on three measures of size memory performance: size error, retrieval success, and retrieval precision. Results are presented separately for the meaningful condition (top row) and the meaningless condition (bottom row). Lower size error and higher retrieval success and precision indicate better memory performance. Statistical significance is indicated as follows: *p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001, ns = not significant.</figDesc><graphic coords="32,77.76,73.20,439.68,355.80" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7</head><label>7</label><figDesc>Figure 7 Group Comparisons on Imagery-Related Questionnaires Note. Violin plots show score distributions for the aphantasia (blue) and control (purple) groups across nine imagery-related measures: VVIQ (visual imagery vividness), OSIVQ_object (object imagery), OSIVQ_spatial (spatial imagery), OSIVQ_verbal (verbal strategy use), IRQ_manipulation (representational manipulation), IRQ_orthographic (orthographic imagery), IRQ_visual (visual imagery tendencies), IRQ_verbal (inner speech), and SUIS (spontaneous use of imagery). Asterisks indicate significance after FDR correction (*pFDR &lt; .05, **pFDR &lt; .01, ***pFDR &lt; .001).</figDesc><graphic coords="34,123.36,71.76,348.48,313.20" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 8</head><label>8</label><figDesc>Figure 8 Correlations Between Imagery Measures and Size Memory Performance Note. Panels show correlations between imagery measures and size memory performance for the meaningful condition (top) and the meaningless condition (bottom). Size error is shown in pink, retrieval success in yellow, and retrieval precision in green. The meanings of the imagery-related measures are the same as in Figure 7. Asterisks indicate significance after FDR correction (*pFDR &lt; .05, **pFDR &lt; .01, ***pFDR &lt; .001).</figDesc><graphic coords="35,83.76,436.92,427.68,188.28" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="28,94.80,551.04,405.60,198.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Demographic Characteristics of Participants in Experiment 1</figDesc><table><row><cell>Demographics</cell><cell>Aphantasia (n = 20)</cell><cell>Control (n = 20)</cell><cell>Statistical test</cell></row><row><cell>Gender (Male/Female)</cell><cell>9 / 11</cell><cell>10 / 10</cell><cell>χ²(1, 40) = 0.10, p = 0.75, φ = 0.05</cell></row><row><cell>Age (years)</cell><cell>M = 24.80, SD = 4.60</cell><cell>M = 22.95, SD = 2.16</cell><cell>t(38) = 1.63, p = 0.11, d = 0.52</cell></row><row><cell>Education (years)</cell><cell>M = 16.05, SD = 2.31</cell><cell>M = 16.25, SD = 1.55</cell><cell>t(38) = -0.32, p = .75, d = -0.10</cell></row><row><cell cols="3">Note. M = mean; SD = standard deviation</cell><cell></cell></row><row><cell cols="4">Participants who took part in the stimulus evaluation task were also primarily</cell></row><row><cell cols="4">recruited online (25 males, 19 females; age: M = 26.27, SD = 3.35). All participants</cell></row><row><cell cols="4">reported normal or corrected-to-normal vision and no history of psychiatric disorders.</cell></row><row><cell cols="4">The study was approved by the Institutional Review Board of the National Key</cell></row><row><cell cols="4">Laboratory of Cognitive Neuroscience and Learning at Beijing Normal University.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Correlations Between Imagery Questionnaire Scores and Memory Performance</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="funder">Major Project of National Social Science Foundation</rs> (<rs type="grantNumber">24&amp;ZD252</rs>) and <rs type="funder">National Natural Science Foundation of China</rs> (<rs type="grantNumber">32271091</rs> and <rs type="grantNumber">82372555</rs>). We thank all the research participants for their patience and time. We would also like to express our sincere appreciation to <rs type="person">Professor Yanchao Bi</rs> and her lab members for their generous provision of the Chinese-translated version of the measurement questionnaire employed in this study.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_BDuhZeQ">
					<idno type="grant-number">24&amp;ZD252</idno>
				</org>
				<org type="funding" xml:id="_V8zruDf">
					<idno type="grant-number">32271091</idno>
				</org>
				<org type="funding" xml:id="_6X24Grx">
					<idno type="grant-number">82372555</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and codes accessibility statement</head><p>The data and code supporting the findings of this study are available from the corresponding author (zzhhan@bnu.edu.cn) upon reasonable request. We welcome data requests for further analysis or related research. The dataset will also be made publicly available soon.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Whitney U = 190.50, p = 0.71; control: Mann-Whitney U = 221, p = 0.57), or VVIQ scores (aphantasia: Mann-Whitney U = 157, p = 0.48; control: t(38) = -0.93, p = 0.36, Cohen's d = -0.29). Together, these results confirm that the two experimental samples were demographically and cognitively comparable, ensuring overall group homogeneity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimuli</head><p>Stimuli were identical to those used in the colour-memory task (120 images: 90 meaningful, 30 meaningless; six sets of 20 images per participant), except that all images were presented in white. To manipulate size, images were uniformly scaled while maintaining a 1:1 aspect ratio. Object size was defined as the image height relative to the window height, and varied across 20 levels (10%-105% of window height, in 5% increments). Importantly, even when scaled to 105%, objects did not extend beyond the window boundaries, as they were centrally positioned within the images and surrounded by sufficient margins. For each participant, the 20 images within each set were randomly assigned to the 20 size levels, ensuring a unique sizeimage mapping. All stimuli were centrally presented against a uniform grey background (RGB: <ref type="bibr">[128,</ref><ref type="bibr">128,</ref><ref type="bibr">128]</ref>) using PsychoPy (version 2021.2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design and Procedure</head><p>The procedure closely paralleled that of Experiment 1, except that participants memorized and reproduced object sizes rather than colours (Figure <ref type="figure">5</ref>).</p><p>During the encoding phase, each trial began with a 750 ms fixation cross, followed by a white shape presented for 6 seconds, during which participants memorized its size. Stimuli were presented in a pseudorandomized order, with one meaningless image following every three meaningful images as in Experiment 1. After all 20 items had been displayed, a 10-second retention interval was introduced.</p><p>In the recall phase, participants were asked to reproduce the previously studied size of each image as accurately as possible. Each trial started with a 1000-ms fixation cross, followed by presentation of a shape at a fixed size of 60% at screen centre, accompanied by a horizontal slider below. The slider allowed continuous adjustment of size over a wider range than the encoded values (5%-115%, step size = 0.1%). As participants moved the slider, the shape scaled dynamically in real time. Responses were confirmed with a spacebar press. The recall phase was self-paced, with no feedback or time limits, and the order of stimuli was fully randomised relative to encoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of competing interest</head><p>The authors declare no competing financial interests. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Credit authorship contribution statement</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The episodic buffer: a new component of working memory?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baddeley</surname></persName>
		</author>
		<idno type="DOI">10.1016/S1364-6613(00</idno>
		<ptr target="https://doi.org/10.1016/S1364-6613(00" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1538" to="1540" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Working memory: theories, models, and controversies</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baddeley</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-120710-100422</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-120710-100422" />
	</analytic>
	<monogr>
		<title level="j">Annu Rev Psychol</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Quantifying aphantasia through drawing: Those without visual imagery show deficits in object but not spatial memory</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Bainbridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pounder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Eardley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Baker</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2020.11.014</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2020.11.014" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="159" to="172" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fitting Linear Mixed-Effects Models Usinglme4</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mächler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v067.i01</idno>
		<ptr target="https://doi.org/10.18637/jss.v067.i01" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The precision of visual working memory is set by allocation of a shared resource</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Catalao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Husain</surname></persName>
		</author>
		<idno type="DOI">10.1167/9.10.7</idno>
		<ptr target="https://doi.org/10.1167/9.10.7" />
	</analytic>
	<monogr>
		<title level="j">J Vis</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="7" to="7" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Assessing aphantasia prevalence and the relation of self-reported imagery abilities and memory task performance</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Beran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Haseltine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Kleider-Offutt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.concog.2023.103548</idno>
		<ptr target="https://doi.org/10.1016/j.concog.2023.103548" />
	</analytic>
	<monogr>
		<title level="j">Conscious Cogn</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page">103548</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The new object-spatial-verbal cognitive style model: Theory and measurement</title>
		<author>
			<persName><forename type="first">O</forename><surname>Blazhenkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kozhevnikov</surname></persName>
		</author>
		<idno type="DOI">10.1002/acp.1473</idno>
		<ptr target="https://doi.org/10.1002/acp.1473" />
	</analytic>
	<monogr>
		<title level="j">Applied Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="638" to="663" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Two Eyes of the Blind Mind: Object vs. Spatial Aphantasia?</title>
		<author>
			<persName><forename type="first">O</forename><surname>Blazhenkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pechenkova</surname></persName>
		</author>
		<idno type="DOI">10.47010/19.4.5</idno>
		<ptr target="https://doi.org/10.47010/19.4.5" />
	</analytic>
	<monogr>
		<title level="j">The Russian Journal of Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Visual long-term memory has the same limit on fidelity as visual working memory</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Konkle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797612465439</idno>
		<ptr target="https://doi.org/10.1177/0956797612465439" />
	</analytic>
	<monogr>
		<title level="j">Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="981" to="990" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imageless imagery in aphantasia revealed by early visual cortex decoding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meng</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2024.12.012</idno>
		<ptr target="https://doi.org/10.1016/j.cub.2024.12.012" />
	</analytic>
	<monogr>
		<title level="j">Curr Biol</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="591" to="599" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Impact of imagery deficit on word-based object colour retrieval: Evidence from congenital aphantasia</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1080/02643294.2025.2536855</idno>
		<ptr target="https://doi.org/10.1080/02643294.2025.2536855" />
	</analytic>
	<monogr>
		<title level="j">Cogn Neuropsychol</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The prevalence of aphantasia (imagery weakness) in the general population</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ipser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Simner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.concog.2021.103243</idno>
		<ptr target="https://doi.org/10.1016/j.concog.2021.103243" />
	</analytic>
	<monogr>
		<title level="j">Conscious Cogn</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page">103243</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A cognitive profile of multisensory imagery, memory and dreaming in aphantasia</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Dawes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Andrillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-020-65705-7</idno>
		<ptr target="https://doi.org/10.1038/s41598-020-65705-7" />
	</analytic>
	<monogr>
		<title level="j">Sci Rep</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">10022</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Memories with a blind mind: Remembering the past and imagining the future with aphantasia</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Dawes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Robuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2022.105192</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2022.105192" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">227</biblScope>
			<biblScope unit="page">105192</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Memory and creativity: A meta-analytic examination of the relationship between memory systems and creative cognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Gerver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Beaty</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-023-02303-4</idno>
		<ptr target="https://doi.org/10.3758/s13423-023-02303-4" />
	</analytic>
	<monogr>
		<title level="j">Psychon Bull Rev</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2116" to="2154" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Visual working memory performance in aphantasia</title>
		<author>
			<persName><forename type="first">C</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Schwarzkopf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Silvanto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<idno type="DOI">10.1016/j.cortex.2017.10.014</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2017.10.014" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="61" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The pupillary light response as a physiological index of aphantasia, sensory and phenomenological imagery strength</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Andrillon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.72484</idno>
		<ptr target="https://doi.org/10.7554/eLife.72484" />
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The blind mind: No sensory visual imagery in aphantasia</title>
		<author>
			<persName><forename type="first">R</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2017.10.012</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2017.10.012" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="53" to="60" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Revisiting the blind mind: Still no evidence for sensory visual imagery in individuals with aphantasia</title>
		<author>
			<persName><forename type="first">R</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neures.2024.01.008</idno>
		<ptr target="https://doi.org/10.1016/j.neures.2024.01.008" />
	</analytic>
	<monogr>
		<title level="j">Neurosci Res</title>
		<imprint>
			<biblScope unit="volume">201</biblScope>
			<biblScope unit="page" from="27" to="30" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visual working memory in aphantasia: Retained accuracy and capacity with a different strategy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wicken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2021.07.012</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2021.07.012" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="237" to="253" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Healthy ageing reduces the precision of episodic memory retrieval</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Korkki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jeyarathnarajah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Simons</surname></persName>
		</author>
		<idno type="DOI">10.1037/pag0000432</idno>
		<ptr target="https://doi.org/10.1037/pag0000432" />
	</analytic>
	<monogr>
		<title level="j">Psychol Aging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="124" to="142" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">lmerTest Package: Tests in Linear Mixed Effects Models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H B</forename><surname>Christensen</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v082.i13</idno>
		<ptr target="https://doi.org/10.18637/jss.v082.i13" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page">82</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Probing the unimaginable: The impact of aphantasia on distinct domains of visual mental imagery and visual perception</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bartolomeo</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2023.06.003</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2023.06.003" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page" from="338" to="347" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Aphantasia as a functional disconnection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bartolomeo</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2025.05.012</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2025.05.012" />
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visual imagery differences in the recall of pictures</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Marks</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2044-8295.1973.tb01322.x</idno>
		<ptr target="https://doi.org/10.1111/j.2044-8295.1973.tb01322.x" />
	</analytic>
	<monogr>
		<title level="j">Br J Psychol</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="24" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Aphantasia as imagery blindsight</title>
		<author>
			<persName><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Block</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lau</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2024.11.002</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2024.11.002" />
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8" to="9" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mental imagery: The role of primary visual cortex in aphantasia</title>
		<author>
			<persName><forename type="first">F</forename><surname>Milton</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2024.09.076</idno>
		<ptr target="https://doi.org/10.1016/j.cub.2024.09.076" />
	</analytic>
	<monogr>
		<title level="j">Curr Biol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="1088" to="R1090" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Monzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Leelaarporn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lutz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brunheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mccormick</surname></persName>
		</author>
		<title level="m">Hippocampal-occipital connectivity reflects autobiographical memory deficits in aphantasia</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName><surname>Elife</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.94916</idno>
		<ptr target="https://doi.org/10.7554/eLife.94916" />
		<imprint>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Memory deficits in aphantasics are not restricted to autobiographical memory -Perspectives from the Dual Coding Approach</title>
		<author>
			<persName><forename type="first">M</forename><surname>Monzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vetterlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reuter</surname></persName>
		</author>
		<idno type="DOI">10.1111/jnp.12265</idno>
		<ptr target="https://doi.org/10.1111/jnp.12265" />
	</analytic>
	<monogr>
		<title level="j">J Neuropsychol</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="444" to="461" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Unconscious mental imagery</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nanay</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2019.0689</idno>
		<ptr target="https://doi.org/10.1098/rstb.2019.0689" />
	</analytic>
	<monogr>
		<title level="j">Philos Trans R Soc Lond B Biol Sci</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<date type="published" when="1817">2021. 1817. 20190689</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Varieties of aphantasia</title>
		<author>
			<persName><forename type="first">B</forename><surname>Nanay</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2025.06.008</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2025.06.008" />
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Mental Representations: A dual coding approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paivio</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780195066661.001.0001</idno>
		<ptr target="https://doi.org/10.1093/acprof:oso/9780195066661.001.0001" />
		<imprint>
			<date type="published" when="1990">1990</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Dual coding theory: Retrospect and current status</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paivio</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0084295</idno>
		<ptr target="https://doi.org/10.1037/h0084295" />
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Psychology / Revue canadienne de psychologie</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="255" to="287" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Mind and Its Evolution: A Dual Coding Theoretical Approach (1st ed.)</title>
		<author>
			<persName><forename type="first">A</forename><surname>Paivio</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315785233</idno>
		<ptr target="https://doi.org/https://doi.org/10.4324/9781315785233" />
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Psychology Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Congenital lack and extraordinary ability in object and spatial imagery: An investigation on sub-types of aphantasia and hyperphantasia</title>
		<author>
			<persName><forename type="first">L</forename><surname>Palermo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Boccia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Piccardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nori</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.concog.2022.103360</idno>
		<ptr target="https://doi.org/10.1016/j.concog.2022.103360" />
	</analytic>
	<monogr>
		<title level="j">Conscious Cogn</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page">103360</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Aphantasia does not affect veridical and false memory: Evidence from the DRM paradigm</title>
		<author>
			<persName><forename type="first">K</forename><surname>Pauly-Takacs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Younus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sigala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pfeifer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.concog.2025.103888</idno>
		<ptr target="https://doi.org/10.1016/j.concog.2025.103888" />
	</analytic>
	<monogr>
		<title level="j">Conscious Cogn</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page">103888</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The human imagination: the cognitive neuroscience of visual mental imagery</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41583-019-0202-9</idno>
		<ptr target="https://doi.org/10.1038/s41583-019-0202-9" />
	</analytic>
	<monogr>
		<title level="j">Nat Rev Neurosci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="624" to="634" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Spared spatial imagery solves the puzzle of aphantasia</title>
		<author>
			<persName><forename type="first">I</forename><surname>Phillips</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2025.05.004</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2025.05.004" />
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Only minimal differences between individuals with congenital aphantasia and those with typical imagery on neuropsychological tasks that involve imagery</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Pounder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Loveday</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Eardley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Silvanto</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2021.12.010</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2021.12.010" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="180" to="192" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Are there unconscious visual images in aphantasia? Development of an implicit priming paradigm</title>
		<author>
			<persName><forename type="first">R</forename><surname>Purkart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Delem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ranson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Andrey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Versace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Cavalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Plancher</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2024.106059</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2024.106059" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">256</biblScope>
			<biblScope unit="page">106059</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Non-visual spatial strategies are effective for maintaining precise information in visual working memory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Reeder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pounder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Figueroa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jullig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Azanon</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2024.105907</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2024.105907" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="page" from="251" to="105907" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Intuitions and introspections about imagery: the role of imagery experience in shaping an investigator&apos;s theoretical views</title>
		<author>
			<persName><forename type="first">D</forename><surname>Reisberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kosslyn</surname></persName>
		</author>
		<idno type="DOI">10.1002/acp.858</idno>
		<ptr target="https://doi.org/10.1002/acp.858" />
	</analytic>
	<monogr>
		<title level="j">Applied Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="160" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Distinct neural mechanisms underlie the success, precision, and vividness of episodic memory</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">R</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bays</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Simons</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.18260</idno>
		<ptr target="https://doi.org/10.7554/eLife.18260" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Elife</publisher>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The Internal Representations Questionnaire: Measuring modes of thinking</title>
		<author>
			<persName><forename type="first">H</forename><surname>Roebuck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lupyan</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-020-01354-y</idno>
		<ptr target="https://doi.org/10.3758/s13428-020-01354-y" />
	</analytic>
	<monogr>
		<title level="j">Behav Res Methods</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2053" to="2070" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The Mind&apos;s Eye is Not a Metaphor: Visuospatial Working Memory and Mental Imageries for Learning and Language Comprehension</title>
		<author>
			<persName><forename type="first">A</forename><surname>Savarimuthu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Ponniah</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12646-024-00789-z</idno>
		<ptr target="https://doi.org/10.1007/s12646-024-00789-z" />
	</analytic>
	<monogr>
		<title level="j">Psychological Studies</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="158" to="168" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Absence of shared representation in the visual cortex challenges unconscious imagery in aphantasia</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">O</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Monzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2025.05.009</idno>
		<ptr target="https://doi.org/10.1016/j.cub.2025.05.009" />
	</analytic>
	<monogr>
		<title level="j">Curr Biol</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="645" to="R646" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Visual memory, the long and the short of it: A review of visual working memory and long-term memory</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Schurgin</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-018-1522-y</idno>
		<ptr target="https://doi.org/10.3758/s13414-018-1522-y" />
	</analytic>
	<monogr>
		<title level="j">Atten Percept Psychophys</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1035" to="1056" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Metacognitive Awareness and the Subjective Experience of Remembering in Aphantasia</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Siena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Simons</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_02120</idno>
		<ptr target="https://doi.org/10.1162/jocn_a_02120" />
	</analytic>
	<monogr>
		<title level="j">J Cogn Neurosci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1578" to="1598" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Color gamut transform pairs</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1145/965139.807361</idno>
		<ptr target="https://doi.org/10.1145/965139.807361" />
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Comput. Graph</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="19" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The interplay of language and visual perception in working memory</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Skora</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2017.05.038</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2017.05.038" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page" from="277" to="297" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Visual mental imagery: Evidence for a heterarchical neural architecture</title>
		<author>
			<persName><forename type="first">A</forename><surname>Spagna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Heidenry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Miselevich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Eisenstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tremblay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bartolomeo</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.plrev.2023.12.012</idno>
		<ptr target="https://doi.org/10.1016/j.plrev.2023.12.012" />
	</analytic>
	<monogr>
		<title level="j">Phys Life Rev</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="113" to="131" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Modeling visual working memory with the MemToolbox</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Suchow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fougnie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Alvarez</surname></persName>
		</author>
		<idno type="DOI">10.1167/13.10.9</idno>
		<ptr target="https://doi.org/10.1167/13.10.9" />
	</analytic>
	<monogr>
		<title level="j">J Vis</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Working memory signals in early visual cortex are present in weak and strong imagers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Christophel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gorgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Soch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Haynes</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.26590</idno>
		<ptr target="https://doi.org/10.1002/hbm.26590" />
	</analytic>
	<monogr>
		<title level="j">Hum Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">26590</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The critical role of mental imagery in human emotion: insights from fear-based imagery and aphantasia</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wicken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearson</surname></persName>
		</author>
		<idno type="DOI">10.1098/rspb.2021.0267</idno>
		<ptr target="https://doi.org/10.1098/rspb.2021.0267" />
	</analytic>
	<monogr>
		<title level="j">Proc Biol Sci</title>
		<imprint>
			<biblScope unit="volume">288</biblScope>
			<biblScope unit="page">20210267</biblScope>
			<date type="published" when="1946">2021. 1946</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Lives without imagery -Congenital aphantasia</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dewar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Della Sala</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2015.05.019</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2015.05.019" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="378" to="380" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Discrete fixed-resolution representations in visual working memory</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Luck</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature06860</idno>
		<ptr target="https://doi.org/10.1038/nature06860" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">453</biblScope>
			<biblScope unit="issue">7192</biblScope>
			<biblScope unit="page" from="233" to="235" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
