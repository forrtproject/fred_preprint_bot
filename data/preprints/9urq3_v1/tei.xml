<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TIMING AND FREQUENCY OF INSTRUCTION 1 THE TIMING AND FREQUENCY OF INSTRUCTION TO FOSTER NEW LEARNING: COMPARING COGNITIVE AND MOTIVATIONAL STRATEGIES IN CATEGORY LEARNING</title>
				<funder ref="#_4TtCAtz">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_U3nyreU">
					<orgName type="full">Japan Society</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Kyosuke</forename><surname>Kakinuma</surname></persName>
							<email>kkakinuma10@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">School of Economics &amp; Management</orgName>
								<orgName type="institution">Kochi University of Technology</orgName>
								<address>
									<postCode>780-8515</postCode>
									<settlement>Kochi</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Japan Society for the Promotion of Science</orgName>
								<address>
									<postCode>102-0083</postCode>
									<settlement>Tokyo</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Keise</forename><surname>Izuma</surname></persName>
							<email>izuma.keise@kochi-tech.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">School of Economics &amp; Management</orgName>
								<orgName type="institution">Kochi University of Technology</orgName>
								<address>
									<postCode>780-8515</postCode>
									<settlement>Kochi</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Research Center for Mind, Brain, and Behavior</orgName>
								<orgName type="institution">Kochi University of Technology</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Southampton</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">School of Economics &amp; Management</orgName>
								<orgName type="institution">Kochi University of Technology</orgName>
								<address>
									<addrLine>2-22 Eikokuji-cho, Kochi-shi</addrLine>
									<postCode>780-8515</postCode>
									<settlement>Izuma, Kochi</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">TIMING AND FREQUENCY OF INSTRUCTION 1 THE TIMING AND FREQUENCY OF INSTRUCTION TO FOSTER NEW LEARNING: COMPARING COGNITIVE AND MOTIVATIONAL STRATEGIES IN CATEGORY LEARNING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F46237D4E1A6753918EE94D43BDDCF91</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-21T13:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>category learning</term>
					<term>feature highlighting</term>
					<term>forward effect of testing</term>
					<term>new learning</term>
					<term>testpotentiated learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Portions of this work (Experiment 1) have been presented at the 45th Annual Meeting of the Cognitive Science Society (Kakinuma &amp; Izuma, 2023). Specifically, The method and results sections of Experiment 1 was partly based on this preliminary report.</p><p>The authors used a generative AI tool (ChatGPT, OpenAI) to assist in drafting some English sentences, and in phrasing and polishing the language. The authors take full responsibility for the content, including its accuracy and integrity.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Instruction from an experienced person to a novice learner is one of the foundations of human society. In an effective instructional environment, learners develop the capacity to explore solutions independently-even in novel situations. For example, imagine a novice learner participating in a field study of wild animals alongside an expert. At first, the learner learns from the expert through instruction that highlights which features are relevant for distinguishing between two animal categories. Years later, the learner might conduct a new field study independently in a different region with unfamiliar animals. The learner can actively explore such uncertain environments and acquire new knowledge by learning from the feedback arising from their own actions. This raises a central question for educational research: Which timing and frequency strategies of instruction most effectively prepare learners to succeed when learning independently in new situations? This is referred to hereafter as new learningsubsequent learning of new material <ref type="bibr">(Chan et al., 2018)</ref>. The present study develops various instructional strategies inspired by theories from both motivation and cognition and experimentally tests whether each strategy enhances new learning and which strategy is most effective.</p><p>A widely used approach to enhance learners' performance across educational settings is to provide instruction at every opportunity. This full-instruction approach has been shown to enhance performance during instruction <ref type="bibr" target="#b3">(Biele et al., 2009;</ref><ref type="bibr" target="#b57">Rosedahl et al., 2021)</ref>. However, when learners subsequently face unfamiliar situations, this approach may backfire. Overly detailed instruction can reduce opportunities for exploration and hinder learners' ability to adapt flexibly in new environments. For example, when learners are directly taught how to operate a novel machine, they are less likely to explore its other possible functions or discover alternative ways of using it on their own <ref type="bibr" target="#b6">(Bonawitz et al., 2011)</ref>. Similarly, learners who are consistently provided with correct answers achieve lower transfer performance than those who are given opportunities to think for themselves <ref type="bibr" target="#b45">(Pan et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instructional approach in motivation research</head><p>In the field of educational psychology, research on motivation has investigated how learners develop independence. According to self-determination theory <ref type="bibr" target="#b61">(Ryan &amp; Deci, 2017)</ref>, one of the key motivational factors for learners is feeling effective in their interactions with the environment, often referred to as competence (see also <ref type="bibr" target="#b72">White, 1959)</ref>. Learners' competence can be supported by various instructional practices <ref type="bibr" target="#b0">(Aelterman et al., 2019)</ref>, such as clearly communicating expectations and goals (i.e., clarifying) and providing adaptive, needs-based help as they make progress (i.e., guiding). Correlational studies have shown that when learners receive such competence-supportive practices, they demonstrate greater behavioral engagement and enjoyment <ref type="bibr" target="#b65">(Skinner &amp; Belmont, 1993;</ref><ref type="bibr" target="#b49">Patall et al., 2024)</ref>. Learners who receive such support also tend to use more effective self-regulated learning strategies <ref type="bibr" target="#b0">(Aelterman et al., 2019;</ref><ref type="bibr" target="#b64">Sierens et al., 2009)</ref>. Furthermore, a meta-analysis by <ref type="bibr" target="#b49">Patall et al. (2024)</ref> demonstrated that these practices were significantly and positively associated with students' achievement. It also showed that training teachers to implement competence-supportive practices led to significant improvements in students' achievement.</p><p>Among competence-supportive practices, adaptive instruction constitutes a promising approach to realizing optimal timing and frequency of instruction. Adaptive instruction deliberately avoids giving full solutions or detailed instructions. Instead, it scaffolds learners toward success by dynamically adjusting the amount and type of support to match their current level of understanding <ref type="bibr" target="#b0">(Aelterman et al., 2019;</ref><ref type="bibr" target="#b69">van de Pol et al., 2010)</ref>. To deliver such contingent and tailored support, instructors must engage in diagnostic processes-including formative assessment and real-time monitoring-to accurately assess learners' performance and determine when and how to intervene <ref type="bibr" target="#b32">(Koedinger &amp; Aleven, 2007;</ref><ref type="bibr" target="#b69">van de Pol et al., 2010)</ref>. As learners demonstrate improved performance, support is gradually faded, thereby transferring responsibility for task completion to them <ref type="bibr" target="#b0">(Aelterman et al., 2019;</ref><ref type="bibr" target="#b69">van de Pol et al., 2010)</ref>.</p><p>The adaptive instruction strategy-adjusting the timing and frequency of instruction according to learners' performance-may foster new learning. Prior studies on motivation suggest that when teachers provide adaptive support, learners are more likely to engage actively, enjoy tasks, and discover effective learning strategies during instruction <ref type="bibr" target="#b0">(Aelterman et al., 2019;</ref><ref type="bibr" target="#b65">Skinner &amp; Belmont, 1993)</ref>. Building on these findings, learners who receive adaptive instruction are plausibly more likely to apply what they learned during instruction. Consequently, they may be better able to learn independently in novel contexts.</p><p>However, previous research has not empirically tested whether adaptive instruction enhances learners' ability to learn independently in novel situations. The adaptive approach has been extensively incorporated across various areas of educational research-not only motivation <ref type="bibr" target="#b0">(Aelterman et al., 2019;</ref><ref type="bibr" target="#b49">Patall et al., 2024)</ref>, but also scaffolding <ref type="bibr" target="#b69">(van de Pol et al., 2010)</ref>, memory <ref type="bibr" target="#b24">(Fiechter &amp; Benjamin, 2019)</ref>, category learning <ref type="bibr" target="#b46">(Pashler et al., 2013)</ref>, computer-based scaffolding <ref type="bibr" target="#b2">(Belland et al., 2017)</ref>, intelligent tutoring systems <ref type="bibr" target="#b32">(Koedinger &amp; Aleven, 2007)</ref>, and adaptive learning technologies <ref type="bibr" target="#b1">(Aleven et al., 2017)</ref>. Although these studies have examined the association between adaptive approaches and various educational outcomes, their potential to foster new learning remains unclear.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Instructional approaches in cognitive research</head><p>Another influential approach has emerged from cognitive and educational psychology: the testing effect (retrieval practice) <ref type="bibr" target="#b11">(Carpenter et al., 2022;</ref><ref type="bibr" target="#b22">Dunlosky et al., 2013)</ref>. In this line of research, testing is regarded not merely as a tool for assessment but as a powerful learning activity in itself <ref type="bibr" target="#b31">(Karpicke &amp; Roediger, 2008)</ref>. Traditionally, research on testing has focused on the backward testing effect, whereby retrieving previously studied information enhances retention of that content <ref type="bibr" target="#b29">(Karpicke &amp; Blunt, 2011;</ref><ref type="bibr" target="#b55">Roediger &amp; Karpicke, 2006;</ref><ref type="bibr" target="#b58">Rowland, 2014)</ref>.</p><p>More recently, however, researchers have identified another noteworthy benefit, known as the forward testing effect-also referred to as test-potentiated new learning or the interim test effect.</p><p>This effect shows that taking a test on certain material can enhance the learning of subsequent new material (see reviews by <ref type="bibr">Chan et al., 2018;</ref><ref type="bibr" target="#b45">Pan et al., 2018;</ref><ref type="bibr" target="#b76">Yang et al., 2018)</ref>. This effect is thought to occur because testing increases learners' engagement in subsequent learning and encourages them to adopt more effective learning strategies <ref type="bibr">(Chan et al., 2018;</ref><ref type="bibr" target="#b77">Yang et al., 2022)</ref>.</p><p>Several studies have demonstrated the forward testing effect using various learning procedures, including word list memory <ref type="bibr">(Pastötter et al., 2011)</ref>, video lectures <ref type="bibr" target="#b66">(Szpunar et al., 2013)</ref>, and category learning <ref type="bibr" target="#b36">(Lee &amp; Ahn, 2018)</ref>. For example, in a category learning study by <ref type="bibr" target="#b36">Lee and Ahn. (2018)</ref>, participants learned the painting styles of various artists in two separate sessions (A and B). In Session A, as part of the initial learning session, participants were shown a painting with the artist's name one by one (study trials). They were then randomly assigned to a restudy condition or an interim test condition. Participants in the restudy condition were represented with the same painting-and-name pairs. In the interim test condition, participants were shown each painting and prompted to type the corresponding artist's name, followed by corrective feedback. Subsequently, in Session B, as part of the new learning session, all participants studied the painting styles of entirely new artists, again by viewing paintings from each artist. Finally, their performance was assessed with a final test that required them to classify previously unseen paintings from the Session B artists by selecting the correct name from a list of all artists. The results showed that participants in the interim test condition achieved significantly higher accuracy on these final test items than those in the restudy condition. This finding suggests that the interim test in the initial learning (Session A) enhanced the new learning (Session B).</p><p>Although testing is an effective learning approach <ref type="bibr">(Chan et al., 2018;</ref><ref type="bibr" target="#b36">Lee &amp; Ahn, 2018;</ref><ref type="bibr" target="#b76">Yang et al., 2018)</ref>, little is known about its combination with explicit instruction. In educational settings, for example, while students take a practice test, teachers may assist them by highlighting key features relevant to categorization. Such instruction may complement the testing effect by providing useful information to facilitate subsequent learning <ref type="bibr" target="#b42">(Miyatsu et al., 2019)</ref>.</p><p>Nevertheless, instruction carries the risk of diminishing the desirable difficulty necessary for learning <ref type="bibr" target="#b4">(Bjork &amp; Bjork, 2011)</ref>. Indeed, <ref type="bibr" target="#b28">Kang et al. (2023)</ref> found that providing instruction on every trial, either during the test or immediately after it as feedback, did not enhance performance compared to testing alone. They suggested that when instruction makes it easier to retrieve answers, learners may have exerted less cognitive effort. This reduced effort may, in turn, prevent them from learning sufficiently from the instruction. These considerations suggest that balancing the benefits of instruction with the desirable difficulty of testing without instruction is critical for new learning. A key open question, therefore, is how the frequency and timing of instruction should be determined to achieve this balance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The present study</head><p>The goal of the present study was to examine which timing and frequency strategy of instruction leads to the best performance when learners subsequently work independently in a novel situation. To this end, we developed and systematically compared several instructional strategies, each grounded in theories of motivation and cognition. To evaluate these strategies, we designed an experimental paradigm consisting of two types of sessions: a teaching session and an independent session. The teaching session implemented the experimental manipulation, in which the timing and frequency of instruction varied across experimental conditions. The independent session assessed the effects of this manipulation on new learning, in which participants worked without instruction.</p><p>To examine how learners explore uncertain environments and form new concepts, we employed a category learning task-a type of conceptual learning paradigm <ref type="bibr" target="#b78">(Zeithamova et al., 2019)</ref>. In this task, participants were presented with a stimulus on each trial and asked to classify it into one of two categories. The task consisted of two phases: a learning phase and a generalization phase. In the learning phase, participants received trial-by-trial feedback (i.e., correct or incorrect). This phase required participants to identify features relevant to the underlying category structure through repeated classification and feedback <ref type="bibr" target="#b34">(Kruschke, 1992;</ref><ref type="bibr" target="#b43">Nosofsky, 1986)</ref>. In the generalization phase, participants were presented with novel items of the same category structure as in the learning phase. No feedback was provided during this phase. This phase required participants to apply the category rule they had acquired during the learning phase <ref type="bibr" target="#b8">(Bowman &amp; Zeithamova, 2018)</ref>.</p><p>We conducted this category learning task across both teaching and independent sessions. Each session included both the learning and generalization phases, except that in Experiment 1, the teaching sessions did not include the generalization phase. In the teaching session, regardless of the phase, participants could learn through instruction. Instruction was implemented via feature highlighting, which indicated features relevant to the categories and helped participants identify the underlying category rule <ref type="bibr" target="#b28">(Kang et al., 2023;</ref><ref type="bibr" target="#b42">Miyatsu et al., 2019)</ref>. The timing and frequency of feature highlighting were experimentally manipulated, such that the pattern of highlighting and no-highlighting trials varied across conditions. In the independent session, participants had to learn new categories solely from the outcomes of their own responses, without any feature highlighting. This self-guided, trial-and-error learning was implemented through trial-by-trial feedback in the learning phase. Based on previous studies on category learning <ref type="bibr" target="#b7">(Bowman et al., 2022;</ref><ref type="bibr" target="#b41">Minda &amp; Smith, 2001)</ref>, we used classification accuracy in both learning and generalization phases of the independent session as indices of new learning.</p><p>Three experiments were conducted. In Experiments 1 and 2 (not preregistered), we tested the effectiveness of an adaptive instruction strategy as a first step. To precisely manipulate this strategy, we developed an algorithm for adaptive instruction. We then compared the adaptive condition with two control conditions to evaluate its effectiveness. One control condition was the no-instruction condition, in which participants did not receive any feature highlighting and thus could not learn from instruction. The other control condition was the full-instruction condition, in which participants received feature highlighting on every trial during the teaching sessions, likely undermining their effort to think on their own. After these experiments, we conducted Experiment 3 (preregistered), in which we examined whether the adaptive strategy offers distinctive benefits over other theoretically promising instructional strategies. In this experiment, we implemented five additional instructional strategies grounded in influential theories of motivation and cognition (e.g., the forward testing effect) and evaluated their effectiveness alongside that of the adaptive strategy. All experiments were approved by the ethics committee of the first author's institution.</p><p>To ensure transparency and reproducibility, all materials, analysis code, data, and codebooks are available on OSF (URL). We report all manipulations and exclusions in this manuscript, and all measures are described either in the manuscript or in the Supplementary Information (SI). In addition, the preregistration of Experiment 3 specified the study design, planned sample size, exclusion criteria, and planned analyses for the primary hypotheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments 1 and 2</head><p>Experiment 1 served as an initial test of the adaptive strategy. Experiment 2 addressed two limitations identified in Experiment 1 by slightly modifying the procedure and the adaptive algorithm. We report the two experiments together because they shared the same basic structure and outcome measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants and design. We recruited 172 and 196 adults for Experiments 1 and 2, respectively, via Prolific. After excluding participants who failed attention checks, the final samples consisted of 170 and 195 participants. Participants were randomly assigned to the noinstruction, full-instruction, and adaptive conditions. Detailed participant information is provided in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Prior to recruitment, we conducted a power analysis using G*Power <ref type="bibr" target="#b23">(Faul, Erdfelder, Lang, &amp; Buchner, 2007)</ref>. We set the desired power at .80, the alpha level at .05. As this study was the first to examine the effect of an adaptive strategy using a category learning task, we assumed a medium effect size (f = .25) for comparing three between-subjects conditions. The analysis indicated that a sample size of 159 participants would be required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials.</head><p>We created four types of creature stimuli based on previous category learning studies <ref type="bibr" target="#b8">(Bowman &amp; Zeithamova, 2018;</ref><ref type="bibr" target="#b10">Bozoki et al., 2006;</ref><ref type="bibr" target="#b56">Rosedahl &amp; Ashby, 2018)</ref>. Each creature type consisted of eight items (see Figure <ref type="figure" target="#fig_0">1</ref>). Each item was defined by three features (e.g., crest, foot, and tail), which varied across exemplars within a type (e.g., bird-like creatures).</p><p>Items were assigned to one of two categories: red or blue. Each category had prototypical features (e.g., blue-category birds had one crest, whereas red-category birds had two). Items were categorized based on the number of features that matched the prototypical features of each category.</p><p>Procedure. The experiments were conducted online using jsPsych <ref type="bibr" target="#b19">(de Leeuw, 2015)</ref>. The experiment consisted of four sessions: three teaching sessions and one independent session (Figure <ref type="figure">2</ref>). In each session, four types of creatures were randomly assigned, with each creature consisting of eight items. In each trial, an item was presented for up to two seconds, and participants responded by pressing the "f" or "j" key at their own pace. The order of item presentation was pseudo-randomized so that each item appeared once per set, and no more than three items from the same category were shown successively <ref type="bibr" target="#b8">(Bowman &amp; Zeithamova, 2018)</ref>.</p><p>In the teaching sessions of Experiment 1 (Figure <ref type="figure">2</ref>; upper part), which consisted only of the learning phase, participants classified each of the eight items of a creature (Figure <ref type="figure" target="#fig_0">1</ref>) 15 times (a total of 120 trials per session). In each trial, the algorithm determined whether to provide feature highlighting (Figure <ref type="figure">2</ref>; upper part), which highlighted the relevant features of an item using circles with the corresponding category color <ref type="bibr" target="#b28">(Kang et al., 2023;</ref><ref type="bibr" target="#b42">Miyatsu et al., 2019)</ref>.</p><p>The timing and frequency of providing feature highlighting varied depending on the experimental condition. After each classification, they received feedback indicating whether their response was correct or incorrect.</p><p>In the independent session, participants classified eight items from a new type of creature, without feature highlighting. This session consisted of two phases: learning and generalization. In the learning phase, participants classified each of the eight items 15 times, receiving feedback after each trial. In the generalization phase, they classified both the same eight items and 40 novel items of the same creature (48 trials in total). The novel items differed slightly in their features from those presented during the learning phase and included additional, irrelevant features. No feedback was provided during this phase. Participants were told to apply the category rule they had learned in the learning phase, but they were not told that irrelevant features were added to the items in the generalization phase.</p><p>In Experiment 2, the procedure was identical to that of Experiment 1, except that each teaching session included the generalization phase in addition to the learning phase. Specifically, in the teaching sessions, participants classified each of the eight items 15 times, each followed by feedback. They then proceeded to the generalization phase, in which participants classified both the same eight items and 40 novel items of the same creature, and feedback was not provided for these classifications. During both the learning and generalization phases of the teaching sessions, feature highlighting was provided depending on the condition. We added the generalization phase to allow participants to practice applying category rules to novel stimuli during the teaching sessions.</p><p>Experimental conditions. In both Experiments 1 and 2, three experimental conditions were implemented: no-instruction, full-instruction, and adaptive conditions. The conditions differed in the timing and frequency of feature highlighting during the teaching sessions. The independent session was identical across all conditions.</p><p>In the no-instruction condition, participants did not receive feature highlighting on any trial. In the full-instruction condition, participants received feature highlighting on every trial during both the learning and generalization phases of the teaching sessions.</p><p>In the adaptive condition, the algorithm assessed participants' understanding and adjusted when to provide feature highlighting. Full details are provided in the SI; here we summarize the key steps. To tailor the adaptive teaching process, the algorithm divided the eight items into four pairs based on the structure of the features (Pair 0 to Pair 3 in Figure <ref type="figure" target="#fig_0">1</ref>) and performed assessment and adjustment for each pair. At the beginning of the first teaching session, the algorithm provided feature highlighting. It then presented trials without highlighting, requiring participants to respond on their own. Based on participants' responses during these nohighlighting trials, the algorithm assessed their understanding. For the assessment, the algorithm calculated classification accuracy in Experiment 1, whereas Bayesian updating was used in Experiment 2 to enable more timely feature highlighting (see the SI for details). If the assessment met a predetermined performance criterion (accuracy greater than 80% in Experiment 1 and a 95% HDI that did not include the chance level in Experiment 2), the algorithm continued to present a no-highlighting trial. After each no-highlighting trial, the algorithm re-assessed understanding. As long as the re-assessed understanding met the criterion, it withheld feature highlighting and continued the process on a trial-by-trial basis. If the accuracy fell below the criterion, it provided feature highlighting on the next trial. In Experiment 2, this adaptive feature highlighting was applied in the same way in both the learning and generalization phases.</p><p>Furthermore, in the second and third teaching sessions, the algorithm assessed how many trials were needed for a participant to reach the criterion based on their performance during the preceding session and delayed the start of feature highlighting accordingly.</p><p>Measures. Accuracy in the generalization phase was calculated using all 48 trials from the generalization phase of the independent session. Accuracy in the learning phase was calculated using only the latter half of trials from the learning phase (60 trials), because participants were expected to learn the category through trial and error in the earlier part.</p><p>Additional subsidiary self-reported measures are reported in Table <ref type="table" target="#tab_0">S1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data analysis.</head><p>To examine the effectiveness of the adaptive strategy, we compared it with each of the two control conditions (no-instruction and full-instruction). As the primary analysis, we tested the effects on accuracy in the generalization phase using multiple regression analysis. Two dummy variables were created <ref type="bibr" target="#b17">(Cohen et al., 2003)</ref>: a no-instruction contrast (adaptive = 0, no-instruction = -1, full-instruction = 0), and a full-instruction contrast (adaptive = 0, no-instruction = 0, full-instruction = -1). In the model, the two dummy variables were entered as independent variables, and accuracy in the generalization phase served as the dependent variable.</p><p>As a secondary analysis, we tested the effects on accuracy in the learning phase using a meta-analysis that combined data from both experiments, following the approach recommended by <ref type="bibr" target="#b18">Cumming (2012)</ref>. Meta-analysis was chosen because both experiments included the same learning phase in the teaching sessions (unlike the generalization phase, which differed between experiments), and pooling the data could increase statistical power. We conducted the metaanalysis using a random-effects model with the R package metafor <ref type="bibr" target="#b70">(Viechtbauer, 2010)</ref>. All statistical tests were one-tailed, because neither the no-instruction nor the full-instruction condition was expected to outperform the adaptive condition. All analyses were performed in R (R Core Team, 2022).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>Descriptive statistics. The means and 95% confidence intervals (CIs) of accuracy in the learning and generalization phases are shown in Figure <ref type="figure">3</ref>. Descriptive statistics for other variables and the correlations among variables are provided in Figures <ref type="figure" target="#fig_0">S1-S3</ref> and Tables <ref type="table" target="#tab_1">S2-S3</ref> of the SI. The proportion of feature highlighting trials in the adaptive condition is reported in Table <ref type="table">S4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Primary results (accuracy in the generalization phase).</head><p>In Experiment 1, neither the noinstruction contrast nor the full-instruction contrast was significantly associated with accuracy in the generalization phase (b * = .08, p = .191; b * = -.02, p = .590; Table <ref type="table" target="#tab_2">S5</ref>). We found no evidence supporting the effectiveness of adaptive instruction. In Experiment 2, however, the fullinstruction contrast was significantly associated with accuracy (b * = .15, p = .035), whereas the no-instruction contrast was not (b * = .12, p = .070), as shown in Table <ref type="table" target="#tab_2">S5</ref>. This indicates that the adaptive condition exhibited significantly higher accuracy than the full-instruction condition in Experiment 2. These results suggest that by including a generalization phase in the teaching sessions, participants in the performance-adapted condition may have better learned how to apply category rules to novel stimuli.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Secondary results (accuracy in the learning phase).</head><p>The first meta-analysis compared the adaptive condition with the no-instruction condition and revealed a significant advantage of the adaptive condition (d = 0.41, p = .001; Figure <ref type="figure">4</ref>, upper panel). Heterogeneity across studies was low (τ² = 0.05, I² = 6.69%). The second meta-analysis compared the adaptive condition with the full-instruction condition and again found a significant effect (d = 0.29, p = .013; Figure <ref type="figure">4</ref>, lower panel). No heterogeneity was observed (τ² = 0, I² = 0%). These results indicate that participants in the adaptive condition achieved higher accuracy than both the no-instruction and full-instruction conditions. This suggests that participants in the adaptive condition were better able to learn categories through trial and error when learning independently in novel situations.</p><p>We reported the effects of conditions on other variables (Table <ref type="table" target="#tab_3">S6</ref>) and the results of additional analyses using an alternative computation of accuracy in the SI (Figure <ref type="figure">S4</ref> and Table <ref type="table">S7</ref>).</p><p>Additional results regarding accuracy in the generalization phase. In Experiment 2, the adaptive condition exhibited significantly higher accuracy in the generalization phase than the full-instruction condition, but not the no-instruction condition. One possible explanation for the difference in statistical significance is individual variability in ability and engagement with the task. Statistically controlling for baseline variables may reduce standard error and increase the power.</p><p>To test this possibility, we simulated baseline accuracy and reaction time. Reaction time was used as an index of task engagement because it was significantly positively correlated with accuracy (Tables <ref type="table" target="#tab_1">S2-S3</ref>), suggesting that longer reaction times reflected more careful observation of the stimuli and greater deliberation during categorization. Baseline variables were simulated using data from the first teaching session in the no-instruction condition, which served as a benchmark prior to the experimental manipulation. We then conducted a multiple regression analysis controlling for these variables (see the SI for details). The results showed that, after statistically controlling for these simulated baseline variables, both the no-instruction and fullinstruction contrasts were significantly associated with accuracy in the generalization phase (b * = .12, p = .028; b * = .15, p = .011; Table <ref type="table">S8</ref>). These findings suggest that the adaptive condition outperforms the no-instruction condition when baseline variables are statistically controlled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>Building on the initial evidence for the effectiveness of the adaptive strategy from Experiments 1 and 2, we next examined whether this strategy yields advantages over other theoretically promising instructional strategies. Thus, in Experiment 3, we introduced five new strategies based on principles from the learning sciences (Table <ref type="table">2</ref>), along with the adaptive strategy. By comparing each of these six strategies with the no-instruction and full-instruction conditions, we aimed to comprehensively evaluate which instructional strategy best fosters new learning. In the following paragraphs, we describe the rationale of the five newly introduced strategies.</p><p>Among the five new strategies, four of them were based on the forward testing effect: the blocked-50%, blocked-10%, mixed-50%, and mixed-10% conditions (Table <ref type="table">2</ref>). Research on the forward testing effect has shown that taking a test on certain material enhances new learning, as noted in the Introduction <ref type="bibr">(Chan et al., 2018)</ref>. In typical procedures used in prior studies (e.g., <ref type="bibr" target="#b36">Lee &amp; Ahn, 2018)</ref>, participants were first presented with correct information through study trials.</p><p>Then, they practiced retrieving it (test condition) or they were re-presented with the same information (restudy condition). Participants in the test condition achieved significantly higher performance in a new learning session than those in the restudy condition <ref type="bibr">(Chan et al., 2018;</ref><ref type="bibr" target="#b36">Lee &amp; Ahn, 2018)</ref>.</p><p>Previous research has proposed several mechanisms for this effect <ref type="bibr">(Chan et al., 2018;</ref><ref type="bibr" target="#b36">Lee &amp; Ahn, 2018;</ref><ref type="bibr" target="#b74">Yang et al., 2019)</ref>, two of which are particularly relevant to the learning context of the present study. One proposed mechanism is increased task engagement. During test trials, participants may become more aware of the task difficulty and consequently invest greater effort in subsequent learning. Supporting this idea, prior studies have shown that participants in an interim test condition exhibited higher task engagement than those in a condition without interim testing <ref type="bibr" target="#b27">(Healy et al., 2017;</ref><ref type="bibr" target="#b75">Yang et al., 2017)</ref>. The other mechanism is a shift in learning strategies. While being tested, participants may reevaluate and modify their learning strategies, switching from less effective to more effective ones. Empirical findings support this idea, showing that participants in an interim test condition used more effective learning strategies than those in a restudy condition <ref type="bibr">(Chan et al., 2018;</ref><ref type="bibr" target="#b77">Yang et al., 2022)</ref>.</p><p>Based on the mechanisms underlying the forward testing effect, the contrast between restudy and test trials in previous research can be mapped onto the contrast between highlighting and no-highlighting trials in the present study. Prior studies have demonstrated the forward testing effect by contrasting test and restudy trials <ref type="bibr">(Chan et al., 2018;</ref><ref type="bibr" target="#b36">Lee &amp; Ahn, 2018;</ref><ref type="bibr" target="#b74">Yang et al., 2019)</ref>. These studies suggest that test trials make participants aware of the task difficulty, thereby enhancing their task engagement and improving their learning strategies. The contrast between highlighting and no-highlighting trials in the present study is also likely to involve a similar difference in the experience of task difficulty. Although highlighting trials require participants to respond, they are likely easier than no-highlighting trials and may therefore lack desirable difficulty, as is the case for restudy trials. Thus, inserting no-highlighting trials by deliberately limiting the number of highlighting trials may be effective in a manner similar to the forward testing effect. By experiencing the difficulty of retrieval without highlighting, participants may have become more engaged in the task and refined their learning strategies, thereby facilitating performance in subsequent new learning situations. Adapting the standard paradigm used in testing-effect research <ref type="bibr" target="#b30">(Karpicke &amp; Roediger, 2007;</ref><ref type="bibr" target="#b36">Lee &amp; Ahn, 2018)</ref>, we implemented a blocked-50% strategy (Table <ref type="table">2</ref>): trials with feature highlighting and those without it were grouped into separate blocks and alternated in a fixed sequence.</p><p>Despite its promise, blocked instruction may pose a risk of metacognitive bias. When learners are presented with a block of highlighted items, they are likely to experience a streak of correct responses, which can make them feel that the task is overly fluent. This sense of fluency has been shown to inflate learners' confidence <ref type="bibr" target="#b12">(Carpenter et al., 2013)</ref>, and such overconfidence may, in turn, reduce their task engagement <ref type="bibr" target="#b21">(Dunlosky &amp; Rawson, 2012)</ref>. Consequently, blocked instruction may undermine engagement during highlighting trials.</p><p>To mitigate this potential risk, we introduced three alternative strategies (mixed-50%, blocked-10%, mixed-10%; Table <ref type="table">2</ref>). The first was the mixed strategy, which presented highlighting and no-highlighting trials in a mixed sequence, inspired by research on interleaved learning <ref type="bibr" target="#b33">(Kornell &amp; Bjork, 2008;</ref><ref type="bibr" target="#b40">Metcalfe &amp; Xu, 2016)</ref>. This strategy may reduce overconfidence by limiting the number of successive correct responses. The second was an approach that shortened instructional time and increased tests without instruction <ref type="bibr" target="#b53">(Risko et al., 2024)</ref>. In our study, this was implemented by providing a small number of highlighting trials and a large number of no-highlighting trials (blocked-10%). This low-frequency instruction strategy may encourage learners to monitor their ability more accurately during opportunities for retrieval practice without highlighting <ref type="bibr" target="#b62">(Scheck &amp; Nelson, 2005;</ref><ref type="bibr" target="#b71">West et al., 2025)</ref>. Thus, both mixed and low-frequency instruction strategies may help learners maintain high task engagement during highlighting trials while retaining the benefits of the forward testing effect seen in the blocked-50% strategy. Based on these considerations, we included both blocked and mixed strategies and, for each strategy, implemented a low-frequency condition (approximately 10%) as well as a standard-frequency condition (50%). We consider 50% standard because this frequency has often been used in previous research <ref type="bibr" target="#b30">(Karpicke &amp; Roediger, 2007;</ref><ref type="bibr" target="#b36">Lee &amp; Ahn, 2018)</ref>. Furthermore, by comparing these new conditions to the adaptive condition, we aimed to test whether the effects observed in Experiments 1 and 2 were due to adaptivity itself or merely to low frequency or the mixed presentation of instruction.</p><p>In contrast to the strategies in which instructional timing and frequency were externally determined, we also introduced an alternative approach that allowed learners to make their own choices about whether to receive instruction (Choice condition; Table <ref type="table">2</ref>). This approach was based on research on motivation and self-regulated learning. According to self-determination theory and research on autonomy support, offering learners choices can benefit motivation <ref type="bibr" target="#b52">(Reeve &amp; Cheon, 2021;</ref><ref type="bibr" target="#b61">Ryan &amp; Deci, 2017)</ref>. A meta-analysis of the choice effect found that learners who were given choices reported greater task enjoyment and engagement compared to those who were not <ref type="bibr" target="#b48">(Patall et al., 2008</ref>). Nevertheless, a potential drawback is that learners may make pedagogically suboptimal choices. Indeed, research on self-regulated learning has shown that learners often prefer less effective strategies (e.g., restudying) over more effective ones (e.g., testing) <ref type="bibr" target="#b5">(Bjork et al., 2013;</ref><ref type="bibr" target="#b54">Rivers, 2021)</ref>. One way to mitigate this risk is through a stepwise display format, in which questions are presented before additional information (van den <ref type="bibr" target="#b68">Broek et al., 2023)</ref>. Analogously, in our choice strategy, participants first attempted the task without feature highlighting and then decided whether to receive it.</p><p>In summary, we implemented six instructional conditions: blocked-50%, mixed-50%, blocked-10%, mixed-10%, choice, and adaptive. We aimed to test their effects on new learning by comparing each condition with the no-instruction and full-instruction conditions. Furthermore, we planned to exploratorily compare conditions that significantly outperformed both control conditions.</p><p>In addition to testing the effectiveness of these six instructional strategies, we examined their potential mediating processes. Specifically, we tested the roles of task engagement, task enjoyment, and learning strategies employed by participants to classify stimuli. Reaction time was used as an index of task engagement, because longer reaction times were associated with higher accuracy in Experiments 1 and 2 and suggested more careful processing during the task.</p><p>Task enjoyment was measured with a self-report scale. To estimate category learning strategies, we applied computational models of category learning <ref type="bibr" target="#b41">(Minda &amp; Smith, 2001;</ref><ref type="bibr">Nosofsky, 1987;</ref><ref type="bibr" target="#b63">Shepard, 1957)</ref> to participants' trial-by-trial responses.</p><p>We preregistered three primary hypotheses. First, the blocked-50%, blocked-10%, mixed-50%, mixed-10%, choice, and adaptive conditions would exhibit higher accuracy in the generalization phase than both the no-instruction and full-instruction conditions. Second, reaction time would mediate the effects of these six strategies. *1 Third, task enjoyment would mediate the effects of the choice and adaptive strategies.</p><p>In addition, we tested secondary hypotheses that were not preregistered. First, the six experimental conditions would exhibit higher accuracy in the learning phase than in both the noinstruction and full-instruction conditions. Second, reaction time and task enjoyment would mediate the effects on accuracy in the learning phase, in the same way as for accuracy in the generalization phase. Third, learning strategies-specifically, prototype use and maximum attention weight, as described in the Data analysis section-would mediate the effects of the six instructional strategies on both accuracy in the learning and generalization phases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants and design. We recruited 1,199 adults via Prolific. According to a preregistered sampling plan, we excluded 42 participants who failed attention check tests or reported on the questionnaire that they took notes or pictures of stimuli many times. The final sample consisted of 1,157 participants. Participants were randomly assigned to one of the eight conditions. Detailed participant information is provided in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Prior to recruitment, we estimated the required sample size for Experiment 3. Based on the additional results of Experiment 2, we conducted a power analysis for testing the regression coefficient, assuming that baseline accuracy and reaction time would be statistically controlled (see the SI for details). In the power analysis, the alpha level was set at .05; a one-tailed test was used; and we set the target power for each regression coefficient at .895 so that the joint power (i.e., both the no-instruction and full-instruction contrasts being significant) would be approximately .80 (.895 × .895 = .801). This was because we planned to reject an individual null hypothesis only if both contrasts were significant. The power analysis indicated that 1,096 participants were required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials.</head><p>To estimate category learning strategy by fitting the models, we modified the stimuli to include six features per item (Figure <ref type="figure">5</ref> for an example), instead of three. Using six features made it possible to create items with varying levels of similarity to the categories, enabling an estimation of model fit and parameters. Each creature set consisted of 44 items, with each item characterized by a unique combination of the six features. These were selected from the 64 possible combinations (2⁶), excluding 20 items that shared an equal number of features from both categories and thus could not be clearly classified. The structure of the items is shown in Tables <ref type="table" target="#tab_0">S9-S10</ref>.</p><p>Procedure. The basic procedure was identical to Experiment 2. In Experiment 3, we added a baseline session at the beginning of the experiment to statistically control for baseline categorization accuracy and reaction time. In this session, participants were asked to classify items from a type of creature without feature highlighting, as in the independent session. Due to the limitation of total experiment duration, we reduced the number of teaching sessions from three to two. *2 Thus, the experiment consisted of four sessions: a baseline session, two teaching sessions, and an independent session. Each session included both a learning phase and a generalization phase.</p><p>Because the number of features increased, we extended the maximum presentation time for each item from two seconds to four seconds. In addition, we adjusted the number of trials in each phase accordingly. In the learning phase of all sessions, participants classified each of 14 items of a creature over six blocks, without repetition within a block (a total of 84 trials). The number of trials in the learning phase was the same across all sessions. In the generalization phase, participants classified 30 novel items of the same creature that were constructed by recombining relevant features from the learning phase. The number of trials in the generalization phase varied across sessions. In the baseline session, the 30 novel items were presented twice (60 trials). In the teaching sessions, the 30 novel items were presented once (30 trials). In the independent session, the 30 novel items and the same 14 items from the learning phase were each presented twice, resulting in 88 trials. The same 14 items were included for the purpose of model fitting.</p><p>Experimental conditions. Depending on the condition, the timing and frequency of feature highlighting varied during the teaching sessions. The no-instruction and full-instruction conditions were identical to those used in Experiments 1 and 2.</p><p>The adaptive algorithm was nearly identical to that used in Experiments 1 and 2, with minor adjustments reflecting changes in the stimulus structure. The algorithm divided the items into three-item groups based on the number of prototypical features of the creature. Two items with six prototypical features were allocated to Group 1, 12 items with five prototypical features were allocated to Group 2, and 30 items with four prototypical features were allocated to Group participants' understanding for each group and determined whether to provide feature highlighting, as in Experiment 2. Furthermore, in the second teaching session, the algorithm calculated the number of trials required for a participant to reach the criterion and delayed the onset of feature highlighting accordingly, as in Experiment 1.</p><p>In the blocked-50% and blocked-10% conditions, a block of successive feature highlighting trials and a block of successive no-highlighting trials were presented in an alternating sequence, respectively (Table <ref type="table" target="#tab_1">3</ref>). In the learning phase, which consisted of six 14-trial blocks, the blocked-50% algorithm provided feature highlighting on all trials within the evennumbered blocks (2nd, 4th, and 6th), and withheld feature highlighting in the odd-numbered blocks (1st, 3rd, and 5th). The blocked-10% algorithm provided feature highlighting only during the first four trials of the even-numbered blocks, withholding feature highlighting for the remaining trials. *3 In the generalization phase, the blocked-50% algorithm alternated between blocks of five feature highlighting trials and five no-highlighting trials, whereas the blocked-10% algorithm provided feature highlighting only on the first trial within each five-trial feature highlighting block.</p><p>In the mixed-50% and mixed-10% conditions, feature highlighting trials and nohighlighting trials were presented in a pseudorandom order (Table <ref type="table" target="#tab_1">3</ref>). In the mixed-50% condition, feature highlighting was provided on 50% of all trials, with no more than three successive feature highlighting trials. In the mixed-10% condition, feature highlighting was provided on approximately 10% of all trials and was interspersed with 6 to 10 no-highlighting trials. Participants in the blocked and mixed conditions were told that feature highlighting might be presented during the teaching sessions, but they were not informed about the timing and frequency in which it would appear.</p><p>In the choice condition, feature highlighting was provided only upon participants' request. Each trial began with an item presented without feature highlighting for up to four seconds, during which participants could press the L key to request it. If feature highlighting was requested, the item was re-presented with the feature highlighting for the remaining duration.</p><p>Participants were informed about this option prior to the teaching sessions. This design ensured that the maximum stimulus duration was identical to that in the other conditions, thereby preventing the maximum stimulus duration from becoming a confounding factor.</p><p>Measures. Accuracy in the learning and generalization phases was calculated in the same way as in Experiments 1 and 2. Baseline accuracy (i.e., accuracy in the baseline session) was calculated using the same procedure. Reaction time during the teaching sessions was used as an index of task engagement, with mean reaction time calculated after processing outliers (see the SI for details). Baseline reaction time was calculated by averaging reaction times from the baseline session after processing outliers. Task enjoyment was assessed using a four-item subscale of the Intrinsic Motivation Inventory <ref type="bibr" target="#b60">(Ryan, 1982</ref>; e.g., "I enjoyed doing the practicesession task very much."; 1 = not at all, 7 = very true), and a mean score was computed across the four items (α = .94). Additional subsidiary self-reported measures are reported in Table <ref type="table" target="#tab_0">S1</ref>.</p><p>Data analysis. The analyses described below were preregistered, except for the analyses of accuracy in the learning phase, and except for the use of prototype and maximum attention weight as mediators. Any deviations from the preregistered analysis plan are noted in the manuscript. All preregistered analyses are reported either in the main manuscript or in the SI.</p><p>To examine the effectiveness of the instructional strategies, we compared six experimental conditions (blocked-50%, blocked-10%, mixed-50%, mixed-10%, choice, and adaptive) against two control conditions (no-instruction and full-instruction), using both conjunction and individual testing logic <ref type="bibr" target="#b59">(Rubin, 2021)</ref>. For each comparison, we created two dummy variables: the no-instruction contrast (six experimental conditions = 0, no-instruction condition = -1, full-instruction condition = 0) and the full-instruction contrast (six experimental conditions = 0, no-instruction condition = 0, full-instruction condition = -1). We then conducted separate multiple regression analyses for six subsets of the data, each containing one experimental condition and the two control conditions (e.g., the subset including blocked-50%, no-instruction, and full-instruction). In each regression model, the two dummy variables were entered as independent variables, with baseline accuracy (generalization or learning) and baseline reaction time included as covariates. One-tailed tests were used to assess each regression coefficient. We rejected a null hypothesis about an experimental condition only if the regression coefficients of both dummy variables were significant. We separately tested each experimental condition. Note that although we conducted six multiple regression analyses, we did not need to adjust the alpha level of the tests because we had only one opportunity to make a type 1 error about an individual null hypothesis <ref type="bibr" target="#b59">(Rubin, 2021)</ref>.</p><p>Mediation analyses were performed using the bootstrap method implemented in the R package mediation <ref type="bibr" target="#b67">(Tingley et al., 2014)</ref>, with 10,000 bootstrap samples drawn with replacement and using two-tailed tests.</p><p>To estimate the category learning strategies used by participants, we followed procedures established in previous category learning research <ref type="bibr" target="#b8">(Bowman &amp; Zeithamova, 2018)</ref>. Specifically, we used the prototype model, in which the similarity of each generalization item to the prototype was computed <ref type="bibr" target="#b8">(Bowman &amp; Zeithamova, 2018;</ref><ref type="bibr" target="#b41">Minda &amp; Smith, 2001;</ref><ref type="bibr" target="#b63">Shepard, 1957)</ref>. *4 The model was fit to participants' trial-by-trial classification responses in the generalization phase of the independent session. Then, using Monte Carlo simulations, we examined whether the model fit reliably better than a random model. As a deviation from the preregistration, we did not conduct chi-square tests to compare the proportion of participants who used the prototype strategy across conditions. Instead, we used two estimates derived from the prototype model as mediators indexing category learning strategies <ref type="bibr" target="#b7">(Bowman et al., 2022)</ref>: (1) prototype use, which indicates the extent to which participants abstracted a central tendency (prototype) for each category and used it to classify items, and (2) maximum attention weight, which reflects the extent to which participants relied heavily on a single feature to classify items. In the present study, the task was designed such that using the prototype and having a lower maximum attention weight (i.e., distributing attention more evenly across features rather than focusing on a single feature) would lead to higher accuracy in the learning and generalization phases. Model fitting and Monte Carlo simulations were performed using MATLAB (MathWorks, Natick, MA).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>Descriptive statistics. The means and 95% confidence intervals (CIs) of accuracy in the learning and generalization phases are shown in Figure <ref type="figure">6</ref>. Descriptive statistics for other variables are provided in Figures <ref type="figure" target="#fig_0">S5-S10</ref>. The correlations among the variables are presented in Table <ref type="table">4</ref>. Prototype use was significantly positively correlated with accuracy in the learning and generalization phases (r = .69, p &lt; .001; r = .52, p &lt; .001), which indicates that the more participants classified items using the prototype, the higher their accuracy was. In addition, maximum attention weight was significantly negatively correlated with accuracy in the learning and generalization phases (r = -.46, p &lt; .001; r = -.46, p &lt; .001), which indicates that the more participants paid attention to all features of items instead of only one of the features, the higher their accuracy was. The proportion of feature highlighting trials in each condition is reported in Table <ref type="table" target="#tab_0">S11</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Primary results (accuracy in the generalization phase).</head><p>In the datasets including each of the six experimental conditions, neither the no-instruction contrast nor the full-instruction contrast was significantly associated with accuracy in the generalization phase (ps &gt; .053; Table <ref type="table" target="#tab_2">5</ref>). Thus, we found no evidence supporting the prediction that the instructional conditions would yield higher accuracy in the generalization phase than the control conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Secondary results (accuracy in the learning phase).</head><p>In the dataset including the blocked-10% condition, both the no-instruction and full-instruction contrasts were significantly positively associated with accuracy in the learning phase (b * = .14, p = .001; b * = .08, p = .043; Table <ref type="table" target="#tab_3">6</ref>), indicating that the blocked-10% condition yielded significantly higher accuracy than both the no-instruction and full-instruction conditions. In the datasets including the blocked-50% and mixed-50% conditions, respectively, the no-instruction contrast was significantly positively associated with accuracy (b * = .11, p = .007; b * = .12, p = .008), whereas the full-instruction contrast was not (b * = .05, p = .157; b * = .06, p = .118; Table <ref type="table" target="#tab_3">6</ref>). In the datasets including each of the remaining three conditions, neither the no-instruction contrast nor the full-instruction contrast was significantly associated with accuracy (ps &gt; .064; Table <ref type="table" target="#tab_3">6</ref>). In contrast to Experiments 1 and 2, we found no evidence supporting the benefit of the adaptive strategy. Additional analyses using an alternative computation of accuracy are reported in the SI (Table <ref type="table">S22</ref>).</p><p>So far, our data showed that only the blocked-10% strategy enhanced participants' accuracy in the learning phase, compared to both control conditions. To further examine the effects of the blocked-10% strategy on accuracy in the learning phase, we conducted mediation analyses. In the mediation model, four variables were included as mediators: reaction time during the teaching sessions, task enjoyment, prototype use, and maximum attention weight.</p><p>Mediation effects through reaction time and maximum attention weight were significant for both the no-instruction and full-instruction contrasts: for reaction time, the standardized indirect effects were .04 (95% CI = [.02, .08], p = .001) and .06 (95% CI = [.02, .10], p = .001), respectively; for maximum attention weight, they were .08 (95% CI = [.05, .12], p &lt; .001) and .03 (95% CI = [.00, .06], p = .048), respectively. In contrast, the mediation effects through task enjoyment and prototype use were not significant (ps &gt; .33). These results suggest that the blocked-10% strategy enhanced participants' task engagement (as indexed by reaction time) and encouraged them to attend to all relevant features of the stimuli, which in turn facilitated their accuracy in the learning phase. The effects of conditions on the mediator variables are reported in Table <ref type="table" target="#tab_0">S12</ref>-S15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional results regarding the blocked-10% condition.</head><p>To investigate whether the effect of the blocked-10% strategy on accuracy in the learning phase was driven by timing, frequency, or both, we compared the blocked-10% condition with each of the mixed-10% and blocked-50% conditions. We conducted a multiple regression analysis on a dataset that included these three conditions. The blocked-10% condition was chosen as the reference condition, and two dummy variables were created: the mixed-10% contrast (blocked-10% = 0, mixed-10% = -1, blocked-50% = 0), and the blocked-50% contrast (blocked-10% = 0, mixed-10% = 0, blocked-50% = -1). In the model, the two dummy variables were entered as independent variables, with baseline accuracy in the learning phase and baseline reaction time included as covariates.</p><p>Regression coefficients for the two dummy variables were tested using two-tailed tests.</p><p>Results showed that the mixed-10% contrast was significantly positively associated with accuracy in the learning phase (b * = .10, p = .033), whereas the blocked-50% contrast was not (b * = .02, p = .719), as shown in Table <ref type="table" target="#tab_3">S16</ref>. These results indicate that the blocked-10% condition yielded significantly higher accuracy than the intermixed-10% condition. These findings suggest that timing (i.e., whether feature highlighting is blocked or mixed), rather than frequency, contributed to the effects of the blocked-10% condition on accuracy in the learning phase. This effect was mediated by maximum attention weight (standardized indirect effect = .03, 95% CI [.01, .06], p = .021), but not by any other variable (ps &gt; .14). In addition, results of analyses for the effects on the mediator variables (Tables <ref type="table" target="#tab_0">S17-S18</ref>) showed that the blocked-10% condition yielded significantly longer reaction times than the blocked-50% condition (b * = .07, p = .0496). Specifically, a significant difference was found in reaction times on highlighting trials (b * = .34, p &lt; .001), but not on no-highlighting trials (b * = -.05, p = .193). The SI also reports an alternative computation of accuracy (Table <ref type="table" target="#tab_1">S23</ref>).</p><p>Additional results regarding the adaptive condition. We examined whether adaptive instruction affected reaction time (an index of task engagement), task enjoyment, prototype use, and maximum attention weight (indices of learning strategies), as suggested by previous studies on motivation <ref type="bibr" target="#b0">(Aelterman et al., 2019;</ref><ref type="bibr" target="#b65">Skinner &amp; Belmont, 1993)</ref>. We selected the mixed-10% condition as an appropriate benchmark because it shares several key characteristics with the adaptive condition-namely, the combination of the feature highlighting and no-highlighting trials, and the no-blocked presentation of feature highlighting. The mixed-10% condition also had the frequency of feature highlighting trials closest to that of the adaptive condition among all conditions (Table <ref type="table" target="#tab_0">S11</ref>). In the regression model, a dummy variable (mixed-10% = 0, adaptive = 1) was entered as the independent variable, with baseline accuracy in the generalization phase and baseline reaction time included as covariates. The results showed that the dummy variable was not significantly associated with any of the variables (ps &gt; .30; Tables <ref type="table" target="#tab_0">S19-S21</ref>). These results provide no evidence that adaptive instruction had beneficial effects on task engagement, task enjoyment, or learning strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>In the present study, we aimed to examine which timing and frequency strategies of instruction best foster learners' performance when they work independently in novel situations.</p><p>Across three experiments, we employed a category learning paradigm to systematically evaluate the effectiveness of various instructional strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects on accuracy in the learning phase</head><p>A meta-analysis of Experiments 1 and 2 showed that the adaptive condition led to significantly higher accuracy in the learning phase than both no-instruction and full-instruction conditions. In contrast, Experiment 3 found no significant effect of the adaptive condition.</p><p>Instead, the blocked-10% condition yielded significantly higher accuracy than the two control conditions. This effect was mediated by longer reaction time, suggesting increased task engagement, and by lower maximum attention weight, indicating the use of a more effective learning strategy. The blocked-50% and mixed-50% conditions also yielded significantly higher accuracy than the no-instruction condition, with this effect being mediated by longer reaction time and lower maximum attention weight, although the difference between these conditions and the full-instruction condition was not significant.</p><p>In Experiment 3, among all conditions, the blocked-10% condition yielded the highest accuracy in the learning phase, followed by the blocked-50% and mixed-50% conditions. These three conditions included the two key instructional patterns: (1) the successive presentation of highlighting trials (which occurred with moderate frequency in the mixed-50% condition) and</p><p>(2) the alternation between highlighting and no-highlighting trials. In contrast, the instructional conditions that did not differ significantly from the no-instruction condition contained only one of these instructional patterns. These findings suggest that both instructional patterns may be necessary to produce the effect on new learning. While we had predicted the role of alternation between highlighting and no-highlighting trials based on research on the forward testing effect, we had not anticipated the role of successive highlighting.</p><p>The account of the successive presentation of feature highlighting provides a possible explanation for why the results of the adaptive condition differed across the three experiments. In the adaptive condition, the rate of successive feature highlighting differed across the experiments. Specifically, the succession rate of highlighting trials-defined as the number of successive transitions between highlighting trials (e.g., two consecutive trials = 1, three = 2, four = 3) divided by the total number of highlighting trials-was 59% in Experiment 1, 21% in Experiment 2, and 11% in Experiment 3. In other words, feature highlighting in the adaptive condition was most blocked in Experiment 1, intermediate in Experiment 2, and more dispersed in Experiment 3. This raises the possibility that the significant effects observed in the adaptive condition of Experiments 1 and 2 may have resulted not from adaptive instruction per se, but rather from the blocked presentation of feature highlighting. Moreover, in Experiment 3, there were no significant differences between the adaptive and the mixed-10% conditions (the two conditions with similar frequency of feature highlighting) across multiple indices. These findings suggest that the adaptivity of the algorithm, as implemented in our study, may not have provided additional advantages.</p><p>The successive presentation of feature highlighting, one of the two key instructional patterns in the present study, can be interpreted in light of research on inductive learning. Based on the psychological mechanism proposed in category learning studies <ref type="bibr" target="#b13">(Carvalho &amp; Goldstone, 2015;</ref><ref type="bibr">2017)</ref>, when learners are successively presented with items that share a common attribute, they are likely to attend to the commonalities between these items. According to research on analogical encoding <ref type="bibr" target="#b25">(Gentner et al., 2003)</ref>, such a focus on commonalities across multiple cases facilitates the acquisition of more abstract and transferable knowledge. In the present study, learners may have been more likely to notice the commonalities that all category-relevant features were highlighted when highlighted trials were presented successively than when they were presented in isolation. This may have led them to abstract the general knowledge that attending to all relevant features was important for accurate classification-a category learning strategy applicable across sessions. As a result, they may have attended to all features in the independent session, as reflected in lower maximum attention weight.</p><p>The other key instructional pattern, namely the alternation between highlighting and nohighlighting trials is consistent with findings from the forward testing effect <ref type="bibr">(Chan et al., 2018;</ref><ref type="bibr" target="#b36">Lee &amp; Ahn, 2018;</ref><ref type="bibr" target="#b74">Yang et al., 2019)</ref>. Prior studies have shown that, as a result of being tested, learners engage more in subsequent learning <ref type="bibr" target="#b27">(Healy et al., 2017;</ref><ref type="bibr" target="#b75">Yang et al., 2017)</ref> and switch from less effective to more effective learning strategies <ref type="bibr">(Chan et al., 2018;</ref><ref type="bibr" target="#b77">Yang et al., 2022)</ref>. In our study, participants may have recognized the difficulty of the task during no-highlighting trials and consequently increased their task engagement, as reflected in longer reaction times. Furthermore, they may have evaluated their prior category learning strategies and acquired more effective category learning strategies during these trials, as indicated by lower maximum attention weight.</p><p>To examine the effects of instructional frequency, we compared the blocked-10% and blocked-50% conditions. Although accuracy in the learning phase did not significantly differ between the two conditions, the blocked-10% condition yielded significantly longer reaction times on highlighting trials than the blocked-50% condition. This suggests that participants in the blocked-10% condition were more engaged with highlighting trials than those in the blocked-50% condition. A possible explanation is that the blocked-10% condition reduced the risk of metacognitive bias that may have been induced in the blocked-50% condition. In the blocked-50% condition, participants may have experienced high fluency from a streak of correct responses during highlighting trials, which can lead to overconfidence <ref type="bibr" target="#b12">(Carpenter et al., 2013)</ref> and subsequently reduce task engagement <ref type="bibr" target="#b21">(Dunlosky &amp; Rawson, 2012)</ref>. In contrast, the blocked-10% condition provided more opportunities for retrieval practice without highlighting, which may have encouraged participants to monitor their ability more accurately. Consequently, participants in the blocked-10% condition may have recognized the difficulty of the task, treated the infrequent feature highlighting as more valuable, and processed it more carefully. Despite using the same frequency of highlighting as the blocked-10% condition, the intermixed-10% condition did not enhance accuracy in the learning phase. In fact, it yielded significantly lower accuracy in the learning phase than the blocked-10% condition, and this effect was mediated by maximum attention weight. These results suggest that the intermixed-10% condition may have hindered the development of effective learning strategies, leading to reduced accuracy. In previous research using a mixed strategy, exemplars from different categories were intermixed <ref type="bibr" target="#b33">(Kornell &amp; Bjork, 2008;</ref><ref type="bibr" target="#b40">Metcalfe &amp; Xu, 2016)</ref>, whereas in our study, highlighting and no-highlighting trials were intermixed. This type of intermixing may have made it difficult for learners to compare highlighted items, thereby impairing the formation of an effective learning strategy.</p><p>The choice condition showed no advantage over the control conditions. One likely reason is that each trial in this condition initially displayed an item without highlighting. Although we adopted this type of choice design to enhance accuracy by reducing the risk that participants would overuse feature highlighting, it may have eliminated the benefits of successive highlighting trials. During category learning, learners tend to compare the current item with the previously studied one <ref type="bibr" target="#b13">(Carvalho &amp; Goldstone, 2015;</ref><ref type="bibr">2017)</ref>. In our study, participants in the choice condition may have compared a highlighted item with a no-highlighted item rather than with another highlighted item. Consequently, they may have failed to attend to the common principle underlying highlighted items, which may have made it difficult for them to identify an effective category learning strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects on accuracy in the generalization phase</head><p>Whereas the effects on accuracy in the learning phase were observed across all experiments, the effects on accuracy in the generalization phase differed across experiments. In Experiment 1, no significant differences were found between the adaptive and control conditions.</p><p>In Experiment 2, the adaptive condition showed significantly higher accuracy than the fullinstruction condition in the original regression model, and a significant advantage over the noinstruction condition only when controlling for simulated baseline variables. In Experiment 3, no significant differences across conditions were found. One possible explanation for the difference in accuracy between the learning and generalization phases is that the generalization phase involved different types of cognitive processing than the learning phase. In the learning phase, learners needed to identify relevant features and determine category assignments based on feedback <ref type="bibr" target="#b34">(Kruschke, 1992;</ref><ref type="bibr" target="#b43">Nosofsky, 1986)</ref>. In contrast, the generalization phase required them to make judgments based on category representations constructed during the preceding learning phase <ref type="bibr" target="#b8">(Bowman &amp; Zeithamova, 2018)</ref>.</p><p>Feature highlighting, which visually highlighted relevant features, may have been helpful for identifying relevant features, but not for constructing accurate category representations.</p><p>Moreover, the differences in accuracy in the generalization phase across experiments may have been due to differences in the generalization items. In Experiments 1 and 2, the items included additional irrelevant features, while retaining the same relevant features as those used in the learning phase. In contrast, the generalization items in Experiment 3 were created by recombining relevant features from the learning phase. Thus, the generalization items in Experiment 3 required participants to rely more heavily on the category representation constructed during the preceding learning phase, potentially limiting the benefits of feature highlighting. Identifying instructional strategies that effectively enhance generalization remains a critical direction for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The theoretical and practical implications</head><p>Previous studies on category learning have examined the effectiveness of feature highlighting <ref type="bibr" target="#b20">(Do et al., 2023;</ref><ref type="bibr" target="#b42">Miyatsu et al., 2019;</ref><ref type="bibr" target="#b39">Meagher et al., 2022;</ref><ref type="bibr" target="#b73">Whitehead et al., 2022)</ref>. Specifically, <ref type="bibr" target="#b28">Kang et al. (2023)</ref> investigated its effects on new learning but found no significant benefit. Our findings suggest that the effectiveness of feature highlighting for new learning may depend on how it is presented. The blocked-10%, blocked-50%, and mixed-50% conditions in Experiment 3 as well as the adaptive condition in Experiments 1 and 2 showed significantly higher accuracy in the learning phase compared to the no-instruction condition. These conditions combined the successive presentation of highlighting trials with the alternation between highlighting and no-highlighting trials, which was not incorporated in previous studies. This combination may have helped learners to abstract an effective category learning strategy and refine their existing strategies, thereby enhancing their ability to learn new categories.</p><p>Nevertheless, it should be noted that our study used artificial stimuli with well-defined category structures, whereas previous studies employed natural categories with more complex and fuzzy boundaries (e.g., <ref type="bibr" target="#b28">Kang et al., 2023;</ref><ref type="bibr" target="#b42">Miyatsu et al., 2019)</ref>. Future research should test the effectiveness of this combination with more complex and naturalistic categories.</p><p>In addition, our findings have implications for the attentional mechanisms underlying the effects of feature highlighting. A prior study proposed that feature highlighting may facilitate the learning of appropriate attention weights to category-relevant dimensions, thereby enhancing classification accuracy <ref type="bibr" target="#b42">(Miyatsu et al., 2019)</ref>. However, this possibility has not been directly tested. In the present study, we examined the role of attention weights by fitting a category learning model to participants' responses. Our results showed that maximum attention weight mediated the difference in accuracy in the learning phase between the blocked-10% and noinstruction conditions, whereas prototype use did not. These results provide preliminary evidence for the proposed mechanism.</p><p>The present study contributes to research on the testing effect by combining instruction with testing. Recent studies on the testing effect have examined its combination with other techniques <ref type="bibr" target="#b35">(Latimier et al., 2021;</ref><ref type="bibr" target="#b38">McDaniel, 2023)</ref>, but the combination with other techniques does not necessarily produce stronger effects than testing alone <ref type="bibr" target="#b28">(Kang et al., 2023;</ref><ref type="bibr" target="#b44">O'Day &amp; Karpicke, 2021)</ref>. For example, <ref type="bibr" target="#b28">Kang et al. (2023)</ref> implemented a test-plus-instruction condition, in which instruction (feature highlighting) was provided on every trial either during or immediately after the test, and compared it with a test-only condition. They found no significant difference in performance in the new learning session between them. In our study, the fullinstruction condition, despite providing instruction most frequently, did not yield significantly higher accuracy than the no-instruction condition (Table <ref type="table">S24</ref>). Instead, it led to shorter reaction times than all other conditions (Table <ref type="table" target="#tab_0">S12</ref>), suggesting a decrease in engagement. While instruction provides useful information, it may diminish the desirable difficulty inherent in retrieval effort <ref type="bibr" target="#b4">(Bjork &amp; Bjork, 2011)</ref>. When learners consistently receive instruction, they may extract only the information needed to answer correctly during instruction, and thus fail to learn from it sufficiently to succeed when working independently in novel situations.</p><p>Going beyond previous findings, our study demonstrates that arranging instruction (feature highlighting) and testing without instruction (no feature highlighting) with appropriate timing and frequency plays a crucial role in fostering new learning, as reflected in accuracy in the learning phase. In our study, the blocked-10%, blocked-50%, and mixed-50% conditions improved accuracy in the learning phase compared to the no-instruction condition, and the blocked-10% condition also outperformed the full-instruction condition. These results highlight two critical aspects of the timing and frequency: (1) interspersing tests without instruction by deliberately restricting the frequency of instruction and (2) providing instruction in successive sequences before testing. This appears to balance between the useful information provided by instruction and the desirable difficulty of testing without instruction, enabling learners to acquire knowledge that facilitates subsequent new learning.</p><p>Although our study did not employ the exact control conditions used in prior research on the forward testing effect, this difference can be considered a strength rather than a limitation. Specifically, we compared the experimental conditions against an active control condition that involved testing (the no-instruction condition). In contrast, prior studies have typically used a restudy control condition, in which learners were passively provided with information and did not take any tests. Importantly, the active control condition in our study set a higher bar for demonstrating effects because test conditions have been shown to produce better performance in new learning than restudy conditions <ref type="bibr" target="#b28">(Kang et al., 2023;</ref><ref type="bibr" target="#b36">Lee &amp; Ahn, 2018)</ref>. Against the strong control condition (the no-instruction condition), the blocked-10% strategy still produced significantly higher accuracy in the learning phase. This suggests that its effect size would likely be even larger if tested against a traditional restudy control condition.</p><p>Our findings on the effective combination of instruction and testing may inform instructional practices for real-world educational settings. In school, students learn about the behavior of living creatures in biology classes. Later, they may independently explore the behavior of unfamiliar creatures outside the classroom, using the creatures' responses as feedback. For example, a teacher might present several different examples and successively point out the key characteristics of each one, and then alternate this block of instruction with short quizzes. This combined approach may allow students to extract effective learning strategies from the instruction and subsequently apply them when exploring the behavior of unfamiliar creatures on their own. The present findings for the adaptive condition suggest that the effects of adaptive instruction reported in previous research on motivation may have been confounded with other pedagogical factors (e.g., instructional methods). Adaptive instruction has been regarded as one of several important practices in motivation research <ref type="bibr" target="#b0">(Aelterman et al., 2019)</ref>. The existing evidence for its effect has come from surveys or interventions that combined multiple instructional techniques, as reflected in a recent meta-analysis <ref type="bibr">(Patall et al., 2023)</ref>. However, these methodologies were limited in their internal validity. Our findings point to a potential confound that the positive effects of the adaptive condition in Experiments 1 and 2 might be attributable to its incidental use of a more blocked presentation compared to Experiment 3. This suggests that, more broadly, positive outcomes often attributed to adaptive instruction in less controlled settings may in fact be driven by confounding strategies-such as blocked presentation-rather than by adaptivity itself. Future research should use experimental methods to isolate the unique effect of adaptive instruction from other confounding pedagogical factors.</p><p>In the present study, the adaptive instruction algorithm has several aspects that could be improved. First, the algorithm relied on only two indicators to estimate learners' understanding: classification accuracy and the number of trials needed to reach a mastery level. However, in real world settings, a wider range of methods can be used to assess learner understanding. For example, teachers may infer understanding based on facial expressions, tone of voice, and reaction time. Incorporating a broader range of estimation methods may enable more precise assessments and allow the algorithm to support learners more appropriately in timing and frequency.</p><p>Second, the algorithm adjusted only partial aspects of instruction. Specifically, the adaptive algorithm adjusted for the timing of providing feature highlighting and for which items feature highlighting was presented. However, it did not adjust the quality of instruction. For example, it neither varied the number of highlighted features, nor employed different types of instruction (e.g., explanations of category rules or prompts addressing common errors). Such diverse and flexible adjustments may make adaptive instruction more attuned to learners' needs.</p><p>Third, the simplicity of the experimental task constrained the reliability and breadth of the indicators used for the algorithm. In the experimental task, we employed a binary-choice format in which participants could respond correctly by chance even without a full understanding of the category. In contrast, response formats with more options or open-ended responses may offer a more accurate assessment of learners' understanding. Moreover, real-world learning situations often involve more complex and heterogeneous content than our experimental task.</p><p>Under such conditions, the algorithm may become more effective if it incorporates more granular, multi-step adjustments to accommodate the substantial variability across individual learners. Refining these aspects in future research may help improve the design of adaptive strategies and yield more definitive implications for motivation research.</p><p>A limitation of this study is that we examined our instructional strategies only within a category learning paradigm, leaving it unclear whether the findings can be extended to other learning contexts. Future research should therefore investigate the effectiveness of a blocked-10% strategy in promoting new learning in other tasks. For example, using a probabilistic reversal learning task, we could test its effect on learners' ability to infer the abstract rule in new situations <ref type="bibr" target="#b26">(Hampton et al., 2006;</ref><ref type="bibr" target="#b37">Marković et al., 2019)</ref>. In this task, learners choose between two options with different reward probabilities that periodically reverse. This requires learners to identify the underlying rule by which the reward probabilities switch. A blocked-10% strategy could provide a block of infrequent trials highlighting the currently optimal choice, followed by a block of no-highlighting trials. Compared to no-instruction or full-instruction, this strategy may enhance both task engagement and the acquisition of an effective learning strategy for identifying the underlying rule, which, in turn, may foster better performance when learners encounter a new underlying rule.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In the present study, we investigated which timing and frequency strategies best foster new learning. Our findings demonstrated that the blocked-10% strategy-which involved the successive presentation of instructions, an increased frequency of tests without instruction, and alternation between them-fostered the ability to independently discover correct knowledge in novel situations, but did not enhance generalization. This effect is likely driven by increased task engagement and the development of effective learning strategies during instruction. By contrast, the adaptive strategy-which dynamically adjusts instruction according to learners' performance-did not yield significant effects under the conditions of the present study. To foster new learning, teachers might consider alternating between providing successive instructions and giving learners more opportunities to work on their own. Footnote 1 In our preregistration, we initially identified recognition accuracy as a potential mediator. However, we treated recognition accuracy as a dependent variable, consistent with a previous category learning study <ref type="bibr" target="#b9">(Bowman &amp; Zeithamova, 2020)</ref>. The results of the recognition accuracy analysis are reported in the SI (Table <ref type="table" target="#tab_2">S25</ref>), because they fall outside the primary scope of the present study.</p><p>2 Before Experiment 3, we analyzed the data from Experiment 2 and confirmed that accuracy in the no-highlighting trials of the adaptive condition improved from teaching session 1 to session 2, but not from session 2 to session 3 (Figure <ref type="figure" target="#fig_0">S11</ref>). These results suggest that two sessions were sufficient to capture the effects of the adaptive strategy. Block 2 Block 3 Blocked-50% 0,0,0,0,0,0,0,0,0,0,0,0,0,0 1,1,1,1,1,1,1,1,1,1,1,1,1,1 0,0,0,0,0,0,0,0,0,0,0,0,0,0 Blocked-10% 0,0,0,0,0,0,0,0,0,0,0,0,0,0 1,1,1,1,0,0,0,0,0,0,0,0,0,0 0,0,0,0,0,0,0,0,0,0,0,0,0,0 Mixed-50% 0,1,0,0,1,1,0,1,1,1,0,0,0,1 1,0,1,0,0,0,1,1,0,0,0,1,1,1 0,1,1,0,0,1,0,0,1,0,1,1,0,1 Mixed-10% 0,0,0,0,0,0,1,0,0,0,0,1,0,0 0,0,0,0,0,0,1,0,0,0,0,0,0,1 0,0,0,0,0,1,0,0,0,0,0,0,1,0 Block 4 Block 5 Block 6 Blocked-50% 1,1,1,1,1,1,1,1,1,1,1,1,1,1 0,0,0,0,0,0,0,0,0,0,0,0,0,0 1,1,1,1,1,1,1,1,1,1,1,1,1,1 Blocked-10% 1,1,1,1,0,0,0,0,0,0,0,0,0,0 0,0,0,0,0,0,0,0,0,0,0,0,0,0 1,1,1,1,0,0,0,0,0,0,0,0,0,0 Mixed-50% 0,1,1,1,0,1,1,1,0,0,0,1,0,0 0,1,0,0,1,0,1,1,1,0,0,1,1,0 1,0,0,1,1,0,1,0,0,1,0,1,0,1 Mixed-10% 0,0,0,1,0,0,0,0,1,0,0,0,0,0 1,0,0,0,0,0,0,0,0,1,0,0,0,0 0,0,0,1,0,0,0,0,0,0,1,0,0,0 Generalization phase (30 trials) Blocked-50% 0,0,0,0,0, 1,1,1,1,1, 0,0,0,0,0, 1,1,1,1,1, 0,0,0,0,0, 1,1,1,1,1 Blocked-10% 0,0,0,0,0, 1,0,0,0,0, 0,0,0,0,0, 1,0,0,0,0, 0,0,0,0,0, 1,0,0,0,0 Mixed-50% 0,0,1,0,0, 1,1,0,1,1, 1,0,1,0,1, 0,0,1,1,0, 1,1,0,0,1, 1,0,1,0,0 Mixed-10% 0,0,0,0,0, 0,0,1,0,0, 0,0,0,0,0, 0,0,0,1,0, 0,0,0,0,0, 0,1,0,0,0 Note. 0 = no-feature highlighting trial; 1 = feature highlighting trial. The timing of feature highlighting was fixed in the blocked conditions and pseudo-randomized in the mixed conditions. = standardized partial regression coefficient. Each regression was conducted using a data subset that included the listed experimental condition and the two control conditions (no-instruction and full-instruction). Coefficients were tested using one-tailed tests. Control variables (baseline accuracy in the generalization phase and baseline reaction time) were included in the model but are not reported in the table for brevity.  <ref type="bibr">-.11, .08</ref>] .05 -0.28 .610 Note. b * = standardized partial regression coefficient. Each regression was conducted using a data subset that included the listed experimental condition and the two control conditions (no-instruction and full-instruction). Coefficients were tested using one-tailed tests. Control variables (baseline accuracy in the learning phase and baseline reaction time) were included in the model but are not reported in the table for brevity. Participants categorized each item at their own pace by pressing the "f" or "j" key. In the teaching sessions (upper panels), feature highlighting was provided depending on the condition, highlighting relevant features with red or blue circles. In the independent session (lower panels), participants classified items from a new type of creature without feature highlighting. Each session included both the learning and generalization phases, except that in Experiment 1 the teaching sessions did not include the generalization phase. In the learning phase, participants classified each item, followed by feedback. In the generalization phase, participants classified both the same items and novel items from the same creature, and feedback was not provided for these classifications. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 An</head><label>1</label><figDesc>Figure 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 DescriptiveFigure 4 Figure 5</head><label>345</label><figDesc>Figure 3</figDesc><graphic coords="66,73.40,144.33,468.00,224.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="67,57.84,161.23,443.56,216.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="67,57.84,421.88,443.60,221.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="69,73.40,153.33,468.00,157.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="69,73.40,334.60,468.00,157.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Demographic Characteristics and Condition Assignments of Participants</figDesc><table><row><cell></cell><cell>Experiment 1</cell><cell>Experiment 2</cell><cell>Experiment 3</cell></row><row><cell>Recruited (n)</cell><cell>172</cell><cell>196</cell><cell>1,199</cell></row><row><cell>Final sample (n)</cell><cell>170</cell><cell>195</cell><cell>1,157</cell></row><row><cell>Age (M ± SD)</cell><cell>35.42 ± 7.99</cell><cell>32.88 ± 7.77</cell><cell>34.10 ± 7.75</cell></row><row><cell>Female</cell><cell>75</cell><cell>69</cell><cell>607</cell></row><row><cell>Male</cell><cell>94</cell><cell>124</cell><cell>542</cell></row><row><cell>Other</cell><cell>0</cell><cell>1</cell><cell>6</cell></row><row><cell>Not reported</cell><cell>1</cell><cell>1</cell><cell>2</cell></row><row><cell>Compensation</cell><cell>£3.80</cell><cell>£4.50</cell><cell>£3.75</cell></row><row><cell>Condition assignment (n)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>No-instruction</cell><cell>66</cell><cell>61</cell><cell>142</cell></row><row><cell>Full-instruction</cell><cell>53</cell><cell>69</cell><cell>145</cell></row><row><cell>Adaptive</cell><cell>51</cell><cell>65</cell><cell>142</cell></row><row><cell>Blocked-50%</cell><cell>-</cell><cell>-</cell><cell>146</cell></row><row><cell>Blocked-10%</cell><cell>-</cell><cell>-</cell><cell>147</cell></row><row><cell>Mixed-50%</cell><cell>-</cell><cell>-</cell><cell>143</cell></row><row><cell>Mixed-10%</cell><cell>-</cell><cell>-</cell><cell>151</cell></row><row><cell>Choice</cell><cell>-</cell><cell>-</cell><cell>141</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3</head><label>3</label><figDesc>Timing and Frequency of Feature Highlighting in the Blocked and Mixed Conditions Learning phase (14 trials per block) Block 1</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 5</head><label>5</label><figDesc>Effects of Each Contrast on Accuracy in the Generalization Phase(Experiment 3)    </figDesc><table><row><cell>Experimental Condition</cell><cell>Contrast</cell><cell>b *</cell><cell>95% CI</cell><cell>SE</cell><cell>t</cell><cell>p</cell></row><row><cell>Blocked-50%</cell><cell>No-instruction contrast</cell><cell cols="5">.03 [-.06, .12] .05 0.60 .276</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">-.03 [-.12, .06] .05 -0.62 .734</cell></row><row><cell>Blocked-10%</cell><cell>No-instruction contrast</cell><cell cols="5">.05 [-.04, .14] .05 1.12 .131</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">.00 [-.09, .09] .05 -0.06 .523</cell></row><row><cell>Mixed-50%</cell><cell>No-instruction contrast</cell><cell cols="5">.08 [-.02, .17] .05 1.62 .053</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">.03 [-.07, .12] .05 0.53 .299</cell></row><row><cell>Mixed-10%</cell><cell>No-instruction contrast</cell><cell cols="5">-.03 [-.13, .06] .05 -0.74 .770</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">-.09 [-.18, .00] .05 -1.89 .970</cell></row><row><cell>Choice</cell><cell>No-instruction contrast</cell><cell cols="5">-.01 [-.11, .08] .05 -0.29 .613</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">-.07 [-.17, .02] .05 -1.58 .942</cell></row><row><cell>Adaptive</cell><cell>No-instruction contrast</cell><cell cols="5">-.01 [-.10, .08] .05 -0.23 .591</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">-.07 [-.16, .03] .05 -1.40 .919</cell></row><row><cell>Note. b *</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6</head><label>6</label><figDesc>Effects of Each Contrast on Accuracy in the Learning Phase(Experiment 3)    </figDesc><table><row><cell>Experimental Condition</cell><cell>Contrast</cell><cell>b *</cell><cell>95% CI</cell><cell>SE</cell><cell>t</cell><cell>p</cell></row><row><cell>Blocked-50%</cell><cell>No-instruction contrast</cell><cell cols="5">.11 [.02, .20] .05 2.45 .007</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">.05 [-.04, .14] .05 1.01 .157</cell></row><row><cell>Blocked-10%</cell><cell>No-instruction contrast</cell><cell cols="5">.14 [.05, .23] .05 3.11 .001</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">.08 [-.01, .17] .05 1.72 .043</cell></row><row><cell>Mixed-50%</cell><cell>No-instruction contrast</cell><cell cols="5">.12 [.02, .21] .05 2.44 .008</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">.06 [-.04, .15] .05 1.19 .118</cell></row><row><cell>Mixed-10%</cell><cell>No-instruction contrast</cell><cell cols="5">.03 [-.06, .12] .05 0.63 .264</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">-.04 [-.13, .06] .05 -0.75 .773</cell></row><row><cell>Choice</cell><cell>No-instruction contrast</cell><cell cols="5">.07 [-.02, .17] .05 1.53 .064</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell cols="5">.01 [-.09, .10] .05 0.13 .446</cell></row><row><cell>Adaptive</cell><cell>No-instruction contrast</cell><cell cols="5">.05 [-.04, .15] .05 1.10 .137</cell></row><row><cell></cell><cell>Full-instruction contrast</cell><cell>-.01 [</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>In both the blocked-10% and mixed-10% conditions, the proportion of feature highlighting trials in the learning phase was approximately 14%, because the number of trials in that phase was not a multiple of 10.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>We also fit the exemplar model, in which similarity was computed between each generalization item and all exemplars presented during the learning phase(Nosofsky, 1987). However, because a greater number of participants were better fit by the prototype model (TableS26), we used the estimates derived from the prototype model as indices of learning strategies in the present study.</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>This study was supported by two grants-in-aid from <rs type="funder">Japan Society</rs> for the Promotion of Science: 1) Grant Number <rs type="grantNumber">23K12879</rs> (to K.K.) and 2) Grant Number <rs type="grantNumber">JP19K24680</rs> (to K.I.).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_U3nyreU">
					<idno type="grant-number">23K12879</idno>
				</org>
				<org type="funding" xml:id="_4TtCAtz">
					<idno type="grant-number">JP19K24680</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2 Overview of the Eight Conditions in Experiment 3</head><p>Condition Description 1 No-instruction No feature highlighting was provided on any trial.</p><p>2 Full-instruction Feature highlighting was provided on every trial.</p><p>3 Blocked-50%</p><p>Feature highlighting and no-feature highlighting trials were grouped into separate blocks and presented in a fixed sequence (50% of trials included feature highlighting).</p><p>4 Blocked-10%</p><p>Feature highlighting and no-feature highlighting trials were grouped into separate blocks and presented in a fixed sequence (10% of trials included feature highlighting).</p><p>5 Mixed-50% Feature highlighting and no-feature highlighting trials were mixed in a pseudorandom sequence (50% of trials included feature highlighting).</p><p>6 Mixed-10% Feature highlighting and no-feature highlighting trials were mixed in a pseudorandom sequence (10% of trials included feature highlighting).</p><p>7 Choice Participants first attempted each trial without feature highlighting and then decided whether to receive it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Adaptive</head><p>The algorithm estimated learners' ability in real time and dynamically adjusted whether to provide feature highlighting. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Toward an integrative and fine-grained insight in motivating and demotivating teaching styles: The merits of a circumplex approach</title>
		<author>
			<persName><forename type="first">N</forename><surname>Aelterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vansteenkiste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Haerens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Soenens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R J</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reeve</surname></persName>
		</author>
		<idno type="DOI">10.1037/edu0000293</idno>
		<ptr target="https://doi.org/10.1037/edu0000293" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="497" to="521" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Instruction based on adaptive learning technologies</title>
		<author>
			<persName><forename type="first">V</forename><surname>Aleven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Glenn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Koedinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of research on learning and instruction</title>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mayer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Alexander</surname></persName>
		</editor>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="522" to="560" />
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Bayesian network metaanalysis to synthesize the influence of contexts of scaffolding use on cognitive outcomes in STEM education</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Belland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lefler</surname></persName>
		</author>
		<idno type="DOI">10.3102/0034654317723009</idno>
		<ptr target="https://doi.org/10.3102/0034654317723009" />
	</analytic>
	<monogr>
		<title level="j">Review of Educational Research</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1042" to="1081" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Computational models for the combination of advice and individual learning</title>
		<author>
			<persName><forename type="first">G</forename><surname>Biele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gonzalez</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1551-6709.2009.01010.x</idno>
		<ptr target="https://doi.org/10.1111/j.1551-6709.2009.01010.x" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="206" to="242" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Making things hard on yourself, but in a good way: Creating desirable difficulties to enhance learning</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Bjork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bjork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Psychology and the real world: Essays illustrating fundamental contributions to society</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Gernsbacher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Pew</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Hough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Pomerantz</surname></persName>
		</editor>
		<imprint>
			<publisher>Worth Publishers</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="59" to="68" />
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Self-regulated learning: Beliefs, techniques, and illusions</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bjork</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dunlosky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kornell</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-113011-143823</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-113011-143823" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="417" to="444" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The double-edged sword of pedagogy: Instruction limits spontaneous exploration and discovery</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bonawitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shafto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gweon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Spelke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2010.10.001</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2010.10.001" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="322" to="330" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The effects of age on category learning and prototype-and exemplar-based generalization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Iwashita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zeithamova</surname></persName>
		</author>
		<idno type="DOI">10.1037/pag0000714</idno>
		<ptr target="https://doi.org/10.1037/pag0000714" />
	</analytic>
	<monogr>
		<title level="j">Psychology and Aging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="800" to="815" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Abstract memory representations in the ventromedial prefrontal cortex and hippocampus support concept generalization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zeithamova</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.2811-17.2018</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.2811-17.2018" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2605" to="2614" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Training set coherence and set size effects on concept generalization and recognition</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zeithamova</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0000824</idno>
		<ptr target="https://doi.org/10.1037/xlm0000824" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1442" to="1464" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Can patients with Alzheimer&apos;s disease learn a category implicitly?</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bozoki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">E</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2005.08.001</idno>
		<ptr target="https://doi.org/10.1016/j.neuropsychologia.2005.08.001" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="816" to="827" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The science of effective learning with spacing and retrieval practice</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Butler</surname></persName>
		</author>
		<idno type="DOI">10.1038/s44159-022-00089-1</idno>
		<ptr target="https://doi.org/10.1038/s44159-022-00089-1" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Psychology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="496" to="511" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Appearances can be deceiving: Instructor fluency increases perceptions of learning without increasing actual learning</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Wilford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kornell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Mullaney</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-013-0442-z</idno>
		<ptr target="https://doi.org/10.3758/s13423-013-0442-z" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1350" to="1356" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The benefits of interleaved and blocked study: Different tasks benefit from different schedules of study</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Goldstone</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-014-0676-4</idno>
		<ptr target="https://doi.org/10.3758/s13423-014-0676-4" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="281" to="288" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The sequence of study changes what information is attended to, encoded, and remembered during category learning</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Goldstone</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0000406</idno>
		<ptr target="https://doi.org/10.1037/xlm0000406" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1699" to="1719" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Testing potentiates new learning across a retention interval and a lag: A strategy change perspective</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C K</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Manley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Szpunar</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jml.2018.05.007</idno>
		<ptr target="https://doi.org/10.1016/j.jml.2018.05.007" />
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="83" to="96" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Retrieval potentiates new learning: A theoretical and meta-analytic review</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C K</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Meissner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Davis</surname></persName>
		</author>
		<idno type="DOI">10.1037/bul0000166</idno>
		<ptr target="https://doi.org/10.1037/bul0000166" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1111" to="1146" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Applied multiple regression/correlation analysis for the behavioral sciences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Aiken</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Lawrence Erlbaum Associates</publisher>
		</imprint>
	</monogr>
	<note>rd ed.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cumming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">jsPsych: A JavaScript library for creating behavioral experiments in a Web browser</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>De Leeuw</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-014-0458-y</idno>
		<ptr target="https://doi.org/10.3758/s13428-014-0458-y" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The underappreciated benefits of interleaving for category learning</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Do</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Thomas</surname></persName>
		</author>
		<idno type="DOI">10.3390/jintelligence11080153</idno>
		<ptr target="https://doi.org/10.3390/jintelligence11080153" />
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligence</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">153</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Overconfidence produces underachievement: Inaccurate self evaluations undermine students&apos; learning and retention</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dunlosky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Rawson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.learninstruc.2011.08.003</idno>
		<ptr target="https://doi.org/10.1016/j.learninstruc.2011.08.003" />
	</analytic>
	<monogr>
		<title level="j">Learning and Instruction</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="271" to="280" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improving students&apos; learning with effective learning techniques: Promising directions from cognitive and educational psychology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dunlosky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Rawson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Marsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Nathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Willingham</surname></persName>
		</author>
		<idno type="DOI">10.1177/1529100612453266</idno>
		<ptr target="https://doi.org/10.1177/1529100612453266" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science in the Public Interest</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="58" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">G*Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-G</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03193146</idno>
		<ptr target="https://doi.org/10.3758/BF03193146" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="191" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Techniques for scaffolding retrieval practice: The costs and benefits of adaptive versus diminishing cues</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Fiechter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Benjamin</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-019-01617-6</idno>
		<ptr target="https://doi.org/10.3758/s13423-019-01617-6" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1666" to="1674" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning and transfer: A general role for analogical encoding</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gentner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Loewenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Thompson</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-0663.95.2.393</idno>
		<ptr target="https://doi.org/10.1037/0022-0663.95.2.393" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="393" to="408" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Hampton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bossaerts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Doherty</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.1010-06.2006</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.1010-06.2006" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">32</biblScope>
			<biblScope unit="page" from="8360" to="8367" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Timing of quizzes during learning: Effects on motivation and retention</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Lalchandani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Tack</surname></persName>
		</author>
		<idno type="DOI">10.1037/xap0000123</idno>
		<ptr target="https://doi.org/10.1037/xap0000123" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Applied</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">128</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">When more is not better: Effects of interim testing and feature highlighting in natural category learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10648-023-09772-y</idno>
		<ptr target="https://doi.org/10.1007/s10648-023-09772-y" />
	</analytic>
	<monogr>
		<title level="j">Educational Psychology Review</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">51</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Retrieval practice produces more learning than elaborative studying with concept mapping</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Karpicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Blunt</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1199327</idno>
		<ptr target="https://doi.org/10.1126/science.1199327" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">331</biblScope>
			<biblScope unit="issue">6018</biblScope>
			<biblScope unit="page" from="772" to="775" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Repeated retrieval during learning is the key to long-term retention</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Karpicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Roediger</surname></persName>
		</author>
		<author>
			<persName><surname>Iii</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jml.2006.09.004</idno>
		<ptr target="https://doi.org/10.1016/j.jml.2006.09.004" />
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="162" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The critical importance of retrieval for learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Karpicke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Roediger</surname></persName>
		</author>
		<author>
			<persName><surname>Iii</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1152408</idno>
		<ptr target="https://doi.org/10.1126/science.1152408" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">319</biblScope>
			<biblScope unit="issue">5865</biblScope>
			<biblScope unit="page" from="966" to="968" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Exploring the assistance dilemma in experiments with cognitive tutors</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Koedinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Aleven</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10648-007-9049-0</idno>
		<ptr target="https://doi.org/10.1007/s10648-007-9049-0" />
	</analytic>
	<monogr>
		<title level="j">Educational Psychology Review</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="239" to="264" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning concepts and categories: Is spacing the &quot;enemy of induction</title>
		<author>
			<persName><forename type="first">N</forename><surname>Kornell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bjork</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.2008.02127.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-9280.2008.02127.x" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="585" to="592" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">ALCOVE: A connectionist model of human category learning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.99.1.22</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.99.1.22" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="44" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A meta-analytic review of the benefit of spacing out retrieval practice episodes on retention</title>
		<author>
			<persName><forename type="first">A</forename><surname>Latimier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Peyre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ramus</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10648-020-09572-8</idno>
		<ptr target="https://doi.org/10.1007/s10648-020-09572-8" />
	</analytic>
	<monogr>
		<title level="j">Educational Psychology Review</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="959" to="987" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Testing prepares students to learn better: The forward effect of testing in category learning</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ahn</surname></persName>
		</author>
		<idno type="DOI">10.1037/edu0000211</idno>
		<ptr target="https://doi.org/10.1037/edu0000211" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="217" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Predicting change: Approximate inference under explicit representation of temporal structure in changing environments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M F</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Kiebel</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1006707</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1006707" />
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1006707</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Combining retrieval practice with elaborative encoding: Complementary or redundant?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcdaniel</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10648-023-09784-8</idno>
		<ptr target="https://doi.org/10.1007/s10648-023-09784-8" />
	</analytic>
	<monogr>
		<title level="j">Educational Psychology Review</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">75</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Effects of feature highlighting and causal explanations on category learning in a natural-science domain</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Meagher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<idno type="DOI">10.1037/xap0000369</idno>
		<ptr target="https://doi.org/10.1037/xap0000369" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Applied</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="283" to="313" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">People mind wander more during massed than spaced inductive learning</title>
		<author>
			<persName><forename type="first">J</forename><surname>Metcalfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0000216</idno>
		<ptr target="https://doi.org/10.1037/xlm0000216" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="978" to="984" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Prototypes in category learning: The effects of category size, category structure, and stimulus complexity</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Minda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.27.3.775</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.27.3.775" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="775" to="799" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Feature highlighting enhances learning of a complex natural-science category</title>
		<author>
			<persName><forename type="first">T</forename><surname>Miyatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gouravajhala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcdaniel</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0000538</idno>
		<ptr target="https://doi.org/10.1037/xlm0000538" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Attention, similarity, and the identification-categorization relationship</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.115.1.39</idno>
		<ptr target="https://doi.org/10.1037/0096-3445.115.1.39" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="57" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Comparing and combining retrieval practice and concept mapping</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>O'day</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Karpicke</surname></persName>
		</author>
		<idno type="DOI">10.1037/edu0000486</idno>
		<ptr target="https://doi.org/10.1037/edu0000486" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="986" to="997" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Transfer of test-enhanced learning: Meta-analytic review and synthesis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Rickard</surname></persName>
		</author>
		<idno type="DOI">10.1037/bul0000151</idno>
		<ptr target="https://doi.org/10.1037/bul0000151" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="710" to="756" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">When does fading enhance perceptual category learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pashler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Mozer</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0031679</idno>
		<ptr target="https://doi.org/10.1037/a0031679" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1162" to="1173" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Retrieval practice enhances new learning: The forward effect of testing</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pastötter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-H</forename><forename type="middle">T</forename><surname>Bäuml</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2014.00286</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2014.00286" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">83305</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The effects of choice on intrinsic motivation and related outcomes: A meta-analysis of research findings</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Patall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Robinson</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.134.2.270</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.134.2.270" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="270" to="300" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A meta-analysis of teachers&apos; provision of structure in the classroom and students&apos; academic competence beliefs, engagement, and achievement</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Patall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Beretvas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hanson</surname></persName>
		</author>
		<idno type="DOI">10.1080/00461520.2023.2274104</idno>
		<ptr target="https://doi.org/10.1080/00461520.2023.2274104" />
	</analytic>
	<monogr>
		<title level="j">Educational Psychologist</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing</title>
		<author>
			<orgName type="collaboration">R Core Team.</orgName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Version 4.2.0) [Computer software</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<ptr target="https://www.R-project.org/" />
		<title level="m">R Foundation for Statistical Computing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Autonomy-supportive teaching: Its malleability, benefits, and potential to improve educational practice</title>
		<author>
			<persName><forename type="first">J</forename><surname>Reeve</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Cheon</surname></persName>
		</author>
		<idno type="DOI">10.1080/00461520.2020.1862657</idno>
		<ptr target="https://doi.org/10.1080/00461520.2020.1862657" />
	</analytic>
	<monogr>
		<title level="j">Educational Psychologist</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="54" to="77" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Speeding lectures to make time for retrieval practice: Can we improve the efficiency of interpolated testing</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Risko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bianchi</surname></persName>
		</author>
		<idno type="DOI">10.1037/xap0000494</idno>
		<ptr target="https://doi.org/10.1037/xap0000494" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Applied</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="268" to="281" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Metacognition about practice testing: A review of learners&apos; beliefs, monitoring, and control of test-enhanced learning</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Rivers</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10648-020-09578-2</idno>
		<ptr target="https://doi.org/10.1007/s10648-020-09578-2" />
	</analytic>
	<monogr>
		<title level="j">Educational Psychology Review</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="823" to="862" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">The power of testing memory: Basic research and implications for educational practice</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Roediger</surname></persName>
		</author>
		<author>
			<persName><surname>Iii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Karpicke</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1745-6916.2006.00012.x</idno>
		<ptr target="https://doi.org/10.1111/j.1745-6916.2006.00012.x" />
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="210" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">A new stimulus set for cognitive research</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rosedahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Ashby</surname></persName>
		</author>
		<idno type="DOI">10.17605/OSF.IO/2XZ3Q</idno>
		<ptr target="https://doi.org/10.17605/OSF.IO/2XZ3Q" />
	</analytic>
	<monogr>
		<title level="j">PsyArXiv</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">When instructions don&apos;t help: Knowing the optimal strategy facilitates rule-based but not information-integration category learning</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Rosedahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Serota</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Ashby</surname></persName>
		</author>
		<idno type="DOI">10.1037/xhp0000940</idno>
		<ptr target="https://doi.org/10.1037/xhp0000940" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1226" to="1236" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">The effect of testing versus restudy on retention: A meta-analytic review of the testing effect</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Rowland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1432" to="1463" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">When to adjust alpha during multiple testing: A consideration of disjunction, conjunction, and individual testing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rubin</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11229-021-03276-4</idno>
		<ptr target="https://doi.org/10.1007/s11229-021-03276-4" />
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">199</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="10989" to="11018" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Control and information in the intrapersonal sphere: An extension of cognitive evaluation theory</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Ryan</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.43.3.450</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.43.3.450" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="450" to="461" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Self-determination theory: Basic psychological needs in motivation, development, and wellness</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Deci</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>The Guilford Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Lack of pervasiveness of the underconfidence-with-practice effect: Boundary conditions and an explanation via anchoring</title>
		<author>
			<persName><forename type="first">P</forename><surname>Scheck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Nelson</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.134.1.124</idno>
		<ptr target="https://doi.org/10.1037/0096-3445.134.1.124" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="124" to="128" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Stimulus and response generalization: A stochastic model relating generalization to distance in psychological space</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02288967</idno>
		<ptr target="https://doi.org/10.1007/BF02288967" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="325" to="345" />
			<date type="published" when="1957">1957</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">The synergistic relationship of perceived autonomy support and structure in the prediction of selfregulated learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Sierens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vansteenkiste</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Goossens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Soenens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dochy</surname></persName>
		</author>
		<idno type="DOI">10.1348/000709908X304398</idno>
		<ptr target="https://doi.org/10.1348/000709908X304398" />
	</analytic>
	<monogr>
		<title level="j">The British Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="68" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Motivation in the classroom: Reciprocal effects of teacher behavior and student engagement across the school year</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Skinner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Belmont</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-0663.85.4.571</idno>
		<ptr target="https://doi.org/10.1037/0022-0663.85.4.571" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="571" to="581" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Interpolated memory tests reduce mind wandering and improve learning of online lectures</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Szpunar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Y</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Schacter</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1221764110</idno>
		<ptr target="https://doi.org/10.1073/pnas.1221764110" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="6313" to="6317" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">mediation: R package for causal mediation analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Tingley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hirose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Keele</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Imai</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v059.i05</idno>
		<ptr target="https://doi.org/10.18637/jss.v059.i05" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Optimizing multiple-choice questions for retrieval practice: Delayed display of answer alternatives enhances vocabulary learning</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S E</forename><surname>Van Den Broek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Gerritsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">T J</forename><surname>Oomen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Velthoven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">H J</forename><surname>Van Boxtel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Van Gog</surname></persName>
		</author>
		<idno type="DOI">10.1037/edu0000810</idno>
		<ptr target="https://doi.org/10.1037/edu0000810" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1087" to="1109" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Scaffolding in teacher-student interaction: A decade of research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Van De Pol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Volman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beishuizen</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10648-010-9127-6</idno>
		<ptr target="https://doi.org/10.1007/s10648-010-9127-6" />
	</analytic>
	<monogr>
		<title level="j">Educational Psychology Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="271" to="296" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Conducting meta-analyses in R with the metafor package</title>
		<author>
			<persName><forename type="first">W</forename><surname>Viechtbauer</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v036.i03</idno>
		<ptr target="https://doi.org/10.18637/jss.v036.i03" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Increased metamemory accuracy with practice does not require practice with metamemory</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Kuhns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Touron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">W</forename><surname>Mulligan</surname></persName>
		</author>
		<idno type="DOI">10.1177/17470218241269322</idno>
		<ptr target="https://doi.org/10.1177/17470218241269322" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1280" to="1302" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Motivation reconsidered: The concept of competence</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0040934</idno>
		<ptr target="https://doi.org/10.1037/h0040934" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="297" to="333" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Transfer of category learning to impoverished contexts</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Whitehead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De-Jesús-Echevarría</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Egner</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-021-02031-7</idno>
		<ptr target="https://doi.org/10.3758/s13423-021-02031-7" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1035" to="1044" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">The forward effects of testing transfer to different domains of learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-J</forename><surname>Chew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<idno type="DOI">10.1037/edu0000321</idno>
		<ptr target="https://doi.org/10.1037/edu0000321" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="751" to="763" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">The forward testing effect on self-regulated study time allocation and metamemory monitoring</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<idno type="DOI">10.1037/xap0000122</idno>
		<ptr target="https://doi.org/10.1037/xap0000122" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Applied</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="277" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Enhancing learning and retrieval of new information: A review of the forward testing effect. npj Science of Learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41539-018-0024-y</idno>
		<ptr target="https://doi.org/10.1038/s41539-018-0024-y" />
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Testing potential mechanisms underlying test-potentiated new learning</title>
		<author>
			<persName><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0001021</idno>
		<ptr target="https://doi.org/10.1037/xlm0001021" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1127" to="1143" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Brain mechanisms of concept learning</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zeithamova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Mack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Braunlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Seger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Van Kesteren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
