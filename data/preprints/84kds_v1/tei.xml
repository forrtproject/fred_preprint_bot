<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Speakers strategically adjust their descriptions based on perceived memorability</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Urvi</forename><surname>Suwal</surname></persName>
							<email>urvi.suwal@yale.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
								<address>
									<settlement>New Haven</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ben</forename><surname>Morris</surname></persName>
							<email>benjamin.morris@yale.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
								<address>
									<settlement>New Haven</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Qi</forename><surname>Lin</surname></persName>
							<email>qi.lin@riken.jp</email>
							<affiliation key="aff1">
								<orgName type="institution">RIKEN</orgName>
								<address>
									<settlement>Wako</settlement>
									<region>Saitama</region>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Paula</forename><surname>Rubio-Fernández</surname></persName>
							<email>paula.rubiofernandez@mpi.nl</email>
							<affiliation key="aff2">
								<orgName type="department">Max Planck Institute for Psycholinguistics</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julian</forename><surname>Jara-Ettinger</surname></persName>
							<email>julian.jara-ettinger@yale.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
								<address>
									<settlement>New Haven</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Speakers strategically adjust their descriptions based on perceived memorability</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8E0E66B3FED098C9471A79DAAE9C5CC1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-21T13:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>communication</term>
					<term>theory of mind</term>
					<term>memory</term>
					<term>reference</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>When talking about the world in front of us, humans are remarkably efficient communicators. Our referential expressions help listeners efficiently find what we're talking about by strategically adding color or material words as needed. But most conversations are about things that are not physically in front of us. In these cases, do we also use language to efficiently help a listener retrieve an item from memory? Across two experiments, we asked participants to describe images to help a listener recall each image. In Experiment 1 (total n = 600), participants spontaneously incorporated expectations about memorability, providing relatively more description for images that people expect to be less memorable. In Experiment 2 (n = 300), we replicated this pattern even when participants had no access to or knowledge of their listener's prior experience. Interestingly, people's descriptions were more aligned with subjective estimates of memorability, rather than objective, empiricallyderived metrics. Together, this work provides new evidence that speakers spontaneously guide listeners' mental processes to effectively facilitate their memory recall.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Humans are remarkably efficient communicators. The need for efficiency exerts a pressure that fundamentally shapes language, driving how we speak and how we understand others <ref type="bibr" target="#b5">(Gibson et al., 2019)</ref>. Efficiency is partly captured by the Gricean Maxim of Quantity: to provide as much information as needed, but no more <ref type="bibr" target="#b6">(Grice, 1975)</ref>. Of course, determining what is "efficient" is not trivial and cannot be done in a vacuum, but instead, efficiency is profoundly shaped by the context at hand and who we are speaking to (e.g., <ref type="bibr" target="#b4">Fussell &amp; Krauss, 1992;</ref><ref type="bibr" target="#b14">Rubio-Fernandez &amp; Jara-Ettinger, 2020;</ref><ref type="bibr" target="#b17">Sedivy et al., 1999)</ref>.</p><p>Efficiency shapes language at every scale, from the longterm development of a lexicon (e.g., <ref type="bibr" target="#b10">Kemp &amp; Regier, 2012)</ref> to the real-time unfolding of an utterance (e.g., <ref type="bibr" target="#b16">Sedivy, 2005)</ref>. Efficiency has often been formalized as the minimum amount of information needed to convey a message, such that saying "the red mug" is efficient if multiple mugs are present, but redundant or overinformative if it is the only mug present (e.g., <ref type="bibr" target="#b3">Engelhardt et al., 2006)</ref>.</p><p>Importantly, speakers are not just planning efficiency over an entire utterance, but instead generating referential expressions that account for a listener's real-time incremental processing as that expression unfolds. This perspective sheds light on why speakers sometimes produce seemingly overinformative descriptions, such as saying "the red mug" when no other mugs are present to contrast with <ref type="bibr" target="#b1">(Degen et al., 2020;</ref><ref type="bibr">Rubio-Fernandez, 2016;</ref><ref type="bibr" target="#b13">Rubio-Fernandez, 2019)</ref>. In a complex scene or a scene where redness is particularly salient (even with no other mugs), speakers may provide this additional color information not because it is strictly necessary, but instead to minimize the effort needed for the listener to identify the referent <ref type="bibr" target="#b8">(Jara-Ettinger &amp; Rubio-Fernandez, 2022)</ref>. That is, as the expression unfolds, the listener will be able to identify the target referent more quickly with this additional information; and thus the speaker is facilitating the listener's visual search accounting for this real-time processing <ref type="bibr">(Rubio-Fernandez, 2016;</ref><ref type="bibr" target="#b8">Jara-Ettinger &amp; Rubio-Fernandez, 2022)</ref>.</p><p>And yet much of communication (even just much of referential communication) is about topics that are displaced from the here-and-now, rather than about the world around us (e.g., <ref type="bibr" target="#b2">Dunbar, 2004)</ref>. Is this pressure for speakers to spontaneously facilitate reference resolution limited to the narrow set of communicative interactions dealing with physical reference? This might be the case for two reasons. First, it could be that this capacity is limited to guiding attention, as this is a universal feature of language use (Jara-Ettinger &amp; Rubio-Fernandez, 2024), and people might not have a similar capacity for guiding other cognitive processes like memory. Second, it may be relatively easy to align attention in physical space because the referential space is concrete and typically co-experienced. When people are instead talking about what happened last week, what is happening at work, or some more abstract concept-visual attention is no longer at play and people might have a less clear sense of the space of alternatives that the listener is considering. Nevertheless, if language users are efficient communicators, we hypothesized the capacity to efficiently guide the listener to the intended referent should generalize to memory search.</p><p>In the current work, we focus on when people are talking about things in memory (rather than things directly in front of them). For example: imagine telling a friend "Remember that time we got lost on that hike?" to elicit a memory recall of an event experienced together. We hypothesize that in such situations, people may spontaneously and effectively speak in a way that helps others recall things. That is, in much the same way that speakers work to facilitate the listener's visual search, speakers may also work to facilitate the listener's mental search through memory space. If speakers aim to produce descriptions to facilitate efficient memory recall, we hypothesized that they should be sensitive to the memorability of what they are describing. For example: if you were trying to get a friend to recall a shared trip to Disneyland, it would be safe to assume that it is a rare and memorable occurrence and that the memory would be easy to retrieve with relatively little information. If instead, you were trying to get that friend to recall one of many shared trips to a favorite cafe, you might provide much more information to help them recall the specific trip you are remembering.</p><p>In two experiments, we asked participants to describe images to a hypothetical partner with the goal of helping them recall the target image. The images varied in their underlying memorability, an index of their item-level likelihood to be remembered on average (see Experiment 1 or Rust &amp; Mehrpour, 2020 for details). We then analyzed the length of description participants provide to the listener as a function of the image's expected memorability, based on both subjective expectations and objective empirical metrics of memorability <ref type="bibr" target="#b11">(Navarro-Báez et al., 2024)</ref>. We included both subjective (people's intuitive beliefs about how memorable an image is) and objective measures of memorability (empirical estimates of how memorable the image actually is) because prior work has indicated that these two can diverge (e.g., <ref type="bibr" target="#b7">Isola et al., 2013)</ref>. We hypothesized that speakers would adjust their description length as a function of how memorable an image is, a pattern of production that would selectively and effectively facilitate a listener's memory search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>Experiment 1 tests how the length of description people produce for an image changes when their goal is to help someone else recall that image. Specifically, we test how description length varies based on the image's objective memorability and subjective memorability. Objective memorability is an item-level metric that captures the empirical memorability rate for an image (x). It is measured using a repeat detection task in which participants view a sequence of images and identify when an image is repeated. The objective memorability score is calculated for each item as the percentage of correct detections made by participants. Subjective memorability scores are the average of two metamemory judgement scores for each scene image -Memory Judgement (MJ) and Judgement of Learning (JOL) <ref type="bibr" target="#b11">(Navarro-Báez et al., 2024)</ref>. MJs are one's belief about how memorable the image is, and JOLs are predictions of one's own later memory performance for the studied image.</p><p>Participants previewed a set of images, shown one at a time, and then wrote descriptions of target images as if they were helping another person recall the image from the set (see Figure <ref type="figure">1</ref>). In a separate survey, we collected a baseline description of each target image. We then analyze people's memory descriptions relative to each image's individual baseline number of words people use, which allows us to control for potential differences that might emerge across images due to differences in the availability of salient or non-Figure <ref type="figure">1</ref>. Example stimuli and experimental design. A) Four example images representing the variability in objective and subjective memorability of our stimuli. In the stimuli set, there were 9 images per group and a total of 36 images. B) Exposure phase of Experiment 1: participants are shown 48 scene images (36 of the images from the stimuli set and 12 filler images) in random order, each displayed for 1 second. C) Target Description phase: After the exposure phase, an image from the exposure phase was presented for 2 seconds after which participants had to write a description to help another person who also saw the exposure phase recall that image. This process was repeated for six test items. Experiment 2 eliminated the Exposure phase, such that participants did not know the identity, quantity, or speed of images the other participant saw. This was done to examine whether people rely on shared knowledge to make adjustments in their communicative style to support memory recall. salient features that introduce differences in the number of words needed to express them. All aspects of the stimuli, experiment, and analyses were pre-registered unless explicitly noted. All materials are available on our online OSF repository: https://osf.io/ewu79/?view_only=b5722c41003c42518346cc 296bf4686f</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Participants 300 adults with US-based IP addresses were recruited via Prolific for the Memory Task (MAge(SD) = 35.6(11.3); 172 women, 125 men, 2 prefer not to say, 1 no response; 186 white, 48 black, 22 Asian, 25 mixed, 13 other, 6 no response). A separate group of 300 participants with USbased IP addresses were recruited via Prolific for the Baseline Task (M Age (SD) = 34.6(10.8); 165 women, 133 men, 2 prefer not to say; 204 white, 33 black, 24 Asian, 27 mixed, 8 other, 4 no response). Stimuli We selected a subset of 36 target images drawn from scene images used by <ref type="bibr" target="#b11">Navarro-Báez et al. (2024)</ref>. We used this dataset because each image had a corresponding subjective memorability and objective memorability scores</p><p>In selecting stimuli, we aimed to capture variability in both objective and subjective memorability scores. To do this, we did a median split over both subjective and objective memorability, categorizing each image as high or low for each measure. This created four groups of images (high subjective, low subjective, high objective, and low objective memorability). From each group, we selected 9 images in a way that represented the full range of the group. This helped us ensure enough variability in both the subjective and objective memorability scale and minimize the correlation between the two variables, so that we could better distinguish which measure of memorability (subjective vs objective) is tied to how people adjust communication to facilitate recall. For the final set of 36 target images, this yielded a correlation value of r=0.38 between objective and subjective memorability scores.</p><p>For counterbalancing, we used six stimuli sets, made up of 6 images from the 36 target images. For both tasks, participants were randomly assigned to one of six stimuli sets (n=50 per set). For each stimuli set, we preserved variation across objective and subjective memorability by randomly drawing an image from each group without replacement (high vs low, subjective vs. objective memorability), giving us 4 initial images. Then 2 additional images were drawn at random from any two separate groups. The full stimuli set configuration was pre-registered.</p><p>For the Exposure Phase (Figure <ref type="figure">1B</ref>), we used a total of 48 images, including all 36 of the target images. For the remaining 12 images, three images from each quadrant were drawn at random from the complete set of images without repetition. Procedure The experiment consisted of a baseline task where participants were simply asked to describe an image, and a memory task, where a separate group of participants saw a set of images and then had to write descriptions that would help another person recall the image. The tasks were implemented using jsPsych <ref type="bibr" target="#b0">(de Leeuw, 2015)</ref>. Memory Task Participants were instructed that they would see a series of images that would change quickly, and to remember the images that appeared. Participants were then shown each of the 48 scene images, one at a time, each displayed for 1 second (Figure <ref type="figure">1B</ref>).</p><p>In the second part of the task, participants completed six Target Description trials (Figure <ref type="figure">1C</ref>). In each of these trials, participants saw an image from the exposure phase for 2 seconds, and they were then asked to write a description that would help another person who also completed the exposure phase (Figure <ref type="figure">1B</ref>) recall the image as quickly as possible. Participants were informed that another person who had seen the images before would be shown the descriptions they provided; they would respond as soon as they recalled the image based on the participant's description. We also reminded participants that the other person would have to respond to their descriptions as quickly as possible. There were 6 target images presented in a random order. Participants had unlimited time to write the description for each image. Baseline Task A separate group of participants completed the Baseline Task, which had the exact structure as the Memory Task except that there was no mention of memory as the purpose. These participants received image exposures and were merely instructed that they would see some images for which they had to write a description as they appeared. Participants were shown 6 target images. Each target image appeared for 2 seconds, followed by a text box with the prompt "Describe the image you just saw". Participants had unlimited time to write the description for each image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>First, as a sanity check, we examined descriptions from the baseline task, which we included on the expectation that people might describe images as a function of memorability differently at baseline and such differences would obscure the ability to detect adjustment. We expected that more memorable images may contain a higher amount of salient features that people feel spontaneously called to mention and thus elicit longer expressions at baseline, counter to our predictions about the communicative setting (see Table <ref type="table">1</ref> for examples). Indeed as expected, at baseline, images with both low objective and subjective memorability had an average description length of 6.67 words, whereas images with high objective and subjective memorability scores had an average description length of 8.93 words.</p><p>To account for these differences, our pre-registered analysis focuses on a measure we call the Recall Description Adjustment-the difference between the average number of words in the description from the Memory Task and the number of words in the baseline description. Similar to the raw description length, higher Recall Description Adjustment values indicate more words, but this measure controls for image-level differences that affect how many words people need to use to refer to what's in an image.</p><p>To test whether people strategically adjust their communication to help memory recall, we calculated the correlation between images' Recall Description Adjustment and their subjective and objective memorability scores. We found a statistically significant negative correlation between the Recall Description Adjustment and subjective memorability (r = -0.37, p = 0.026; Figure <ref type="figure" target="#fig_0">2A</ref>), such that the more subjectively memorable an image is, the fewer words participants used to describe it. This suggests that people may use their intuitive beliefs about memorability to adjust their communication style. While we also found a negative correlation between the Recall Description Adjustment and objective memorability (r = -0.30; Figure <ref type="figure" target="#fig_0">2B</ref>), this was not significant (p = 0.079), suggesting that this effect is driven by subjective rather than objective memorability. Taken together, these results suggest that people adjust how they refer to an image in accordance with their subjective estimate of how memorable an image is.</p><p>To better account for variability across participants and images, we also ran a mixed-effects linear regression predicting the Recall Description Adjustment as a function of subjective memorability, including random intercepts and slopes for both participants and images (the regression included the maximal random-effects structure that allowed the model to converge). This revealed that people indeed adjust their communication style as a function of memorability, using fewer words (relative to baseline) as subjective memorability increases (β = -0.034, p = 0.003).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>In Experiment 1, participants were told that their audience shared the same prior experience with the relevant set of images (i.e. knew exactly what images the hypothetical person had seen and how long each image was displayed). As a result, participants could rely on an expectation of shared knowledge of what other images were in the set. While an expectation of shared knowledge is often the case in physical space (if we're both looking at the same set of objects), fully shared knowledge is almost never the case in memory space. That is, we do not have access to other people's memory of what they have experienced, since memories are unobservable (unlike the shared physical world). Experiment 2 explores whether it is necessary for people to see the full set of alternatives to produce descriptions that support recall. To test this, we ran a modified version of Experiment 1, where participants had no prior exposure to the images before being asked to write descriptions, and thus could not rely on an expectation of fully shared experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Participants 300 adults with US-based IP addresses were recruited via Prolific (MAge (SD) = 34.5 (11.9); 156 women, 142 men, 1 prefer not to say, 1 no response; 159 white, 85 black, 12 Asian, 30 mixed, 10 other, 4 no response). Participants were randomly assigned to one of six conditions (n = 50 per condition). Stimuli Stimuli was the same as those used in Experiment 1. Procedure Experiment 2 followed a similar procedure as Experiment 1, with the only difference being that participants did not complete an Exposure Phase. In Experiment 2, participants read a brief instruction that explained their task was to help others recall something. Participants were told that they would see some images that someone saw in the past and that they had to write some text to help that person recall the image. Unlike Experiment 1, participants did not see the images (Exposure Phase), so they did not know how many images the other person saw, the relative distribution of image categories, the exposure length, or how long ago they were presented. Then, participants were informed that another person who had seen the images before would be shown the descriptions they provided; they would press a button as soon as they recalled the image based on the participant's description. Following this, just like in the second part of Experiment 1, participants completed six Target Description trials (Figure <ref type="figure">1C</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>As pre-registered, we once again calculated the Recall Description Adjustment for each image using the baseline descriptions collected in Experiment 1 (see Exp 1 procedure for motivation and definition). Given that Experiment 1 had already provided support for the role of subjective memorability, in Experiment 2, we focused exclusively on this measure.</p><p>Similar to Experiment 1, a correlation between Recall Description Adjustment and subjective memorability revealed a significant negative correlation (r = -0.40, p = 0.015; Figure <ref type="figure" target="#fig_2">3</ref>), suggesting that people show a stronger decrease relative to baseline for images they subjectively consider to be highly memorable.</p><p>We also wanted to test whether people are making similar adjustments across the two experiments (when they have or do not have full access to all the images another person saw). To test this, we computed the image-level correlation between Recall Description Adjustment across the two experiments. This correlation showed a high significant relationship (r=0.78; p&lt;0.001), suggesting that people may use similar strategies of adjustment in their communicative style across the two experiments despite the difference in access to relevant prior experience. This means that we can use this strategy in real-life conversations even when we don't have full access to what the other person has seen.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>Across two experiments, we show that speakers produce descriptions that spontaneously account for memorability. Specifically, we find that speakers use relatively more words for images that are believed to be less memorable-precisely where a listener may require additional information. In Experiment 1, when participants had full knowledge about the image set, the Recall Description Boost was negatively correlated with subjective memorability judgments, but not objective memorability scores. In Experiment 2, this same relationship with subjective memorability remained even when participants no longer had prior experience with the images (such that they could not straightforwardly rely on their own memory traces of the images). Together, these results suggest that people adjust how they communicate to help others remember.</p><p>These findings provide new evidence on the efficiency of communication. We know that speakers at least sometimes plan utterances by reasoning about how to facilitate a listener's visual search effectively (e.g., Jara-Ettinger &amp; Rubio Fernandez, 2022), but the current work suggests a similar process is at play even when we're not talking about objects in front of us. That is, people are also able to use language to efficiently guide a listener through memory search, providing additional description when the search is likely to be more difficult (because an item is believed to be less memorable). Importantly, the current work thus demonstrates that this is a more general principle of communication, which widely expands the scope of its Table <ref type="table">1</ref>: Two example comparisons between the Baseline descriptions, Memory Task descriptions, and calculated Recall Description Adjustments from Experiment 1. The objective memorability scores for the top and bottom images were 9.47/10 and 6.11/10. Their subjective memorability scores were 6.92/10 and 3.57/10. relevance given that communication is most often displaced from the here-and-now. Indeed, the work also suggests that these principles may be at play in many everyday conversational settings because Experiment 2 suggests that people even make adjustments for other's memory without access to directly shared experiences, as is more reflective of naturalistic contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image</head><p>People's adjustments were correlated with subjective memorability across both experiments, but we did not see evidence that adjustments correlated with objective memorability. In principle, either form of memorability provides a possible index that people could exploit to make these memory based adjustments. For example, it could be that through statistical learning, people develop a sense for memorability without knowing why by aggregating over a large number of experiences, and thus their adjustments would have been correlated with objective memorability. Instead, our results point to a different possibility, namely that people are relying on an intuitive, subjective assessment of how much someone needs to remember, and thus adjustments are correlated with subjective memorability.</p><p>While the production patterns we observe are consistent with language use aimed at facilitating a listener's efficient, real-time memory recall of a given referent, it is important to note that we do not yet know whether these strategies actually support a memory boost for listeners. In future work, we will need to test if these descriptions actually help listeners recall the images more efficiently relative to the baseline. We note that this does not necessarily predict a pattern where highmemorability images are retrieved better than low, given that the efficiency argument implies that speakers are titrating the appropriate amount of description for a given image. Even if these descriptions do not facilitate recall, such a finding would still prompt interesting questions about why speakers are using this strategy, despite somehow failing to actually help.</p><p>It is also important to note that while the current work demonstrates that specifically shared experiences are not necessary for speakers to make memory-based adjustments, this certainly does not mean that shared experiences are not relevant or never impact the kinds of adjustments people make. At a minimum, to the extent that manipulations of the exposure phase yield significant effects (e.g., varying exposure time or manipulating a contrast set), it would suggest that shared experiences do indeed matter for how people make adjustments. For instance, an image that has low subjective memorability (e.g., an unmarked scene of rooftops on the horizon, as in Figure <ref type="figure">1</ref>) could nonetheless be treated as memorable if it was highly distinctive compared with the other images of in the exposure set (e.g., all natural scenes of forests). In such a case, we expect that participants would use relatively fewer words to describe the image, despite its overall low memorability. Thus, while full mutual knowledge is not necessary for the kind of memory-based adjustments we see in the current work, mutual knowledge certainly plays a role in the type of adjustments people are making.</p><p>One limitation of the current approach is that while our hypotheses are more general, our analyses rely on word count as the sole measure of description adjustment. Word count is a fairly coarse measure of informativeness, and thus this limits our ability to capture variation in the content of the descriptions that people produce. Future work could use information-theoretic measures to quantify the amount of information in a description and test whether effects of memorability also shape the content of people's descriptions (beyond just the number of words they use), as we would expect. Overall, the current work demonstrates that people effectively adjust their communication by spontaneously incorporating expectations about the memorability of a referent. Participants were never asked about the memorability of the images, and yet their descriptions are sensitive to subjective memorability estimates, and show a hallmark pattern of efficiency: providing more information precisely when it is needed. Together, this work opens new questions about our ability to use language efficiently to guide listeners not just in their reasoning about physical space, but also in their reasoning about mental space. Furthermore, these adjustments do not strictly rely on shared experience with the other person or even on specific knowledge of what the other person has seen, but rather people are able to engage in memory-based adjustments in many situations even without such privileged access. In natural, everyday conversations, speakers are readily using language designed in a way that helps the listener know what they are referring to and to do so quickly, even when that referent is a thing of the past.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This work was supported by NSF award BCS-2045778. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Experiment 1 Results. Scatterplots showing the correlation between the Recall Description Adjustment and an image's A) subjective memorability (people's belief about how memorable an image is) and B) objective memorability (the true memorability of an image). Recall Description Adjustment is calculated as the difference between the number of words produced for each image in the Memory Task and the Baseline (negative values indicate using fewer words relative to the Baseline Task). Each point represents the average Recall Description Adjustment value for each image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Experiment 2 results. Scatterplot showing the correlation between an image's subjective memorability (x-axis) and its Recall Description Adjustment (y-axis). Each point represents the average Recall Description Adjustment value for each image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="2,75.20,77.95,461.58,153.15" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">jsPsych: A JavaScript library for creating behavioral experiments in a web browser</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>De Leeuw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">When redundancy is useful: A Bayesian approach to &quot;overinformative&quot; referring expressions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Degen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kreiss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000186</idno>
		<ptr target="https://doi.org/10.1037/rev0000186" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="591" to="621" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Gossip in Evolutionary Perspective</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Dunbar</surname></persName>
		</author>
		<idno type="DOI">10.1037/1089-2680.8.2.100</idno>
		<ptr target="https://doi.org/10.1037/1089-2680.8.2.100w" />
	</analytic>
	<monogr>
		<title level="j">Review of General Psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="100" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Do speakers and listeners observe the Gricean Maxim of Quantity?</title>
		<author>
			<persName><forename type="first">P</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ferreira</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jml.2005.12.009</idno>
		<ptr target="https://doi.org/10.1016/j.jml.2005.12.009" />
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="554" to="573" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Coordination of knowledge in communication: Effects of speakers&apos; assumptions about what others know</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Fussell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Krauss</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.62.3.378</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.62.3.378" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="378" to="391" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">How Efficiency Shapes Human Language</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Futrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Piantadosi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Dautriche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mahowald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bergen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2019.02.003</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2019.02.003" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="389" to="407" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Logic and conversation</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Grice</surname></persName>
		</author>
		<idno type="DOI">10.1163/9789004368811_003</idno>
		<ptr target="http://doi.org/10.1163/9789004368811_003" />
	</analytic>
	<monogr>
		<title level="m">Syntax and Semantics</title>
		<title level="s">Speech Acts</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Cole</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Morgan</surname></persName>
		</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1975">1975</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="41" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What makes a photograph memorable</title>
		<author>
			<persName><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2013.200</idno>
		<ptr target="https://doi.org/10.1109/TPAMI.2013.200" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1469" to="1482" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The social basis of referential communication: Speakers construct reference based on listeners&apos; expected visual search</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jara-Ettinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rubio-Fernandez</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000345</idno>
		<ptr target="https://doi.org/10.1037/rev0000345" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1394" to="1413" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Demonstratives as attention tools: Evidence of mentalistic representations within language</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jara-Ettinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rubio-Fernandez</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2402068121</idno>
		<ptr target="https://doi.org/10.1073/pnas.2402068121" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="issue">32</biblScope>
			<biblScope unit="page">121</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Kinship categories across languages reflect general communicative principles</title>
		<author>
			<persName><forename type="first">C</forename><surname>Kemp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Regier</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1218811</idno>
		<ptr target="https://doi.org/10.1126/science.1218811" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="issue">6084</biblScope>
			<biblScope unit="page" from="1049" to="1054" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Predicting the memorability of scene pictures: Improved accuracy through one&apos;s own experience</title>
		<author>
			<persName><forename type="first">S</forename><surname>Navarro-Báez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Undorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<idno type="DOI">10.1177/17470218241239829</idno>
		<ptr target="https://doi.org/10.1177/17470218241239829" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">How Redundant Are Redundant Color Adjectives? An Efficiency-Based Analysis of Color Overspecification</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rubio-Fernández</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2016.00153</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2016.00153" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Overinformative Speakers Are Cooperative: Revisiting the Gricean Maxim of Quantity</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rubio-Fernandez</surname></persName>
		</author>
		<idno type="DOI">10.1111/cogs.12797</idno>
		<ptr target="https://doi.org/10.1111/cogs.12797" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">43</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Incrementality and efficiency shape pragmatics across languages</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rubio-Fernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jara-Ettinger</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1922067117</idno>
		<ptr target="https://doi.org/10.1073/pnas.1922067117" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page" from="13399" to="13404" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Understanding Image Memorability</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><surname>Vahid Mehrpour</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2020.04.001%5C</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2020.04.001" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="557" to="568" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Evaluating explanations for referential context effects: Evidence for Gricean mechanisms in online language interpretation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Sedivy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Approaches to studying world-situated language use: Bridging the language-as-product and language-as-action traditions</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Trueswell</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Tanenhaus</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="345" to="364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Achieving incremental semantic interpretation through contextual representation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Sedivy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Tanenhaus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Carlson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<idno type="DOI">10.1016/s0010-0277(99)00025-6</idno>
		<ptr target="https://doi.org/10.1016/s0010-0277" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="25" to="26" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
