<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">From Talk to Triage: Pluralism is Necessary but Not Sufficient for AI Alignment</title>
				<funder ref="#_eDeRAHR #_cQZhJwj #_uJj9cPj">
					<orgName type="full">Air Force Research Laboratory</orgName>
				</funder>
				<funder>
					<orgName type="full">DARPA</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Brian</forename><surname>Hu</surname></persName>
							<email>brian.hu@kitware.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Kitware, Inc</orgName>
								<address>
									<postCode>12065</postCode>
									<settlement>Clifton Park</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jennifer</forename><surname>Mcvay</surname></persName>
							<email>jennifer.mcvay@caci.com</email>
							<affiliation key="aff1">
								<orgName type="department">Inc Falls Church</orgName>
								<orgName type="institution">CACI</orgName>
								<address>
									<postCode>22042</postCode>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alice</forename><surname>Leung</surname></persName>
							<email>alice.leung@rtx.com</email>
							<affiliation key="aff2">
								<orgName type="laboratory">RTX BBN Technologies Cambridge</orgName>
								<address>
									<postCode>02138</postCode>
									<region>MA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><surname>Chan</surname></persName>
							<email>davidchan@berkeley.edu</email>
							<affiliation key="aff3">
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94611</postCode>
									<settlement>Berkeley Berkeley</settlement>
									<region>CA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rosina</forename><forename type="middle">O</forename><surname>Weber</surname></persName>
							<email>rosina@drexel.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Drexel University Philadelphia</orgName>
								<address>
									<postCode>19104</postCode>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ewart</forename><forename type="middle">J</forename><surname>De Visser</surname></persName>
							<email>ewartdevisser@gmail.com</email>
							<affiliation key="aff5">
								<orgName type="department">De Visser Research Springfield</orgName>
								<address>
									<postCode>22153</postCode>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Amy</forename><surname>Summerville</surname></persName>
							<affiliation key="aff6">
								<orgName type="department">Kairos Research Dayton</orgName>
								<address>
									<postCode>45458</postCode>
									<region>OH</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bharadwaj</forename><surname>Ravichandran</surname></persName>
							<email>barry.ravichandran@kitware.com</email>
							<affiliation key="aff7">
								<orgName type="institution">Kitware, Inc</orgName>
								<address>
									<postCode>12065</postCode>
									<settlement>Clifton Park</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jason</forename><surname>Zhang</surname></persName>
							<email>jzhang@ida.org</email>
							<affiliation key="aff8">
								<orgName type="department">Institute for Defense Analyses Alexandria</orgName>
								<address>
									<postCode>22305</postCode>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matthew</forename><surname>Molineaux</surname></persName>
							<email>matthew.molineaux@parallaxresearch.org</email>
							<affiliation key="aff9">
								<orgName type="institution">Paralax Advanced Research Corporation</orgName>
								<address>
									<postCode>45431</postCode>
									<settlement>Dayton</settlement>
									<region>OH</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
							<email>hengji@illinois.edu</email>
							<affiliation key="aff10">
								<orgName type="institution">University of Illinois Urbana-Champaign Champaign</orgName>
								<address>
									<postCode>61820</postCode>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Arslan</forename><surname>Basharat</surname></persName>
							<email>arslan.basharat@kitware.com</email>
							<affiliation key="aff11">
								<orgName type="institution">Kitware, Inc</orgName>
								<address>
									<postCode>12065</postCode>
									<settlement>Clifton Park</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">From Talk to Triage: Pluralism is Necessary but Not Sufficient for AI Alignment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">64144E52C86CBBDBD53A9A418F6F953F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-21T13:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As AI systems become both more powerful and prevalent, ensuring that their actions align with human values is paramount. The challenge of AI alignment is thus an interdisciplinary one that involves not only a technical challenge for computer science but one with important ties to the psychology of moral values, decision-making, and trust. Early work identified a static set of universal values, without considering the key questions of to whom and to which values AI should be aligned. This perspective paper challenges the notion of universal alignment and instead argues for dynamic, contextspecific alignability across different domains, tasks, and users. Specifically, we emphasize the need to go beyond traditional pluralism and rethink how AI alignment can be achieved through a qualitative and quantitative research process that involves identifying context-specific values, developing alignable AI algorithms using limited human feedback, and evaluating alignment through assessing both an AI's values and actions, while considering how humans trust and delegate to the AI. We discuss several paths forward for our proposed framework, including the potential ethical and societal implications of context-specific alignability, and draw on examples ranging from chatbots to value-aligned decision-making in the medical triage domain.</p><p>Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent advances in artificial intelligence (AI), such as large language models (LLMs) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>, create new possibilities to harness this technology in new and innovative ways. A central question is whether safe and responsible use of AI systems can be achieved by aligning AI actions to human values and intentions <ref type="bibr" target="#b2">[3]</ref>. The increasing use of agentic AI systems, including those capable of autonomous decision-making <ref type="bibr" target="#b3">[4]</ref>, presents additional challenges for alignment. Standard alignment approaches assume the possibility of universal alignment, with a focus on modeling the average preferences of humans using techniques such as reinforcement learning from human feedback (RLHF) <ref type="bibr" target="#b4">[5]</ref>. RLHF typically uses a small and fixed set of values, such as helpful, honest, and harmless <ref type="bibr" target="#b5">[6]</ref>, which have been shown to shape model outputs and improve model performance. However, universal alignment is a static process, computationally expensive, and cannot be easily adapted to new contexts.</p><p>We argue that alignment research must move beyond universal alignment and extend traditional pluralism to also consider context-specific alignability across different domains, tasks, and users. Our position is closely related to recent work on pluralistic alignment <ref type="bibr" target="#b11">[12]</ref>, where AI systems are able to account for, align to, and model trade-offs between diverse user values and perspectives. We extend this prior work by broadening the definition of pluralism, incorporating the need to also align with changing domain-and task-specific values, in addition to user-specific values. While <ref type="bibr" target="#b11">[12]</ref> introduced different types of pluralistic models and benchmarks, we provide an overall human-centric framework for context-specific alignability, including the identification of relevant values and value trade-offs, algorithms for dynamically aligning to these values, and quantified alignment evaluations that incorporate aspects of human trust and delegation that affect AI use and adoption.</p><p>In this paper, we outline our proposed framework and take a multidisciplinary approach that draws on work in decision-making and psychology <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref>. First, we introduce previous work on alignment and highlight the limitations of universal alignment (Sec. 2). Next, we define context-specific alignability and explain why existing alignment approaches do not directly translate across domains, tasks, or users (Sec. 3). In contrast to current alignment research, which presumes the possibility of universal alignment to a small and fixed set of values, we instead propose a three-step framework to incorporate values, algorithms, and evaluations for context-specific alignability (Sec. 4). We start with the need to identify and assess context-specific values that directly impact human actions and decisions (Sec. 4.1). Current alignment algorithms require large amounts of human preference data, which cannot easily be obtained in many real-world settings where human experts are only able to provide limited feedback. As such, we highlight the need for data-efficient alignment algorithms and tunable test-time alignability (Sec. <ref type="bibr">4.2)</ref>. Current alignment evaluations focus on measuring stated values and can easily be gamed, making them unreliable markers of overall progress on alignment <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. Instead, we argue that alignment evaluations should measure expressed values via quantifiable actions and decisions in complex settings, while also incorporating aspects of human trust and delegation to the aligned AI system (Sec. 4.3). To ground our position, we present an example case study around value-aligned decision-making in the medical triage domain (Sec. 5). Finally, we provide additional insights on the ethical and societal implications of context-specific alignability (Sec. 6), and conclude with an overall discussion of our framework and limitations (Sec. 7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>We first summarize current research on AI alignment through the lens of values, algorithms, and evaluations (Figure <ref type="figure">1</ref>). We then note several limitations to this universal alignment approach, highlighting instead the need for context-specific alignability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Universal Alignment</head><p>Values. AI alignment generally focuses on a small and fixed set of values, such as helpfulness, honesty, and harmlessness <ref type="bibr" target="#b5">[6]</ref>. Recent research has started to look at finer-grained values and attributes (e.g. verbosity, correctness) <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>, including work on truthfulness characterization <ref type="bibr" target="#b21">[22]</ref> and scalable AI feedback-refined attributes <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>. Others have investigated alignment with human values using existing frameworks such as the Schwartz Theory of Basic Values <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>, Moral Foundations Theory <ref type="bibr" target="#b26">[27]</ref>, or social norms and ethics <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref>. Across these examples, work on universal alignment has largely prioritized a small subset of all possible human values, with the assumption that static alignment to these values enables use of AI across many different contexts.</p><p>Algorithms. Alignment approaches such as reinforcement learning from human feedback (RLHF) train a reward model on human preference data <ref type="bibr" target="#b29">[30]</ref>, which provides a coarse signal for shaping model outputs (e.g. to produce helpful, honest, and harmless content). RLHF has been used successfully to align large language models (LLMs) to follow instructions and user preferences <ref type="bibr" target="#b4">[5]</ref>. More recent work uses finergrained reward signals <ref type="bibr" target="#b30">[31]</ref> and tool learning <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33]</ref>, which can also provide additional control of LLM outputs at test time <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. Recent attention has also been drawn to pluralistic alignment <ref type="bibr" target="#b35">[36]</ref>, including work on aligning to different cultures <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b36">37]</ref>, demographics <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>, or personas <ref type="bibr" target="#b37">[38]</ref> to ensure that AI systems can address the diverse needs of all people. Alternative alignment strategies include inverse reinforcement learning (IRL) <ref type="bibr" target="#b38">[39]</ref>, constitutional AI <ref type="bibr" target="#b39">[40]</ref>, or multi-agent debate <ref type="bibr" target="#b40">[41]</ref>. Universal alignment algorithms such as RLHF produce an aligned model (generally for a fixed context), but do not address the need for dynamic alignment across different contexts, including varying domains, tasks, and users.</p><p>Evaluations. There are several standard benchmarks for evaluating AI alignment, which can be roughly categorized into human feedback-based <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45]</ref>, LLM feedback-based <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>, or more general LLM bias and safety evaluations <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55]</ref>. These approaches generally assess alignment alongside model performance across several domains and tasks. For chat-based systems, head-to-head rankings of chatbots such as Chatbot Arena <ref type="bibr" target="#b10">[11]</ref> can also be used to evaluate their capabilities, although there are known limitations to these types of leaderboard approaches <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Limitations of Universal Alignment</head><p>Universal versus context-specific alignment. It is unclear whether universal alignment is the correct objective, especially when considering how to align models to different users or tasks. There are many examples of specialist systems that outperform generalist systems on various problems <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58]</ref>, suggesting a similar need for context-specific alignment that can be adapted to different domains, tasks, or users. For instance, the Kaleido model <ref type="bibr" target="#b35">[36]</ref> outperformed a larger GPT-4 model in accuracy and coverage of contextualized values in a large dataset of crowd-sourced scenarios. Universal alignment approaches such as RLHF <ref type="bibr" target="#b4">[5]</ref> are also data intensive, requiring large amounts of high-quality human preference data to learn appropriate reward signals, which limits their applicability in specific contexts. This may be particularly challenging in high-stakes domains, where expert human feedback may be harder to obtain, and there may be novel situations that fall outside of learned values or principles. As a result, an important area of research is how to adapt alignment to potentially dynamic environments or changing contexts <ref type="bibr" target="#b58">[59]</ref> with limited data and based on different domains, tasks, or users.</p><p>Aligning to attitudes versus actions and decisions. Alignment to different values is typically evaluated through text-based surveys or polls <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b36">37]</ref>; while these are supported by the literature on social science, they usually capture stated values through attitudes instead of expressed values through actions and decisions. Within cognitive science, research on human attitudes has identified a congruence principle of attitudes; general attitudes and the endorsement of values ("are you pro-environment") only weakly predict specific actions and decisions (e.g., purchase of an electric vehicle) <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b60">61]</ref>. In addition to establishing that specific decisions are more strongly linked to future decisions than are general attitudes and values, the congruence principle and associated theories note that there are specific contextual constraints on decisions. That is, an individual's goals and priorities may differ across contexts. Similarly, alignment should be considered at the level of the specific context in which an AI system operates under. As a corollary, if what we care about is what an AI system does and not simply believes, we should define values and metrics for alignment at the level of actions and decisions rather than attitudes. We believe that it is important not only to characterize the values AI systems identify with, but also to quantify how these values actually impact their actions and decisions.</p><p>Alignment versus alignability. Alignment generally assumes a static, fixed end to an overall process; while alignability instead suggests a process that is adaptive and can be updated according to user needs or task demands. Whereas "aligned" systems are static and trained once on empirical data (as is common with most existing universal alignment approaches), "alignable" systems are dynamic and continuously updated over time to respond to changing contexts and environments. We argue that more work has to be done on understanding alignability, which also creates a need for alignable algorithms, and not algorithms that are simply aligned.</p><p>Competence versus alignment. Within a domain, there are generally sets of actions and decisions that represent objectively correct or competent choices. Because an AI system should always produce a correct answer on these choices, it need not (and should not) align with a person's level of competence. Indeed, there are inherent risks to empirical alignment <ref type="bibr" target="#b61">[62]</ref>. For example, decisions made by humans under conditions such as time pressure, uncertainty, and limited resources (as is often present in many downstream datasets) can preclude the optimal decision from being accessed or perceived <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b63">64]</ref>. When this happens, AI algorithms trained to produce an "optimal" decision will necessarily become unaligned <ref type="bibr" target="#b64">[65]</ref> with human decisions, deviating from models capable of incorporating context-specific details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">What are examples of context-specific alignability?</head><p>In this paper, we argue against universal alignment and instead that alignment should be performed in a context-specific manner, which shapes what values should be aligned to, how to dynamically align to these values, and how to evaluate whether this alignment is effective. We define context to be a specific combination of domain, task, and user. A domain is a particular application area that may require specialized expertise or knowledge (e.g., healthcare, transportation). A task is a particular problem that may require reasoning and entails a goal that a user wants the AI system to achieve. A user is the group of people or individual interacting with the AI system. Effective alignment is challenging, as it must consider each of these three components and adapt alignment of the AI system to different contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Alignment to Different Domains</head><p>Many critical domains, such as healthcare, finance, transportation, etc. may require aligning to domain-specific values that are not traditionally covered by universal alignment approaches, motivating the need to move beyond a set of universal values. In these domains, alignment may also require incorporation of domain knowledge, such as laws and policies <ref type="bibr" target="#b28">[29]</ref> that could inform the appropriate use of AI technology <ref type="bibr" target="#b65">[66,</ref><ref type="bibr" target="#b66">67]</ref>. To adapt models to these new domains, various model fine-tuning techniques have been proposed <ref type="bibr" target="#b67">[68,</ref><ref type="bibr" target="#b68">69]</ref>. These can be viewed as a form of domain-specific alignment, which provides the model with relevant knowledge and values beyond that which is available from pre-training. For example, in the medical domain, recent work has explored value alignment in different healthcare scenarios <ref type="bibr" target="#b69">[70]</ref>. The ability to adapt AI algorithms (and how they are aligned) to different domains is an open area of research, and something we argue must be considered for context-specific alignment research. Alignment of algorithms to different sociocultural norms or values can potentially also be viewed as a form of domain-specific alignment <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b71">72]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Alignment to Different Tasks</head><p>Even within a particular given domain (e.g., chatbots), the task and how the AI system is to be used can impact alignment in a context-specific manner. For example, asking a chatbot for a cooking recipe requires the chatbot to perform a generation task; asking a chatbot for a medical diagnosis is a type  of classification task. The task indicates how the user intends to act upon the provided response. The degree of alignment may therefore change depending on the task and the user's intent, a human factors topic previously explored in adaptive automation research <ref type="bibr" target="#b72">[73,</ref><ref type="bibr" target="#b73">74,</ref><ref type="bibr" target="#b74">75]</ref>. In analogy to fine-tuning, instruction tuning <ref type="bibr" target="#b75">[76,</ref><ref type="bibr" target="#b76">77]</ref> can be used to align models to various types of tasks. This enables pre-trained models within a particular domain to provide outputs that better align with particular user queries. There is also preliminary work on understanding how alignment might handle emergent or changing situations, which may require dynamic alignment and thinking outside the box <ref type="bibr" target="#b77">[78]</ref>.</p><p>Developing new methods and benchmarks to evaluate AI systems (including newer forms of agentic AI) and their context-specific alignment when switching between tasks will become increasingly important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Alignment to Different Users</head><p>Universal alignment approaches assume a shared set of values and seek to maximize alignment with the average preferences of a given population <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b4">5]</ref>. However, human values and preferences are not uniform, and the diverse values and perspectives of individuals or subgroups of people may be lost without explicitly taking into account pluralism. Recent work has instead proposed pluralistic alignment <ref type="bibr" target="#b11">[12]</ref>, which can be used to model individual user preferences through interaction, steering models towards these preferences <ref type="bibr" target="#b78">[79,</ref><ref type="bibr" target="#b79">80]</ref>. We argue that this is a form of context-specific alignment, which requires the ability to align AI algorithms to individual users or groups of users. This requires research on what types of values are predictive of individual preferences and data-efficient ways to align models to these identified values. A closely related line of research follows work on AI personalization and individual preference learning, such as for LLMs <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b81">82]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A Framework for Human-Centric, Context-Specific Alignability</head><p>We propose a three-step process and framework to enable context-specific alignability (see Figure <ref type="figure" target="#fig_0">2</ref>). While we highlight prior work on language model alignment as a motivating example, our approach applies more broadly to value alignment in other AI systems. We believe that this is a flexible framework that can be used across different domains, tasks, and users, and encompasses several previous works, including that on pluralistic alignment <ref type="bibr" target="#b11">[12]</ref>.</p><p>1. Identifying context-specific values (Sec. 4.1). In the first step, relevant context-specific values and attributes that may impact AI actions and decisions must be identified from the selected group of humans using an assessment method. Identification of values and attributes is successful when they predict variation in actions or decisions in novel settings.</p><p>2. Developing alignable AI algorithms (Sec. 4.2). In the second step, AI algorithms must be trained on these values and attributes, taking into account value trade-offs and domain-specific knowledge. AI algorithms must be alignable and quantitatively evaluated on the degree to which they are able to dynamically align across a human-driven spectrum of alignment targets.</p><p>3. Performing alignment evaluations (Sec. 4.3). In the third step, the decisions of the aligned AI are presented back to a group of humans and assessed for outcomes such as trust, acceptance, delegation, or performance. Overall success here is when alignment between the target users and the AI predicts the chosen outcome variable. We note that the groups of participants used in Step 1 (value identification) and Step 3 (alignment evaluation) do not have to be the same, but are expected to be drawn from the same population (e.g. medical triage professionals).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">What context-specific values should AI systems be aligned to?</head><p>Within cognitive science, the naturalistic decision-making framework <ref type="bibr" target="#b82">[83]</ref> for understanding human decisions emphasizes that people begin by recalling exemplars of other instances of a familiar problem and how they acted-not by applying a top-down formula of abstract value priorities and calculating an expected utility. To understand what humans will do, the best predictor is to ask them what they have previously experienced and done <ref type="bibr" target="#b12">[13]</ref>. Although there are many universal values, we propose that disagreements between humans can be boiled down to their differences over a small set of relevant values. Thus, it is necessary to identify these context-specific values and attributes that characterize differences between humans in difficult decisions. These attributes can then be assessed in a scenario-based way, so that the attributes are concretely tied to actions and decisions. Below we describe a general methodology for identifying key context-specific values and attributes, and also describe a methodology for designing the test probes used to assess these values and attributes. We note that it is also possible to use a similar framework to identify subsets or subgroups of people based on their values and attributes, potentially enabling more personalized forms of alignment.</p><p>Identifying key values and attributes. <ref type="bibr" target="#b83">[84]</ref> describe a method for identifying key values and attributes. In interviews, they asked experts to describe situations where they faced a difficult decision, one where they were not sure what to do and perhaps second-guessed the decision. These situations generally involved conflicting values or goals. They were then asked what factors in the situation they considered when making the decision and under what different circumstances they would have made a different decision. These interviews were used to identify recurring value trade-offs, where a secondary value or goal came into conflict with the central goal of the task. A human expert or an AI system's actions and decisions can then be modeled in terms of when and how much they prioritize these identified values or attributes. For medical question-answering, use of fine-grained values and attributes has been shown to enable better performance <ref type="bibr" target="#b84">[85]</ref>. Even in chatbot settings, many values can be context-specific, as shown by recent work on user and language model interactions <ref type="bibr" target="#b85">[86]</ref>.</p><p>Assessing key values and attributes. In contrast to approaches which assess value alignment through general text-based surveys or polls <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b36">37]</ref>, we propose that key values and attributes can be systematically assessed by considering the major recurring types of actions or decisions encountered for a given domain and task. Each action or decision poses a trade-off or judgment call between the central goal of the task and a set of competing values or priorities. An assessment can be performed with a set of these decisions that cover a range of situational conditions where alignment to particular values and attributes would impact the chosen actions and decisions, creating a matrix of situations with different combinations of these factors. These scenarios can be validated with a small sample of human experts to check that the selected situational conditions are interpreted similarly but yet there are value-driven disagreements on the decision. These scenarios can be presented to both humans and AI, enabling direct comparison of alignment between the two at the level of actions and decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">How should AI systems be aligned in a context-specific manner?</head><p>From static alignment to dynamic alignability. A transition from static alignment to dynamic alignability reflects a fundamental acknowledgment that AI systems must continuously adapt to remain aligned with human intentions and evolving contexts in the real world. AI systems must continuously align with the evolving expertise of human operators and dynamic environmental conditions to ensure safe and effective deployment, particularly in high-stakes domains such as healthcare or medical triage <ref type="bibr" target="#b86">[87,</ref><ref type="bibr" target="#b87">88]</ref>. The static nature of traditional aligned AI models, trained on fixed datasets with predefined objectives, inherently limits their ability to adapt to different contexts <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b63">64]</ref>. Consequently, such models inevitably face misalignment when encountering novel situations or when human preferences and expertise evolve post-deployment. This discrepancy poses significant risks, especially in critical applications where misaligned AI behavior can have severe consequences <ref type="bibr" target="#b87">[88]</ref>. We therefore believe that static aligned models cannot adequately participate in such a co-adaptive process, and for AI systems to remain aligned over extended periods and across diverse, evolving contexts, they must be capable of dynamic adaptation of alignment, which is closely related to the field of lifelong learning <ref type="bibr" target="#b88">[89,</ref><ref type="bibr" target="#b89">90]</ref>.</p><p>Interpretable alignment algorithms for contexts with limited data. When modeling the preferences of individual users, there is typically less user-specific data available that can capture their distinct values and preferences. Emerging work focuses on alignment algorithms that use limited data of user interactions to infer user behaviors and values <ref type="bibr" target="#b90">[91,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b80">81,</ref><ref type="bibr" target="#b78">79]</ref>. Other work focuses on self-improving or self-rewarding models that can iteratively improve their alignment over time, starting with limited data <ref type="bibr" target="#b91">[92,</ref><ref type="bibr" target="#b92">93]</ref>. To aid interpretability, chain-of-thought can be used to guide model outputs through a series of simpler intermediate reasoning steps <ref type="bibr" target="#b93">[94]</ref> and constitutional AI <ref type="bibr" target="#b39">[40]</ref> can ground alignment in user-derived values or principles. As another example, the Trustworthy Algorithmic Delegate (TAD) <ref type="bibr" target="#b94">[95]</ref> learns to align to individuals by learning their behavior patterns under different circumstances. TAD addresses limited data by using decision analytics <ref type="bibr" target="#b94">[95]</ref> and counterfactual-based augmentation <ref type="bibr" target="#b95">[96]</ref>. TAD is also interpretable due to its use of case-based reasoning (CBR) <ref type="bibr" target="#b96">[97,</ref><ref type="bibr" target="#b97">98]</ref>, which is a technique that uses specific training instances for analogical reasoning on new decisions. TAD has been successful in aligning to medical triage and health insurance decisions <ref type="bibr" target="#b63">[64]</ref>.</p><p>Alignment with context-specific rules and policies. Universal alignment algorithms <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref> build off an extensive pre-training step, which acts to provide models with general knowledge of the world. Alignment via fine-tuning and instruction tuning then acts on top of this general world knowledge to improve instruction following and adherence to certain values or principles. However, in many specialized contexts, knowledge of a domain is under-represented in the pre-training data, resulting in models that are less effective in these domains. We argue that novel methods for efficiently incorporating domain-specific knowledge, and enabling alignment on top of this domain knowledge are needed. One noteworthy example <ref type="bibr" target="#b98">[99]</ref> introduced a framework that iteratively improves LLMs by automatically generating and applying constitutions-ethical guidelines-derived from red teaming interactions, thus reducing reliance on human annotations. Another noteworthy example <ref type="bibr" target="#b28">[29]</ref> leverages LLMs and codes of ethics from specific professions via ontologies adopting the model context protocol <ref type="bibr" target="#b99">[100]</ref>, enabling various LLMs and other sources of documents and ontologies to be incorporated at runtime. One more potential direction would be to extend retrieval-augmented generation (RAG) <ref type="bibr" target="#b100">[101]</ref> or external modules <ref type="bibr" target="#b101">[102,</ref><ref type="bibr" target="#b102">103]</ref> to also incorporate aspects of alignment to various laws or policies. The ability to dynamically reference and cite important documents for a given domain may also be a useful feature that provides additional transparency into alignment. This is related to how approaches such as constitutional AI <ref type="bibr" target="#b39">[40]</ref> are aligned to a set of fixed, user-specified principles, but with the ability to easily adapt models by pulling in relevant documents without extensive retraining or prompting.</p><p>Robust and safe alignment to combat potential attacks. Safety is a fundamental requirement for AI alignment, with the expectation that AI outputs should not cause harm to individuals or society <ref type="bibr" target="#b103">[104]</ref>.</p><p>For LLM-based models, researchers typically improve safety through prompting techniques <ref type="bibr" target="#b98">[99,</ref><ref type="bibr" target="#b104">105]</ref>, representation engineering <ref type="bibr" target="#b105">[106,</ref><ref type="bibr" target="#b106">107,</ref><ref type="bibr" target="#b107">108]</ref> or reinforcement learning <ref type="bibr" target="#b108">[109,</ref><ref type="bibr" target="#b109">110,</ref><ref type="bibr" target="#b110">111,</ref><ref type="bibr" target="#b111">112]</ref>. However, improvements in model safety often come at the cost of overall model utility <ref type="bibr" target="#b112">[113,</ref><ref type="bibr" target="#b113">114]</ref>, and vice versa <ref type="bibr" target="#b114">[115]</ref>. This trade-off remains one of the fundamental challenges for AI alignment <ref type="bibr" target="#b115">[116,</ref><ref type="bibr" target="#b113">114]</ref>. Models can also be particularly vulnerable to knowledge poisoning attacks <ref type="bibr" target="#b116">[117]</ref>, where misinformation or irrelevant knowledge is intentionally injected into external knowledge bases to manipulate model outputs to be incorrect and even harmful. To combat these types of attacks, alignment through behavior steering, which involves directly modifying AI behaviors with minimal cost, has gained considerable attention. Researchers have proposed prompt-based methods <ref type="bibr" target="#b117">[118,</ref><ref type="bibr" target="#b93">94]</ref>, as well as computation-efficient model editing <ref type="bibr" target="#b118">[119,</ref><ref type="bibr" target="#b119">120]</ref> and knowledge updating <ref type="bibr" target="#b120">[121,</ref><ref type="bibr" target="#b121">122]</ref> techniques. These include methods such as prefix tuning <ref type="bibr" target="#b122">[123]</ref> and suffix tuning <ref type="bibr" target="#b123">[124]</ref>, which optimize continuous prompts, LLM-Steer <ref type="bibr" target="#b124">[125]</ref>, which steers output embeddings, and ROME <ref type="bibr" target="#b125">[126]</ref>, which edits knowledge using rank-one updates.</p><p>Existing alignment methods focus primarily on reactive feedback. Although they excel at maximizing short-term safety protocols on topics such as toxicity or explicit misuse, reactive methods may not capture the indirect impacts that unfold over time (and are not immediately obvious). <ref type="bibr" target="#b126">[127]</ref> describes a proof-of-concept framework that projects how model-generated advice could propagate through societal systems on a macroscopic scale over time, enabling more robust alignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">How should context-specific alignability be evaluated?</head><p>Describing versus demonstrating a value. Alignment to a set of values should be predictive of how an AI system acts in different settings, which requires evaluation at the level of actions and decisions. An AI system should be able to use a set of values to consistently guide its actions and decisions in novel situations. Current alignment evaluations typically quantify how often an AI endorses a set of values, which only represents stated values as general attitudes. Instead, alignment evaluations should measure expressed values, with a focus on predicting value-based actions and decisions in realistic situations.</p><p>Defining alignment targets. Once the AI system is alignable to a range of identified values and attributes (e.g. using trade-off steerable benchmarks <ref type="bibr" target="#b11">[12]</ref>), a specific set of alignment targets for the use case must be established. Consistent with pluralistic alignment, the AI system can be aligned to reflect the values of an individual, a group of people (e.g. using jury-pluralistic benchmarks <ref type="bibr" target="#b11">[12]</ref>), or an organizational ideal. An important area of research is whether group-aligned or organizationally ideal-aligned AI produce the same effect in willingness to delegate as individually-aligned AI. There are likely situational and contextual factors that lead to different operational settings in which the most trustworthy alignment targets can shift between the individual, group, and organizational ideal <ref type="bibr" target="#b127">[128]</ref>.</p><p>Effective baselines for measuring alignment. For evaluation purposes, choosing the correct baseline can be challenging. Typical LLM alignment evaluations use base models that have only undergone pre-training without any additional fine-tuning <ref type="bibr" target="#b4">[5]</ref>, but these may be insufficient for fully characterizing the effects of alignment. Even an unaligned baseline AI may have some degree of implicit value alignment based on its pre-training <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b128">129]</ref>, and comparison to an aligned AI may not always reveal noticeable differences. The effect of value alignment is easiest to observe when comparing the most aligned and least aligned (e.g. deliberately misaligned) sets of AI actions and decisions; however, it is still important to consider the difference between the most aligned and baseline to evaluate whether value alignment is necessary to increase trust. Both of these conditions (baseline and misaligned) should be included in the evaluation, depending on the specific research question.</p><p>Quantifying the effect of alignment. Traditional alignment evaluation focuses on human preferences, which is a narrow view of trust <ref type="bibr" target="#b129">[130]</ref>. A key component of our proposed framework is the evaluation of human trust and delegation to the aligned AI system, moving beyond preferences. It is not enough for an AI system to demonstrate alignment, even pluralistic alignment. We need to measure the impact of this alignment on the human response to the system. When a human delegates decision-making to another human, it is by nature a fixed choice option based on the number of available human decision-makers. The design of alignable AI systems can potentially increase the number of available decision-makers, but only if humans are willing to count these systems as reliable options. Therefore, we need to ensure that we are designing and building alignable AI systems that lead to good performance outcomes, but also take into account the likelihood that humans will consider them as trustworthy systems.</p><p>Observable indicators of alignable AI. The perception of trustworthiness of an AI system is based on observable cues to their reasoning or decision-making process, filtered through the trustor's own attributes and experiences, a process known as trustworthiness assessment <ref type="bibr" target="#b130">[131]</ref>. These trust cues <ref type="bibr" target="#b131">[132]</ref> are used by experts especially to establish swift trust, which can be used to quickly assess the expertise of another agent <ref type="bibr" target="#b132">[133,</ref><ref type="bibr" target="#b133">134]</ref>, e.g. by observing hand movements during surgery <ref type="bibr" target="#b134">[135]</ref>. Alignment, therefore, is not just a problem of aligning the AI to certain values, but to matching both the influence and the weight of those values to the filter through which the potential trustor or delegator considers the AI system. The question of whether to also provide explanations for alignment is a well-studied one and should also be carefully considered in evaluating alignment <ref type="bibr" target="#b135">[136,</ref><ref type="bibr" target="#b136">137,</ref><ref type="bibr" target="#b137">138]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Application of Framework: Context-Specific Alignability for Medical Triage</head><p>We motivate and ground our proposed framework through an example use case in the healthcare domain of autonomous, value-aligned decision-making for medical triage (Figure <ref type="figure">3</ref>). This is a challenging domain because medical triage often deals with critical life-and-death decisions, where there may not be one single correct answer. For these difficult decisions, trusted human experts may </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human Value Assessment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alignment Target Selection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Trust and Delegation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Review AI Actions and Decisions</head><p>Figure <ref type="figure">3</ref>: The proposed context-specific alignment process applied to two key values identified in the medical triage domain (merit focus and affiliation focus). Different AI decision-maker algorithms are then aligned to these values. The end goal is this alignment is a set of autonomous AI decision-makers that are trusted by humans and who are willing to delegate to them in complex situations.</p><p>even disagree about the correct decision, and each individual's decision may largely be impacted by their own set of personal values and priorities. Building autonomous medical triage decision-makers then requires accurately modeling how these values influence decision-making at both the group and individual levels, and can serve as an effective testbed for understanding context-specific alignment.</p><p>Methods. The general framework for context-specific alignment evaluation can be applied to the medical triage domain for high-stakes decision-making in situations with no objectively correct answers. Namely, does alignment to the values of human decision-makers increase trust and improve the likelihood of delegation? The alignment evaluation design assumed identification of a set of validated domain-specific values and attributes (Step 1), such as merit focus (the degree to which one prioritizes moral responsibility) and affiliation focus (the degree to which one prioritizes ingroup status). Furthermore, a set of alignable AI decision-makers are created (Step 2), based on algorithms leveraging approaches such as large language models or case-based reasoning. In the final evaluation (Step 3), the alignment score metric used quantified the relationship between the human delegator and the AI decision-maker and the outcome variables of interest, such as trust, agreement, or delegation preference.</p><p>Results. Research in the medical triage domain has shown that alignment between the AI decisionmaker and the human delegator predicts trust and delegation preference <ref type="bibr" target="#b87">[88]</ref>. Different alignable AI decision-makers have also been developed for the medical triage domain <ref type="bibr" target="#b63">[64,</ref><ref type="bibr" target="#b138">139,</ref><ref type="bibr" target="#b139">140,</ref><ref type="bibr" target="#b140">141]</ref>, showing variation in decisions as a function of alignment targets based on the key values and attributes identified within the domain <ref type="bibr" target="#b83">[84,</ref><ref type="bibr" target="#b141">142]</ref>. Alignment scores can be computed as a function of the distance between the value profiles of the human and the AI system. The AI system's decisions were then presented back to human decision-makers to individually rate on trust, trustworthiness, agreement, and self-reported aligned and comparatively for delegation preference.</p><p>6 What are the implications of context-specific alignability?</p><p>User trust should not be the sole evaluation metric. If developers design an AI system to focus solely on improving user trust, it may achieve trust by potentially aligning to unacceptable values. An AI system aligned to unacceptable values might not only directly cause harm, but also normalize and scale unethical behavior if widely trusted and used. To prevent this, developers should decide upon and set limits to alignment: which context-specific values are acceptable to align to, what context-specific biases to avoid, whether certain groups of people should or should not be aligned to, and what requirements or laws should bound the AI system's actions and decisions. Indeed, such questions raise a fundamental issue about the boundaries of pluralism. Should an AI system align with any expressed preference, regardless of its ethical implications or societal impact? Or should there be underlying constraints and principles that limit the scope of acceptable alignment targets? Defining these boundaries and establishing mechanisms to prevent alignment with harmful or unethical preferences is a fundamental challenge that needs careful consideration <ref type="bibr" target="#b142">[143,</ref><ref type="bibr" target="#b143">144,</ref><ref type="bibr" target="#b144">145,</ref><ref type="bibr" target="#b61">62]</ref>. Possible mitigation measures include using metrics that capture harm and adopting a position that trust cannot come at the expense of performance.</p><p>Explainability must not be sacrificed for trust. If context-specific alignment can help earn users' trust, then systems that merely seem to be aligned can earn higher levels of trust than they truly warrant, known as mis-calibrated trust <ref type="bibr" target="#b145">[146,</ref><ref type="bibr" target="#b146">147,</ref><ref type="bibr" target="#b147">148,</ref><ref type="bibr" target="#b130">131]</ref>. For example, the ability of some AI systems to explain their decisions to users can be a means of demonstrating alignment and therefore building trust. However, if trust is the sole goal, as described above, explainable AI systems could feign alignment by providing misleading post-hoc rationalizations that match users' sensibilities instead of describing their true decision-making process, leading users to falsely believe that alignment exists to a higher (or lower) degree than it actually does.</p><p>Implications for how a context-specific aligned AI will be used. External factors beyond the design of an AI system itself, such as what users are told about it, how they are trained to use it, how its user interface presents information, and who is considered responsible for its decisions, also affect users' trust and carry ethical and legal implications. For example, if usage of an AI algorithm is made mandatory in a business or military setting because it is aligned to subject matter experts, then lay users would have little basis to question the system's recommendations while still potentially being held accountable for its actions. In contexts that are beyond the AI system's ability, even users who should have enough domain knowledge to recognize the system's limitations might use it anyway if they are ordered to do so or if they over-trust the system. Approaches such as value-sensitive design <ref type="bibr" target="#b148">[149]</ref> and context-sensitive frames <ref type="bibr" target="#b141">[142]</ref>, which can be used to embed context-specific alignment within the overall socio-technical design process, may be helpful for avoiding these pitfalls.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>Limitations. Despite the weaknesses of universal alignment, context-specific alignment itself comes with several inherent tradeoffs. Perhaps the most important is the increased complexity and data requirements for AI models -collecting data to approximate a distribution of "universal" views is significantly easier than collecting localized (and labeled) alignment data <ref type="bibr" target="#b88">[89]</ref>. Additionally, because the contextspecific alignment approach proposed in this paper relies on user-provided decisions and justifications, it would only include those that participants remember and are willing to share, resulting in selection biases that researchers must control for when implementing it. Without advances in efficient modeling or continual learning, collecting data at a scale required for context-specific alignment may be intractable <ref type="bibr" target="#b149">[150,</ref><ref type="bibr" target="#b150">151,</ref><ref type="bibr" target="#b151">152]</ref>. Further prescient is the potential for fragmentation and inconsistency among aligned models. If systems are constantly adapting to uniquely different contexts, it may become difficult to ensure baseline levels of competency, consistency, and reliable behavior <ref type="bibr" target="#b151">[152,</ref><ref type="bibr" target="#b152">153]</ref>. Such issues could lead to significant user confusion and a lack of trust in the system's predictability <ref type="bibr" target="#b152">[153]</ref>. Broader concerns for context-specific alignment also exist for risks of model preference manipulation and misalignment. Malicious actors could attempt to exploit the system's adaptability to achieve their own ends. Furthermore, even with good intentions, there's a risk that the system might misinterpret or inaccurately model user preferences, leading to unintended and potentially negative consequences <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b61">62]</ref>.</p><p>In this paper, we argue that universal alignment as a static process does not directly translate to the large set of domains, tasks, and users that are encountered in the real world. Our proposed context-specific alignment framework builds off of research on pluralistic alignment <ref type="bibr" target="#b11">[12]</ref>, and generalizes the concept of pluralism to also cover different dynamically changing domains and tasks (e.g. going from low-stakes to high-stakes situations), not just different types of users. In conclusion, we argue that as AI systems are increasingly deployed into high-stakes, critical domains, new approaches to context-specific alignability are needed that allow them to incorporate different values and be dynamically aligned to these values. In our paper, we have also highlighted the need for additional research into: 1) how to accurately identify and characterize context-specific values across domains, tasks, and users; 2) how to develop alignable AI algorithms that enable dynamic and efficient alignment to these values, often with limited expert human feedback; and 3) how to evaluate alignment across potentially changing environments, while taking into account values that directly impact actions and decisions. We hope that thinking through how to do context-specific alignment will enable more safe and robust AI systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Three-step process and framework for performing context-specific alignment across domains, tasks, and users. (1) Relevant context-specific values and attributes have to first be identified and validated. (2) AI algorithms have to be alignable to these values and attributes, taking into account potential value trade-offs and domain-specific knowledge as needed. (3) AI alignment evaluation involves quantifying AI actions and decisions, as well as elements of human trust and delegation.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>This material is based upon work supported by <rs type="funder">DARPA</rs> and <rs type="funder">Air Force Research Laboratory</rs> under award numbers <rs type="grantNumber">FA8650-23-C-7316</rs>, <rs type="grantNumber">FA8650-23-C-7314</rs>, and <rs type="grantNumber">FA8650-23-C-7318</rs>. The views and conclusions contained herein are those of the authors and should not be interpreted as representing the official policies or endorsements, either expressed or implied, of <rs type="affiliation">DARPA</rs> or the <rs type="institution">U.S. Government</rs>. Approved for public release; distribution is unlimited.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_eDeRAHR">
					<idno type="grant-number">FA8650-23-C-7316</idno>
				</org>
				<org type="funding" xml:id="_cQZhJwj">
					<idno type="grant-number">FA8650-23-C-7314</idno>
				</org>
				<org type="funding" xml:id="_uJj9cPj">
					<idno type="grant-number">FA8650-23-C-7318</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<title level="m">OpenAI. Gpt-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Artificial intelligence, values, and alignment. Minds and machines</title>
		<author>
			<persName><forename type="first">Iason</forename><surname>Gabriel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="411" to="437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">Tula</forename><surname>Masterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandi</forename><surname>Besen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mason</forename><surname>Sawtell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Chao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2404.11584</idno>
		<title level="m">The landscape of emerging ai agent architectures for reasoning, planning, and tool calling: A survey</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Training language models to follow instructions with human feedback</title>
		<author>
			<persName><forename type="first">Long</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Diogo</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carroll</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katarina</forename><surname>Slama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Ray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="27730" to="27744" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Training a helpful and harmless assistant with reinforcement learning from human feedback</title>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamal</forename><surname>Ndousse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nova</forename><surname>Dassarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanislav</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackson</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Conerly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sheer</forename><surname>El-Showk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nelson</forename><surname>Elhage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zac</forename><surname>Hatfield-Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tristan</forename><surname>Hume</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shauna</forename><surname>Kravec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liane</forename><surname>Lovitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Nanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chris</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ben</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Training a helpful and harmless assistant with reinforcement learning from human feedback</title>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamal</forename><surname>Ndousse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nova</forename><surname>Dassarma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawn</forename><surname>Drain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stanislav</forename><surname>Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Ganguli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.05862</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">Shibani</forename><surname>Santurkar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esin</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faisal</forename><surname>Ladhak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cinoo</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><surname>Hashimoto</surname></persName>
		</author>
		<title level="m">Whose opinions do language models reflect? International Conference on Machine Learning (ICML)</title>
		<imprint>
			<biblScope unit="page">2023</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Towards measuring the representation of subjective global opinions in language models</title>
		<author>
			<persName><forename type="first">Durmus</forename><surname>Esin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karina</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Schiefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anton</forename><surname>Bakhtin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carol</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zac</forename><surname>Hatfield-Dodds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liane</forename><surname>Lovitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orowa</forename><surname>Sikder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Tamkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janel</forename><surname>Thamkul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">First Conference on Language Modeling</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The prism alignment dataset: What participatory, representative and individualised human feedback reveals about the subjective and multicultural alignment of large language models</title>
		<author>
			<persName><forename type="first">Rose</forename><surname>Hannah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alexander</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Whitefield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Rottger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katerina</forename><surname>Bean</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Margatina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juan</forename><surname>Mosquera-Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Ciro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adina</forename><surname>Bartolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">He</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="105236" to="105344" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Chatbot arena: An open platform for evaluating llms by human preference</title>
		<author>
			<persName><forename type="first">Wei-Lin</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anastasios</forename><surname>Nikolas Angelopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianle</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Banghua</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">E</forename><surname>Gonzalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Forty-first International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A roadmap to pluralistic alignment</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jared</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jillian</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niloofar</forename><surname>Mitchell L Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Mireshghallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andre</forename><surname>Michael Rytting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ximing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouha</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><surname>Dziri</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="46280" to="46302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Naturalistic decision making</title>
		<author>
			<persName><forename type="first">Gary</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human factors</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="456" to="460" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Judgment under uncertainty: Heuristics and biases: Biases in judgments reveal some heuristics of thinking under uncertainty</title>
		<author>
			<persName><forename type="first">Amos</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">185</biblScope>
			<biblScope unit="issue">4157</biblScope>
			<biblScope unit="page" from="1124" to="1131" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Conflict: How soldiers make impossible decisions</title>
		<author>
			<persName><forename type="first">Laurence</forename><forename type="middle">J</forename><surname>Neil D Shortland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">M</forename><surname>Alison</surname></persName>
		</author>
		<author>
			<persName><surname>Moran</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Shivalika</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiyang</forename><surname>Nan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D'</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sayash</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmet</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanmi</forename><surname>stn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuntian</forename><surname>Koyejo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2504.20879</idno>
		<title level="m">The leaderboard illusion</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">Ariba</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Hadfield-Menell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2503.08688</idno>
		<title level="m">Randomness, not representation: The unreliability of evaluating cultural alignment in llms</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Helpsteer: Multi-attribute helpfulness dataset for steerlm</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Virginia</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Narsimhan</forename><surname>Makesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Sreedhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Egert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jane</forename><forename type="middle">Polak</forename><surname>Delalleau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Scowcroft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aidan</forename><surname>Kant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksii</forename><surname>Swope</surname></persName>
		</author>
		<author>
			<persName><surname>Kuchaiev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Helpsteer2: Open-source dataset for training top-performing reward models</title>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Olivier</forename><surname>Delalleau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiaqi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Egert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimmy</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Makesh Narsimhan</forename><surname>Sreedhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ruben Miguez1, Preslav Nakov, Dietram Scheufele, Shivam Sharma, and Giovanni Zagni. Factuality challenges in the era of large language models</title>
		<author>
			<persName><forename type="first">Isabelle</forename><surname>Augenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meeyoung</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanmoy</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Giovanni</forename><forename type="middle">Luca</forename><surname>Ciampaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Corney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Renee</forename><surname>Diresta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emilio</forename><surname>Ferrara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Hale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alon</forename><surname>Halevy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Filippo</forename><surname>Menczer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Yue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chujie</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yujun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanbo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiayi</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhaoyi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianrui</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongping</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kehan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bryan</forename><surname>Hooi Kuen-Yew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elias</forename><surname>Stengel-Eskin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huaxiu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jaehong</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaijie</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ranjay</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swabha</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taiwei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijia</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexing</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengqing</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhihao</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhize</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengzhong</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiyang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jieyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Furong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Or</forename><surname>Cohen Sasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prasanna</forename><surname>Sattigeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anka</forename><surname>Reuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Max</forename><surname>Lamparth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yue</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouha</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chaowei</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianfeng</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">S</forename><surname>Backes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pin-Yu</forename><surname>Zhenqiang Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiangliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>On the trustworthiness of generative foundation models -guideline. assessment, and perspective. In arxiv</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">TruthfulQA: Measuring how models mimic human falsehoods</title>
		<author>
			<persName><forename type="first">Stephanie</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Owain</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Preslav</forename><surname>Smaranda Muresan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aline</forename><surname>Nakov</surname></persName>
		</editor>
		<editor>
			<persName><surname>Villavicencio</surname></persName>
		</editor>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2022-05">May 2022</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3214" to="3252" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Using interactive feedback to improve the accuracy and explainability of question answering systems post-deployment</title>
		<author>
			<persName><forename type="first">Zichao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prakhar</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xing</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackie</forename><forename type="middle">Ck</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siva</forename><surname>Reddy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2204.03025</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Ganqu</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lifan</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ning</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingxiang</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Guotong</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruobing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yankai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><surname>Ultrafeedback</surname></persName>
		</author>
		<title level="m">Boosting language models with scaled ai feedback</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Are there universal aspects in the structure and contents of human values</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shalom</surname></persName>
		</author>
		<author>
			<persName><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of social issues</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="19" to="45" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">An overview of the schwartz theory of basic values</title>
		<author>
			<persName><forename type="first">H</forename><surname>Shalom</surname></persName>
		</author>
		<author>
			<persName><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Online readings in Psychology and Culture</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Moral foundations theory: The pragmatic validity of moral pluralism</title>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Haidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sena</forename><surname>Koleva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Motyl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ravi</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><forename type="middle">P</forename><surname>Wojcik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">H</forename><surname>Ditto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in experimental social psychology</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page" from="55" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Social chemistry 101: Learning to reason about social and moral norms</title>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jena</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vered</forename><surname>Shwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Sap</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="653" to="670" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Role-based ethics for decision-maker alignment</title>
		<author>
			<persName><forename type="first">C</forename><surname>Rauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Molineaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mainali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">O</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Artificial Intelligence 2025 (IEEE CAI 2025</title>
		<meeting>the IEEE Conference on Artificial Intelligence 2025 (IEEE CAI 2025</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>Workshop on Human Alignment in AI Decision-Making Systems (HAADMS)</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">Jan</forename><surname>Leike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tom</forename><surname>Everitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miljan</forename><surname>Martic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishal</forename><surname>Maini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shane</forename><surname>Legg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.07871</idno>
		<title level="m">Scalable agent alignment via reward modeling: a research direction</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Rm-r1: Reward modeling as reasoning</title>
		<author>
			<persName><forename type="first">Xiusi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gaotang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongru</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denghui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanghang</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>In arxiv</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Toolrl: Reward is all tool learning needs</title>
		<author>
			<persName><forename type="first">Emre</forename><surname>Cheng Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Can Acikgoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongru</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiusi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilek</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gokhan</forename><surname>Hakkani-Tr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Tur</surname></persName>
		</author>
		<author>
			<persName><surname>Ji</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>In arxiv</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Otc: Optimal tool calls via reinforcement learning</title>
		<author>
			<persName><forename type="first">Hongru</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wanjun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiusi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiahao</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shijue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bowen</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengdi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>In arxiv</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fine-grained human feedback gives better rewards for language model training</title>
		<author>
			<persName><forename type="first">Zeqiu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yushi</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Weijia</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouha</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alane</forename><surname>Suhr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prithviraj</forename><surname>Ammanabrolu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="59008" to="59033" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Steerlm: Attribute conditioned sft as an (user-steerable) alternative to rlhf</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhilin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Narsimhan</forename><surname>Makesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xianchao</forename><surname>Sreedhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oleksii</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><surname>Kuchaiev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Value kaleidoscope: Engaging ai with pluralistic human values, rights, and duties</title>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jena</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sydney</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Valentina</forename><surname>Pyatkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nouha</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ximing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kavel</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="19937" to="19947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Can language models reason about individualistic human values and preferences?</title>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sydney</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pluralistic Alignment Workshop at NeurIPS</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">PERSONA: A reproducible testbed for pluralistic alignment</title>
		<author>
			<persName><forename type="first">Louis</forename><surname>Castricato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><surname>Lile</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Rafailov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan-Philipp</forename><surname>Frnken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Leo</forename><surname>Wanner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marianna</forename><surname>Apidianaki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hend</forename><surname>Al-Khalifa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Barbara</forename><surname>Di Eugenio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Steven</forename><surname>Schockaert</surname></persName>
		</editor>
		<meeting>the 31st International Conference on Computational Linguistics<address><addrLine>Abu Dhabi, UAE</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2025-01">January 2025</date>
			<biblScope unit="page" from="11348" to="11368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Cooperative inverse reinforcement learning</title>
		<author>
			<persName><forename type="first">Dylan</forename><surname>Hadfield-Menell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anca</forename><surname>Dragan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Yuntao</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandipan</forename><surname>Kundu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jackson</forename><surname>Kernion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andy</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Goldie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Azalia</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cameron</forename><surname>Mckinnon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2212.08073</idno>
		<title level="m">Constitutional ai: Harmlessness from ai feedback</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Christiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00899</idno>
		<title level="m">Ai safety via debate</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Taori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yann</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tatsunori</forename><forename type="middle">B</forename><surname>Hashimoto</surname></persName>
		</author>
		<ptr target="https://github.com/tatsu-lab/stanford_alpaca" />
		<title level="m">Stanford alpaca: An instruction-following llama model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Self-instruct: Aligning language models with self-generated instructions</title>
		<author>
			<persName><forename type="first">Yizhong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yeganeh</forename><surname>Kordi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Swaroop</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alisa</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Lamini-lm: A diverse herd of distilled models from large-scale instructions</title>
		<author>
			<persName><forename type="first">Minghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abdul</forename><surname>Waheed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chiyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><surname>Abdul-Mageed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alham</forename><surname>Fikri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aji</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Rrhf: Rank responses to align language models with human feedback without tears</title>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">AlignScore: Evaluating factual consistency with a unified alignment function</title>
		<author>
			<persName><forename type="first">Yuheng</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruichen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhiting</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023-07">July 2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="11328" to="11348" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">G-eval: NLG evaluation using gpt-4 with better human alignment</title>
		<author>
			<persName><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Iter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruochen</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">Houda</forename><surname>Bouamor</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Juan</forename><surname>Pino</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kalika</forename><surname>Bali</surname></persName>
		</editor>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2023-12">December 2023</date>
			<biblScope unit="page" from="2511" to="2522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">GPTScore: Evaluate as you desire</title>
		<author>
			<persName><forename type="first">Jinlan</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">See-Kiong</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhengbao</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<editor>
			<persName><forename type="first">Kevin</forename><surname>Duh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Helena</forename><surname>Gomez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</editor>
		<meeting>the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Mexico City, Mexico</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024-06">June 2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6556" to="6576" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Factscore: Fine-grained atomic evaluation of factual precision in long form text generation</title>
		<author>
			<persName><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kalpesh</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinxi</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pang</forename><surname>Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="12076" to="12100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Can large language models be an alternative to human evaluations?</title>
		<author>
			<persName><forename type="first">Cheng-Han</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hung-Yi</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 61st Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="15607" to="15631" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Exploring the use of large language models for reference-free text quality evaluation: An empirical study</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haiyun</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shuming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: IJCNLP-AACL 2023 (Findings)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="361" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Large language models are not fair evaluators</title>
		<author>
			<persName><forename type="first">Peiyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zefan</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dawei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binghuai</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunbo</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lingpeng</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhifang</forename><surname>Sui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Lun-Wei</forename><surname>Ku</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andre</forename><surname>Martins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vivek</forename><surname>Srikumar</surname></persName>
		</editor>
		<meeting>the 62nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Bangkok, Thailand</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2024-08">August 2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="9440" to="9450" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Judging llm-as-a-judge with mt-bench and chatbot arena</title>
		<author>
			<persName><forename type="first">Lianmin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei-Lin</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ying</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhanghao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonghao</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhuohan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dacheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Neural Information Processing Systems</title>
		<meeting>the 37th International Conference on Neural Information Processing Systems</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="46595" to="46623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Verbosity bias in preference labeling by large language models</title>
		<author>
			<persName><forename type="first">Keita</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Akifumi</forename><surname>Wachi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Koki</forename><surname>Wataoka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Youhei</forename><surname>Akimoto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.10076</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">Aman</forename><surname>Singh Thakur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kartik</forename><surname>Choudhary</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.12624</idno>
		<title level="m">Venkat Srinik Ramayapally, Sankaran Vaidyanathan, and Dieuwke Hupkes. Judging the judges: Evaluating alignment and vulnerabilities in llms-as-judges</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Symbolic knowledge distillation: from general language models to commonsense models</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jena</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ronan</forename><surname>Le Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ximing</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2022 Conference of the North American Chapter</title>
		<meeting>the 2022 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="4602" to="4625" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Investigating machine moral judgement through the delphi experiment</title>
		<author>
			<persName><forename type="first">Liwei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jena</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Ronan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jenny</forename><forename type="middle">T</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sydney</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesse</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Keisuke</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jack</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName><surname>Hessel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Towards generalist biomedical ai</title>
		<author>
			<persName><forename type="first">Tao</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shekoofeh</forename><surname>Azizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danny</forename><surname>Driess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Schaekermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohamed</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pi-Chuan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryutaro</forename><surname>Tanno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ira</forename><surname>Ktena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AIoa2300138</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Adaptive ai alignment: Established resources for aligning machine learning with human intentions and values in changing environments</title>
		<author>
			<persName><forename type="first">Stephen</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning and Knowledge Extraction</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2570" to="2600" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Specificity of the attitude as a determinant of attitude-behavior congruence</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">Ta</forename><surname>Russell H Weigel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><forename type="middle">N</forename><surname>Vernon</surname></persName>
		</author>
		<author>
			<persName><surname>Tognacci</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">724</biblScope>
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Attitude-behavior relations: A theoretical analysis and review of empirical research</title>
		<author>
			<persName><forename type="first">Icek</forename><surname>Ajzen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><surname>Fishbein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">888</biblScope>
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">A statistical case against empirical human-ai alignment</title>
		<author>
			<persName><forename type="first">Julian</forename><surname>Rodemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esteban</forename><forename type="middle">Garces</forename><surname>Arias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Luther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Augustin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.14581</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Behavioral decision theory</title>
		<author>
			<persName><forename type="first">P</forename><surname>Slovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lichtenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="39" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Decision maker alignment: Benchmark datasets</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mainali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Rauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Molineaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Artificial Intelligence 2025 (IEEE CAI 2025</title>
		<meeting>the IEEE Conference on Artificial Intelligence 2025 (IEEE CAI 2025</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>Workshop on Human Alignment in AI Decision-Making Systems (HAADMS)</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Judgment and decision making under time pressure</title>
		<author>
			<persName><forename type="first">A</forename><surname>Edland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Svenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Time Pressure and Stress in Human Judgment and Decision Making</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Maule</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><surname>Svenson</surname></persName>
		</editor>
		<meeting><address><addrLine>Boston, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer US</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="27" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Work domain analysis: Concepts, guidelines, and cases</title>
		<author>
			<persName><forename type="first">Neelam</forename><surname>Naikar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Cognitive work analysis: Toward safe, productive, and healthy computer-based work</title>
		<author>
			<persName><forename type="first">Vicente</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Fine-tuning or retrieval? comparing knowledge injection in llms</title>
		<author>
			<persName><forename type="first">Oded</forename><surname>Ovadia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Menachem</forename><surname>Brief</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moshik</forename><surname>Mishaeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oren</forename><surname>Elisha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2024 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="237" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">A survey on post-training of large language models</title>
		<author>
			<persName><forename type="first">Guiyao</forename><surname>Tie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zeli</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dingjie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fuyang</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yurou</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhejian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiangyue</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Su</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2503.06072</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Vital: A new dataset for benchmarking pluralistic alignment in healthcare</title>
		<author>
			<persName><forename type="first">Anudeex</forename><surname>Shetty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amin</forename><surname>Beheshti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Dras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Usman</forename><surname>Naseem</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Normsage: Multi-lingual multi-cultural norm discovery from conversations on-the-fly</title>
		<author>
			<persName><forename type="first">Yi</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tuhin</forename><surname>Chakrabarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Owen</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Smaranda</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="15217" to="15230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">Chan</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Park</forename><surname>Shuyue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stella</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hayoung</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Svitlana</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanushree</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Jurgens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2407.02472</idno>
		<title level="m">Valuescope: Unveiling implicit norms and values via return potential model of social interactions</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Toward a characterization of adaptive systems: A framework for researchers and system designers</title>
		<author>
			<persName><forename type="first">Karen</forename><forename type="middle">M</forename><surname>Feigh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">C</forename><surname>Dorneich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Caroline</forename><forename type="middle">C</forename><surname>Hayes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human factors</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1008" to="1024" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Theoretical perspectives on adaptive automation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName><surname>Scerbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automation and human performance</title>
		<imprint>
			<publisher>CRC Press</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="37" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Psychophysiology and adaptive automation</title>
		<author>
			<persName><forename type="first">Evan</forename><forename type="middle">A</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raja</forename><surname>Parasuraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological psychology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="268" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Finetuned language models are zero-shot learners</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vincent</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelvin</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adams</forename><forename type="middle">Wei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Lester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Scaling instruction-finetuned language models</title>
		<author>
			<persName><forename type="first">Chung</forename><surname>Hyung Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shayne</forename><surname>Longpre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunxuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhartha</forename><surname>Brahma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">70</biblScope>
			<biblScope unit="page" from="1" to="53" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<author>
			<persName><forename type="first">Peixuan</forename><surname>Cheng Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qinyu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bingxiang</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiusi</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuji</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiarui</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaocheng</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denghui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2412.13549</idno>
		<title level="m">Pushing language models to think outside the box</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Aligning llms with individual preferences via interaction</title>
		<author>
			<persName><forename type="first">Shujin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><forename type="middle">R</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cheng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeonghwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dilek</forename><surname>Hakkani-Tur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Computational Linguistics</title>
		<meeting>the 31st International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2025">2025</date>
			<biblScope unit="page" from="7648" to="7662" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Mediq: Question-asking llms and a benchmark for reliable interactive clinical reasoning</title>
		<author>
			<persName><forename type="first">Stella</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vidhisha</forename><surname>Balachandran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shangbin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Ilgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emma</forename><surname>Pierson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pang</forename><surname>Wei W Koh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="28858" to="28888" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Pad: Personalized alignment of llms at decoding-time</title>
		<author>
			<persName><forename type="first">Ruizhe</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaotian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Meng</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhao</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zuozhu</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.04070</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">When large language models meet personalization: Perspectives of challenges and opportunities</title>
		<author>
			<persName><forename type="first">Jin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenwang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gangwei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanhao</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuxuan</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaolong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xingmei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">World Wide Web</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">42</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Recognition-primed decisions</title>
		<author>
			<persName><forename type="first">Gary</forename><surname>Klein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>JAI Press, Inc</publisher>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="47" to="92" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">A framework for identifying key decision-maker attributes in uncertain and complex environments</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Borders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Artificial Intelligence 2025 (IEEE CAI 2025</title>
		<meeting>the IEEE Conference on Artificial Intelligence 2025 (IEEE CAI 2025</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>Workshop on Human Alignment in AI Decision-Making Systems (HAADMS)</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Aligning llms to ask good questions a case study in clinical reasoning</title>
		<author>
			<persName><forename type="first">Stella</forename><surname>Shuyue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jimin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Faeze</forename><surname>Mun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><forename type="middle">S</forename><surname>Brahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yulia</forename><surname>Ilgen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName><surname>Sap</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2502.14860</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<author>
			<persName><forename type="first">Saffron</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Esin</forename><surname>Durmus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Miles</forename><surname>Mccain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunal</forename><surname>Handa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Tamkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jerry</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arushi</forename><surname>Somani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiuruo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deep</forename><surname>Ganguli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2504.15236</idno>
		<title level="m">Values in the wild: Discovering and analyzing values in real-world language model interactions</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Negotiative alignment: An interactive approach to human-ai co-adaptation for clinical applications</title>
		<author>
			<persName><forename type="first">Florence</forename><surname>Xini Doo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikhil</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pranav</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vishwa</forename><surname>Sanjay Parekh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR 2025 Workshop on Bidirectional Human-AI Alignment</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Trust in aligned ai decision makers</title>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Mcvay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ewart</forename><forename type="middle">J</forename><surname>Visser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Pippin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashutosh</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><forename type="middle">N</forename><surname>Hyde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Kman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Artificial Intelligence 2025 (IEEE CAI 2025</title>
		<meeting>the IEEE Conference on Artificial Intelligence 2025 (IEEE CAI 2025</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>Workshop on Human Alignment in AI Decision-Making Systems (HAADMS)</note>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<author>
			<persName><forename type="first">Min-Hsuan</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leitian</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuefeng</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixuan</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.01957</idno>
		<title level="m">How reliable is human feedback for aligning large language models? arXiv preprint</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Redefining superalignment: From weak-to-strong alignment to human-ai co-alignment to sustainable symbiotic society</title>
		<author>
			<persName><forename type="first">Feifei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuwei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Enmeng</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongcheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bing</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haibo</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yao</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dongqi</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2504.17404</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title level="m" type="main">A survey on personalized and pluralistic preference alignment in large language models</title>
		<author>
			<persName><forename type="first">Zhouhang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Junda</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiran</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yu</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xintong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaron</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sachin</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bodhisattwa</forename><surname>Prasad Majumder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jingbo</forename><surname>Shang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2504.07070</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Large language models can self-improve</title>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shixiang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2023 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1051" to="1068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Self-rewarding language models</title>
		<author>
			<persName><forename type="first">Weizhe</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">Yuanzhe</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st International Conference on Machine Learning</title>
		<meeting>the 41st International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>ICML&apos;24. JMLR.org</note>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Chain-of-thought prompting elicits reasoning in large language models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuezhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dale</forename><surname>Schuurmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Bosma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fei</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ed</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denny</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Aligning to human decision-makers in military medical triage</title>
		<author>
			<persName><forename type="first">Matthew</forename><surname>Molineaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosina</forename><forename type="middle">O</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Menager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Othalia</forename><surname>Larue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ursula</forename><surname>Addison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ray</forename><surname>Kulhanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noah</forename><surname>Reifsnyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Rauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mallika</forename><surname>Mainali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Case-Based Reasoning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="371" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Counterfactual-based synthetic case generation</title>
		<author>
			<persName><forename type="first">Anik</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mallika</forename><surname>Mainali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">B</forename><surname>Rauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ursula</forename><surname>Addison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prateek</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Karneeb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ray</forename><surname>Kulhanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Othalia</forename><surname>Larue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Mnager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Case-Based Reasoning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="388" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Tom</surname></persName>
		</author>
		<author>
			<persName><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="1997">1997</date>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>McGraw-hill</note>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Case-Based Reasoning: A Textbook</title>
		<author>
			<persName><forename type="first">M</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rosina</forename><forename type="middle">O</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><surname>Weber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin; Heidelberg, Berlin, Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Iteralign: Iterative constitutional alignment of large language models</title>
		<author>
			<persName><forename type="first">Xiusi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongzhi</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sreyashi</forename><surname>Nag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qingyu</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruirui</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference of the North American Chapter</title>
		<meeting>the 2024 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1423" to="1433" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Model context protocol (mcp): Landscape, security threats, and future research directions</title>
		<author>
			<persName><forename type="first">Xinyi</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanjie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shenao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoyu</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2503.23278</idno>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Retrieval-augmented generation for knowledge-intensive nlp tasks</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aleksandra</forename><surname>Piktus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heinrich</forename><surname>Kttler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><surname>Rocktschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9459" to="9474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Position: LLMs can&apos;t plan, but can help planning in LLM-modulo frameworks</title>
		<author>
			<persName><forename type="first">Subbarao</forename><surname>Kambhampati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karthik</forename><surname>Valmeekam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lin</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mudit</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kaya</forename><surname>Stechly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siddhant</forename><surname>Bhambri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lucas</forename><surname>Paul Saldyt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anil</forename><forename type="middle">B</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Forty-first International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Case-based reasoning meets large language models: A research manifesto for open challenges and research directions</title>
		<author>
			<persName><forename type="first">Kerstin</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralph</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Florian</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><surname>Caro-Martnez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Viktor</forename><surname>Eisenstadt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lasal</forename><surname>Jayawardena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Leake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirko</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukas</forename><surname>Malburg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>hal.science</note>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<author>
			<persName><forename type="first">Yue</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lichao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoran</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qihui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chujie</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenhan</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yixuan</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.05561</idno>
		<title level="m">Trustworthiness in large language models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">On prompt-driven safeguarding for large language models</title>
		<author>
			<persName><forename type="first">Chujie</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fan</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fandong</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Forty-first International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">Rethinking jailbreaking through the lens of representation engineering</title>
		<author>
			<persName><forename type="first">Tianlong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xuanjing</forename><surname>Huang</surname></persName>
		</author>
		<idno>abs/2401.06824</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Improving alignment and robustness with circuit breakers</title>
		<author>
			<persName><forename type="first">Andy</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Long</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><surname>Duenas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maxwell</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maksym</forename><surname>Andriushchenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zico Kolter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Fredrikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-eighth Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Representation noising: A defence mechanism against harmful finetuning</title>
		<author>
			<persName><forename type="first">Domenic</forename><surname>Rosati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Wehner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lukasz</forename><surname>Bartoszcze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robie</forename><surname>Gonzales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Subhabrata</forename><surname>Majumdar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hassan</forename><surname>Sajjad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frank</forename><surname>Rudzicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="12636" to="12676" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<monogr>
		<author>
			<persName><forename type="first">Tong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alec</forename><surname>Helyar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johannes</forename><surname>Heidecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Vallone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><surname>Kivlichan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Molly</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2411.01111</idno>
		<title level="m">Alex Beutel, John Schulman, and Lilian Weng. Rule based rewards for language model safety</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Gibbs sampling from human feedback: A provable kl-constrained framework for rlhf</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanze</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenlu</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. The Forty-first International Conference on Machine Learning (ICML2024</title>
		<meeting>The Forty-first International Conference on Machine Learning (ICML2024</meeting>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b110">
	<analytic>
		<title level="a" type="main">Iterative preference learning from human feedback: Bridging theory and practice for rlhf under kl-constraint</title>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanze</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenlu</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ziqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Han</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR2024 Workshop on Mathematical and Empirical Understanding of Foundation Models</title>
		<meeting>ICLR2024 Workshop on Mathematical and Empirical Understanding of Foundation Models</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Enable lanuguage models to implicitly learn self-improvement from data</title>
		<author>
			<persName><forename type="first">Ziqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Le</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tianjian</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuexin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yunxuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hongkun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. The Twelfth International Conference on Learning Representations</title>
		<meeting>The Twelfth International Conference on Learning Representations</meeting>
		<imprint>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
	<note>ICLR2024</note>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Mitigating the alignment tax of rlhf</title>
		<author>
			<persName><forename type="first">Yong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hangyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shizhe</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jianmeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haoxiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wenbin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hanning</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2024 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="580" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<author>
			<persName><forename type="first">Andy</forename><surname>Arditi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Obeso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aaquib</forename><surname>Syed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Paleka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nina</forename><surname>Panickssery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wes</forename><surname>Gurnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neel</forename><surname>Nanda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.11717</idno>
		<title level="m">Refusal in language models is mediated by a single direction</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b114">
	<monogr>
		<author>
			<persName><forename type="first">Xiangyu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tinghao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pin-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruoxi</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prateek</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Henderson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2310.03693</idno>
		<title level="m">Fine-tuning aligned language models compromises safety, even when users do not intend to! arXiv preprint</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<monogr>
		<author>
			<persName><forename type="first">Yotam</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Noam</forename><surname>Wies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dorin</forename><surname>Shteyman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Binyamin</forename><surname>Rothberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amnon</forename><surname>Shashua</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2401.16332</idno>
		<title level="m">Tradeoffs between alignment and helpfulness in language models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b116">
	<monogr>
		<title level="m" type="main">Mm-poisonrag: Disrupting multimodal rag with local and global poisoning attacks</title>
		<author>
			<persName><forename type="first">Hyeonjeong</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Qiusi</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeonghwan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dimitrios</forename><surname>Bralios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saikrishna</forename><surname>Sanniboina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>In arxiv</note>
</biblStruct>

<biblStruct xml:id="b117">
	<monogr>
		<author>
			<persName><forename type="first">Pranab</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayush</forename><forename type="middle">Kumar</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sriparna</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vinija</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samrat</forename><surname>Mondal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aman</forename><surname>Chadha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2402.07927</idno>
		<title level="m">A systematic survey of prompt engineering in large language models: Techniques and applications</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b118">
	<monogr>
		<author>
			<persName><forename type="first">Yunzhi</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bozhong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Siyuan</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zhoubo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shumin</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Huajun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ningyu</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2305.13172</idno>
		<title level="m">Editing large language models: Problems, methods, and opportunities</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b119">
	<analytic>
		<title level="a" type="main">Knowledge editing for large language models: A survey</title>
		<author>
			<persName><forename type="first">Song</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yaochen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haochen</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zaiyi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jundong</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b120">
	<analytic>
		<title level="a" type="main">Why does new knowledge create messy ripple effects in llms?</title>
		<author>
			<persName><forename type="first">Jiaxin</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chi</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. The 2024 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>The 2024 Conference on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b121">
	<analytic>
		<title level="a" type="main">Evedit: Event-based knowledge editing with deductive editing boundaries</title>
		<author>
			<persName><forename type="first">Jiateng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuji</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sha</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zixuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. The 2024 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>The 2024 Conference on Empirical Methods in Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page">2024</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b122">
	<monogr>
		<title level="m" type="main">Prefix-tuning: Optimizing continuous prompts for generation</title>
		<author>
			<persName><forename type="first">Lisa</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Percy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.00190</idno>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b123">
	<monogr>
		<title level="m" type="main">Universal and transferable adversarial attacks on aligned language models</title>
		<author>
			<persName><forename type="first">Andy</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zifan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Milad</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zico Kolter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matt</forename><surname>Fredrikson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2307.15043</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b124">
	<analytic>
		<title level="a" type="main">Word embeddings are steers for language models</title>
		<author>
			<persName><forename type="first">Chi</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jialiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Manling</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chenkai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tarek</forename><surname>Abdelzaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 62nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="16410" to="16430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b125">
	<analytic>
		<title level="a" type="main">Locating and editing factual associations in gpt</title>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Andonian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yonatan</forename><surname>Belinkov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="17359" to="17372" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b126">
	<analytic>
		<title level="a" type="main">Beyond reactive safety: Risk-aware llm alignment via long-horizon simulation</title>
		<author>
			<persName><forename type="first">Chenkai</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Denghui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. The 63rd Annual Meeting of the Association for Computational Linguistics (ACL2025) Findings</title>
		<meeting>The 63rd Annual Meeting of the Association for Computational Linguistics (ACL2025) Findings</meeting>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b127">
	<analytic>
		<title level="a" type="main">Colliding sacred values: a psychological theory of least-worst option selection</title>
		<author>
			<persName><forename type="first">Neil</forename><surname>Shortland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurence</forename><surname>Alison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Thinking &amp; Reasoning</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="118" to="139" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b128">
	<analytic>
		<title level="a" type="main">Language models are alignable decision-makers: Dataset and application to the medical triage domain</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bill</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><surname>Summerville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Joy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Funk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arslan</forename><surname>Basharat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 Conference of the North American Chapter</title>
		<meeting>the 2024 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="213" to="227" />
		</imprint>
	</monogr>
	<note>Industry Track)</note>
</biblStruct>

<biblStruct xml:id="b129">
	<analytic>
		<title level="a" type="main">Beyond preferences in ai alignment</title>
		<author>
			<persName><forename type="first">Tan</forename><surname>Zhi-Xuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Micah</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matija</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hal</forename><surname>Ashton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Studies</title>
		<imprint>
			<biblScope unit="page" from="1" to="51" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b130">
	<analytic>
		<title level="a" type="main">How do we assess the trustworthiness of ai? introducing the trustworthiness assessment model (tram)</title>
		<author>
			<persName><forename type="first">Nadine</forename><surname>Schlicker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alarith</forename><surname>Uhde</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarah</forename><surname>Sterz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">C</forename><surname>Hirsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Langer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">170</biblScope>
			<biblScope unit="page">108671</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b131">
	<analytic>
		<title level="a" type="main">A design methodology for trust cue calibration in cognitive agents</title>
		<author>
			<persName><forename type="first">Ewart J De</forename><surname>Visser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marvin</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amos</forename><surname>Freedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raja</forename><surname>Parasuraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Virtual, Augmented and Mixed Reality. Designing and Developing Virtual and Augmented Environments: 6th International Conference</title>
		<meeting><address><addrLine>Heraklion, Crete, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014-06-22">2014. 2014. June 22-27, 2014. 2014</date>
			<biblScope unit="page" from="251" to="262" />
		</imprint>
	</monogr>
	<note>Proceedings, Part I 6</note>
</biblStruct>

<biblStruct xml:id="b132">
	<analytic>
		<title level="a" type="main">Trust development in swift starting action teams: A multilevel framework</title>
		<author>
			<persName><forename type="first">Marissa</forename><forename type="middle">L</forename><surname>Jessica L Wildman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><forename type="middle">H</forename><surname>Shuffler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephen</forename><forename type="middle">M</forename><surname>Lazzara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shawn</forename><surname>Fiore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduardo</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sena</forename><surname>Salas</surname></persName>
		</author>
		<author>
			<persName><surname>Garven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Group &amp; organization management</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="170" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b133">
	<analytic>
		<title level="a" type="main">Applying the swift trust model to human-robot teaming</title>
		<author>
			<persName><forename type="first">Kerstin</forename><forename type="middle">S</forename><surname>Haring</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><forename type="middle">H</forename><surname>Lazzara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><forename type="middle">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">R</forename><surname>Keebler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Trust in Human-Robot Interaction</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="407" to="427" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b134">
	<monogr>
		<author>
			<persName><forename type="first">Debra</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><forename type="middle">E</forename><surname>Weick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roderick</forename><forename type="middle">M</forename><surname>Kramer</surname></persName>
		</author>
		<title level="m">Swift trust and temporary groups. Trust in organizations: Frontiers of theory and research</title>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b135">
	<analytic>
		<title level="a" type="main">The false hope of current approaches to explainable artificial intelligence in health care</title>
		<author>
			<persName><forename type="first">Marzyeh</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luke</forename><surname>Oakden-Rayner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">L</forename><surname>Beam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Lancet Digital Health</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="745" to="e750" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b136">
	<analytic>
		<title level="a" type="main">On the risk of confusing interpretability with explicability</title>
		<author>
			<persName><forename type="first">Christian</forename><surname>Herzog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI and Ethics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="219" to="225" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b137">
	<analytic>
		<title level="a" type="main">Explaining technology we do not understand</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Adamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Technology and Society</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="34" to="45" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b138">
	<analytic>
		<title level="a" type="main">A roadmap for alignable algorithmic decision-makers in the medical triage domain</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Taylor</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiusi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arslan</forename><surname>Basharat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Alignment in AI Decision-Making Systems: An Inter-disciplinary Approach towards Trustworthy AI</title>
		<meeting>the Human Alignment in AI Decision-Making Systems: An Inter-disciplinary Approach towards Trustworthy AI<address><addrLine>Santa Clara, California, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b139">
	<analytic>
		<title level="a" type="main">Predictive models of decision making in medical triage</title>
		<author>
			<persName><forename type="first">Jordan</forename><surname>Lampi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Simona</forename><surname>Temereanca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><forename type="middle">D</forename><surname>Shortland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jon</forename><surname>Sussman-Fort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Bixler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2025 IEEE Conference on Artificial Intelligence (CAI)</title>
		<imprint>
			<date type="published" when="2025">2025</date>
			<biblScope unit="page" from="1243" to="1246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b140">
	<analytic>
		<title level="a" type="main">A proof-of-concept validation of alignment in decision-making attributes for trustworthy ai</title>
		<author>
			<persName><forename type="first">Amy</forename><surname>Summerville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Louis</forename><surname>Mart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ion</forename><surname>Juvina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Locke Welborn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cara</forename><surname>Widmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alice</forename><surname>Leung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2025 IEEE Conference on Artificial Intelligence (CAI)</title>
		<imprint>
			<date type="published" when="2025">2025</date>
			<biblScope unit="page" from="1184" to="1187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b141">
	<analytic>
		<title level="a" type="main">Context sensitive frames and ai alignment</title>
		<author>
			<persName><forename type="first">Jared</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2025 IEEE Conference on Artificial Intelligence (CAI)</title>
		<imprint>
			<date type="published" when="2025">2025</date>
			<biblScope unit="page" from="1251" to="1254" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b142">
	<analytic>
		<title level="a" type="main">Value pluralism</title>
		<author>
			<persName><forename type="first">Elinor</forename><surname>Mason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Stanford Encyclopedia of Philosophy</title>
		<imprint>
			<publisher>Stanford University Press</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b143">
	<analytic>
		<title level="a" type="main">Value pluralism</title>
		<author>
			<persName><forename type="first">Ruth</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Encyclopedia of the Social and Behavioral Sciences</title>
		<editor>
			<persName><forename type="first">James</forename><surname>Wright</surname></persName>
		</editor>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="21" to="26" />
		</imprint>
	</monogr>
	<note>Second Edition</note>
</biblStruct>

<biblStruct xml:id="b144">
	<analytic>
		<title level="a" type="main">The limits of pluralism</title>
		<author>
			<persName><forename type="first">Patrick</forename><surname>Riordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies: An Irish Quarterly Review</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">365</biblScope>
			<biblScope unit="page" from="42" to="50" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b145">
	<analytic>
		<title level="a" type="main">Trust in automation: Designing for appropriate reliance</title>
		<author>
			<persName><forename type="first">D</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Katrina</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><surname>See</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human factors</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="80" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b146">
	<analytic>
		<title level="a" type="main">A meta-analysis of factors influencing the development of trust in automation: Implications for understanding autonomy in future systems</title>
		<author>
			<persName><forename type="first">Kristin</forename><forename type="middle">E</forename><surname>Schaefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessie Yc</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">L</forename><surname>Szalma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">A</forename><surname>Hancock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human factors</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="400" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b147">
	<analytic>
		<title level="a" type="main">Towards a theory of longitudinal trust calibration in human-robot teams</title>
		<author>
			<persName><forename type="first">Ewart J De</forename><surname>Visser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marieke Mm</forename><surname>Peeters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malte F</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Spencer</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tyler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Pak</surname></persName>
		</author>
		<author>
			<persName><surname>Neerincx</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of social robotics</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b148">
	<analytic>
		<title level="a" type="main">Designing value-sensitive ai: a critical review and recommendations for socio-technical design processes</title>
		<author>
			<persName><forename type="first">Malak</forename><surname>Sadek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><forename type="middle">A</forename><surname>Calvo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cline</forename><surname>Mougenot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI and Ethics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="949" to="967" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b149">
	<monogr>
		<title level="m" type="main">Personalizing reinforcement learning from human feedback with variational preference learning</title>
		<author>
			<persName><forename type="first">Sriyash</forename><surname>Poddar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanming</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hamish</forename><surname>Ivison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhishek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natasha</forename><surname>Jaques</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2408.10075</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b150">
	<monogr>
		<author>
			<persName><forename type="first">Thom</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2406.17692</idno>
		<title level="m">From distributional to overton pluralism: Investigating large language model alignment</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b151">
	<monogr>
		<author>
			<persName><forename type="first">Jingyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Elgohary</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Magooda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2410.08968</idno>
		<title level="m">Controllable safety alignment: Inference-time adaptation to diverse safety requirements</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b152">
	<monogr>
		<author>
			<persName><forename type="first">Jesse</forename><forename type="middle">C</forename><surname>Cresswell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2504.07170</idno>
		<title level="m">Trustworthy ai must account for intersectionality</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
