<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Benchmarking AI and Human Text Classifications in the Context of Newspaper Frames: A Multi-Label LLM Classification Note</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2024-10-09">October 9, 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Alexander</forename><surname>Tripp</surname></persName>
							<email>alexander.j.tripp@vanderbilt.edu.</email>
							<affiliation key="aff0">
								<orgName type="department">PhD Candidate</orgName>
								<orgName type="institution">Vanderbilt University</orgName>
								<address>
									<settlement>Nashville</settlement>
									<region>TN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Benchmarking AI and Human Text Classifications in the Context of Newspaper Frames: A Multi-Label LLM Classification Note</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-10-09">October 9, 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">17DADB8864ABC77F5A2A452CC22FA421</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-23T06:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>text as data</term>
					<term>natural language processing</term>
					<term>statistical analysis of texts</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Amid the explosion of research using artificial intelligence and Large Language Models, I compare the multi-label classification abilities of AI models (ChatGPT and Claude) and undergraduate coders using Spanish, immigration-focused, newspaper articles. Deriving my codebook from existing research on immigration-focused media narratives, I prompt LLMs to label articles by either an 8-label schema-directly analogous to the assignment of the undergraduate coders-or a 4-label schema-a more generalized approach aggregating the 8 labels into broader thematic categories. With undergraduate coders as the benchmark, I determine that a Few Shot ChatGPT 4o model with 8 labels is currently the most reliable AI classifier, with a hamming loss of 0.1. I emphasize two additional takeaways: 1) AI models using 8 labels outperform their 4 label counterparts and 2) AI models bias toward false positives. This article is optimistic about the abilities of AI models to supplement human coders, although human coding still provides a valuable benchmark for text classification tasks. I encourage authors and publishers to consider systematic meta-analyses of these tasks so as to better understand the generalizability of AI performance across different contexts and tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One might imagine a coding quality hierarchy. Ideally, researchers would code their own corpora, leveraging their original ideas and expertise. However, this ideal introduces bias, as a researcher's familiarity with her hypotheses could influence her results. As such, researchers instead employ coders to assess their designs with greater integrity. Direct peers or graduate students might be the next best option as coders, followed by undergraduates. This coding quality hierarchy reflects decreasing familiarity with the project's theoretical underpinnings and less research experience, alongside less bias from knowledge of the project's hypotheses. Undergraduates, while most readily available, sit at the bottom of this hierarchy due to their limited research skill set. This note attempts to determine where generative AI models place in this coding quality hierarchy as compared to undergraduates in a multi-label classification context.</p><p>Text classification has recently seen a large increase in popularity across the social sciences due to the emergence of powerful generative AIs like OpenAI's ChatGPT and Anthropic's Claude. Recent research continues to innovate on this frontier, with newer models employing strategies such as pairwise comparisons of latent traits (Wu et al. 2023) or built-in chains of thought (Wei et al.  2022) to improve performance. Across a range of settings, large language models (LLMs) perform comparably to humans. <ref type="bibr">1</ref> I assess the text classification abilities of three popular LLMs-ChatGPT 4 Turbo, ChatGPT 4o, and Claude Sonnet 3.5-across two primary characteristics: 4 vs. 8 labels and Zero vs. One vs. Few Shot prompts. Existing work shows meaningful differences in performance based on the provision of accurate examples (Chae and Davidson 2024), highlighting the need to evaluate these prompts under varying specifications. I compare these LLMs in particular based on their analysis of Spanish texts, incorporation of large context windows, and ease of access to researchers. This project uses Colombian newspapers covering Venezuelan immigration due to my substantive research interests.</p><p>My case provides a hard test for the conclusion of existing research-that LLMs are useful tools comparable to humans-in two ways. First, the identification of news frames requires a thoroughly validated coding schema, because they represent subtle, implied cues rather than concrete information, like the identification of sentiment or topic. Second, I use non-English texts. Traditionally, cutting-edge LLMs have been designed using English. English is the highest resourced language, meaning that it has high quality digitized text on which models can train (Nicholas and  Bhatia 2023). Languages with less digitized text are less likely to be supported by these models and exhibit weaker performance. As a result, non-English researchers have been excluded from these advances.</p><p>I find that a Few Shot ChatGPT 4o model with 8 labels performs best, showing an average hamming loss of 0.10 across labels. Digging deeper, I uncover that 1) AI models using 8 labels are generally more reliable than their 4 label counterparts and 2) AI models are biased toward false positive errors.</p><p>My work contributes to scholarship on the text classification abilities of generative AI models by exploring how their output differs from undergraduates and providing a blueprint for the efficient, robust usage of LLMs by applied researchers in non-English contexts.<ref type="foot" target="#foot_1">foot_1</ref> While I do not test the generalizability of this work to other prompts and/or languages, I am optimistic that it extends to The undergraduates parsed each newspaper article for the 8 labels, coding articles that matched as 1s and those that did not match as 0s. If the primary topic of the article was not immigrationrelated, the undergraduates were instructed to set all labels to 0. The output of this coding exercise is a dataset where each row represents a newspaper article and each column represents a label, with 1s if the label occurred in the article and 0 if it did not.</p><p>Since this task involved three independent coders, it inevitably produced disagreement. In this case, because each of the three undergraduates read and coded many of the same articles, there were Perceptions that immigrants are uniquely vulnerable, fellow humans (Feldman and  Steenbergen 2001)   2: Humanitarian-Refugee Perceptions that immigrants are like refugees fleeing harsh, impossible conditions (Fraser and Murakami 2022)   3: Threat-Disease Fears that immigration will bring disease (Kam and Estes 2016)   4: Threat-Economic Fears that immigration will lead to economic competition locally and nationally (Hainmueller and Hiscox 2010)   5: Threat-Instability Fears, broadly construed, that immigration will cause social instability 6: Threat-Violence Fears that immigration will lead to increased crime and violence (Sniderman,  Hagendoorn, and Prior 2004)   7: Benefit Perceptions that immigration can improve local and national economies 8: Policy &amp; Integration Neutral, technical reports about immigration policies and government action multiple opportunities for disagreement. Reassuringly, only 3% of all label-article cells disagreed. To resolve these disagreements for the purposes of assigning true labels, I first join these three output datasets together based on agreed values. Then, for cells with disagreement, I default to responses from the two coders with the highest intercoder reliability metrics.<ref type="foot" target="#foot_3">foot_3</ref> I first fill in disagreed values with output from the coder in this pair with the most research experience and Spanish fluency. Then, I fill in additional disagreed cells with the second coder in this pair. For any remaining disagreed cells, I use the output from my third coder.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The AI Models</head><p>I compare the output of my undergraduate coders to three generative AI models: OpenAI's ChatGPT (models: 4 Turbo and 4o) and Anthropic's Claude (model: Sonnet 3.5). I employ these AI models within my analysis to uncover 1) which is the best classifier, 2) whether it is a sufficient replacement for human coders, and 3) how its outputs might differ from other LLMs and undergraduates. My work contributes to recent research (e.g., Brown et al. 2020 and Pangakis, Wolken, and Fasching 2023)  by assessing LLMs in a non-English context, analyzing how disaggregated information in prompts may improve their performance, and assessing how they systematically differ from undergraduate coders. I use these models specifically, because they 1) were trained on Spanish-language corpora, 2) have large context windows, and 3) are comparatively accessible. The first two characteristics are necessary for comparability between undergraduates and AI, as both sets of coders must understand the language of the texts and make their decisions using the entirety of the data.</p><p>I focus my classification exercises in a non-English context. Recent attempts to train LLMs on multiple languages at once-dubbed multilingual language models-have expanded language support (Nicholas and Bhatia 2023). These multilingual AI models are increasingly proficient in less resourced languages, diversifying the field by allowing scholars from non-English backgrounds to employ cutting-edge models in their native languages. ChatGPT and Claude respond well to Spanish language prompts,<ref type="foot" target="#foot_4">foot_4</ref> so my project explores their text classification capabilities as compared to undergraduates that also know Spanish.</p><p>Furthermore, each model has a large context window, meaning that it can fully incorporate information from longer prompts. Some newspaper articles in my dataset are over 10,000 tokens (over 7,500 words), and many existing LLMs would not be able to process these larger texts due to their smaller context windows.<ref type="foot" target="#foot_5">foot_5</ref> Since undergraduate coders can read and incorporate all of the text into their decision-making, the classification models in question should do the same.</p><p>Finally, these ChatGPT and Claude models do not require any large downloads, computational power, or fine-tuning on the side of the researchers, making them more accessible to researchers less familiar with LLMs. I gear the insights and analysis of this paper toward applied researchers using LLMs as a tool, rather than those looking to build or fine-tune their own models. <ref type="bibr">7</ref> To create the prompts that I send to each AI model, I adapt the codebook given to my undergraduate research team and follow the best practices in prompt engineering.<ref type="foot" target="#foot_7">foot_7</ref> I then combine the prompt with each newspaper article and use the relevant API to send my request.<ref type="foot" target="#foot_8">foot_8</ref> Throughout the course of this project, I iteratively refined and validated my prompts to both ensure that they match the content of the codebook and to maximize model performance. <ref type="bibr">10</ref> I now discuss the trade-offs of using LLMs versus human coders. Human coding is highly valuable, because these coders 1) can accurately classify texts given some set of instructions, asking clarification questions when needed, 2) can explain their decision-making process, and 3) are often students gaining useful research experience and training to be the next generation of social scientists, constituting a social good. On the other hand, human coding is expensive and slow, and many researchers face a lack of institutional resources or short time horizons that leave them unable to utilize human coding. The cost and time differentials between my human and AI coders are large, but those between AI models are usually not. Human coders necessitate either course credit or hourly pay, often by semester. For the coding of 600 newspaper articles, my human coders took about 180 hours throughout one semester, while my AI models took roughly 15 minutes and cost about $10. However, I spent many hours revising the prompts before I was satisfied with the model results. Over the entire course of this project, I spent over $1,000 running and rerunning these LLMs, so the costs can quickly add up if one is not disciplined in their analytical strategy.<ref type="foot" target="#foot_10">foot_10</ref> 3 Comparative Analysis I evaluate model performance by comparing the output of my AI classification models to that of my undergraduate coders.<ref type="foot" target="#foot_11">foot_11</ref> In my main analyses, I use hamming loss to determine the reliability of these models. Hamming loss shows the fraction of incorrectly predicted labels to the total number of labels in a multi-label setting, providing intuitive model comparisons based on the proportion of correct classifications in multi-label tasks (Pal, Selvakumar, and Sankarasubbu 2020). Models with hamming loss values closer to zero are the better performers, as they predict fewer incorrect labels as a proportion of all labels. So, a hamming loss of 0.25 would indicate that 25% of labels in an article were incorrectly classified compared to the standard. My analysis includes 18 LLM specifications in total: models from Claude Sonnet 3.5, ChatGPT 4 Turbo, or ChatGPT 4o, models with 4 labels or 8 labels, and Zero Shot, One Shot, or Few Shot models.</p><p>While I write my prompts in English, I provide examples for the One Shot and Few Shot models in Spanish.<ref type="foot" target="#foot_12">foot_12</ref> I find no notable differences across model metrics for models run with fully Spanish prompts versus those with instructions in English and examples in Spanish.<ref type="foot" target="#foot_13">foot_13</ref> This provides some evidence that the language of the prompt instructions is not hugely influential, making it easier for researchers to conduct analyses for languages in which they are not fluent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">How do LLMs Compare to Undergraduate Coders?</head><p>In Figure <ref type="figure" target="#fig_0">1</ref>, I contrast the hamming loss pooled across labels for each AI model specification as compared to my undergraduate coders. <ref type="bibr">15</ref> The graph is ordered so that better performing models are at the top and worse performing models are at the bottom.</p><p>I find that the Few Shot ChatGPT 4o model with 8 labels has the lowest average hamming loss across LLMs. <ref type="bibr">16</ref> The Few Shot ChatGPT 4o model with 8 labels has an average hamming loss of 0.10, incorrectly predicting 10% of the labels as compared to the benchmark of my undergraduate coders. Compared to recent literature, a hamming loss of 0.10 is fairly competitive with other state-of-the-art LLMs, conditional on the fact that media frames are more difficult to systematically identify (El Rifai, Al Qadi, and Elnagar 2022; Nicholls and Culpepper 2021).</p><p>ChatGPT 4 Turbo appears slightly worse than 4o across the board, and it is considerably more expensive to run than 4o and Claude Sonnet 3.5. Sonnet 3.5 performs worse than 4o and 4 Turbo, though it shows less variation in its performance across the 4 and 8 labels specifications. Additionally, its Few Shot specification does not improve over its Zero and One Shot models to the same degree as ChatGPT 4o and 4 Turbo. I break this analysis down by label and label specification in Figure <ref type="figure" target="#fig_1">2</ref> below, where values closer to zero again indicate better performance. For each label, the AI models vary from one another by hamming loss metrics of about .15 on average, and the performance for some labels is much better than others. For example, in the 8 label specification, LLMs identify the Disease Threat, Economic Threat, and Economic Benefit labels quite well-with hamming loss scores of less than 0.10-while they struggle to identify other labels, such as Instability and P &amp; I. In the 4 label specification, the Benefit label performs best, and the P &amp; I label shows the greatest variation. In the next two sections, I explore what might be contributing to these differences in LLM performance via prompt structure and a potential false positive bias. 3.2 How does Prompt Structure Affect LLM Outputs?</p><p>In Figure <ref type="figure" target="#fig_0">1</ref>, the 8 label models outperform their 4 label counterparts. This begs the question of how prompts-and more specifically, the structure of the information in the prompts-influence LLM output.</p><p>The 8 label models may perform better because they provide more clearly structured information to the AI models than the 4 label prompts.<ref type="foot" target="#foot_16">foot_16</ref> With this in mind, it is important to note that the four label specifications contain the same information and examples as the 8 label specifications, barring slight changes to the names of the labels. <ref type="bibr">18</ref> The AI models may exploit the more structured explanations of each label, using this information to classify articles more akin to the undergraduate coders than the aggregated information found in the 4 label prompts.</p><p>Moreover, the One Shot and Few Shot models-by providing correctly identified examples of each label from the undergraduate coders-display better metrics than the zero-shot models, in line with scholarly expectations that more detailed sets of information improve AI performance across the board (Chae and Davidson 2024).</p><p>These findings have notable implications for the best practices of text classification tasks for both undergraduates and AI models. There exists a trade-off for the instruction of undergraduate coders in classification: codebooks must be balanced in terms of length, structure, and detail, as undergraduates will 1) become fatigued if the instructions are too long or 2) be unclear as to their assignment if the instructions are ill-defined. I disaggregate my original conception of four overarching frames into eight more specific frames in my codebook to reflect a balance in the level of detail, structure, and cognitive load. Adapting this codebook to AI prompts thus provides additional evidence that more structured information improves text classification performance for AI models. Writ large, one might be optimistic about using Few Shot LLMs to supplement undergraduate codings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">LLM Classifiers are Prone to False Positives</head><p>I now explore how the output of LLMs might be systematically different from undergraduate coders by focusing on LLMs' seeming bias toward false positives. Those models that display the worst performance metrics-in this case, higher values for hamming loss-simultaneously exhibit the false positive bias more egregiously (e.g., the Zero Shot ChatGPT 4 Turbo model).</p><p>To better depict this trend, I display the proportion of articles that undergraduates coded as 1s subtracted from the proportion of articles that LLMs coded as 1s in Figure <ref type="figure" target="#fig_2">3</ref> for both the 4 and 8 label specifications. A value of zero on these graphs indicates no false positives by LLMs in comparison to undergraduate coders, whereas higher positive values indicate more false positive errors. <ref type="bibr">19</ref> On average, the 8 label models do not show this false positive bias as strongly as the 4 label models, but the general trend remains that the performance of AI models in this analysis seem to be correlated with their level of false positive bias. In order to better understand why these false positives may be occurring, I conducted close readings of several newspaper articles coded as 1s by LLMs and 0 by undergraduates. <ref type="bibr">20</ref> Anecdotally, I find that the LLMs seemed to pick up on more subtle label cues than the human coders did, but they had trouble differentiating certain labels, such as the Vulnerable and Refugee labels in the 8 label specification. Moreover, the LLMs were more likely to make multiple coding errors within the same article, as opposed to mistakenly coding one label and getting the others correct.</p><p>While existing literature notes the problematic, black-box nature of LLMs (see Bisbee et al. 2024  and Spirling 2023), I am unaware of any existing work that explains this false positive bias. <ref type="bibr">21</ref> This systematic bias thus constitutes an area of future research. 22</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Conclusion</head><p>In this note, I analyze the reliability of LLMs in comparison to undergraduates, providing evidence that a Few Shot ChatGPT 4o model with 8 labels is the most reliable classifier. I offer two additional takeaways to practitioners and the burgeoning literature on LLM classifiers. First, LLMs using more structured prompts-those with their information broken down into more discrete parts-perform better than those using more general prompts. Second, these LLMs are biased toward false positive errors.</p><p>Use cases for social science applications of LLMs and text classification models vary in their difficulty and complexity. While AI models have recently approached human abilities on some tasks that are easier for humans, these models still struggle in other, more difficult applications. This project represents one of those more difficult applications, showing that the best performing AI model misclassifies labels about 10% more often than undergraduate coders. Despite the systematic biases of these models, they only lag slightly behind the undergraduate coders on the more complicated task of identifying newspaper frames. With this in mind, I place LLMs near the same level-or perhaps, slightly lower-than undergraduates on the coding quality hierarchy.</p><p>While these figures are likely to change as AI models improve, this article provides a framework for assessment of their performance as compared to both undergraduates and researchers. In this light, I encourage publishers and researchers to both incentivize and conduct regular tests of LLM performance across a variety of social science tasks. A centralized meta-analysis hub, for instance, might aggregate research such as this and contribute more broadly to our understandings of the generalizability of LLMs across languages and tasks, as well as the reliability and replicability of their results over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Disagreements and Intercoder Reliability</head><p>Using the output of my three coders, I rely on the codings of my two coders with the highest intercoder reliability scores for those coding outputs that do not agree.<ref type="foot" target="#foot_20">foot_20</ref> I measure intercoder reliability using Cohen's kappa. I calculate these scores for both the 8 label model and the 4 label model (by aggregating the 8 labels into their respective 4 label categories). The Cohen's kappa for coders 1 and 2 is 0.69 in the 8 label model and 0.71 in the 4 label model. These values indicate moderate reliability. Since each of my coders was randomly assigned to code half of all articles in the corpus, I utilize coder 3 to substitute for the values not coded by coders 1 and 2 (bringing the total articles coded by humans from 300 to 590). In the 8 label model, coder 3 has a Cohen's kappa score of 0.53 with coder 1 and 0.62 with coder 2. In the 4 label model, coder 3 has a Cohen's kappa score of 0.60 with coder 1 and 0.63 with coder 2. Each of these Cohen's kappa statistics are significant with p-values less than 0.05, meaning that the observed agreements are unlikely to result from random chance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B API Calls</head><p>I program and send my calls to the ChatGPT and Anthropic APIs using the httr package in R. However, when first sending these API calls, I faced server timeout errors if the prompts exceeded around 4,000 characters. To get around this error, I attempted to increase the length of the timeout for both my R session and my call to ChatGPT/Claude, to no avail. Instead, I found that sending a very short initial prompt-in my case, I pasted "Nada." instead of a full-length newspaper article at the end of my prompt instructions-would jump-start the process. After this faux article jump-started the API calls, I faced no timeout errors regarding the length of later prompts, even if they well-exceeded the 4,000 character pseudo-limit.</p><p>In later iterations for the ChatGPT calls, I used its batching feature, which was more cost effective and often faster than calling the API from R.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Costs</head><p>The start-up costs for running models through ChatGPT or Claude are moderate, and I intend to illuminate the necessary steps to perform these classification tasks through my discussion of API calls, prompts, and the replication code. After creating API accounts for the service of interest, one must then purchase $50-$200 of API credits and wait for a certain amount of time to pass (around 2 weeks) after account creation to access higher rate limits. After this point, researchers can send large API calls without issue.</p><p>Additionally, One Shot and Few Shot models require examples of the ground truth for training the models. Generating these examples is often a time-consuming process, especially if the researcher does not speak the necessary language(s). It took several hours to validate the examples provided by my undergraduate researchers alone, so it will likely take many more to identify them on one's own.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Additional Model Statistics</head><p>In Table <ref type="table" target="#tab_2">3</ref>, I display the raw values for area under the curve (AUC; the accuracy of binary classifiers), recall (proportion of true 1s correctly identified by the model), F1 (harmonic mean of precision and recall), hamming loss, Intraclass Correlation Coefficient (ICC; the strength of coder agreement across model and human classification), and percentage of articles coded as 1s for each LLM in comparison to the undergraduate coders. Most models fall between 0.74 and 0.81 for AUC, 0.78 and 0.92 for recall, 0.85 and 0.94 for F1, 0.23 and 0.10 for hamming loss, and 0.31 and 0.55 for the ICC. I highlight each cell with the best model statistic value in dark gray. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Model Statistics without Disagreed Values</head><p>In Table <ref type="table" target="#tab_3">4</ref>, I display the AUC, recall, F1 score, hamming loss, ICC, and percentage of articles coded as 1s for each LLM in comparison to the undergraduate coders, excluding all articles for which the human coders disagreed in labeling. Most models fall between 0.75 and 0.85 for AUC, 0.80 and 0.94 for recall, 0.86 and 0.95 for F1 score, 0.21 and 0.09 for hamming loss, and 0.31 and 0.58 for the ICC. These model metrics are largely similar to the full dataset, and I still conclude that the Few Shot ChatGPT 4o with 8 labels is the best classification model based on its optimal scores for recall, F1 score, hamming loss, and percentage classified as 1s. However, note that the Claude Sonnet 3.5 models perform better with the disagreed values excluded across most metrics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Prompt Comparisons and Explanations</head><p>In this section of the appendix, using a Zero Shot ChatGPT 4o model with an 8 label specification, I compare my prompts across two dimensions: earlier versus later versions of my prompts and the inclusion of explanations. My prompts went through a series of adjustments to improve performance over the course of this project (though most of these changes concerned the structure of the output rather than the substantive content of the labels). I compare the performance of my models across one of the earliest versions of my prompt and the latest version in Figures <ref type="figure" target="#fig_3">4</ref> and <ref type="figure">5</ref> along metrics for hamming loss and the proportion of articles classified as 1s. These graphs show that the latest version of my prompt has considerably improved the performance across the hamming loss and proportion classified as 1s metrics.</p><p>In addition to comparing the performance of my earlier versus later prompts, I analyze how requesting explanations for the model's output might improve performance. I find that asking the models to justify their responses slightly improves performance in the earlier prompt while reducing performance in the later prompt. Figure 5: Proportion 1s by Prompt on ChatGPT 4o</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Comparison to the Author's Codings</head><p>To provide another point of comparison, I code the same set of newspaper articles following the undergraduate codebook and analyze the output of both undergraduates and LLMs with my codings as the benchmark. Figure <ref type="figure" target="#fig_4">6</ref> displays the hamming loss of each model in comparison to my codings, with the results pooled across labels. I find that the 8 label ChatGPT 4o model performs best. More generally, the 8 label models perform better than the 4 label models, and the Few Shot models perform better than the One and Zero Shot models. Moving forward with the best performing model, I break out the results of undergraduates and ChatGPT 4o across labels in Figure <ref type="figure" target="#fig_5">7</ref>. With my codings as a benchmark, the output of ChatGPT 4o only differs from that of the undergraduates by an average hamming loss of 0.03. This is strong evidence in support of using these LLMs as supplements or replacements to human coders. <ref type="bibr">24</ref> This analysis comes to the same conclusions of my comparisons with undergraduates and LLMs-these AI models are performing at a similar level to undergraduate coders. Figure 8: AUC Across Models Figure 10: F1 Score Across Models </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I Predicting Alignment Between Human and AI Output</head><p>In this section, I attempt to understand the variation across labels for both the 8 and 4 label specifications of the best performing model: ChatGPT 4o (Few Shot). Tables <ref type="table" target="#tab_4">5</ref> and <ref type="table" target="#tab_5">6</ref> regress the probability of correct AI predictions on article word counts, complexity (using the Type-Token Ratio-which is the number of unique tokens divided by the total number of tokens-via R's quanteda package), and human coder agreement (Rul 2019).</p><p>In the 8 label model of Table <ref type="table" target="#tab_4">5</ref>, I find that articles in which human coders agreed on the final label were more likely to have aligned codings between humans and AI. While longer articles do not have any consistent effects across models, greater complexity largely predicts more alignment between human and AI labels (except for Label5, in which complexity has a large, negative effect on the probability of alignment). In the 4 label model of Table <ref type="table" target="#tab_5">6</ref>, I find largely similar results for the human agreement variable. However, in these models, I do not see the same positive results-in which greater text complexity predicts greater alignment-but rather a null effect. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>J Prompts</head><p>I paste below examples of the 4 and 8 label prompts used for ChatGPT. The Claude prompts only differ in that I pasted the newspaper article before the instructions rather than after, as I did here.</p><p>4 label specification (Zero Shot):</p><p>Consider the following themes that may be present in newspaper articles:</p><p>1: Humanitarianism, empathy, and perspective-taking. Does the article portray immigrants as vulnerable victims of circumstance or focus on their poverty, victimhood, and lack of choice? Does the article attempt to make the audience see life from an immigrant's point of view, encouraging further thinking and reflection on the issue? Does it provoke sympathy for immigrants? Does the article mention that some immigrants are refugees fleeing persecution or extreme economic deprivation?</p><p>2: Economic, disease, and violent threats. Does the article relate issues of health and disease spread to immigration? Does the article mention how immigration may lead to worse economic outcomes, such as job loss, lower salaries, or less access to public services for citizens? Does the article mention how immigration may lead to increases in violence, crime, or physical insecurity? Does the article associate immigrants with crime, violence, or illicit activities? Does the connect political or societal instability to immigration? Does it use the size of immigration flows to provoke worry or fear (for example, language like "hordes of immigrants" or "massive immigration flows")?</p><p>3: Economic benefits. Does the article mention how immigration may improve economic conditions?</p><p>4: Immigration policies and integration. Does the article bring up the relationship between immigration policies or government actions and immigrant integration? I will provide you with a newspaper article, and you will determine whether it matches any of the above themes. Label each theme with a 1 if it occurs in the article and a 0 if not. For example, if only theme 3 is mentioned, your response should be: "Theme1": 0, "Theme2": 0, "Theme3": 1, .... If the article is not primarily concerned with immigration, code all themes as 0s.</p><p>Your response should be structured like this: ["Theme1": 0, "Theme2": 0, "Theme3": 1, ...]</p><p>Do not include any output other than the JSON structured response, and your responses should be in English. The newspaper article is below:</p><p>4 label specification (One Shot):</p><p>Consider the following themes that may be present in newspaper articles. For each theme, I provide an explanation and then an example text embodying that theme.</p><p>1: Humanitarianism, empathy, and perspective-taking. Does the article portray immigrants as vulnerable victims of circumstance or focus on their poverty, victimhood, and lack of choice? Does the article attempt to make the audience see life from an immigrant's point of view, encouraging further thinking and reflection on the issue? Does it provoke sympathy for immigrants? Does the article mention that some immigrants are refugees fleeing persecution or extreme economic deprivation?</p><p>Example: "El drama de más de 100 migrantes, refugiados en parque Las Banderas. Muchos de estos migrantes habían clamado por ayuda, sobre todo, porque había niños y adultos mayores con síntomas de gripa, debido a la intensas lluvias de las últimas semanas."</p><p>2: Economic, disease, and violent threats. Does the article relate issues of health and disease spread to immigration? Does the article mention how immigration may lead to worse economic outcomes, such as job loss, lower salaries, or less access to public services for citizens? Does the article mention how immigration may lead to increases in violence, crime, or physical insecurity? Does the article associate immigrants with crime, violence, or illicit activities? Does the connect political or societal instability to immigration? Does it use the size of immigration flows to provoke worry or fear (for example, language like "hordes of immigrants" or "massive immigration flows")?</p><p>Example: "Aunque oficialmente no se ha reconocido un monto exacto, se calcula que cada paciente crónico extranjero atendido le cuesta a Colombia entre 200 y 220 millones de pesos al año. El Ministro recalcó que estas cifras son parciales y no dimensionan el gasto total para el país. Por eso pidió a todas las entidades territoriales y a las EPS, a través de una circular de febrero pasado, detallar los costos que ha generado este año la atención a extranjeros."</p><p>3: Economic benefits. Does the article mention how immigration may improve economic conditions?</p><p>Example: "Si hay alguna característica que uno puede buscar en un inmigrante es, que es gente aspiracional, gente que busca algo mejor. Van a trabajar, a, sacrificarse, a luchar."</p><p>4: Immigration policies and integration. Does the article bring up the relationship between immigration policies or government actions and immigrant integration?</p><p>Example: "'Sus políticas de integración, salud y educación han sido pioneras en la región', añadió el embajador. Colombia sigue necesitando mucho apoyo de la cooperación internacional para atender a los migrantes."</p><p>I will provide you with a newspaper article, and you will determine whether it matches any of the above themes. Label each theme with a 1 if it occurs in the article and a 0 if not. For example, if only theme 3 is mentioned, your response should be: "Theme1": 0, "Theme2": 0, "Theme3": 1, .... If the article is not primarily concerned with immigration, code all themes as 0s.</p><p>Your response should be structured like this: ["Theme1": 0, "Theme2": 0, "Theme3": 1, ...]</p><p>Do not include any output other than the JSON structured response, and your responses should be in English. The newspaper article is below:</p><formula xml:id="formula_0">4 label specification (Few Shot):</formula><p>Consider the following themes that may be present in newspaper articles. For each theme, I provide an explanation and then a few example texts embodying that theme.</p><p>1: Humanitarianism, empathy, and perspective-taking. Does the article portray immigrants as vulnerable victims of circumstance or focus on their poverty, victimhood, and lack of choice? Does the article attempt to make the audience see life from an immigrant's point of view, encouraging further thinking and reflection on the issue? Does it provoke sympathy for immigrants? Does the article mention that some immigrants are refugees fleeing persecution or extreme economic deprivation?</p><p>Example: "El drama de más de 100 migrantes, refugiados en parque Las Banderas. Muchos de estos migrantes habían clamado por ayuda, sobre todo, porque había niños y adultos mayores con síntomas de gripa, debido a la intensas lluvias de las últimas semanas."</p><p>Example: "El papa aprovechó para recordar "las prolongadas penalidades y angustias" de la crisis humanitaria de Venezuela, agravadas por la pandemia, así como a "todos aquellos que han dejado el país en busca de mejores condiciones de vida", al referirse a los millones de venezolanos que han tenido que emigrar hacia otras naciones."</p><p>Example: "Más de un millón de personas han huido del país en la última década, el 90 por ciento en los últimos cuatro años. La desesperación, el empobrecimiento y la irritación de los venezolanos está creciendo aceleradamente, ocurren brotes espontáneos de violencia todos los días. Existe una anarquía que deja la sensación de que no hay gobierno."</p><p>2: Economic, disease, and violent threats. Does the article relate issues of health and disease spread to immigration? Does the article mention how immigration may lead to worse economic outcomes, such as job loss, lower salaries, or less access to public services for citizens? Does the article mention how immigration may lead to increases in violence, crime, or physical insecurity? Does the article associate immigrants with crime, violence, or illicit activities? Does the connect political or societal instability to immigration? Does it use the size of immigration flows to provoke worry or fear (for example, language like "hordes of immigrants" or "massive immigration flows")?</p><p>Example: "Aunque oficialmente no se ha reconocido un monto exacto, se calcula que cada paciente crónico extranjero atendido le cuesta a Colombia entre 200 y 220 millones de pesos al año. El Ministro recalcó que estas cifras son parciales y no dimensionan el gasto total para el país. Por eso pidió a todas las entidades territoriales y a las EPS, a través de una circular de febrero pasado, detallar los costos que ha generado este año la atención a extranjeros."</p><p>Example: "El presidente de Colombia Iván Duque anunció que se cerrarán los, siete pasos fronterizos con Venezuela, con el objetivo de tratar de detener la propagación del coronavirus en el país."</p><p>Example: "Lo que ha representado 'problemas de desorden social en la región fronteriza, casos de trata de personas, victimización violenta, extorsión y despojos, el desarrollo de toda una economía informal en torno a la masiva migración y un importante ejército de reserva de mano de obra barata para la economía legal, informal e ilegal', según recoge Pares en su informe."</p><p>3: Economic benefits. Does the article mention how immigration may improve economic conditions?</p><p>Example: "Si hay alguna característica que uno puede buscar en un inmigrante es, que es gente aspiracional, gente que busca algo mejor. Van a trabajar, a, sacrificarse, a luchar."</p><p>Example: "Colombia tendrá que destinar entre 0,23 y 0,41% de su PIB en el corto plazo para atender a los migrantes venezolanos que huyen de crisis en su país, aunque bien gestionada la ola migratoria puede darle réditos económicos a mediano y largo plazo."</p><p>Example: "Pero si esos refugiados estuvieran legalizados, podrían pagar impuestos, trabajar, y aportar a la economía de ese país."</p><p>4: Immigration policies and integration. Does the article bring up the relationship between immigration policies or government actions and immigrant integration?</p><p>Example: "'Sus políticas de integración, salud y educación han sido pioneras en la región', añadió el embajador. Colombia sigue necesitando mucho apoyo de la cooperación internacional para atender a los migrantes."</p><p>Example: "Una de esas medidas, acordadas el pasado 4 de agosto, fue la creación de una cédula fronteriza. El documento, que deben portar tanto los ciudadanos venezolanos como colombianos que residen en la frontera, tiene contenida información fundamental de las actividades que desarrollan y los motivos de su paso entre ambos países."</p><p>Example: "Los venezolanos que residen en Colombia y cuentan con el Permiso por Protección Temporal (PPT) podrán obtener su licencia de conducción sin ningún problema. Esto bajo una resolución del Ministerio de Transporte expedida en los últimos días del mandato de Iván Duque. Todo migrante venezolano que tenga con el PPT lo podrá utilizar para realizar trámites asociados con la oficina de tránsito, es decir, podrán iniciar un proceso para solicitar su licencia de conducción y así transitar en vehículos de manera legal por el país."</p><p>I will provide you with a newspaper article, and you will determine whether it matches any of the above themes. Label each theme with a 1 if it occurs in the article and a 0 if not. For example, if only theme 3 is mentioned, your response should be: "Theme1": 0, "Theme2": 0, "Theme3": 1, .... If the article is not primarily concerned with immigration, code all themes as 0s.</p><p>Your response should be structured like this: ["Theme1": 0, "Theme2": 0, "Theme3": 1, ...]</p><p>Do not include any output other than the JSON structured response, and your responses should be in English. The newspaper article is below:</p><formula xml:id="formula_1">8 label specification (Zero Shot):</formula><p>Consider the following themes that may be present in newspaper articles:</p><p>1: Humanitarianism, empathy, and perspective-taking. Does the article portray immigrants as vulnerable victims of circumstance or focus on their poverty, victimhood, and lack of choice? Does the article attempt to make the audience see life from an immigrant's point of view? Does it provoke sympathy for immigrants? 2: Persecution, poverty, and push factors. Does the article mention that some immigrants are refugees fleeing persecution or extreme economic deprivation?</p><p>3: Health issues and threat of disease. Does the article relate issues of health and disease spread to immigration? 4: Economic issues, resource scarcity, and threat. Does the article mention how immigration may lead to worse economic outcomes, such as job loss, lower salaries, or less access to public services for citizens?</p><p>5: Issues of crime, violence, and illegal activities. Does the article mention how immigration may lead to increases in violence, crime, or physical insecurity? Does the article associate immigrants with crime, violence, or illicit activities?</p><p>6: General instability and threat. Does the connect political or societal instability to immigration? Does it use the size of immigration flows to provoke worry or fear (for example, "hordes of immigrants" or "massive immigration flows")?</p><p>7: Economic benefit. Does the article mention how immigration may improve economic conditions?</p><p>8: Immigration policies and integration. Does the article bring up the relationship between immigration policies or government actions and immigrant integration? I will provide you with a newspaper article, and you will determine whether it matches any of the above themes. Label each theme with a 1 if it occurs in the article and a 0 if not. For example, if only theme 3 is mentioned, your response should be: "Theme1": 0, "Theme2": 0, "Theme3": 1, .... If the article is not primarily concerned with immigration, code all themes as 0s.</p><p>Your response should be structured like this: ["Theme1": 0, "Theme2": 0, "Theme3": 1, ...]</p><p>Do not include any output other than the JSON structured response, and your responses should be in English. The newspaper article is below:</p><p>8 label specification (One Shot):</p><p>Consider the following themes that may be present in newspaper articles. For each theme, I provide an explanation and then an example text embodying that theme.</p><p>1: Humanitarianism, empathy, and perspective-taking. Does the article portray immigrants as vulnerable victims of circumstance or focus on their poverty, victimhood, and lack of choice? Does the article attempt to make the audience see life from an immigrant's point of view? Does it provoke sympathy for immigrants?</p><p>Example: "A pesar de que las víctimas que son residentes han sido maltratadas y tienen procesos muy duros, las que están en el exterior son doblemente victimizadas porque se han tenido que ir a otro país y vivir todo el proceso del migrante, adicional al proceso de ser víctima vulnerable."</p><p>2: Persecution, poverty, and push factors. Does the article mention that some immigrants are refugees fleeing persecution or extreme economic deprivation?</p><p>Example: "El drama de más de 100 migrantes, refugiados en parque Las Banderas. Muchos de estos migrantes habían clamado por ayuda, sobre todo, porque había niños y adultos mayores con síntomas de gripa, debido a la intensas lluvias de las últimas semanas."</p><p>3: Health issues and threat of disease. Does the article relate issues of health and disease spread to immigration?</p><p>Example: "El presidente de Colombia Iván Duque anunció que se cerrarán los, siete pasos fronterizos con Venezuela, con el objetivo de tratar de detener la propagación del coronavirus en el país."</p><p>4: Economic issues, resource scarcity, and threat. Does the article mention how immigration may lead to worse economic outcomes, such as job loss, lower salaries, or less access to public services for citizens?</p><p>Example: "Desde que llegó hace un mes, reparte las horas entre buscar empleo y buscar comida. "No hay trabajo para los cucuteños menos para el venezolano", dice este exsargento del Ejército."</p><p>5: Issues of crime, violence, and illegal activities. Does the article mention how immigration may lead to increases in violence, crime, or physical insecurity? Does the article associate immigrants with crime, violence, or illicit activities?</p><p>Example: "Es cierto que grupos criminales se estén aprovechando de estos venezolanos.</p><p>Resulta que en el año 2016 se han capturado, por diferentes delitos, 242 ciudadanos de Venezuela en el área metropolitana de Cúcuta."</p><p>6: General instability and threat. Does the connect political or societal instability to immigration? Does it use the size of immigration flows to provoke worry or fear (for example, "hordes of immigrants" or "massive immigration flows")?</p><p>Example: "El creciente flujo de refugiados hacia Colombia muestra el caos humanitario que se avecina. Ante la tragedia, los mandatarios de la región han resuelto enterrar la cabeza como avestruces."</p><p>7: Economic benefit. Does the article mention how immigration may improve economic conditions?</p><p>Example: "Si hay alguna característica que uno puede buscar en un inmigrante es, que es gente aspiracional, gente que busca algo mejor. Van a trabajar, a sacrificarse, a luchar."</p><p>8: Immigration policies and integration. Does the article bring up the relationship between immigration policies or government actions and immigrant integration?</p><p>Example: "'Sus políticas de integración, salud y educación han sido pioneras en la región', añadió el embajador. Colombia sigue necesitando mucho apoyo de la cooperación internacional para atender a los migrantes."</p><p>I will provide you with a newspaper article, and you will determine whether it matches any of the above themes. Label each theme with a 1 if it occurs in the article and a 0 if not. For example, if only theme 3 is mentioned, your response should be: "Theme1": 0, "Theme2": 0, "Theme3": 1, .... If the article is not primarily concerned with immigration, code all themes as 0s.</p><p>Your response should be structured like this: ["Theme1": 0, "Theme2": 0, "Theme3": 1, ...]</p><p>Do not include any output other than the JSON structured response, and your responses should be in English. The newspaper article is below:</p><p>8 label specification (Few Shot):</p><p>Consider the following themes that may be present in newspaper articles. For each theme, I provide an explanation and then a few example texts embodying that theme.</p><p>1: Humanitarianism, empathy, and perspective-taking. Does the article portray immigrants as vulnerable victims of circumstance or focus on their poverty, victimhood, and lack of choice? Does the article attempt to make the audience see life from an immigrant's point of view? Does it provoke sympathy for immigrants?</p><p>Example: "A pesar de que las víctimas que son residentes han sido maltratadas y tienen procesos muy duros, las que están en el exterior son doblemente victimizadas porque se han tenido que ir a otro país y vivir todo el proceso del migrante, adicional al proceso de ser víctima vulnerable."</p><p>Example: "También tuvo un recuerdo en su mensaje de Navidad para los 'desplazados, los emigrantes y refugiados, y los que hoy son objeto de la trata de personas' y lamentó que muchos pueblos 'sufren por las ambiciones económicas de unos pocos y la avaricia voraz del dios dinero que lleva a la esclavitud.'"</p><p>Example: "El papa aprovechó para recordar "las prolongadas penalidades y angustias" de la crisis humanitaria de Venezuela, agravadas por la pandemia, así como a "todos aquellos que han dejado el país en busca de mejores condiciones de vida", al referirse a los millones de venezolanos que han tenido que emigrar hacia otras naciones."</p><p>2: Persecution, poverty, and push factors. Does the article mention that some immigrants are refugees fleeing persecution or extreme economic deprivation?</p><p>Example: "El drama de más de 100 migrantes, refugiados en parque Las Banderas. Muchos de estos migrantes habían clamado por ayuda, sobre todo, porque había niños y adultos mayores con síntomas de gripa, debido a la intensas lluvias de las últimas semanas."</p><p>Example: "El 80% de esas personas refugiadas está en una situación de refugio de largo plazo, es decir que en más de cinco años no han podido volver a su país de origen, y esto se da o porque el conflicto sigue o porque hay explosiones de otros conflictos."</p><p>Example: "Más de un millón de personas han huido del país en la última década, el 90 por ciento en los últimos cuatro años. La desesperación, el empobrecimiento y la irritación de los venezolanos está creciendo aceleradamente, ocurren brotes espontáneos de violencia todos los días. Existe una anarquía que deja la sensación de que no hay gobierno."</p><p>3: Health issues and threat of disease. Does the article relate issues of health and disease spread to immigration?</p><p>Example: "El presidente de Colombia Iván Duque anunció que se cerrarán los, siete pasos fronterizos con Venezuela, con el objetivo de tratar de detener la propagación del coronavirus en el país."</p><p>Example: "Los médicos descubrieron entonces que los migrantes se contagiaban en los ríos, donde caen las heces contaminadas con cercarias de las aves migratorias que transitan por el Darién."</p><p>Example: "Esto los tiene en alerta roja con una ocupación hospitalaria en las unidades de cuidados intensivos que llega al 98 por ciento y que se agravaría si los migrantes venezolanos continúan su paso sin control."</p><p>4: Economic issues, resource scarcity, and threat. Does the article mention how immigration may lead to worse economic outcomes, such as job loss, lower salaries, or less access to public services for citizens? Example: "Desde que llegó hace un mes, reparte las horas entre buscar empleo y buscar comida. "No hay trabajo para los cucuteños menos para el venezolano", dice este exsargento del Ejército." Example: "Aunque oficialmente no se ha reconocido un monto exacto, se calcula que cada paciente crónico extranjero atendido le cuesta a Colombia entre 200 y 220 millones de pesos al año. El Ministro recalcó que estas cifras son parciales y no dimensionan el gasto total para el país. Por eso pidió a todas las entidades territoriales y a las EPS, a través de una circular de febrero pasado, detallar los costos que ha generado este año la atención a extranjeros." Example: "¿El problema es ver a los refugiados como una carga para los Estados? Así es. En el caso de Ecuador, este lunes el Gobierno dio una rueda de prensa en la que explicaban que los 56.000 refugiados colombianos le cuestan al Estado 30 millones de dólares." 5: Issues of crime, violence, and illegal activities. Does the article mention how immigration may lead to increases in violence, crime, or physical insecurity? Does the article associate immigrants with crime, violence, or illicit activities? Example: "Es cierto que grupos criminales se estén aprovechando de estos venezolanos. Resulta que en el año 2016 se han capturado, por diferentes delitos, 242 ciudadanos de Venezuela en el área metropolitana de Cúcuta."</p><p>Example: "Teniendo en cuenta que el ingreso de venezolanos ilegales a la ciudad ha sido relacionado con el incremento de la inseguridad, el Mandatario dijo que solicitaron una unidad especial de Migración Colombia para realizar algunas deportaciones."</p><p>Example: "Lo que ha representado 'problemas de desorden social en la región fronteriza, casos de trata de personas, victimización violenta, extorsión y despojos, el desarrollo de toda una economía informal en torno a la masiva migración y un importante ejército de reserva de mano de obra barata para la economía legal, informal e ilegal', según recoge Pares en su informe."</p><p>6: General instability and threat. Does the connect political or societal instability to immigration? Does it use the size of immigration flows to provoke worry or fear (for example, "hordes of immigrants" or "massive immigration flows")?</p><p>Example: "El creciente flujo de refugiados hacia Colombia muestra el caos humanitario que se avecina. Ante la tragedia, los mandatarios de la región han resuelto enterrar la cabeza como avestruces."</p><p>Example: "La ciudad, de 350.000 habitantes, está colapsada. Y si no fuera por las remesas de su hermano, Tilus y su familia estarían en la calle, como otros migrantes."</p><p>Example: "La crisis no termina y estamos tratando con consecuencias, de otra serie de problemas políticos que si no se solucionan este flujo, no logrará controlarse."</p><p>7: Economic benefit. Does the article mention how immigration may improve economic conditions?</p><p>Example: "Si hay alguna característica que uno puede buscar en un inmigrante es, que es gente aspiracional, gente que busca algo mejor. Van a trabajar, a sacrificarse, a luchar."</p><p>Example: "Colombia tendrá que destinar entre 0,23 y 0,41% de su PIB en el corto plazo para atender a los migrantes venezolanos que huyen de crisis en su país, aunque bien gestionada la ola migratoria puede darle réditos económicos a mediano y largo plazo."</p><p>Example: "Pero si esos refugiados estuvieran legalizados, podrían pagar impuestos, trabajar, y aportar a la economía de ese país. "</p><p>8: Immigration policies and integration. Does the article bring up the relationship between immigration policies or government actions and immigrant integration?</p><p>Example: "'Sus políticas de integración, salud y educación han sido pioneras en la región', añadió el embajador. Colombia sigue necesitando mucho apoyo de la cooperación internacional para atender a los migrantes."</p><p>Example: "Una de esas medidas, acordadas el pasado 4 de agosto, fue la creación de una cédula fronteriza. El documento, que deben portar tanto los ciudadanos venezolanos como colombianos que residen en la frontera, tiene contenida información fundamental de las actividades que desarrollan y los motivos de su paso entre ambos países."</p><p>Example: "Los venezolanos que residen en Colombia y cuentan con el Permiso por Protección Temporal (PPT) podrán obtener su licencia de conducción sin ningún problema. Esto bajo una resolución del Ministerio de Transporte expedida en los últimos días del mandato de Iván Duque. Todo migrante venezolano que tenga con el PPT lo podrá utilizar para realizar trámites asociados con la oficina de tránsito, es decir, podrán iniciar un proceso para solicitar su licencia de conducción y así transitar en vehículos de manera legal por el país."</p><p>I will provide you with a newspaper article, and you will determine whether it matches any of the above themes. Label each theme with a 1 if it occurs in the article and a 0 if not. For example, if only theme 3 is mentioned, your response should be: "Theme1": 0, "Theme2": 0, "Theme3": 1, .... If the article is not primarily concerned with immigration, code all themes as 0s.</p><p>Your response should be structured like this: ["Theme1": 0, "Theme2": 0, "Theme3": 1, ...]</p><p>Do not include any output other than the JSON structured response, and your responses should be in English. The newspaper article is below:</p><p>L Correlations and Close Readings  Based on these correlations and the false positive biases of the AI models, I perform close readings of randomly chosen articles for each label that were coded as 1s by the Few Shot ChatGPT 4o model with 8 labels but 0s by the human coders (performed after my own codings of the articles). Anecdotally, I find that the model picks up on more subtle label cues than the human coders did, but it had trouble differentiating certain labels, such as labels 1 and 2. Furthermore, the AI model had more miscodings among the more prevalent labels, suggesting that these miscodings might scale with the prevalence of the labels in the corpus. The miscodings seemed more beneficial in this analysis for labels 6 and 8, picking up on more subtle frames that my human coders could detect and correctly coding these documents according to my readings. However, for labels 2, 3, 4, and 5, the miscodings may have been more detrimental, with the AI model seemingly coding this mislabeled articles at random. Notably, many of the articles that I read were miscoded in multiple labels. That is, those articles that were miscoded were more likely to have several miscoded values. This may indicate that the LLMs were not sufficiently coding the articles not focused on immigration as 0s.</p><p>I generate three takeaways from my close readings. 1) One should be as specific and structured as possible in the codebook and validate the results of the classification task, given that the AI models may code articles in a way that correlates labels more closely than humans would. 2) Small-scale, close readings can be helpful in ensuring that one's codebook is specific enough for each label, includes the necessary topics and keywords for each label, and includes all relevant labels. For example, in this project, I remove the cultural benefit label from my original codebook due to its low prevalence in the corpus and poor intercoder reliability scores for the human coders. However, I noticed that articles with this theme were categorized into labels 4 and 5 multiple times, suggesting that its inclusion might benefit a more substantive analysis. 3) Since the Few Shot ChatGPT model with 8 labels is the best comparison to human coders in my context, I suggest using it for classification tasks. However, if one wants to descriptively estimate the prevalence of these labels, it may be more accurate to aggregate them up to the broader, 4 label framework (after classification with the more discrete, 8 label specification) before assessing their prevalence over time. This will minimize any error that may arise when AI models-unsure as to the correct labels-classify article into multiple, similarly correlated labels (such as labels 1 and 2). <ref type="bibr">25</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Few Shot ChatGPT 4o model with 8 labels performs best</figDesc><graphic coords="7,108.94,95.04,394.13,281.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: LLM performance substantially varies across label</figDesc><graphic coords="8,91.80,95.04,428.40,214.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: LLMs are biased toward false positives</figDesc><graphic coords="9,91.80,320.59,428.40,214.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Hamming Loss by Prompt on ChatGPT 4o</figDesc><graphic coords="15,91.80,285.17,428.41,306.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Few Shot ChatGPT 4o Model with 8 Labels Performs Best</figDesc><graphic coords="17,108.94,201.49,394.13,281.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: On average, ChatGPT 4o Performs 3% Worse than Undergraduates</figDesc><graphic coords="18,108.94,179.67,394.13,281.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure</head><figDesc>Figure 9: AUC Across Labels</figDesc><graphic coords="20,102.51,413.81,406.98,203.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>I</head><figDesc>display here a depiction of the differences in the correlation matrices of the undergraduate and ChatGPT 4o (Few Shot) output for the 8 label specification. Darker purple values indicate that the LLM label correlations are smaller than their undergraduate equivalents, while darker red values indicate that they are larger. Cells with pluses in them indicate that both correlations-for the undergraduate and ChatGPT 4o output-were positive, while minuses indicate that both were negative. The tilde symbol indicates that the correlations were different signs. Most differences in correlations are small, though note the larger decrease (a difference of nearly 0.5) in the correlations for Label 2 of each model. Furthermore, most correlations for both AI models and undergraduates are positive, though a fair number are negative or mixed, especially for labels 7 and 8.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 17 :</head><label>17</label><figDesc>Figure 17: Differences in Correlation Matrices</figDesc><graphic coords="36,113.22,237.31,385.56,330.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="16,91.80,95.04,428.41,306.01" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="21,113.22,95.04,385.56,275.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="21,102.51,413.81,406.98,203.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="22,113.22,95.04,385.56,275.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="22,102.51,413.81,406.98,203.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="23,113.22,95.04,385.56,275.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="23,102.51,413.81,406.98,203.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="35,91.80,249.31,428.40,214.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>4 Label Framework for Coding Articles</figDesc><table><row><cell>Label</cell><cell>Description</cell></row><row><cell cols="2">1: Humanitarian Perceptions that immigrants are vulnerable,</cell></row><row><cell></cell><cell>fellow humans fleeing harsh conditions</cell></row><row><cell>2: Threat</cell><cell>Fears, broadly construed, that immigration</cell></row><row><cell></cell><cell>will worsen the host country's economy,</cell></row><row><cell></cell><cell>health outcomes, and/or safety</cell></row><row><cell>3: Benefit</cell><cell>Perceptions that immigration can improve</cell></row><row><cell></cell><cell>local and national economies</cell></row><row><cell>4: Policy &amp;</cell><cell>Neutral, technical reports about immigration</cell></row><row><cell>Integration</cell><cell>policies and government action</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>8 Label Framework for Coding Articles</figDesc><table><row><cell>Label</cell><cell>Description</cell></row><row><cell>1: Humanitarian-</cell><cell></cell></row><row><cell>Vulnerability</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Model Comparison MetricsPercentage of articles in the sample coded as 1s. The mean percentage of articles coded as 1s by humans is 10% for the 8 label models and 23% for the 4 label models. So, the best value for this metric would be that closest to the human coded values.</figDesc><table><row><cell>Model</cell><cell cols="5">No. Labels Prompt Type AUC Recall F1</cell><cell cols="2">Hamming Loss ICC % 1s a</cell></row><row><cell>GPT 4 Turbo</cell><cell>8</cell><cell>Zero Shot</cell><cell>0.77</cell><cell>0.83</cell><cell cols="2">0.89 0.17</cell><cell>0.32</cell></row><row><cell></cell><cell>4</cell><cell>Zero Shot</cell><cell>0.77</cell><cell>0.80</cell><cell cols="2">0.86 0.20</cell><cell>0.48</cell></row><row><cell></cell><cell>8</cell><cell>One Shot</cell><cell>0.79</cell><cell>0.89</cell><cell cols="2">0.92 0.13</cell><cell>0.42</cell></row><row><cell></cell><cell>4</cell><cell>One Shot</cell><cell>0.75</cell><cell>0.87</cell><cell cols="2">0.90 0.16</cell><cell>0.46</cell></row><row><cell></cell><cell>8</cell><cell>Few Shot</cell><cell>0.77</cell><cell>0.90</cell><cell cols="2">0.93 0.12</cell><cell>0.43</cell></row><row><cell></cell><cell>4</cell><cell>Few Shot</cell><cell>0.77</cell><cell>0.88</cell><cell cols="2">0.90 0.15</cell><cell>0.49</cell></row><row><cell>GPT 4o</cell><cell>8</cell><cell>Zero Shot</cell><cell>0.81</cell><cell>0.86</cell><cell cols="2">0.91 0.14</cell><cell>0.43</cell></row><row><cell></cell><cell>4</cell><cell>Zero Shot</cell><cell>0.79</cell><cell>0.82</cell><cell cols="2">0.88 0.18</cell><cell>0.48</cell></row><row><cell></cell><cell>8</cell><cell>One Shot</cell><cell>0.80</cell><cell>0.90</cell><cell cols="2">0.93 0.12</cell><cell>0.46</cell></row><row><cell></cell><cell>4</cell><cell>One Shot</cell><cell>0.78</cell><cell>0.87</cell><cell cols="2">0.90 0.15</cell><cell>0.52</cell></row><row><cell></cell><cell>8</cell><cell>Few Shot</cell><cell>0.78</cell><cell>0.92</cell><cell cols="2">0.94 0.10</cell><cell>0.48</cell></row><row><cell></cell><cell>4</cell><cell>Few Shot</cell><cell>0.80</cell><cell>0.88</cell><cell cols="2">0.91 0.14</cell><cell>0.55</cell></row><row><cell cols="2">Claude Sonnet 3.5 8</cell><cell>Zero Shot</cell><cell>0.82</cell><cell>0.83</cell><cell cols="2">0.90 0.16</cell><cell>0.38</cell></row><row><cell></cell><cell>4</cell><cell>Zero Shot</cell><cell>0.80</cell><cell>0.84</cell><cell cols="2">0.88 0.17</cell><cell>0.49</cell></row><row><cell></cell><cell>8</cell><cell>One Shot</cell><cell>0.83</cell><cell>0.83</cell><cell cols="2">0.89 0.17</cell><cell>0.37</cell></row><row><cell></cell><cell>4</cell><cell>One Shot</cell><cell>0.78</cell><cell>0.87</cell><cell cols="2">0.89 0.16</cell><cell>0.51</cell></row><row><cell></cell><cell>8</cell><cell>Few Shot</cell><cell>0.82</cell><cell>0.85</cell><cell cols="2">0.90 0.16</cell><cell>0.39</cell></row><row><cell></cell><cell>4</cell><cell>Few Shot</cell><cell>0.78</cell><cell>0.85</cell><cell cols="2">0.89 0.17</cell><cell>0.48</cell></row><row><cell>a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Model Comparison Metrics without Disagreed ValuesPercentage of articles in the sample coded as 1s. The mean percentage of articles coded as 1s by humans is 9% for the 8 label models and 16% for the 4 label models. So, the best value for this metric would be that closest to the human coded values.</figDesc><table><row><cell>Model</cell><cell cols="5">No. Labels Prompt Type AUC Recall F1</cell><cell cols="2">Hamming Loss ICC % 1s a</cell></row><row><cell>GPT 4 Turbo</cell><cell>8</cell><cell>Zero Shot</cell><cell>0.79</cell><cell>0.85</cell><cell cols="2">0.91 0.15</cell><cell>0.34</cell></row><row><cell></cell><cell>4</cell><cell>Zero Shot</cell><cell>0.78</cell><cell>0.82</cell><cell cols="2">0.88 0.19</cell><cell>0.40</cell></row><row><cell></cell><cell>8</cell><cell>One Shot</cell><cell>0.79</cell><cell>0.91</cell><cell cols="2">0.93 0.11</cell><cell>0.43</cell></row><row><cell></cell><cell>4</cell><cell>One Shot</cell><cell>0.76</cell><cell>0.89</cell><cell cols="2">0.91 0.14</cell><cell>0.48</cell></row><row><cell></cell><cell>8</cell><cell>Few Shot</cell><cell>0.79</cell><cell>0.92</cell><cell cols="2">0.94 0.10</cell><cell>0.45</cell></row><row><cell></cell><cell>4</cell><cell>Few Shot</cell><cell>0.78</cell><cell>0.90</cell><cell cols="2">0.92 0.13</cell><cell>0.51</cell></row><row><cell>GPT 4o</cell><cell>8</cell><cell>Zero Shot</cell><cell>0.80</cell><cell>0.88</cell><cell cols="2">0.92 0.13</cell><cell>0.43</cell></row><row><cell></cell><cell>4</cell><cell>Zero Shot</cell><cell>0.79</cell><cell>0.85</cell><cell cols="2">0.90 0.16</cell><cell>0.50</cell></row><row><cell></cell><cell>8</cell><cell>One Shot</cell><cell>0.80</cell><cell>0.91</cell><cell cols="2">0.94 0.10</cell><cell>0.48</cell></row><row><cell></cell><cell>4</cell><cell>One Shot</cell><cell>0.79</cell><cell>0.89</cell><cell cols="2">0.91 0.14</cell><cell>0.53</cell></row><row><cell></cell><cell>8</cell><cell>Few Shot</cell><cell>0.77</cell><cell>0.94</cell><cell cols="2">0.95 0.09</cell><cell>0.49</cell></row><row><cell></cell><cell>4</cell><cell>Few Shot</cell><cell>0.80</cell><cell>0.90</cell><cell cols="2">0.92 0.12</cell><cell>0.58</cell></row><row><cell cols="2">Claude Sonnet 3.5 8</cell><cell>Zero Shot</cell><cell>0.83</cell><cell>0.85</cell><cell cols="2">0.91 0.15</cell><cell>0.38</cell></row><row><cell></cell><cell>4</cell><cell>Zero Shot</cell><cell>0.81</cell><cell>0.85</cell><cell cols="2">0.90 0.16</cell><cell>0.52</cell></row><row><cell></cell><cell>8</cell><cell>One Shot</cell><cell>0.83</cell><cell>0.85</cell><cell cols="2">0.91 0.15</cell><cell>0.38</cell></row><row><cell></cell><cell>4</cell><cell>One Shot</cell><cell>0.80</cell><cell>0.88</cell><cell cols="2">0.91 0.14</cell><cell>0.55</cell></row><row><cell></cell><cell>8</cell><cell>Few Shot</cell><cell>0.83</cell><cell>0.87</cell><cell cols="2">0.92 0.14</cell><cell>0.40</cell></row><row><cell></cell><cell>4</cell><cell>Few Shot</cell><cell>0.79</cell><cell>0.87</cell><cell cols="2">0.90 0.15</cell><cell>0.51</cell></row></table><note><p>a</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Predicting AI-Human Aligned Responses in 8 Label Models</figDesc><table><row><cell></cell><cell cols="2">Label1 Label2</cell><cell cols="6">Label3 Label4 Label5 Label6 Label7 Label8</cell></row><row><cell cols="2">Word Count (By 100) 0.003</cell><cell cols="2">-0.0002 0.002</cell><cell>0.001</cell><cell cols="3">-0.001 0.0005 0.001</cell><cell>0.004</cell></row><row><cell></cell><cell cols="2">(0.003) (0.002)</cell><cell cols="6">(0.001) (0.001) (0.002) (0.002) (0.001) (0.003)</cell></row><row><cell>Text Complexity</cell><cell>0.28</cell><cell>0.58</cell><cell>0.40</cell><cell>0.13</cell><cell>-0.80</cell><cell>0.44</cell><cell>0.22</cell><cell>0.16</cell></row><row><cell></cell><cell>(0.26)</cell><cell>(0.25)</cell><cell>(0.14)</cell><cell>(0.12)</cell><cell>(0.25)</cell><cell>(0.25)</cell><cell>(0.12)</cell><cell>(0.27)</cell></row><row><cell>Human Agreement</cell><cell>0.21</cell><cell>0.17</cell><cell>0.02</cell><cell>0.05</cell><cell>0.04</cell><cell>0.09</cell><cell>0.02</cell><cell>0.16</cell></row><row><cell></cell><cell>(0.04)</cell><cell>(0.04)</cell><cell>(0.02)</cell><cell>(0.02)</cell><cell>(0.04)</cell><cell>(0.04)</cell><cell>(0.02)</cell><cell>(0.04)</cell></row><row><cell>Intercept</cell><cell>0.50</cell><cell>0.43</cell><cell>0.73</cell><cell>0.86</cell><cell>1.23</cell><cell>0.58</cell><cell>0.84</cell><cell>0.59</cell></row><row><cell></cell><cell>(0.15)</cell><cell>(0.14)</cell><cell>(0.08)</cell><cell>(0.07)</cell><cell>(0.14)</cell><cell>(0.14)</cell><cell>(0.07)</cell><cell>(0.15)</cell></row><row><cell>Observations</cell><cell>589</cell><cell>589</cell><cell>589</cell><cell>589</cell><cell>589</cell><cell>589</cell><cell>589</cell><cell>589</cell></row><row><cell>Adjusted R 2</cell><cell>0.04</cell><cell>0.04</cell><cell>0.01</cell><cell>0.01</cell><cell>0.02</cell><cell>0.01</cell><cell>0.003</cell><cell>0.02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Predicting AI-Human Aligned Responses in 4 Label Models</figDesc><table><row><cell></cell><cell cols="4">Label1 Label2 Label3 Label4</cell></row><row><cell cols="2">Word Count (By 100) 0.002</cell><cell>0.003</cell><cell cols="2">0.0003 0.003</cell></row><row><cell></cell><cell cols="4">(0.003) (0.003) (0.001) (0.003)</cell></row><row><cell>Text Complexity</cell><cell>0.22</cell><cell>0.05</cell><cell>0.08</cell><cell>0.15</cell></row><row><cell></cell><cell>(0.28)</cell><cell>(0.29)</cell><cell>(0.11)</cell><cell>(0.28)</cell></row><row><cell>Human Agreement</cell><cell>0.22</cell><cell>0.11</cell><cell>0.02</cell><cell>0.15</cell></row><row><cell></cell><cell>(0.05)</cell><cell>(0.05)</cell><cell>(0.02)</cell><cell>(0.05)</cell></row><row><cell>Intercept</cell><cell>0.51</cell><cell>0.67</cell><cell>0.92</cell><cell>0.59</cell></row><row><cell></cell><cell>(0.15)</cell><cell>(0.16)</cell><cell>(0.06)</cell><cell>(0.16)</cell></row><row><cell>Observations</cell><cell>589</cell><cell>589</cell><cell>589</cell><cell>589</cell></row><row><cell>R 2</cell><cell>0.04</cell><cell>0.01</cell><cell>0.003</cell><cell>0.02</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>I use "AI models" and "LLMs" interchangeably.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>I include detailed information regarding my prompt and model specifications in the appendix. See Appendix B for more information on my API calls, Appendix F for more information on how my adaptations of my codebook to AI prompts improved from my first to latest prompt, and Appendix J for examples of all my prompt specifications.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>I generate these theoretical labels in my other work.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>See Appendix A for more information on intercoder reliability. As a robustness check, in Appendix E, I rerun my analysis and exclude disagreed values, finding similar results.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Spanish is less resourced than English, though it is still highly digitized and broadly used. Thus, this provides an easier test for the capabilities of these models in non-English languages than, say, Quechua or Welsh.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>For example, the context window of the base BERT model is 512 tokens.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>However, recent research questions the replicability of these closed-source models<ref type="bibr" target="#b16">(Spirling 2023</ref>).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>See https://platform.openai.com/docs/guides/prompt-engineering for ChatGPT-specific best practices, and https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview for Claude-specific best practices. Also see<ref type="bibr" target="#b9">Liu et al. 2023.</ref> </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8"><p>In this API call, I set the temperature-a hyperparameter ranging from 0 to 2 where lower values indicate less randomness in responses-of each model to 0.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9"><p>See Appendix F.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10"><p>Note that Claude Sonnet 3.5 and ChatGPT 4o are much less expensive than ChatGPT 4 Turbo.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11"><p>See Appendix C for an in-depth discussion of the costs involved in running these models.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_12"><p>See Appendix J for examples of each prompt and information on how I constructed them.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_13"><p>Specifically, I rerun a Few Shot ChatGPT 4o model with an 8 label specification using a prompt fully in Spanish. See Appendix J.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_14"><p>In Figure4of Appendix H, I expand this analysis out to show the results of these models across each label. In Appendix G, I perform a similar analysis using my own coding of these newspaper articles as a benchmark.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_15"><p>See Table3in Appendix D for other metrics used to compare the LLM outputs with reference to just the undergraduate codings. Also see Figures 2 through 15 in Appendix H for figures visualizing the results for each of these model metrics.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_16"><p>They also more closely resemble the original task of the author and undergraduates.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_17"><p>For example, Benefit in the 4 label AI prompt and Econ Benefit in the 8 label AI prompt are the exact same, as they both correspond to economic benefits. On the other hand, Human in the 4 label specification contains the same information as Vulnerable and Refugee in the 8 label specification.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_18"><p>Note that in the 8 label specification, undergraduates coded articles as 1s 10% of the time; in the 4 label specification, 23% of the time. For the 4 label undergraduate model, I deterministically aggregate each of their 8 label codings into the respective 4 label categories. In their original task, undergraduates did not code articles into the 4 label schema.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_19"><p>See Appendix L for more information on these close readings. This appendix also explores correlation matrices</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23" xml:id="foot_20"><p>Note that 97% of coding outputs are in agreement.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24" xml:id="foot_21"><p>Though notice the variation across labels. In some, such as Econ Benefit and Threat, ChatGPT 4o outperforms the undergraduates, while in others, such as Instability and Refugee, ChatGPT 4o lags far behind the undergraduates.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="25" xml:id="foot_22"><p>Here, I found that the AI models would code many articles into labels 1 and 2, despite the fact that most of these should have been coded as just label 1. I suspect that this is due to the fact that labels 1 and 2 are highly correlated and deal with humanitarianism from different angles.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements I would like to thank <rs type="person">James Bisbee</rs>, <rs type="person">Joshua Clinton</rs>, <rs type="person">Cindy Kam</rs>, <rs type="person">Brenton Kenkel</rs>, and <rs type="person">Jennifer Larson</rs> for their helpful feedback on this project.</p></div>
<div><head>Funding Statement None.</head><p>Disclosure Statement The authors report there are no competing interests to declare.</p></div>
			</div>
			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data Availability Statement Data will be made available upon acceptance of the article.</p><p>for articles coded by undergraduates and the Few Shot ChatGPT 4o model.</p><p>21 It may be possible to overcome these issues with fine-tuned models or different hyperparameters.</p><p>22 For an exploration into what predicts alignment between undergraduate and AI coders, see Appendix I.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>H Supplementary Model Visualizations</head><p>In this section, I visualize how the LLMs compare across each label for a variety of model metrics, using the undergraduate codings as a baseline. I then display AUC, F1, ICC, and recall 1) across models, 2) across all labels, disaggregated by the 4 and 8 label specifications, and 3) the differences in each metric when going from a 4 to 8 label specification. Most of these graphs supplement the primary takeaways from the main text: the Few Shot GPT 4o model with 8 labels performs best, 8 label models outperform 4 label models, and most models are systematically different from human coders.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>K Fixed vs. Ordered Prompts</head><p>In this section, I test for the phenomenon in Bisbee et al. 2024 that AI models are more likely to select the first label in a text classification task. I rerun my AI models, randomizing the order in which the AI sees each label in the prompt. In Figure <ref type="figure">16</ref> below, I compare the mean proportion of articles coded as 1s by the AI models with fixed and randomized label orderings. This figure shows small differences in the proportion of articles, with the models with randomized label orderings seemingly classifying articles as 1s at higher rates than the fixed label ordering models. However, none of these differences are significant at a 95% confidence level. Furthermore, I compare differences between each label in the fixed and randomized label order models. While there occur some significant differences in the proportions of articles coded as 1s, I do not find that the first labels in the fixed order prompts are any more likely to be chosen than those in the random order prompts. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Synthetic Replacements for Human Survey Data? The Perils of Large Language Models</title>
		<author>
			<persName><forename type="first">James</forename><surname>Bisbee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Analysis</title>
		<imprint>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Language Models are Few-Shot Learners</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Large Language Models for Text Classification: From Zero-Shot Learning to Instruction-Tuning</title>
		<author>
			<persName><forename type="first">Youngjin</forename><surname>Chae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Davidson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>SocArXiv</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Framing Theory</title>
		<author>
			<persName><forename type="first">Dennis</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">N</forename><surname>Druckman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Review of Political Science</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="126" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Arabic Text Classification: The Need for Multi-Labeling Systems</title>
		<author>
			<persName><surname>El Rifai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leen</forename><surname>Hozayfa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashraf</forename><surname>Al Qadi</surname></persName>
		</author>
		<author>
			<persName><surname>Elnagar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing and Applications</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1135" to="1159" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The humanitarian foundation of public support for social welfare</title>
		<author>
			<persName><forename type="first">Stanley</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><forename type="middle">R</forename><surname>Steenbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Political Science</title>
		<imprint>
			<biblScope unit="page" from="658" to="677" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Role of Humanitarianism in Shaping Public Attitudes Toward Refugees</title>
		<author>
			<persName><forename type="first">Nicholas</forename><forename type="middle">A R</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Go</forename><surname>Murakami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Psychology</title>
		<idno type="ISSN">1467-9221</idno>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="255" to="275" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Attitudes toward highly skilled and low-skilled immigration: Evidence from a survey experiment</title>
		<author>
			<persName><forename type="first">Jens</forename><surname>Hainmueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Hiscox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="84" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Disgust Sensitivity and Public Demand for Protection</title>
		<author>
			<persName><forename type="first">Cindy</forename><forename type="middle">D</forename><surname>Kam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Beth</forename><forename type="middle">A</forename><surname>Estes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Politics</title>
		<idno type="ISSN">0022-3816</idno>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="481" to="496" />
			<date type="published" when="2016-09-07">2016. Visited on 07/09/2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</title>
		<author>
			<persName><forename type="first">Pengfei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">35</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Lost in Translation: Large Language Models in Non-English Content Analysis</title>
		<author>
			<persName><forename type="first">Gabriel</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aliya</forename><surname>Bhatia</surname></persName>
		</author>
		<ptr target="https://cdt.org/insights/lost-in-translation-large-language-models-in-non-english-content-analysis/" />
	</analytic>
	<monogr>
		<title level="s">Center for Democracy &amp; Technology</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Computational Identification of Media Frames: Strengths, Weaknesses, and Opportunities</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Nicholls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pepper</surname></persName>
		</author>
		<author>
			<persName><surname>Culpepper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Communication</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="159" to="181" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-Label Text Classification using Attention-based Graph Neural Network</title>
		<author>
			<persName><forename type="first">Ankit</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muru</forename><surname>Selvakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Malaikannan</forename><surname>Sankarasubbu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th International Conference on Agents and Artificial Intelligence</title>
		<meeting>the 12th International Conference on Agents and Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="494" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Automated Annotation with Generative AI Requires Validation</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Pangakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Samuel</forename><surname>Wolken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Neil</forename><surname>Fasching</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">NLP] Basics: Measuring The Linguistic Complexity of Text</title>
		<author>
			<persName><forename type="first">Céline</forename><surname>Rul</surname></persName>
		</author>
		<author>
			<persName><surname>Van Den</surname></persName>
		</author>
		<ptr target="https://towardsdatascience.com/linguistic-complexity-measures-for-text-nlp-e4bf664bd660" />
	</analytic>
	<monogr>
		<title level="m">Medium</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Predisposing Factors and Situational Triggers: Exclusionary Reactions to Immigrant Minorities</title>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">M</forename><surname>Sniderman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markus</forename><surname>Louk Hagendoorn</surname></persName>
		</author>
		<author>
			<persName><surname>Prior</surname></persName>
		</author>
		<idno>0003-0554</idno>
	</analytic>
	<monogr>
		<title level="j">American Political Science Review</title>
		<idno type="ISSN">1537-5943</idno>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="35" to="49" />
			<date type="published" when="2004-02">Feb. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Why open-source generative AI models are an ethical way forward for science</title>
		<author>
			<persName><forename type="first">Arthur</forename><surname>Spirling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">616</biblScope>
			<biblScope unit="issue">7957</biblScope>
			<biblScope unit="page" from="413" to="413" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</title>
		<author>
			<persName><forename type="first">Jason</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="24824" to="24837" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Large Language Models Can Be Used to Estimate the Latent Positions of Politicians</title>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
