<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Model of Phenomenal Experience Based on a Dialectical Framework</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Daniel</forename><surname>Malikov Independent</surname></persName>
							<email>daniel@malikov.ca</email>
						</author>
						<title level="a" type="main">A Model of Phenomenal Experience Based on a Dialectical Framework</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BDF31A9CC4ABA97D96C0D00B43DD3775</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-22T20:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper consists of four sections. First is Ethical statement, where we discuss some risks of creating an artificial phenomenal experience. In Introduction we establish some common ground for our model with the topic of Minimal phenomenal experience. Then we present our model, which is based on our dialectical framework and distinguishes between consciousness and cognition as structurally and functionally distinct phenomena. The model outlines the flow from sensory data and suggests that sophisticated brains can process second-order abstractions, termed virtual objects, which are the only objects available for conscious control. A possible approach to a simulation is mentioned. Further, we make some predictions and inferences from the model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethical statement</head><p>Regarding computer programs: if we base our definitions of phenomenal or conscious states on any type of awareness, then let's consider a computer antivirus program. An antivirus analyzes incoming data and employs a number of strategies to decide on an action. It examines incoming data for potential threats (heuristic detection), predicts outcomes by processing the data in an abstracted space (sandbox), compares the data's behavior against legitimate behavior (host intrusion prevention system) and uses the results of these deliberations to make up its mind, so to speak, on what to do <ref type="bibr" target="#b0">(Corrons, 2023)</ref>. Found in a living organism, such behavior could be called sentient, even conscious: we go through all these steps when approached by a stranger in the street, for example. Furthermore, an antivirus reports its own states, e.g. it's scanning a filesystem or its databases are out of date.</p><p>I doubt that any computational model of awareness functionally similar to embodied awareness, and especially any model based on energy optimization, cannot be found in computer systems. Indeed, operating systems do run an "integrated internal model of their 1 own epistemic space as such" <ref type="bibr" target="#b3">(Metzinger, 2020</ref>; emphasis in the original). It is the space where the applications may process data that is irrelevant to the machine's ecology, i.e., in a way, a space of capacity for abstract thoughts or meditations in the Latin sense. In other words, computer architecture will not allow our model to make it more conscious than it already is.</p><p>More specifically, we consider the risks of creating phenomenal states or genuine conscious experiences excluded for these reasons:</p><p>• The model presented here uses modules that don't have direct biological analogues.</p><p>• The model, as presented here, does not require simulation of some phenomena, such as emotional states.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>This paper is supplementary to philosophico-theoretical work A Dialectical Approach to the Question of Consciousness <ref type="bibr" target="#b2">(Malikov, 2024)</ref> and utilizes its findings. Here we present a model of graded phenomenal experience from pre-cognitive perception to conscious awareness. It is not currently a simulation, but can be turned into one, in time.</p><p>We consider experiencing nothing not to be a conscious state, at least within the widely used definitions of consciousness (subjective experience, what it's like) or correlated notions of wakefulness, alertness, etc. <ref type="bibr" target="#b3">Metzinger (2020)</ref> defines consciousness as knowing that subject is alert. In turn, the basic tonic (as opposed to phasic) alertness comes with arousal and is "a functional property causally enabling cognitive capacities" (ibid), i.e. a potential which is unrealized until a phenomenal experience. The Minimal phenomenal experience (MPE) project then aims, if I understand correctly, to examine this split-second moment, e.g. in the morning from when a healthy subject knows that she is alert, and until the alertness takes phenomenal shape. This moment of MPE, but greatly extended, can also be felt during some practices of transcendental meditation <ref type="bibr" target="#b1">(Gamma &amp; Metzinger, 2021)</ref> in the Eastern sense. I have experienced this state of (almost) nothingness known as "no-mind" (wu-xin, acitta). I had no thoughts and no perception of time, as in a dreamless sleep sometimes. Like the subject from the <ref type="bibr">Winter et al study (2020)</ref>, who reported awareness level 2 out of 10 at the height of meditation, I can't say that my consciousness was completely devoid of content. The content was undefined, muffled, not allowed into awareness, but it was there. Subjects from the Gamma &amp; Metzinger study (2021) also reported various content (broadly understood), e.g. feelings of peace, bliss, harmony.</p><p>Thus MPE does not imply the absolute absence of content, which makes this concept and our model fundamentally compatible. We believe our model can be useful for research and understanding of MPE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model: outline</head><p>Our dialectical framework <ref type="bibr" target="#b2">(Malikov, 2024)</ref> is based on a distinction between consciousness and cognition. We assert that the distinction is structural and functional. Cognition is understood as the processes of analyses of heterogeneous data, producing cognitive objects-mental modal representations of external and internal stimuli. The evolutionary advantage of cognition is, roughly, increased variability of behavioral strategies, compared to instinctive behavior. We define consciousness as voluntary control of cognitive objects.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Levels of awareness C -conscious access B -phenomenal access A -cognition P -initial processing S -stimuli</head><p>What we see here is a module. Sensory data S (including internal -ceptions and other signals) is preprocessed in P and enters the loops A as cognitive objects (the circular triples) we call sensory objects. The red and blue circles represent valence and associative memory mixed into the object. However, both valence and memory can also be understood as a process of this overall form. In other words, a red circle may just as well represent the sensory components of a cognitive object, so if the blue circle represents memory, then the diagram shows the process of valence assignment. If the red and blue circles represent the sensory data and valence, then this is a memory module.</p><p>Speculatively, every component (e.g. sensory) may be split modally (e.g. into audio, video, etc.), possibly even further, adding more, perhaps fractal dimensions to our model. I can not present a mathematical model at this time.</p><p>B is the phenomenal level. Paradoxically, a whole is a kind of an abstraction from its parts, a category, i.e. the table I see is an abstraction from its molecules and fibers and from the retinal reaction to the photons. Sophisticated brains can re-loop a category object, process it (almost) as a sensory object, and get a category of categories or an abstraction in the usual sense (ibid). These higher order abstractions we call virtual objects. The virtual objects are the only objects available to consciousness C in terms of control. (We suggest that it would be beneficial for neuroscience and related fields to demarcate consciousness and cognition along this line. In other words, in our model the notion of "phenomenal consciousness" is not a consciousness at all.)</p><p>Given the apparent fractal-like nature of the model as a direction, and availability of mathematical frameworks that deal with such complexities, a higher-order simulation of the phenomenal level B with a simulation of conscious control C can be built. The question is in the metrics to use. We do tentatively suggest presynaptic GABAb receptor activity as a possible marker for conscious access (ibid).</p><p>Using our taxonomy we can define MPE of meditations mentioned above, as a state of conscious inhibition of cognitive objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model: inferences and predictions</head><p>A few testable predictions:</p><p>1. A recent study <ref type="bibr" target="#b4">(Tacikowski et al., 2024)</ref>, published after our Dialectical paper, seems to support our assertion of the limited role of consciousness and the consciousness/cognition distinction. The participants' hippocampi and entorhinal cortices recognised patterns in the presentation of images and anticipated images without the participants' conscious awareness.</p><p>2. Mental images of the same sight reconstructed with high resolution will differ significantly from person to person.</p><p>3. Hallucinations result from shifted or disrupted GABA balance in the relevant brain area.</p><p>4. Many schizophrenia symptoms, such as hallucinations, reduced deviance detection, schizophasia are correlated with GABA disbalance in relevant brain areas.</p><p>There are some inferences which I am not sure are testable now, but are relevant to MPE. A. Pure consciousness, i.e. consciousness without thoughts, is a common, even default state for most animals, including us. This state can sometimes be very noticeable for non-meditators when watching fire, water, nature and such.</p><p>B. Bedside electroencephalography, as well as JFK Coma Recovery Scale and Glasgow Coma Scale used to assess patients with disorders of consciousness, represent the patients' state reasonably well. Improvement in precision is possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Minimal phenomenal experience is a fairly new research area for modern science, but ancient practice. It represents a paradigm different from the neural correlates approach as it starts with the phenomenality. I think we do need more humanism in the study of consciousness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>Consciousness, we propose, is a recent (&gt;3 million year old) evolutionary development and provides very limited options of control, namely, as we currently see it, allowing or rejecting cognitive objects offered by cognition. The model is presented visually in Figure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 x</head><label>1</label><figDesc>Figure 1x -time, ~1s shown y -graded awareness</figDesc><graphic coords="3,81.00,532.86,284.25,222.00" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>• The model does not attempt to solve or overcome the combination problem.• Our model, if realized on a computer, should run in the software abstraction layer, where all operations are largely homogeneous and avoid any direct low-level hardware control which, in principle, could structurally mimic some functionalities of a brain or of a part of one.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Corrons</surname></persName>
		</author>
		<ptr target="https://us.norton.com/blog/malware/what-is-antivirus" />
		<title level="m">What is antivirus? Definition, types, and benefits</title>
		<imprint>
			<publisher>Norton</publisher>
			<date type="published" when="2023-11-28">2023, November 28</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The Minimal Phenomenal Experience questionnaire (MPE-92M): Towards a phenomenological profile of &quot;pure awareness&quot; experiences in meditators</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Metzinger</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0253694</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0253694" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">253694</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A dialectical approach to the question of consciousness</title>
		<author>
			<persName><forename type="first">D</forename><surname>Malikov</surname></persName>
		</author>
		<idno type="DOI">10.31219/osf.io/wvbsq</idno>
		<ptr target="http://dx.doi.org/10.31219/osf.io/wvbsq" />
	</analytic>
	<monogr>
		<title level="j">Center for Open Science</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Minimal phenomenal experience</title>
		<author>
			<persName><forename type="first">T</forename><surname>Metzinger</surname></persName>
		</author>
		<idno type="DOI">10.33735/phimisci.2020.i</idno>
		<ptr target="https://doi.org/10.33735/phimisci.2020.i" />
	</analytic>
	<monogr>
		<title level="j">Philosophy and the Mind Sciences</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="44" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Human hippocampal and entorhinal neurons encode the temporal structure of experience</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tacikowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kalender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ciliberti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Fried</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-024-07973-1</idno>
		<ptr target="https://doi.org/10.1038/s41586-024-07973-1" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Content-Free awareness: EEG-fcMRI correlates of consciousness as such in an expert meditator</title>
		<author>
			<persName><forename type="first">U</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Levan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Borghardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Akin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wittmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Leyens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2019.03064</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2019.03064" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
