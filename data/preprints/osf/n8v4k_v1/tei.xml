<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Reductive Explanation of Consciousness</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Martin</forename><surname>Wolstencroft</surname></persName>
							<email>wolstencroftm@gmail.com</email>
						</author>
						<title level="a" type="main">A Reductive Explanation of Consciousness</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9A40ABD684BB033B6C2F9036D739339D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-22T20:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Consciousness</term>
					<term>Sentience</term>
					<term>Artificial Intelligence</term>
					<term>Philosophy of mind</term>
					<term>Attention</term>
					<term>Phenomenal Consciousness</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The origins of consciousness and conscious experience have been regarded as a mystery for millennia. Philosophical exploration remains divided on physical or non-physical origins. Research in neuroscience and psychology are revealing the physical construction of the brain and illuminating features of the mind in operation. However, current theories of consciousness and intelligence have not quite crystalised into a workable model that fully explains the emergence of consciousness. Here I propose a logical model for the origin of consciousness. The paper describes step by step how consciousness emerges using only memory plus the capabilities of neurons to distil and match patterns. The model shows that consciousness is inevitable in active creatures. Using the model, the paper addresses the 'hard problem' of consciousness and describes a mechanism for 'attention'. The distillation mechanism, along with the layering of pattern matching, is central to the subsequent development of further features of mind by allowing the brain to learn increasingly complex patterns. Extension of the logical model will yield a general theory of intelligence. As a logical model it can be applied in a non-biological substrate.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>There are several leading theories for consciousness <ref type="bibr" target="#b33">(Seth &amp; Bayne, 2022)</ref>. Some of these theories get close by describing models which make sense. However, most of their detailed descriptions of consciousness are a bit like saying "Aeroplanes fly because they have wings" but without explaining why the wings provide lift. i.e. they fall short of explaining the Bernoulli principle that creates the 'lift'. In the case of consciousness, a clear explanation of 'exactly how' tends to be absent from most of the theories.</p><p>This paper fills that explanatory gap with a logical model rooted in the capabilities of neurons. The model complements some of the other theories and works well alongside them.</p><p>The mechanisms proposed here are not the only mechanisms that operate to create mind. I offer these mechanisms as a contribution to the wider set of theories. I suggest the extended pattern matching model can provide essential missing content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>We know that the brain comprises many neurons. It is also known that neurons can match patterns. The brain can be seen as a massively parallel processing device. One can envisage the contents of the brain information as a bubbling sea of signals (Figure <ref type="figure">1</ref>) where some signals are louder than others or have more attention than others.</p><p>Figure <ref type="figure">1</ref> Within this boiling sea are external sensory signals, internal bodily sensations, and mental activity.</p><p>To turn that into a logical model looks complicated at first sight. However, I have always found that a limited number of simple principles often underly complex activity.</p><p>Secret Sauce I propose pattern distillation and pattern matching as the key components. Together these primitives can be used to describe the emergence of consciousness.</p><p>For clarity: -• 'Pattern Distillation' is when a collection of neurons extract a pattern from example data.</p><p>• 'Pattern Matching' is all about how neurons can flexibly match arriving patterns with remembered patterns.</p><p>With the principles of neurons and neural networks in mind, let us wind back through evolutionary history and consider the life and environment of a non-conscious creature with a basic brain.</p><p>One can imagine how this non-conscious brain witnesses patterns all the time. It would receive patterns from its eyes, patterns from its sense of smell, patterns from touch, patterns from hearing.</p><p>Our creature evolved over millions of years, so it will also have internal bodily sensations and chemical/hormonal influences. It is processing a combination of internal and external sensations -all of these are presented as patterns in the brain's neurons. The mechanisms of pattern-matching and pattern-distillation can be applied to all sources of sensation -not just the obvious senses we think about. The biochemical influence of the body can be viewed as additional patterns on the neurons. Biochemical influences in the brain can be wide ranging, but their net result is to modify or influence the patterns being handled.</p><p>Moving forward through time, let us imagine our non-conscious experimental creature has a brain which is now 'large-enough'. (No, I don't know exactly how large -this is a thought experiment). As our creature interacts with the world it will continue to experience patterns and then distil new patterns and learn them <ref type="bibr" target="#b0">(Aertsen, 2021;</ref><ref type="bibr" target="#b21">Konovalov &amp; Krajbich, 2018;</ref><ref type="bibr" target="#b26">Olsen et al., 2012)</ref>.</p><p>Our creature will have 'been exposed to' many events and circumstances.</p><p>• External events witnessed by the creature sometimes create sensations in the creature's body. Patterns in events reveal 'Self' through distillation of examples All these example signals are seen as patterns in creature's brain. It collects them as examples. Many, many thousands of examples of interaction with the world. As its memory of such interactions expands, the pattern-distillation mechanism cannot help but identify 'self' from the patterns.</p><p>It manages to do this because it has a large collection of example patterns like: -'hunger'; 'moving' 'touched'; 'pain'; 'fly flew past', 'not touched'; 'fly landed', 'touched'; 'fly gone', 'not touched'.</p><p>The pattern distilled as 'a pattern across the patterns witnessed' is the subtle difference of the creature (self) being influenced or not by events. It is an inevitable result of the exposure to the patterns of the world when a brain has the pattern distillation ability. It builds the relationships, the generalisations, the summaries, and the meta-patterns that form the content of mind, and at this early stage it deduces 'self'.</p><p>To labour the point… What has happened is that the creature's exposure to the world has shown it patterns that reveal the existence of self. There is a world of non-self, and a world of self. Our creature has distilled a pattern which clarifies that difference in its mind.</p><p>Human infants go through the same process -collecting sensations both passively and interactively until their 'selfness' begins to become known.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Non-conscious Awareness</head><p>Remember that at this point our experimental creature is not yet conscious. It has merely built sets of patterns that include a pattern that aligns to 'self'. This creature has sensations from its environment, but it is not consciously aware of those sensations. It is also definitely not thinking about them.</p><p>I refer to this as 'pre-consciousness'. It has patterns in its 'mind' that include itself, but it is not thinking in the way we do. Its sensations from the world are visceral and direct.</p><p>(Similar to how human infant also knows nothing about what's going on. It is reacting and accumulating more patterns.) SELF HUNGRY SELF COLD SELF WET Visual Tactile Internal Visceral Sensations Hot/Cold/Wet/Hunger/Pain/Light/Dark</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Collect examples</head><p>Collection and distillation of patterns that include 'self'</p><p>As our non-conscious experimental creature lives in the world, it can respond to incoming sensations in an autonomic manner. Its responses are visceral and immediate. It does not, and cannot, think them through. It has sensations that allow it to react autonomously. It doesn't have any conscious experience of them in the way that a conscious creature can, but it does have the visceral impact of them. It has the sensation/feel of them -the awareness -because it can react to them using evolutionarily embedded responses. There is an example of this in the carabid beetle -which has a very limited range of responses to events <ref type="bibr" target="#b29">(Reznikova &amp; Dorosheva, 2013)</ref>.</p><formula xml:id="formula_0">SELF HUNGRY SELF COLD SELF WET</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Autonomous Action Selection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visual Tactile Internal</head><p>Visceral Sensations Hot/Cold/Wet/Hunger/Pain/Light/Dark</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Circumstances into Patterns</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visceral Sensations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Action Pattern</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Autonomous action selection triggered by detected patterns</head><p>At this point I should share that the word 'experience' is almost a reserved word in the discussion of consciousness and is often used to mean 'having a conscious experience of'.</p><p>So, to hopefully avoid a reprimand from the philosophy police, I plan to use the word 'awareness' to describe the existence in the creature's brain of coherent patterns indicating a relationship between the creature and an event. Without being conscious, and still only reacting autonomously, our creature has patterns which have 'awareness' of its environment.</p><p>But how does identifying 'self' contribute to consciousness? Evolution is efficient at re-using things it makes. Once a body feature exists it can be copied and exapted for re-use. The process is known as exaptation <ref type="bibr" target="#b16">(Gould &amp; Vrba, 1982)</ref>. As an example, a limb functioning as a leg can evolve to be re-used as an arm or even a wing. An Axolotl's fins have become feet and the Handfish has some fins that can even grasp undersea vegetation.</p><p>The principle of exaptation will also operate in the brain and mind -just faster. The pattern discovery or 'distillation' mechanism, once evolved, can be exapted and used more widely. This process will happen in layers of increasing complexity -not just at the raw sensory level, but at more complex levels, distilling patterns-of-patterns and then patterns of those patterns. Constructing these layers of 'patterns-of-patterns' creates a larger 'soft' internal library of patterns for re-use. This library is a diffuse learned collection spread through all the patterns and the neurons involved.</p><p>The mechanism allows the brain to hold this 'self' pattern within additional higher-level patterns. In those more complex patterns, we can explore further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Re-Use</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distilled</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Patterns</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Higher Level</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Patterns</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loose representation of building higher level patterns through layers of pattern distillation</head><p>Let us consider these increasingly high-level patterns rattling around our not yet conscious creature's mental model. There are now patterns that contain 'self' as well as the circumstances and events detected in the outside world. These patterns result not only in the creature identifying itself (without being conscious of the fact), but also having the 'self' pattern for re-use.</p><p>In this way, our creature has created a mental 'label' for self. It's not a word for self -words as labels come much later -but it is loosely analogous to language. We learn the word 'ten' to mean ten of something. We can speak about 'ten green bottles' without working on the detail, or counting items. Similarly, in our creature's brain it now has (without language) a 'shortcut' for 'self'.</p><p>With a shortcut/label, it can now identify 'self' in other patterns. The construction of patterns for "Self on a lawn" and "Self in a tree" become feasible, as do many other patterns or sequences of sensations that include self. The complexity of those 'higher level' patterns is kept to a manageable size because the creature is using a label for self rather than the full history involved in the discovery of self.</p><p>SELF WATER SELF HUNGRY SELF COLD SELF WET SELF TREE SELF NON-SELF Distil Self from examples Visual Tactile Internal Visual Tactile Internal Visceral Sensations Cold/Wet/Hunger/Pain Witnessed Events External, Internal, Contact, Remote</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classify and Distil Patterns</head><p>Visceral Sensations Shortcuts/Labels instead of whole patterns</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Survival Influences</head><p>During the life of a more advanced creature, the patterns it learns will relate to things like: -where it expects to find food, how to avoid being eaten itself, and where to find a mate. These patterns of daily life are strongly influenced by the survival patterns that are innate in the species because they have been embedded by evolution -such as the signals from the body that present 'hunger'.</p><p>The survival patterns have their origin in the long biological evolution of the creature. The biochemistry of the body has been creating influential patterns on neurons while the brain was evolving. This is why I summarise the influence of the chemistry of the body as additional patterns that influence the pattern-matching brain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conscious Awareness</head><p>With patterns and layers accumulating, our creature now has the material to begin to consider its own awareness. i.e. to have more complex patterns containing self that are a step above the visceral reactonly world of non-conscious awareness.</p><p>It can hold patterns of the relationship of visceral sensations to the 'self' of the creature. This overview pattern encompasses the object of self, rather than just being the (lower-level) visceral connection of self to the sensations ('self hungry') At a result of building higher-level patterns, a collection of visceral sensations can also become a pattern that gives an overview e.g. "self was hungry, self ate food, self is sated". From the examples and from the internal mental processes, our creature can then discern/distil a meta-pattern for "self has sensations".</p><p>SELF WATER SELF HUNGRY SELF COLD SELF Label SENSATION PRINCIPLE SELF WET SELF TREE Distil Sensation Distil Location SELF Label LOCATION PRINCIPLE Visceral Sensations</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Distilling Descriptors of Visceral Sensations</head><p>We should also consider how some of these sensations are accompanied by additional chemical responses. More specifically, some are accompanied by signals from the ancient brain which give indications of risk or fear. These indications result from autonomous evolved responses to threats which helped the creature's ancestors to survive. These evolved responses may include a release of adrenaline or a burst of fear when a shadow passes over. With the pattern distillation skills that its brain has developed, it can now hold in its mind some patterns that consider the visceral content. E.g. 'self saw hawk', 'self scared'. This gives our creature the first glimmers of conscious awareness. That conscious awareness isn't super-smart. It's not a cognitive problem solver, but it's no longer an unconscious participant. It has become an observer of its own life and sensations.</p><p>To be clear, it hasn't yet developed a mental shortcut for "I'm alive" (it hasn't assembled or distilled enough patterns). However, it has the core machinery for future levels of understanding, it just needs the pattern samples and the time.</p><p>Whilst our newly conscious creature has started labelling patterns, it remains closely coupled to the sensory inputs and reflexes that served its ancestors well. Being now aware of these sensations does not diminish them, it just makes them accessible for consideration.</p><p>So, what happens because of that?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subjective Conscious Experience</head><p>Our creature has the awareness of conscious experience. It can perceive its conscious experiences because of the juxtaposition of patterns as they happen and as it remembers and recalls them.</p><p>Being a creature with sensory inputs and being consciously aware of those inputs means the brain is witnessing the visceral sensation at the same time as holding the patterns that describe the relationship to 'self'. Our creature thus has awareness of the events at the same time as the visceral sensation. This is also known as phenomenal consciousness, since for our creature there is 'something that it is like' to have the pattern of seeing a predator. The experience of seeing a predator involves the perception of the predator and the conjoined identification with the emotional sense of risk to self.</p><p>This presents within our creature, real-time conscious experiences -using only the capabilities of neurons to distil and match patterns.</p><p>The 'Observation of Experience' that pops out of the top is just a pattern, but it is a pattern that is remembered along with all the other content.</p><p>SELF WATER SELF HUNGRY SELF COLD SELF Label SENSATION PRINCIPLE SELF WET SELF TREE Distil Sensation SELF NON-SELF Distil Self from examples Visual Tactile Internal Visual Tactile Internal Visceral Sensations Cold/Wet/Hunger/Pain Witnessed Events External, Internal, Contact, Remote Classify and Distil Patterns SELF Label SENSATION PRINCIPLE SELF Label REMEMBERED SENSATION VISCERAL SENSATION SELF Label SENSATION Label REAL/ REMEMBERED Distil Visceral vs Memory SELF LOCATION SELF SENSATION Distil Live Sensation Associated Patterns Prediction Emotion Comparison Distil Observation of Experience Distil Location SELF Label LOCATION PRINCIPLE SELF LOCATION SELF SENSATION VISCERAL SENSATION SELF Label SENSATION Label REAL/ REMEMBERED OBSERVATION INFLUENCE of ASSOCIATIONS Subjective Conscious Experience -(Sensation with Observation Pattern) Visceral Sensations</p><p>The distillation of subjective conscious experience</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Memory's Contribution to Experience</head><p>As a pattern matching machine, the brain always continues to fetch the next pattern-match, and the next, and the next. This is the nature of neurons -they match patterns. These patterns come from external and internal stimuli as well as from the activity of the brain as it stores and remembers patterns.</p><p>As we (our creature, and you, and I) have patterns (ideas) passing through our minds, we are simply rolling from pattern match to pattern match -all automatically. It feels like we control it, but we are simply witness to it -until we apply 'attention' (something which really needs more than the cursory exploration included later in this paper). Some of the things flashing through our minds are not live experiences but are memories. Do we experience them?</p><p>Yes. Any retrieval of a pattern from memory is analogous in some ways to re-experiencing the original event <ref type="bibr" target="#b15">(Favila et al., 2020;</ref><ref type="bibr" target="#b31">Schacter, 2021)</ref>. This gives recalled memories the power to create some biological responses in the creature as the patterns of the memory re-traverse the brain and mind.</p><p>When the original sensation happened, the tight coupling of the brain with the body means they respond jointly to stress or surprise -as they always did when the core sensory input arrived in the ancient brain before our creature acquired consciousness. When sensations are recalled from memory, they resemble the originals and so these 'reminders' of those core signals circulate in the pattern-holding machinery. In doing so they trigger repeat responses as well as the memories of the original response.</p><p>So, the patterns are being re-experienced -bringing forth swathes of memories of previous experiences and emotions linked together by the patterns and chemistry of the body. They all contribute to the emotional and physical responses in the creature. Our newly conscious creature will identify these responses as affecting itself and coming from itself. This mechanism is also at the core of Conscious Access. Conscious Access is what we do when we can review our experiences and relay them to others.</p><p>So, in the real-time activity of an experience, we have patterns that are recollections, and we have patterns that are a visceral coupling of event-biology-self. From these, the creature can distil a pattern to identify the real-time visceral events -differentiating them from pure recollection of experience. If that's not a creature experiencing events consciously, then we must agree to differ, or discuss some more.</p><p>At this point, I feel that the mystery of consciousness and conscious experience has been resolvednot with a bang, but with a whimper <ref type="bibr" target="#b14">(Eliot, 1932)</ref>.</p><p>There is more to consider of course.</p><p>1. We have not yet integrated this pattern model with a Predictive model of mind. 2. We need a wider architecture to host a whole mind -like a Global Workspace Theory (GWT) engine. 3. There is a hard problem in the room.</p><p>I will talk to Hard Problem now but must cover the extended pattern matching model and an in-depth general theory of intelligence in the second paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Hard Problem</head><p>There is the slippery matter of what is known as the 'Hard Problem' of consciousness <ref type="bibr" target="#b7">(Chalmers, 2010)</ref>. Specifically, how can it be that when dumb chemistry gets together as biology (and then creatures), it can somehow allow for an inner sensation? That quality is absent at the level of the fundamental ingredients involved, so why does any jiggery pokery in the brain result in us experiencing the world? According to Chalmers, we haven't finished the job of explaining. I think there are three questions hiding in the 'Why' question.</p><p>1. The HOW/why question 2. The WHY do we feel/experience it (why do we have phenomenal consciousness) 3. The WHY has evolution persisted with consciousness at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">The How/Why Question</head><p>The earlier part of this paper describes it, but to summarise… Consciousness is an inevitable occurrence in any sufficiently complex brain occupying a physical body where the following capabilities exist. a) sensing its physical body. b) sensing the external environment. c) sensing some survival responses in its body/brain (ancient autonomic responses to existential threats). d) acting/moving in the environment. e) being able to 'distil' patterns from examples. f) being able to store and recall patterns in a 'pattern matching' style. g) having a sufficiently complex brain Any creature with those capabilities can distil the existence of 'self' as a pattern to work with. It is the inevitable result of the neuronal pattern-distillation machinery under the circumstances.</p><p>The experience of 'being' (what it is like) arises from the nature of the patterns that identify environment and self, being intimately coupled with those visceral sensations and the responses of the ancient brain to those sensations. So, having made consciousness intuitively inevitable, let's explore the other questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Why do we have phenomenal consciousness?</head><p>Phenomenal consciousness -the process through which we have an experience of aspects of our environment or our body.</p><p>Why do we 'feel'? How is it that the sensations exist at all, never mind that they can become conscious?</p><p>The simple reason is that any advanced creature with an internal mental life and having its brain in a dark box (like us) could not distinguish internal mental activity from the real world unless there is a qualitative difference between the two <ref type="bibr" target="#b13">(Dessalles &amp; Zalla, 1998)</ref>. Without phenomenal consciousness it would be impossible for a creature to develop any advanced mental content -since everything would be real -no opportunity to theorise or plan, everything would be the same. It couldn't separate the real world from a thought or memory.</p><p>Reviewing the mechanism:-Why does sensation+pattern feel like anything? -Well, clearly the sensation came first, but after that, did the feeling of that sensation come first or the observation? As described, I propose that the subjective experience is the presence of both as a conjoined pattern in the brain.</p><p>That pattern in mind is one that is best described as an observation, but there is no homunculus, the experience is in the conjoined "Sensation+ObservationPattern" which drives the visceral self in parallel with the cognitive self.</p><p>When you feel pain, the sensation floods through your nerves and neurons. In short order you are acutely aware of the existence of the sensation and how it is directly impacting YOU (your body). You also remember the last few moments world events and your attention is forcefully directed by the risk patterns. The circumstances will trigger memories and possible movements to escape the pain.</p><p>In another scenario, holding your partner's hand feels great! All because of the active sensation and awareness of it, which is enhanced by all the associations and memories you have.</p><p>In all cases, the memory of 'what just happened" -i.e. having a Sensation+ObservationPattern experience -will become part of the 'recent experience' record. The recollection of visceral events rounds out the mechanism. The record(memory) will be available to enhance the next similar occurrence OR the next time you think about it.</p><p>Any pattern about a subject can precipitate an experience, we only need to consider how retrieved memories can trigger bodily responses (memory to physical). In addition, since the brain mechanism for memory to physical already exists, it can be re-used (exapted) by evolution to connect 'intellectual to physical'. In effect this is a pattern for a experiencing a thought (have you ever blushed or winced with embarrassment years after an event?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alternate Views</head><p>I suspect that no matter what mechanism or evolutionary impetus is shown to precipitate conscious experience, it will never be enough for some -because the 'idea of experience' can be shuffled away from the explanation.</p><p>As an analogy -When you are on the telephone to someone, where does the conversation take place? On the telephone handset? In the radio waves to the cell tower? In the fibre network that carries the digital packets representing the sounds? At your house? At their house? Nowhere? Everywhere? In your head? In their head?</p><p>Where is the conversation? Maybe there is no such thing as a conversation if we only describe the physical aspects of how it is held? In reality, it is present in the data of the physical aspects, but the meaning has been skipped if we only consider the data.</p><p>I suggest the description of the physical aspects includes the conversation when we attach meaning to the sounds. The location then either vanishes or includes all the physical parts involved. The key aspect is the meaning -i.e. the perception of the participants in the phone call. This is the same challenge as pinning down experience. We have the underlying logical mechanism for patterns, and we can see how the meaning reaches consciousness. (There are more things to discuss around meaning and understanding, but this is meant to be a short paper.)</p><p>Having outlined the machinery, the meaning and the experience live in the patterns that hold the self and the sensation and the observation all in one. That's the experience.</p><p>i.e. It's no more complicated than having within the brain • a pattern which describes, • an observation of self • in the process of receiving a sensation and • at the same time,</p><p>• having that visceral sensation.</p><p>That combination is immediately saved in short term memory and becomes part of the 'current context' for the creature -giving it meaning.</p><p>Pattern matching never stops, so then the next round of patterns is retrieved. The next round of patterns may elicit emotional responses as well (recalling the pleasure of the evening). The mental model held will be updated and the cycle will repeat, and repeat.</p><p>So, for me, the only 'why' left to answer is the question of evolutionary persistence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Why has evolution persisted with consciousness</head><p>What is the advantage that consciousness confers, such that it is favoured in the evolutionary process?</p><p>The obvious answer (as mentioned) is the differentiation of the real world from the mental world, but it goes further.</p><p>Consciousness, once emerged, is helpful for survival. A conscious creature can be more successful. With the patterns it has captured it can work more constructively to consider options and explore possible outcomes of events and actions. Speed of adaptation is another significant benefit to a creature in survival terms. The faster it can adapt to new circumstances, the less likely it is to suffer an untimely demise. Creatures lacking neuronal structures require the passing of generations of creatures to embed significant behavioural changes.</p><p>Non-conscious Creatures with neurons can adopt behavioural changes that improve their survival chances within their lifetime. The more successful individual creatures may be smarter and so have genetic differences that can be passed on to their offspring.</p><p>The creatures with consciousness can consider patterns of event and possible outcomes based on the patterns they have observed. They can learn faster than their non-conscious brethren.</p><p>Social creatures can learn from their social group and can even survive being less clever because they don't have to solve all the survival problems themselves.</p><p>So, consciousness aids both survival and speed of further discovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing Consciousness</head><p>Let us posit that we have something a bit like a Turing test, or perhaps like Searle's Chinese room <ref type="bibr" target="#b32">(Searle, 1980)</ref>, but it's on a gameshow. "Conscious or Not Conscious? -A whole new gameshow for Saturday nights ! (all rights reserved) "Is the participant in box 'A', a Conscious Entity? or Not a conscious entity?" On this show, there are hidden participants in the 'boxes'. They may be AI, or they may be people. There is also a panel of 'guessing participants' (one assumes this panel is made up of celebrity philosophers, celebrity AI researchers, and TV science communicators).</p><p>Assuming the hidden participants in the gameshow only communicate via messages passed into and out of the box, then it is difficult (impossible?) for the "guessing participants" to know which hidden participant is genuinely conscious, and which are simply well-trained Large Language Models. So they have to use whatever skill or judgement they can muster. They can either make a 'deduction/guess' and 'open the box', or they can 'ask a question'.</p><p>My point is: I suggest the only true test of consciousness is to 'open the box' and see how it works on the inside. I suggest that anything just operating on lots of data which does not have a true understanding of the world and experiences thereof, should not be regarded as conscious (e.g. LLMs). However, something which operates on data and has a visceral/physical/phenomenal perception/understanding of the world may need to be considered differently. To assess an AI for consciousness we need to know how it works inside.</p><p>The best description of AI, if conscious, is that it will be a very different consciousness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Building a General Theory of General Intelligence</head><p>A general theory of intelligence is the primary subject of the second paper in this series, but it is worth covering the start of such a theory to show the potential of the model.</p><p>The pattern matching theory of consciousness includes the distillation model for finding new patterns (described earlier). The theory 'plays nicely' with other theories of consciousness such as Prediction theory and GWT, and each will benefit. In this regard I see pattern matching as a unifying force in a general theory of general intelligence. I commence the explanation here but will complete it in the second paper in this series.</p><p>Remember this is a logical model. It is not mapped to the brain. It provides a way of thinking about the content of mind and explaining aspects of mental activity.</p><p>To begin: Let's understand patterns and pattern-matching in the context of this model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Patterns are content</head><p>Patterns emerged first from the bottom-up work of the senses and neurons and exist as combinations of firing neurons. These patterns allow the construction of a mental model of 'what's out there'.</p><p>Patterns form the content which is held, transferred, and manipulated by the machinery described in alternate theories of consciousness. i.e. it is these patterns with which one or more of GWT, IIT and Prediction Theory will be operating.</p><p>Evolution has delivered a range of senses to living creatures. Along with the senses came different types of pattern for the brain to work with. There are auditory patterns of frequency, there are auditory patterns for rhythm which extend over periods of time, there are patterns for touch, patterns for internal senses and feelings, and most obvious to us humans -visual patterns. Patterns are everything, and they have been for millennia. This is why they work so well as the central element in the model. Bottom-up pattern matching becomes too resource intensive for it to form the complete approach to building a mind. Much more likely is the 'internal mental model' which predicts what happens next and then assesses the incoming patterns <ref type="bibr" target="#b8">(Clark, 2015;</ref><ref type="bibr" target="#b18">Hohwy, 2014)</ref>. All that needs some machinery <ref type="bibr" target="#b3">(Baars &amp; Geld, 2019;</ref><ref type="bibr" target="#b2">Baars, 1998;</ref><ref type="bibr" target="#b22">Mashour et al., 2020)</ref> to operate across the brain. However, Patterns comprise the content of the mental models.</p><p>The currently active patterns that describe the external world are not static. They loop, repeat, and recycle in the brain constantly. The internal model held by the brain and the sensory patterns arriving combine to choose the 'most likely' pattern in the creature's library of experience. So, prediction reduces to 'merely' the selection of the best matching pattern. I anticipate there is a balanced 'juggling' of bottom-up and top-down processing for best efficiency -as devised by evolution.</p><p>If at this point it doesn't sound like pattern matching is bringing anything to the party other than (just) consciousness, please bear with me because the logical model expanded in paper 2 will explain how several features of mind arise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Patterns are active</head><p>Pattern matching is what neurons and brains are good at. This is evident in the way we see a face on the moon, Elvis on a piece of toast, or animals in cloud shapes <ref type="bibr">(Ref 195)</ref>.</p><p>In terms of neurons in the brain, much research has been carried out to give us an understanding of how neural networks match patterns. It is a transitory activity. Input signals from one set of neurons can make other neurons fire when the patterns on the neurons match the remembered patterns closely enough.</p><p>The pattern matching that goes on in the brain is constantly hopping from pattern, to pattern, to pattern, to pattern. These hops are automatic because the neurons just respond to their input signals on the input dendrites and fire when they match something. The patterns 'recognised/retrieved' by those pattern matches then cause other patterns to be retrieved. It's a little bit like (but at a lower level than) how a stream of thought might start with a football, but hop to a specific match, and then to team colours, and then to a similarly coloured car that you saw, which reminds you to buy some petrol. The mechanism operates at many levels, it's not just the stream of thought, it's in all the simple things like smells, colours, up/down, left/right, sloping, 'on top', or underneath. They are all patterns and parts of patterns. The recollection of them and the re-assembly and re-use of them in the 'next' pattern is what goes on during thinking. It shows in the rhythms of EEG brain monitoring (Roohi-Azizi et al., 2017) -where the pattern match neuron firing is of a higher frequency when we are concentrating on something and lower frequency in deep sleep when there are fewer patterns to flip through.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What does all this autonomous activity mean?</head><p>It means that unsupported, unstructured, or unguided networks of neurons will wander down every event-driven 'rabbit-hole' pattern that they come across. For a creature to do more than flit about from subject to subject there needs to be a way for the focus to be controlled -a way to pay attention to something.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention Mechanisms</head><p>Why do some things reach a creature's conscious perception, and some don't? How does its brain work out that it should pay attention to the tiger, and ignore (or not even notice) a rat or some stinging nettles nearby? How does a different creature, when presented with many interesting objects, choose to pay attention to just one object and explore it?</p><p>To answer this question, we need to consider the origins of the attention mechanism. Once we have an attention mechanism, then pattern-matching and exaptation <ref type="bibr" target="#b16">(Gould &amp; Vrba, 1982)</ref> will build the rest. Exaptation of a working mechanism and re-using it for another purpose is what evolution is good at.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Origins of Attention</head><p>The ancient brain of our creature co-evolved with the chemistry of the body and the signals from the senses. These form an interlocking system of signals in both directions. The body is the reason the brain exists, and they work together to stay alive and reproduce. (The self-regulating process by which biological systems maintain stability while adjusting to changing external conditions is known as Homeostasis.) Consider a non-conscious creature. The patterns from the chemistry or the physical body create 'preference signals'. These are patterns that influence the choices/matches during pattern matching. e.g. A hungry creature will have hunger hormones that influence its brain. An adult creature will also have chemistry that causes it to seek out a mate at times. The influence of the hormones on the neurons, and/or the way it handles patterns, will cause changes in other pattern matching activities and cause our creature to prefer patterns that are known to lead to food (or possible partners).</p><p>While searching for food, our creature's amygdala might react to a sensory pattern associated with some type of risk. Perhaps a sound or a sight reminiscent of a predator. As a result, signals from the amygdala encourage attending to the safety of the creature. i.e. the patterns arising from the amygdala (and all the ancient brain) also sway pattern-matching choices.</p><p>I propose that this mechanism of emphasising different patterns at different times (as evolved from the chemical body to influence the brain), is the origin of attention mechanisms. Once the chemical mechanism evolved to be pattern-driven it became capable of dealing with the content of the neural networks and not just the biochemistry. This means that pattern signals from different sources can influence pattern matching cycles. These influences will favour some patterns over others. Nature has thus built a control mechanism and an attention mechanism.</p><p>It's a bit like the invention of the vacuum tube, or the transistor (depending on how old you are). I know the analogy is a bit of a stretch, but one signal can influence the strength of response to another signal.</p><p>In the pattern matching logical model, the patterns already 'in mind' can suppress or emphasise the retrieval of the next pattern. This adds great flexibility to our developing creature. It now has some mental features which can control what it pays attention to -steered by these 'survival patterns' or 'survival desires'. Of course, it's not like an on-off switch or transistor for retrieving a pattern, it's more like the survival pattern becomes part of the overall suite of active patterns that are triggering the next pattern matching cycle. It's like mood music, not Boolean logic.</p><p>However, once embedded as an attention mechanism, it is so effective that it even shows up in daily life. If you are looking for something (say a red book) you can simply hold the idea of it in mind and walk from room to room looking around, your pattern matching brain will do the rest and spot it without you necessarily having to study the room hard. (Personally, I often think about something else on the way and then forget why I went to the library in the first place, but that's just a feature of distraction and memory) By loading the object of your search into your mental model, you have nominated an item as being worthy of attention so the other mechanisms of mind can do their stuff. This is the thought-driven version of pattern preference which originally emerged via the attention mechanism of hormonal preference e.g. hunger.</p><p>There is much more to explore in the pattern model about how we bootstrap into conscious thought, but that would make this paper too long. So sadly. I must stop this part of the exploration here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Obligations for Theories of Consciousness</head><p>Any self-respecting theory of consciousness needs to address a few key features of mind and brain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussed in</head><p>This paper (the Emergence of Consciousness) Feature What it is Location What makes a mental state into a conscious mental state? The root mechanism for consciousness. Discussed in paper 1 Conscious experience Aka Phenomenal Consciousness Do we get close to passing the 'Chalmers Test'? Why is it 'like' something to experience the world? Discussed in paper 1 Consciousness in creatures other than humans. Non-Human Animals Are the differences and similarities accounted for? Is their consciousness encompassed by the theory. Discussed in paper 1 Cognitive Access Aka Access Consciousness Consciousness of things through or by means of conscious thoughts, perceptions, and concepts. Discussed in paper 2 How does 'attention' work? Different types of attention exist. By what mechanism does it come about and how is it manipulated. Mentioned in paper 1, expanded in paper 2 The relationship between consciousness and attention Does the theory have reasoning for incidental attention, conscious attention, and features like inattentional blindness? Mentioned in Paper 1, expanded in paper 2 Affect The mental experience of feelings and emotions. How the brain processes emotion. Mentioned in Paper 1, expanded in paper 2 Discussed in paper 2 (A General Theory of General Intelligence) Feature What it is Location Cognitive access Attention Affect As described above Revisited in paper 2 Human Infants Is their development explained? Mentioned in paper 1, Discussed in paper 2 Unity of Consciousness Why does it seem that we only have one thread of consciousness. Described in paper 2 Mood Prolonged affective states. Discussed in Paper 2 Temporality Does the theory address the experience of time? Discussed in Paper 2 Volition Does the theory address the cognitive process by which a creature decides on and commits to a particular course of action? Discussed in Paper 2 Understanding and Meaning Does the theory clearly address how understanding comes about? Discussed in Paper 2 Thought/Thinking Does the theory describe the cognitive process by which creatures work with models of the world? Thinking is manipulating information, forming concepts, engaging in problem solving, reasoning and make decisions. Discussed in Paper 2 States of Consciousness What does the theory say about the various states of consciousness Discussed in Paper 2 Discussed in paper 3 (Conscious or Not Conscious) Feature What it is Location Can Computers be Conscious? Can they? -arguments for and against Discussed in Paper 3 Faking Consciousness Do you know anyone who does? Discussed in Paper 3 Artificial Systems Can the theory be applied to nonbiological systems. Discussed in Paper 3 Truly Conscious Artificial Intelligence Is there a way to have nonbiological systems that are truly conscious? Discussed in Paper 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consciousness Theory Death-Match</head><p>"Two theories enter, one theory leaves."</p><p>That's just a catchy heading. In truth, no theories of consciousness were harmed in the writing of this paper.</p><p>As the new kid on the block, the pattern distillation and pattern matching model of consciousness and mind should pay more than lip service to the existing theories. It should neither ignore them nor assume they are wrong -because existing theories will be covering ground that the pattern model does not address directly OR will provide a perspective that adds value to the overall understanding.</p><p>We have mentioned the bottom-up approach, and 'Predictive processing', but there are also models known as 'Re-Entry theories', 'Higher Order Theories' (HOT), 'Global Workspace Theory' (GWT), 'Integrated Information Theory' (IIT). These theories and their variants are (were ;-)) the leading theories of consciousness.</p><p>Pattern distillation theory complements many of them because it is a logical model rooted in evolution which opens a productive perspective on consciousness. Prediction is also a logical model, and I view the others as machine structures. We need a collaboration, not a death match. I anticipate that a reproduction of mind and consciousness will require a variety of models and techniques -much like a moon-shot requires a multi-disciplinary team.</p><p>Below I include a summary of the theories mentioned. If you want a deeper understanding, please see these papers <ref type="bibr" target="#b1">(Albantakis et al., 2023;</ref><ref type="bibr" target="#b3">Baars &amp; Geld, 2019;</ref><ref type="bibr" target="#b4">Baars et al., 2021;</ref><ref type="bibr" target="#b2">Baars, 1998;</ref><ref type="bibr" target="#b8">Clark, 2015;</ref><ref type="bibr" target="#b12">Damasio &amp; Damasio, 2023;</ref><ref type="bibr" target="#b9">Damasio, 2000;</ref><ref type="bibr" target="#b11">Damasio, 2012;</ref><ref type="bibr" target="#b18">Hohwy, 2014;</ref><ref type="bibr" target="#b22">Mashour et al., 2020;</ref><ref type="bibr" target="#b23">Mediano et al., 2022;</ref><ref type="bibr" target="#b33">Seth &amp; Bayne, 2022)</ref> as starting points.</p><p>Higher Order Theories (HOT) Higher Order Theories (HOT) of consciousness come in several variants. HOTs try to explain consciousness as existing in higher-order representations of a lower order state of mind. i.e. a higher level thought about a state of mind.</p><p>This has parallels with the pattern distillation and matching model I describe. In fact, the Wolstencroft model qualifies as a HOT, but also underpins them since it includes the mechanism to explain consciousness and the construction of higher-level patterns. In addition, the Wolstencroft model also can describe more complex cognitive processes.</p><p>I think the model falls in the camp of Higher-Order Representationalism. HOWEVER, because HOTs have had the attention of a lot of philosophers and the arguments and counter arguments are complex and interwoven (because of all the variants of HOT) I'm not going to attempt a detailed mapping. If I were to try and fit it exactly into the community of HOTs it is likely I would cause confusion because of the technical jargon that has grown there. So, I politely defer weaving it precisely into the HOT network of theories. I believe all the variants of Higher Order theories will find something helpful in the Wolstencroft model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Global Workspace Theory (GWT)</head><p>GWT <ref type="bibr" target="#b3">(Baars &amp; Geld, 2019;</ref><ref type="bibr" target="#b4">Baars et al., 2021)</ref> and the Global Neural Workspace hypothesis (GNW) <ref type="bibr" target="#b22">(Mashour et al., 2020)</ref>propose that consciousness happens because of the highly connected neuronal workspace that can share information.</p><p>GNW has a good experimental neural grounding. It describes how a brain can operate (and is measured to operate) when being conscious. The GNW as a 'design' is being mapped to brain areas through ongoing fMRI testing. The design is a good one -tightly coupled areas of brain to perform tasks, and long interconnections to other areas of brain to pass information. However (to extend the analogy from earlier), the GWT/GNW machinery has wheels, wings, and a jet engine, and just needs the Bernoulli principle that provides 'lift'.</p><p>I believe that missing lift comes in the form of the logical pattern model that comes out of the latter parts of the Wolstencroft model together with the distillation of self.</p><p>Blum and Blum propose a logical model for a Conscious Turing Machine (CTM) that has its origins in GWT <ref type="bibr" target="#b5">(Blum and Blum, 2021)</ref>. I think their model will be effective. Adding the elements of conscious content from the Wolstencroft model to GWT, GNW and CTM will enhance those approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predictive Processing</head><p>Predictive processing regards the brain as operating (primarily) as a predictive machine. The machine holds a mental model of what is 'out there' in the world, and constantly updates it by addressing the 'errors' (discrepancies) that it finds in incoming signals.</p><p>This is an excellent model for efficiency as well as discussion. Updating a view is less effort than building one from scratch, and requires less data. The technique is used for digital TV transmission to save bandwidth.</p><p>The logical pattern matching model lets us discuss the content that must exist within the predictive machinery. If I were designing an implementation of that predictive machinery it would need to be layered and pattern oriented.</p><p>My reading of the works by Jakob Hohwy <ref type="bibr" target="#b18">(Hohwy, 2014)</ref> and Andy Clark <ref type="bibr" target="#b8">(Clark, 2015)</ref> suggests their view is that the brain is purely a predictive machine. I hope this position has softened -since then it would more resemble the top-down and bottom-up 'juggling' I describe.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Integrated Information Theory (IIT)</head><p>IIT offers a mathematical approach. It focusses on the ability of an entity to create change. It defines conscious experiences as informational structures that are irreducible and integrated within a complex system. Integrated Information Theory is based on several postulates, including completeness, composition, and information exclusion, which define the properties that a system must exhibit to be considered conscious according to IIT. It's central measure of consciousness is Φ (phi). Phi represents the level of integrated information within a system.</p><p>I note that IIT regards experience as an indivisible baseline and builds consciousness on top. I disagree about that baseline as described in the earlier part of this paper, but the prospect of a mathematical description for the higher functions of mind is an intriguing one.</p><p>A good reference paper for IIT is <ref type="bibr" target="#b1">(Albantakis et al., 2023)</ref> Self Comes to Mind Theory -Antonio Damasio Damasio has written several books <ref type="bibr" target="#b12">(Damasio &amp; Damasio, 2023;</ref><ref type="bibr" target="#b9">Damasio, 2000;</ref><ref type="bibr" target="#b10">Damasio, 2006;</ref><ref type="bibr" target="#b11">Damasio, 2012)</ref> including one <ref type="bibr" target="#b11">(Damasio, 2012)</ref> that chimes with distillation theory. I discovered Damasio's work after I developed pattern distillation and matching theory. What is very interesting to me is that he has similar overall principles (identification of self) but he does not have the distillation and pattern matching mechanisms that build the rest of conscious thought (phew!).</p><p>Antonio Damasio describes the feeling elements of consciousness very well. He describes how there is a confluence of body signals near the top of the brainstem <ref type="bibr" target="#b28">(Parvizi &amp; Damasio, 2003)</ref>. His theory suggests that consciousness arises from the interactions of neural circuits distributed throughout the brain. I am not a neuroscientist, and mine is a logical model, not a mapping to the brain. However, I think the theories align. With a bit more computer science, Damasio might have built the pattern model, but (fortunately for me) I get to describe 'how' using pattern distillation and pattern matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quantum Theories</head><p>Quantum theories of consciousness propose that quantum activity plays a key role in consciousness <ref type="bibr" target="#b17">(Hameroff &amp; Penrose, 2014)</ref>.</p><p>There may be quantum activity in the internal mechanism of the neurons -just as there are quantum mechanisms in other biological processes <ref type="bibr" target="#b27">(O'Reilly &amp; Olaya-Castro, 2014)</ref>. However, personally I can't see a direct connection to consciousness on a 'whole creature' scale. I may be wrong, but I draw a parallel with the quantum activity within photosynthesis. Quantum behaviour makes photosynthesis highly efficient <ref type="bibr" target="#b27">(O'Reilly &amp; Olaya-Castro, 2014;</ref><ref type="bibr" target="#b34">TURING, 1950)</ref> but it doesn't change the macro level result of manufacturing sugars to grow leaves, fruit and nuts.</p><p>If consciousness is quantum driven, or perhaps quantum random, we will still need a macro-level explanation -in much the same way that chemistry emerges from physics but we still discuss chemistry as chemistry because it's an appropriate level for the modelling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hypotheses Assemble</head><p>It strikes me that we have all the moving parts for a more deliberate attempt at a combined model.</p><p>• The GQT/GNW/CTM is a brain-oriented description of the interconnections required to share information within a brain and hold it for consideration. It provides a way of thinking about how ideas 'get about'/'move about' in the brain. • The predictive model provides a shorthand way of describing the effect of pattern matching activity (once we have explained prediction in pattern matching terms). It also gives us a lowenergy top-down way of holding a mental model (compared to building the model with bottom-up neuronal activity). • The Distillation and Pattern Matching model contribute two things. A model for the identification of self in patterns (as the key to subjective awareness and consciousness). It also supplies a logical model for the construction of the content of mind, and the mechanisms for thinking. Not least, it provides a model/language which other theories of consciousness can use when handling content. e.g. the content of information passed between sections of the GWT or the content of the Prediction model. • The HOT theories, notably Self-Representational HOTs, provide philosophical context against which the Higher Order aspects of the Pattern Matching model can, I hope, be further explored. • Antonio Damasio's approach provides a rich insight on the body to brain connections and the feelings arising from the body. He also identifies parts of the brain which are strongly associated with the absence or existence of consciousness. • A formalised mathematical future for consciousness could be of great benefit, but we need a logical model too.</p><p>In the next paper I will explore further the logical model of mind based on the pattern matching principles. I think this could be of use to get closer to a final overall assembly that describes mind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Philosophical Arguments against Physicalism</head><p>This paper contains a theory rooted in the philosophical camp of physicalism.</p><p>As shown, consciousness is an inevitable result of the physical processes of mind and body. I don't think there is any external source for consciousness. Neither do I think that all the atoms in my body are somehow each conscious in their own way, and they gang up to create a larger consciousness because I'm a living creature.</p><p>I'm a physicalist and proud. However, there are some well know arguments against physicalism which I discuss here.</p><p>Frank Jackson -Mary's Room Mary's room <ref type="bibr" target="#b19">(Jackson, 1982)</ref> is a thought experiment exploring physicalism. The Mary's room argument is known as 'the knowledge argument'. The knowledge argument claims that there are non-physical properties and knowledge and can only be discovered through conscious experience. It is claimed that this contradicts the theory of physicalism (which says that everything, including mental states, has a physical explanation).</p><p>It is a weird life that Mary has: -</p><p>Our theoretical Mary has lived in a black and white room since birth. EVERYTHING is black and white, even her skin is covered and never exposed to her. She has access to all the scientific knowledge in the world. She knows all about the wavelengths of light and she knows all about colour, colour vision and how it works, but has never experienced it. She has only ever seen black or white. Mary is also very clever; she has all the physical scientific knowledge and information and can remember it all. She has even read this paper and understands the neural patterns and cognitive changes that will occur in a creature experiencing coloured light for the first time.</p><p>So, here is the question as Jackson describes it:-What will happen when Mary is released from her black and white room or is given a colour television? Will she learn anything or not? It seems just obvious that she will learn something about the world and our visual experience of it. But then it is inescapable that her previous knowledge was incomplete. But she had all the physical information. Ergo there is more to have than that, and Physicalism is false.</p><p>He claims that mental states (like colour perception) cannot be described by physical facts.</p><p>My short answer: -Mary was aware of all the physical information. She had all the knowledge of the physical information. However, she has never had this physical information in her neurons representing the colours coming into her brain and mind from her eyes. She may have known it would happen, but that is different from it actually happening in her brain. She has had a physical experience that she could not possibly have acquired by other means. All her knowledge could not insert the exact pattern of the exposure to colour into her brain -only the actual exposure could do this.</p><p>Does the fact that Mary's experience is wholly subjective mean that functionalism is false? No. Her subjective and private experience is still entirely functional/physical.</p><p>The demise of physicalism has been averted. (phew!)</p><p>David Chalmers -The Zombie Argument Chalmers <ref type="bibr" target="#b6">(Chalmers, 1996)</ref> envisaged a creature might exist that is microphysically identical in every way to a conscious creature-but it has no experiences and is not conscious. Despite this, it behaves entirely as if it were conscious by responding in the same way to stimuli and even talking about events in the same way as a conscious creature. For a concise description of Chalmers' argument, please see the short paper on the matter by Amy Kind <ref type="bibr" target="#b20">(Kind 2012)</ref>.</p><p>My short answer :-I cannot envisage the existence of such a creature, for the following reasons: -</p><p>• If the creature is microphysically identical in every way, then its physical brain is the same and it would work the same way as the conscious creature. Since the conscious creature is conscious, the identical creature would also be conscious and could not be a zombie. • Even if we allow the zombie creature to exist, it must not be handling patterns in the way that consciousness emerges (so it is microphysically NOT identical IMHO). Either way, in order to respond to questions or events in the same way as the non-zombie, the zombie creature would instead have to hold a much larger 'library' of appropriate patterns of responses so that it can describe what it 'pretends' are its experiences in a similar manner to the conscious creature. This much larger library would be a significant consumer of resources -way beyond those required for the creature to simply experience things in the way I describe. Such a zombie creature is thus impractical as well as not being microphysically identical.</p><p>The 'large library' mentioned above, which is required to try and make the zombie respond in the same way, sounds pretty much like a Large Language Model to me. Large Language Models (LLMs) are at the core of the generative AI technologies which have been amazing us with generated text, pictures, video, sound, and deep fakes. Despite claims by some, large language models are not conscious as they stand (at the time of ChatGPT 4o), even if they manage to fake the appearance of consciousness in part. They are zombies in the way they are built and operate.</p><p>And finally…. If, instead of a large library, the Chalmer's zombies are animated/operated by external spooky forces where (non-)consciousness descends upon physical creatures from a realm of conscious gloop in the stars, then I'm completely wrong to be a physicalist, but you will have to show me the evidence for this.</p><p>Thomas Nagel -What is it like to be a Bat? First published in 1974, Thomas Nagel's paper <ref type="bibr" target="#b24">(Nagel, 1974)</ref> presents the difficulties posed by consciousness. He chose a bat to explore because being separated from humans by 'seeing' through echolocation helps stop us humans from making assumptions while we consider what it is like for the bat, to be a bat.</p><p>Nagel doesn't deny physicalism but sees it as presenting an incomplete argument by alluding to consciousness being in mental states without describing how. He describes the status of physicalism as being similar that of a pre-Socratic philosopher declaring that 'matter is energy' (i.e. stating it, but not having a detailed theory for it).</p><p>Until now I would agree, but that detail of 'how' is no longer absent, as you have seen in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>John Searle's Chinese Room</head><p>Searle's argument addresses computationalism rather than physicalism, so I shall discuss that in a separate paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, I have presented a detailed physicalist description explaining the emergence of consciousness. It shows that consciousness is an inevitable development in any creature living in the world if it has: a body it can control, sensory input, adequate mental capacity, and an appropriate internal model. The logical model is built at comparatively low level, using known features of neuronal networks.</p><p>The model should 'play nicely' with other theories. If partnered in an n-way 'tag-team' with the other primary theories, I think the pattern matching model will result in interesting synergies.</p><p>The higher-level complexities of mind (which will also be describable by the pattern matching model) are discussed in the second paper planned in this series.</p><p>I think these principles can be applied to non-biological 'creatures'. I aim to discuss these complex matters in a third paper since the pattern matching model opens a possible approach to AI that is less of a black box -something that is a currently a challenge for Large Language Models.</p><p>That aside, despite the brevity of the descriptions herein, but given the comparative simplicity of the model, I hope you now also regard the origin of consciousness to be as obvious and inevitable as I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Epilogue</head><p>In the Second Paper The next paper in this series will extend the pattern matching model. Starting from the consciousness that emerges from pattern matching, it will build the logical components for a general theory of general intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>In the Third Paper</head><p>The final paper in this series will explore the possibilities and consequences of transfer of the Wolstencroft logical model to a non-biological substrate.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>(e.g. a fly landing on it.) • External events witnessed by the creature sometimes do NOT create sensations in the creature's body. (e.g. a bird flying past but not landing) • The creature's body provides to the brain a constant stream of visceral and muscular signals (hunger, satiation, sickness, injury) • Action by the creature also creates visceral body signals (skin response to motion or to touching objects) • Action by the creature sometimes makes other objects move (e.g. a pebble or some grass being moved by a limb)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="2,160.07,354.29,275.14,214.05" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Insights into hippocampal network function</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aertsen</surname></persName>
		</author>
		<idno type="DOI">10.1038/s43588-021-00159-z</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Computational Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="782" to="783" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Integrated information theory (IIT) 4.0: Formulating the properties of phenomenal existence in physical terms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Albantakis</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1011465</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Baars</surname></persName>
		</author>
		<title level="m">A cognitive theory of consciousness</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge Univ. Press</publisher>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Baars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Geld</surname></persName>
		</author>
		<title level="m">On consciousness: Science &amp; subjectivity</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Nautilus Press</publisher>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Global workspace theory (GWT) and prefrontal cortex: Recent developments</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Baars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Geld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kozma</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2021.749868</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Theoretical Computer Science Perspective on Consciousness</title>
		<author>
			<persName><forename type="first">M</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Blum</surname></persName>
		</author>
		<idno type="DOI">10.1142/s2705078521500028</idno>
		<ptr target="https://doi.org/10.1142/s2705078521500028" />
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence and Consciousness</title>
		<imprint>
			<biblScope unit="volume">08</biblScope>
			<biblScope unit="issue">01</biblScope>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Chalmers</surname></persName>
		</author>
		<title level="m">The conscious mind in search of a fundamental theory</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Facing up to the problem of consciousness</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Chalmers</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780195311105.003.0001</idno>
	</analytic>
	<monogr>
		<title level="j">The Character of Consciousness</title>
		<imprint>
			<biblScope unit="page" from="3" to="34" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Radical Predictive Processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1111/sjp.12120</idno>
	</analytic>
	<monogr>
		<title level="j">The Southern Journal of Philosophy</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="27" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Damasio</surname></persName>
		</author>
		<title level="m">The feeling of what happens: Body, emotion and the making of Consciousness</title>
		<meeting><address><addrLine>London; Vintage</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Damasio</surname></persName>
		</author>
		<title level="m">Descartes&apos; error: Emotion, reason and the human brain</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Picador</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Self comes to mind: Constructing the conscious brain</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Damasio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>Vintage Books</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Damasio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Damasio</surname></persName>
		</author>
		<title level="m">Feeling and knowing: Making Minds Conscious</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Robinson</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">Jean-Louis And</forename><surname>Dessalles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tiziana</forename><surname>Zalla</surname></persName>
		</author>
		<ptr target="https://www.dessalles.fr/papers/Dessalles_98072405.pdf" />
		<title level="m">On the evolution of phenomenal consciousness</title>
		<imprint>
			<date type="published" when="1998-09-12">1998. 12 September 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Eliot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1932">1932</date>
			<publisher>Faber and Faber</publisher>
			<biblScope unit="page" from="1909" to="1925" />
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Transforming the concept of memory reactivation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Favila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Kuhl</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tins.2020.09.006</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Neurosciences</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="939" to="950" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Exaptation-a missing term in the science of form</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gould</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Vrba</surname></persName>
		</author>
		<idno type="DOI">10.1017/s0094837300004310</idno>
	</analytic>
	<monogr>
		<title level="j">Paleobiology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="15" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Consciousness in the universe</title>
		<author>
			<persName><forename type="first">S</forename><surname>Hameroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Penrose</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.plrev.2013.08.002</idno>
	</analytic>
	<monogr>
		<title level="j">Physics of Life Reviews</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="78" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Hohwy</surname></persName>
		</author>
		<title level="m">The predictive mind</title>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Epiphenomenal qualia</title>
		<author>
			<persName><forename type="first">F</forename><surname>Jackson</surname></persName>
		</author>
		<idno type="DOI">10.2307/2960077</idno>
	</analytic>
	<monogr>
		<title level="j">The Philosophical Quarterly</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">127</biblScope>
			<biblScope unit="page">127</biblScope>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Chalmers&apos; Zombie Argument</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kind</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Just the Arguments</title>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Bruce</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Steven</forename><surname>Barbone</surname></persName>
		</editor>
		<imprint>
			<publisher>Wiley-Blackwell</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="327" to="329" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neurocomputational Dynamics of Sequence Learning</title>
		<author>
			<persName><forename type="first">A</forename><surname>Konovalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Krajbich</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2018.05.013</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Conscious processing and the global neuronal workspace hypothesis</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Mashour</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2020.01.026</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="776" to="798" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The strength of weak integrated information theory</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A M</forename><surname>Mediano</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2022.04.008</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="646" to="655" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">What is it like to be a bat?</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nagel</surname></persName>
		</author>
		<idno type="DOI">10.2307/2183914</idno>
	</analytic>
	<monogr>
		<title level="j">The Philosophical Review</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">435</biblScope>
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Discovering sequential patterns by neural networks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Korytkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1109/ijcnn48605.2020.9207461</idno>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The hippocampus supports multiple cognitive processes through relational binding and comparison</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Olsen</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2012.00146</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Non-classicality of the molecular vibrations assisting exciton energy transfer at room temperature</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>O'reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Olaya-Castro</surname></persName>
		</author>
		<idno type="DOI">10.1038/ncomms4012</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Neuroanatomical correlates of brainstem coma</title>
		<author>
			<persName><forename type="first">J</forename><surname>Parvizi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Damasio</surname></persName>
		</author>
		<idno type="DOI">10.1093/brain/awg166</idno>
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1524" to="1536" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Catalog learning: Carabid Beetles learn to manipulate with innate coherent behavioral patterns</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Reznikova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dorosheva</surname></persName>
		</author>
		<idno type="DOI">10.1177/147470491301100304</idno>
	</analytic>
	<monogr>
		<title level="j">Evolutionary Psychology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="513" to="537" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Changes of the brain&apos;s bioelectrical activity in cognition, consciousness, and some mental disorders</title>
		<author>
			<persName><forename type="first">M</forename><surname>Roohi-Azizi</surname></persName>
		</author>
		<idno type="DOI">10.14196/mjiri.31.53</idno>
	</analytic>
	<monogr>
		<title level="j">Medical Journal of the Islamic Republic of Iran</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="307" to="312" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The seven sins of memory: An update</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Schacter</surname></persName>
		</author>
		<idno type="DOI">10.1080/09658211.2021.1873391</idno>
	</analytic>
	<monogr>
		<title level="j">Memory</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="37" to="42" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Searle</surname></persName>
		</author>
		<title level="m">Minds, brains, and programs</title>
		<meeting><address><addrLine>U.S.</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Theories of consciousness</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bayne</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41583-022-00587-4</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="439" to="452" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">I.-Computing Machinery and intelligence</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Turing</surname></persName>
		</author>
		<idno type="DOI">10.1093/mind/lix.236.433</idno>
	</analytic>
	<monogr>
		<title level="j">Mind</title>
		<imprint>
			<biblScope unit="volume">LIX</biblScope>
			<biblScope unit="page" from="433" to="460" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
