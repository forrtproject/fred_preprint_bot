<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Text Embeddings to Measure Text Topics</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Jianjun</forename><surname>Yu</surname></persName>
							<email>jianjyu@uiowa.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Political Science Department</orgName>
								<orgName type="institution">The University of Iowa</orgName>
								<address>
									<settlement>Iowa City</settlement>
									<region>Iowa</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Text Embeddings to Measure Text Topics</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">89FDC176FF3F34A026F4184476BAD02B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-23T06:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Text analysis</term>
					<term>Text embedding</term>
					<term>Topic model</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automated content analysis for measuring specific topics has become increasingly popular in social science research. This article demonstrates that text embedding, combined with cosine similarity, can accurately measure specific topics and explore the relationship between text topics and meta-information. Unlike probabilistic topic models (PTMs) such as the Structural Topic Model (STM) and Keyword-Assisted Topic Model (keyATM), the text embedding method does not require the selection of hyperparameters, keywords, or a training process. This significantly reduces computational resources and makes the method more convenient and faster to use. Additionally, the text embedding method can better capture the meaning of short texts. The findings suggest that text embedding is a superior alternative to commonly used PTMs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In recent years, social scientists have developed several automated content analysis methods based on PTM, such as STM and keyATM, to measure specific topics and explore the relationship between text topics and meta-information <ref type="bibr" target="#b10">(Roberts et al. 2014;</ref><ref type="bibr" target="#b2">Eshima, Imai, and Sasaki 2024)</ref>. These methods have been widely used for text analysis and have significantly advanced the development of social science. However, these methods require considerable effort to select key hyperparameters, such as the number of topics and keywords, complicating their usage and making it challenging to measure specific concepts of interest.</p><p>In this letter, I propose that a text embedding method offer a more convenient alternative to these topic models when scholars aim to measure specific topics and explore the relationship between text topics and meta-information. Unlike commonly used topic models, text embedding allows scholars to focus on measuring specific concepts of substantive interest without clustering texts, freeing them from selecting key hyperparameters. Moreover, text embedding methods require significantly fewer computational resources and support distributed computing, making them more suitable for big data analysis. Finally, compared with PTMs, text embedding can better capture the meaning of short text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Text embedding</head><p>Text embedding in natural language processing (NLP) represents texts as vectors in a multidimensional space to capture their semantic meaning and context, facilitating efficient language data processing <ref type="bibr" target="#b4">(Kiros et al. 2015;</ref><ref type="bibr" target="#b1">Conneau et al. 2017;</ref><ref type="bibr" target="#b9">Reimers and Gurevych 2019)</ref>. By converting text into numerical vectors, machine learning models can better understand and work with language, preserving meaningful relationships and contextual nuances.</p><p>Text embeddings are generated using two main approaches: word embedding algorithms like Word2Vec and GloVe <ref type="bibr" target="#b7">(Mikolov et al. 2013;</ref><ref type="bibr" target="#b8">Pennington, Socher, and Manning 2014)</ref>, and fine-tuned transformer-based language models (TLMs) like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer). Appendices A and B provide more detailed discussions on how these methods generate text embeddings.</p><p>This letter focuses on two popular models: the all-mpnet-base-v2 model (Mpnet model) and the text-embedding-3-large model (GPT model).</p><p>The Mpnet model, fine-tuned on BERT and published in 2022, is compact and transparent, with publicly accessible training data, methodologies, and model structures. This openness allows scholars to scrutinize potential biases and facilitates replication. The Mpnet model is popular for its prominence on Hugging Face, a leading transformer model hub, and its top-tier performance in benchmark tests.</p><p>The GPT model, fine-tuned on OpenAI's GPT-3.5, is one of the most accurate text embedding generation models <ref type="bibr" target="#b3">(Greene et al. 2022</ref>). However, its large size, encompassing billions of parameters, makes it impractical for use on standard personal computers, so users must generate text embeddings through OpenAI's API. Additionally, the opacity of OpenAI's GPT models poses challenges for scholars in assessing potential biases and replicating outcomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Topic score</head><p>I employ cosine similarity between the text embedding of a specific topic (topic embedding) and the text embeddings of the texts of interest to represent the relationship between the topic and the texts. A topic embedding can be the text embedding of a word, phrase, or paragraph describing the topic. I refer to this cosine similarity as the "topic score."</p><p>Cosine similarity is a metric used to measure the similarity between two vectors in a multidimensional space <ref type="bibr" target="#b11">(Salton, Wong, and Yang 1975)</ref>. It calculates the cosine of the angle between two vectors, where a similarity of 1 indicates identical vectors, and a similarity of -1 indicates diametrically opposed vectors. In NLP and machine learning, cosine similarity is used to assess the similarity between vectors representing documents, sentences, or words <ref type="bibr" target="#b5">(Manning 2009)</ref>. The formula for cosine similarity between two vectors A and B is given by:</p><formula xml:id="formula_0">CosineSimilarity(A, B) = A • B ||A|| • ||B|| (1)</formula><p>Cosine similarity of text embeddings between two documents serves as a valuable metric for representing the similarity in content between documents. To illustrate this capability, consider recent tweets from President Joe Biden. Table <ref type="table" target="#tab_0">1</ref> presents three tweets covering topics such as the American economy and abortion. I know that some prices are still too high for too many. I am doing everything in my power to lower costs from energy bills and medicine to addressing hidden junk fees companies use to rip you off.I won't stop fighting for American workers and American families.</p><p>Tweet 2 Our economy created 2.7 million new jobs in 2023 while the unemployment rate was consistently below 4%. That's more jobs than during any year of the prior Administration.This morning's report confirms that it was a great year for American workers Tweet 3 Today's Supreme Court order allows Idaho's abortion ban to go back into effect, denying women emergency abortion care required by law. These bans threaten women's health, force them to travel, and make it harder for doctors to provide care. This should never happen in America.</p><p>Table 2 displays the cosine similarity between these tweets 1 . The first two tweets, focused on 1. All text embeddings are calculated by the Mpnet model</p><p>Biden's efforts to address economic issues, exhibit higher cosine similarity with each other compared to their similarity with the tweet addressing abortion. Table <ref type="table" target="#tab_3">3</ref> delineates the cosine similarity between the tweets and three topics: 'economy,' 'job market,' and 'abortion.' The calculated cosine similarities illustrate the proximity of each tweet to a particular topic. It shows that the first two tweets are more closely aligned with the 'economy' topic and less so with 'abortion.' Additionally, it reveals that the second tweet is thematically nearer to 'job market' than 'economy,' reflecting its specific focus on job market issues. These results show that the topic score can properly reflect the relationship between certain topics and text content.</p><p>The topic score can then be used as a feature of texts, which scholars can use as a variable in their research to explore the relationship between text topics and their meta-information.</p><p>Measuring topics with topic scores offers several advantages compared to PTM. This method allows scholars to measure specific, research-critical concepts. Commonly used methods, such as STM, may not necessarily capture specific concepts of substantive interest. They might create multiple topics with similar content or merge distinct themes into a single topic, leading to miscategorization and obscuring topic interpretation. Topic scores, on the contrary, allow scholars to measure any topics they are interested in.</p><p>Second, topic scores are easier to calculate, freeing researchers from the intensive work of selecting hyperparameters and text pre-processing. While some PTMs, such as keyATM, allow users to assign topics before clustering, they often require selecting keywords, a process with unclear best practices. Moreover, PTMs need a predetermined number of topics, and clustering results are sensitive to this number. Selecting the number of topics involves fitting models with many different values, which is time-consuming, and even then, only provides a range requiring further validation. Additionally, PTMs need extensive text pre-processing, including noise reduction, tokenization, and removal of stop words. Calculating text embeddings and topic scores eliminates the need for these steps.</p><p>Third, text embedding is better at measuring the meaning of short text, such as tweets. PTMs often falter with short texts due to their reliance on word occurrences to estimate topic distributions. Short texts, with their limited word occurrences, pose a challenge in accurately determining their topic distributions <ref type="bibr" target="#b12">(Yan et al. 2013)</ref>, prompting researchers to adopt specific text preprocessing strategies or exclude short texts altogether <ref type="bibr" target="#b0">(Barberá et al. 2019;</ref><ref type="bibr" target="#b13">Ying, Montgomery, and Stewart 2022)</ref>. The generation of text embedding, on the contrary, will consider word meaning, semantic relationships, and contextual information learned during pre-training and fine-tuning, ensuring consistent quality across text lengths.</p><p>Finally, unlike other methods, calculating topic scores does not require a training process, which demands high computational power and memory. For large text data analysis, users can generate topic scores in chunks, avoiding the need to load all data into memory simultaneously, and allowing distributed computing. This significantly reduces the memory needed and facilitates the analysis process, allowing users without access to high-performance clusters to conduct research. Generating text embeddings and calculating topic scores can be done on a mid-level personal CPU or GPU. In the first replication study, I will report the time needed for generating embeddings on an Intel Core i5-13600 CPU, a mid-range CPU, and a V100 NVIDIA GPU, an older and readily available GPU published in 2018. to demonstrate the modest resource usage for topic score calculation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Empirical study</head><p>In the following section, I apply this topic score method to three datasets: American Congressional bills, open-ended survey responses from , and . The American Congressional bills dataset was used by Eshima and his coauthors to show that their recently published keyATM achieves state-of-the-art performance. The other two datasets represent typical data formats on which social scientists conduct automated content analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Replication 1: Congressional bills</head><p>In early 2024, <ref type="bibr" target="#b2">Eshima et al (2024)</ref> proposed a new topic model, keyATM, which uses a small number of keywords to guide the topic generation process, enabling the model to generate topics with specific research interests, they cluster over 4000 American Congressional bills to demonstrate its state-of-the-art performance. These bill was assigned a primary policy topic from among 21 topics by human coders. They used the area under the receiver operating characteristic (AUROC) of topic probabilities from the document-topic distribution as the evaluation metric. To compare  code on the i5 CPU. It took around 16 hours to fit all five chains of the keyATM model to cluster the 4421 bills<ref type="foot" target="#foot_0">foot_0</ref> .</p><p>Figure <ref type="figure" target="#fig_1">1</ref> copies the ROC curves from the original keyATM paper, comparing keyATM and weighted LDA for six selected topics. Figure <ref type="figure">2</ref> shows the ROC curves for topic scores of the same six topics: Figure <ref type="figure">2a</ref> for the Mpnet model and Figure <ref type="figure">2b</ref> for the GPT model. ROC curves for all 21 topics are in Appendix C.</p><p>Comparing Figures <ref type="figure" target="#fig_1">1</ref> and <ref type="figure">2</ref>, keyATM does not outperform the topic scores even generated by the 2022 available Mpnet model. The average AUROC for all 21 topics is 90.00 for keyATM, 90.00 for Mpnet topic scores, and 90.21 for GPT topic scores. These results show that the topic score method provides accuracy comparable to the state-of-the-art keyATM. Moreover, keyATM relies on selecting keywords for each topic and uses time-consuming and memory-intensive Markov chain Monte Carlo (MCMC) algorithms. In contrast, the topic score method requires less memory and is much faster, in partiuclar for large data. The generation of topic embeddings is also very flexible and easier to apply than selecting keywords. Thus, compared to keyATM, the topic score method is more useful when a researcher is interested in measuring specific topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Replication 2: Open-Ended Survey Responses</head><p>In their seminal work on the gender gap in climate change attitudes, Bush and Clayton argued that people in wealthy countries perceive greater costs to climate change mitigation than those in lower-income countries, with men in wealthy countries, such as the USA, being more sensitive to these material costs than women. To support their argument, they conducted a survey across ten countries with an open-ended question about how efforts to stop climate change would harm respondents. Using STM, they found that people in lower-income countries were more likely to be clustered into the topic: 'no harm.' They also showed that male respondents in the USA were more likely to discuss the rising costs of acting to stop climate change.</p><p>To replicate Bush and Clayton's work, I created two topic scores: one with the topic embedding 'climate change does not harm me' (no harm) and another with 'climate change raises material costs' (rising cost). No hyperparameter selection or text preprocessing was done. I used these topic scores as dependent variables to analyze the influence of countries' income and gender.</p><p>Table <ref type="table" target="#tab_4">4</ref> reports the results. The first two columns show regression results for topic scores generated from the Mpnet model, while the last two columns show results for the GPT model. The regression shows that for topic scores generated from both models, income has a negative effect on the 'no harm' topic score, and being female has a negative effect on the 'rising cost' topic score. These findings are consistent with the original work and the effects found from text embedding method is also more significant.</p><p>This replication shows the ability of the text embedding method to explore the relationship between text meaning and meta information. It also shows the advantage of text embedding method to analysis open-ended response from cross countries survey. Most PTMs cannot handle multiple languages without translation, whereas many text embedding models can analyze multilingual texts and convert multiple languages into the same vector space, eliminating the need for translation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Replication 3: Better Ability of Capture Short text meaning</head><p>I compare the performance of the text embedding method and the probabilistic topic model in analyzing short texts by using the two methods to cluster short text. The idea is that if text embeddings better capture the text meanings, it should provide a more coherence clustering result than PTMs.</p><p>The dataset used is the Twitter Financial News dataset from Hugging Face, one of the few publicly available Twitter datasets with topic labels 3 . Its training set contains 17,000 tweets about financial news labeled into 20 topics. For the comparative analysis of clustering methods, purity is employed as the evaluation metric. Purity is specifically designed for assessing the performance of clustering methods <ref type="bibr" target="#b6">(Meilă 2007)</ref>. It measures the extent to which clusters contain a dominant class. Purity hinges on the premise that while clustering methods may partition data into a different number of groups than those determined by human labeling, data points sharing the same human label should be more likely to be grouped together than those with different labels. Table <ref type="table" target="#tab_5">5</ref> presents the comparison of clustering performance using Mpnet and GPT generated text embeddings against STM. The performance of different models is compared across 5 different topic numbers. Similar to other evaluation metrics, purity tends to increase with the number of topics but plateaus after surpassing a certain threshold, which is often considered the optimal topic number for a clustering method. The results consistently indicate superior performance of clustering on text embeddings compared to STM. The findings suggest that clustering utilizing text embeddings outperforms STM in generating clusters characterized by significantly greater semantic coherence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Validation</head><p>Scholars might be concerned about the accuracy of topic scores. Two common validation approaches can address this. The first is to select texts with high and low topic scores and manually examine whether the scores are valid. The second approach involves generating a word frequency matrix weighted by topic scores. Words that frequently appear in texts with high topic scores are selected, and the word intrusion method is used to evaluate whether human coders agree that these high-frequency words reflect the topic's meaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This letter demonstrates that when measuring specific topics and exploring the relationship between text topics and meta-information, the text embedding method, which generates topic scores, provides a more convenient alternative to commonly used methods such as keyATM and STM. Text embedding is not limited to measuring specific topics. For example, combined with clustering methods like k-means, text embedding can also be used to cluster texts and explore content. While demonstrating the advantages of text embedding in other applications is beyond the scope of this letter, it encourages social scientists to further explore its use in their research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>Note: Each line represents the ROC curve from one of the five Markov chains with different starting values for keyATM (blue lines) and wLDA (gray lines). The median AUROC indicates the median value of AUROC among five chains for each model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Comparison of the ROC Curves between keyATM and wLDA for Six Selected Topicswith keyATM, I calculated topic scores for all 21 topics. The topic embeddings were calculated using short descriptions of the 21 topics provided by the Congressional Bills Project, which Eshima and his coauthors used to generate keywords for keyATM. No text pre-processing was performed. Both text embedding models truncated input texts longer than their input length limit. Although best practices involve splitting long texts into chunks and averaging their embeddings, truncation provided sufficiently comparable results in this research.For the topic score of Mpnet model, generating all topic scores took around 20 minutes on an Intel Core i5-13600 CPU and 1 minute on a V100 GPU. I used a V100 GPU on Google Colab, which cost approximately 0.009 USD. For topic score of GPT model, I request text embedding of all bills through OpenAI's API, which cost around 2 USD. I also replicated the Eshima et al's keyATM</figDesc><graphic coords="4,82.49,248.07,319.75,244.82" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( a )Figure 2 .</head><label>a2</label><figDesc>Figure 2. The ROC Curves for Topic Scores of the Six Topics</figDesc><graphic coords="5,51.02,198.52,191.84,122.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Tweets from Biden</figDesc><table><row><cell>Tweets from Biden</cell></row><row><cell>Tweet 1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Tweets Cosine Similarity Between Tweets</figDesc><table><row><cell>Tweets</cell><cell>Tweet 1</cell><cell cols="2">Tweet 2 Tweet 3</cell></row><row><cell>Tweet 1</cell><cell>1</cell><cell>0.458</cell><cell>0.158</cell></row><row><cell>Tweet 2</cell><cell>0.458</cell><cell>1</cell><cell>0.128</cell></row><row><cell>Tweet 3</cell><cell>0.158</cell><cell>0.128</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Tweets Cosine Similarity with Topics</figDesc><table><row><cell></cell><cell cols="2">Economy Job market</cell><cell>Abortion</cell></row><row><cell>Tweet 1</cell><cell>0.267</cell><cell>0.186</cell><cell>0.084</cell></row><row><cell>Tweet 2</cell><cell>0.382</cell><cell>0.405</cell><cell>0.090</cell></row><row><cell>Tweet 3</cell><cell>0.091</cell><cell>0.103</cell><cell>0.503</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Comparison of Methods for Exploring the Effects of Meta Information on TED Talk Topics</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Dependent variable:</cell><cell></cell><cell></cell></row><row><cell>Topic generator</cell><cell cols="2">The Mpnet model</cell><cell cols="2">The GPT model</cell><cell>STM</cell><cell></cell></row><row><cell>InGDPPC</cell><cell>-0.017  *  *  *</cell><cell></cell><cell>-0.019  *  *  *</cell><cell></cell><cell>-0.013  *  *  *</cell><cell></cell></row><row><cell></cell><cell>(0.002)</cell><cell></cell><cell>(0.002)</cell><cell></cell><cell>(0.002)</cell><cell></cell></row><row><cell>Female</cell><cell></cell><cell>-0.039  *  *  *</cell><cell></cell><cell>-0.031  *  *  *</cell><cell></cell><cell>-0.017  *  *</cell></row><row><cell></cell><cell></cell><cell>(0.012)</cell><cell></cell><cell>(0.008)</cell><cell></cell><cell>(0.008)</cell></row><row><cell>Observations</cell><cell>11,849</cell><cell>975</cell><cell>11,849</cell><cell>975</cell><cell>11,849</cell><cell>975</cell></row><row><cell>R 2</cell><cell>0.007</cell><cell>0.036</cell><cell>0.010</cell><cell>0.052</cell><cell></cell><cell></cell></row><row><cell>Adjusted R 2</cell><cell>0.006</cell><cell>0.031</cell><cell>0.010</cell><cell>0.047</cell><cell></cell><cell></cell></row><row><cell>Table note</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">a  *  p&lt;0.1;  *  *  p&lt;0.05;  *  *  *  p&lt;0.01</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>b</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Purity score</figDesc><table><row><cell>Number of topic</cell><cell>Mpnet</cell><cell>GPT</cell><cell>STM</cell></row><row><cell>20</cell><cell>0.513</cell><cell>0.563</cell><cell>0.439</cell></row><row><cell>40</cell><cell>0.560</cell><cell>0.605</cell><cell>0.456</cell></row><row><cell>60</cell><cell>0.605</cell><cell>0.634</cell><cell>0.493</cell></row><row><cell>80</cell><cell>0.615</cell><cell>0.632</cell><cell>0.472</cell></row><row><cell>100</cell><cell>0.620</cell><cell>0.660</cell><cell>0.487</cell></row></table><note><p>3. For more details about the data: https://huggingface.co/datasets/zeroshot/twitter-financial-news-topic</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0"><p>Eshima and his coauthors ran five independent Markov chains with different random starting values for each topic due to PTM sensitivity to initial values</p></note>
		</body>
		<back>

			
			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>Funding Statement No Fund</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing Interests No Competing Interests</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Notes</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Who leads? who follows? measuring issue attention and agenda setting by legislators and the mass public using social media data</title>
		<author>
			<persName><forename type="first">Pablo</forename><surname>Barberá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreu</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jonathan</forename><surname>Nagler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">J</forename><surname>Egan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Bonneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">T</forename><surname>Jost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joshua</forename><forename type="middle">A</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Political Science Review</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="883" to="901" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Loic</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.02364</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Keyword-assisted topic models</title>
		<author>
			<persName><forename type="first">Shusei</forename><surname>Eshima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kosuke</forename><surname>Imai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tomoya</forename><surname>Sasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Political Science</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="730" to="750" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">New and improved embedding model</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ted</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lilian</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<ptr target="https://openai.com/blog/new-and-improved-embedding-model" />
		<imprint>
			<date type="published" when="2022-06-07">2022. June 7, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Skip-thought vectors</title>
		<author>
			<persName><forename type="first">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Russ R Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sanja</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName><surname>Fidler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">An introduction to information retrieval</title>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Comparing clusterings-an information based distance</title>
		<author>
			<persName><forename type="first">Marina</forename><surname>Meilă</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of multivariate analysis</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="873" to="895" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greg</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Glove: global vectors for word representation</title>
		<author>
			<persName><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 conference on empirical methods in natural language processing (emnlp)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (emnlp)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">Nils</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10084</idno>
		<title level="m">Sentence-bert: sentence embeddings using siamese bert-networks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Structural topic models for open-ended survey responses</title>
		<author>
			<persName><forename type="first">Margaret</forename><forename type="middle">E</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dustin</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christopher</forename><surname>Tingley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jetson</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shana</forename><surname>Leder-Luis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bethany</forename><surname>Kushner Gadarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">G</forename><surname>Albertson</surname></persName>
		</author>
		<author>
			<persName><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American journal of political science</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1064" to="1082" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A vector space model for automatic indexing</title>
		<author>
			<persName><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anita</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chung-Shu</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="613" to="620" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A biterm topic model for short texts</title>
		<author>
			<persName><forename type="first">Xiaohui</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jiafeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yanyan</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xueqi</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd international conference on world wide web</title>
		<meeting>the 22nd international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1445" to="1456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Topics, concepts, and measurement: a crowdsourced procedure for validating topics as measures</title>
		<author>
			<persName><forename type="first">Luwei</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jacob</forename><forename type="middle">M</forename><surname>Montgomery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Analysis</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="570" to="589" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
