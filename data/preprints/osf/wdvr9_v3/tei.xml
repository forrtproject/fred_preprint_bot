<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Are peer reviewers influenced by their work being cited?</title>
				<funder ref="#_pnK5NVQ">
					<orgName type="full">European Commission</orgName>
				</funder>
				<funder ref="#_2mjYxpt #_dCeUEha">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2025-10-01">October 1, 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Adrian</forename><surname>Barnett</surname></persName>
							<email>a.barnett@qut.edu.au</email>
							<idno type="ORCID">0000-0001-6339-0374</idno>
							<affiliation key="aff0">
								<orgName type="department">School of Public Health &amp; Social Work</orgName>
								<orgName type="institution">Queensland University of Technology</orgName>
								<address>
									<addrLine>88 Musk Avenue</addrLine>
									<postCode>4059</postCode>
									<region>QLD</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Are peer reviewers influenced by their work being cited?</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-10-01">October 1, 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">3F89D3A59809F80DE52D94AED52318A8</idno>
					<note type="submission">Approved, Approved with reservations, and Not approved. For brevity, we refer to &apos;Approved with Reservations&apos; as</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-22T20:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Here, we used a matched study design to explore how citations influence the peer review process. We used a sample of more than 37,000 peer reviews from four journals that use open peer review and make all article versions available. We find that reviewers who were cited in the article under review were more likely to recommend approval, but only after the first version (odds ratio = 1.61; adjusted 99.4% CI: 1.16 to 2.23).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>In 2024, a published peer reviewed article included this remarkable sentence: "As strongly requested by the reviewers, here we cite some references <ref type="bibr" target="#b34">[35]</ref><ref type="bibr" target="#b35">[36]</ref><ref type="bibr" target="#b36">[37]</ref><ref type="bibr" target="#b37">[38]</ref><ref type="bibr" target="#b38">[39]</ref><ref type="bibr" target="#b39">[40]</ref><ref type="bibr" target="#b40">[41]</ref><ref type="bibr" target="#b41">[42]</ref><ref type="bibr" target="#b42">[43]</ref><ref type="bibr" target="#b43">[44]</ref><ref type="bibr" target="#b44">[45]</ref><ref type="bibr" target="#b45">[46]</ref><ref type="bibr" target="#b46">[47]</ref> although they are completely irrelevant to the present work" <ref type="bibr" target="#b0">[1]</ref>. This was a rare public example of coerced citations, where a reviewer exploits the peer review process to increase their citation counts and hence further their own career <ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. Reviewers should be relevant experts, so some suggestions to cite their articles will be appropriate. However, excessive citation requests or requests to cite unrelated articles are unethical <ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref>. Coerced citations can also come from editors trying to boost their journal's ranking <ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref>.</p><p>Coerced citations are reported as a common problem in peer review. In author surveys, two-thirds reported pressure from peer reviewers to cite unrelated articles <ref type="bibr" target="#b12">[13]</ref> and 23% had experienced a reviewer that "required them to include unnecessary references to their publication(s)" <ref type="bibr" target="#b13">[14]</ref>. Publishers have investigated whether "hundreds of researchers" have manipulated the peer review process to increase their own citations <ref type="bibr" target="#b14">[15]</ref>. Some reviewers may be exploiting their power over authors who "have a strong incentive to [...] accept all 'suggestions' by the referees even if one knows that they are misleading or even incorrect" <ref type="bibr" target="#b15">[16]</ref>.</p><p>As reviewers are often in the same field as the article's authors, they may already be cited in the article without the need for coerced citations. Reviewers who are cited may give a more favourable peer review and be more willing to overlook flaws <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. Some authors may try to exploit this using "referee baiting" <ref type="bibr" target="#b2">[3]</ref> or "flattery citations" <ref type="bibr" target="#b18">[19]</ref> by favourably citing a reviewer's work.</p><p>The interactions during peer review between authors and reviewers can determine whether an 'Reservations'. An article is indexed once it receives two 'Approved' or two 'Reservations' and one 'Approved'. The guidelines for recommending Approved are: "the aims and research methods are adequate; results are presented accurately, and the conclusions are justified and supported by the presented data" <ref type="bibr" target="#b28">[29]</ref>. Peer reviewers are asked to assess the validity of an article's content, rather than novelty or interest levels, an approach designed to combat publication bias <ref type="bibr" target="#b29">[30]</ref>.</p><p>All four journals have a peer reviewer code of conduct and state that reviewers should familiarise themselves with the ethical guidelines for peer reviewers by the Committee On Publication Ethics <ref type="bibr" target="#b30">[31]</ref>. The journals' guidelines for reviewers include the following: "reviewers should explicitly state their reasoning when asking authors to cite their own work".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data extraction</head><p>We extracted data on authors and articles from the OpenAlex database (<ref type="url" target="https://openalex.org/">https://openalex.org/</ref>) and directly from the four journals. OpenAlex combines scholarly data from multiple sources, including ORCID -a unique identifier for researchers, Microsoft Academic, Crossref and PubMed. A recent study compared OpenAlex with the two commonly used proprietary bibliometric databases of Web of Science and Scopus for the years 2015 to 2022 <ref type="bibr" target="#b31">[32]</ref>. The results were mixed, but OpenAlex had better ORCID coverage and covered more Digital Object Identifiers (DOIs) -the unique identifier for publications. We accessed OpenAlex using the openalexR package <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref>. We used each journal's application programming interface (API) to extract data on the articles and peer reviews. The data were extracted in four stages:</p><p>1. Searches were made using the APIs of the four journals to find all articles published between 1 Jan 2012 and 28 May 2025, with the start date to capture all potential articles. 2. For each article, the following data were downloaded in XML format:</p><p>• The article's publication date and version number</p><p>• The reviewers' names and ORCIDs (if available)</p><p>• The text of all reviews and the reviewers' recommendations</p><p>• The DOIs and PMIDs (PubMed IDs) from the article's reference list</p><p>• The DOIs and PMIDs of any articles cited by the reviewers. The online peer review system at F1000 journals includes the DOI of any article cited in the review, which facilitates the identification of citations to the reviewers' articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Articles were excluded if:</head><p>• They were not peer reviewed or had yet to receive any reviews • The reference list was empty 4. The reviewers' publication histories were collected from OpenAlex using their name, institution and ORCID (if available). Reviews were excluded if there was no record for the reviewer in OpenAlex, or if the reviewer had no published articles as there was no potential for them to be cited or request a citation to their own articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study design</head><p>We used two predictor variables about the reviewer:</p><p>• The number of times they were cited in the article (0, 1, 2, . . .).</p><p>• The number of times they included citations to their own articles in their review (0, 1, 2, . . .).</p><p>We fitted both predictors as linear, but reviewers may behave differently with any citation rather than a linear change, and hence we also fitted both predictors as a binary "none versus any" (0 versus 1, 2, . . .). We compared the linear and binary alternatives using the Akaike Information Criterion (AIC) to find the parameterisation that best fitted the data <ref type="bibr" target="#b34">[35]</ref>.</p><p>We matched on article and version to control for confounding by any characteristics of the article <ref type="bibr" target="#b35">[36]</ref>; for example, the article's topic or writing style. Hence, we compared two or more independent reviewers who considered the same article.</p><p>All analyses were stratified by article version, using the first version only or the second and subsequent versions. This is because the reviewers are unknown to the authors for the first version, but from the second version onwards, the authors will know the reviewers as the journals use signed peer reviews. This knowledge could alter the behaviour of authors and reviewers.</p><p>The study design is summarised in Figure <ref type="figure" target="#fig_0">1</ref> Statistical methods</p><p>We used conditional logistic regression to examine the associations between the citations to the reviewer and their ordinal recommendation (Approved → Reservations → Not approved) while matching the article and the version <ref type="bibr" target="#b36">[37]</ref>. Conditional logistic regression requires a binary dependent variable; hence, we fitted two related models that examined the odds of:</p><p>1. "Approved" compared with "Reservations" or "Not approved".</p><p>2. "Approved" or "Reservations" compared with "Not approved", These two models tested the same hypothesis, hence we adjusted for multiple testing. We also used repeated testing due to the stratification by article version and the two formulations of the predictors (linear or none versus any). Since we used 8 (2 × 2 × 2) tests, we displayed all the results using 99.4% confidence intervals instead of 95.0% intervals, which is a 5% type I error divided by eight tests.</p><p>In an unplanned analysis, we examined the association between the reviewer's recommendation and whether they included citations to work other than citations to their own articles. This was added to examine differences between reviewers' citations to their own articles and other articles.</p><p>Outliers were not excluded. No data were missing in the analysis data set.</p><p>The sample size calculation is in Supplement S.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text analysis</head><p>We examined how reviewers' citations to their own articles or other articles were justified and whether their wording differed according to their recommendation. For an initial view of citations to their own articles, we randomly selected 20 reviews and extracted the most relevant sentence concerning the citation.</p><p>To analyse the review text, we first extracted the 100 most commonly used words in all reviews.</p><p>To standardise the text, all words were transformed into tokens, with stop-words removed and then stemmed. We then tested which of the 100 words were associated with recommending Approved versus Reservations or Not approved amongst those reviewers who included a citation to their own articles and those who included a citation to other articles. We chose the set of words using an elastic net with 10-fold cross-validation and selected a parsimonious model by using the lambda within one standard error of the minimum cross-validated error <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b38">39]</ref>. To get uncertainty intervals for the estimates, we fitted a Bayesian model with the set of words selected by the elastic net and using a sceptical Normal prior centred on zero to create shrinkage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reproducibility</head><p>Research question 1 was pre-registered using As Predicted on 20 May 2024 <ref type="bibr" target="#b39">[40]</ref>. Research question 2 was formulated during data collection but before any data analysis and used the same study design and statistical methods as question 1. In the first version of the article, the reviewer Smith (blue) is cited whilst Jones (purple) is not. For the second version of the article, the authors are now aware that Jones is a reviewer and Jones has been cited. The reviewers' recommendations are the outcome and are colour-coded as Not approved (red), Reservations (orange) and Approved (green). We tested whether citations to the reviewer in the article influenced their recommendation. The matched design means that only reviewers of the same article are compared (here, Smith and Jones) and the overall effect is estimated by aggregating over multiple matched comparisons. Research question 2 used the same design but examined citations to the reviewers' articles in their reviews.</p><p>All data extraction and analyses were conducted using R version 4.4.1 <ref type="bibr" target="#b40">[41]</ref>. The data and R code are available on GitHub <ref type="bibr" target="#b41">[42]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>A flow chart of the included reviews is shown in Supplement S.2. The final sample size was over 37,000 reviews. There were more than 3,500 articles that were not included because they had not yet been peer reviewed, especially recent articles. More than 2,000 reviewers did not have a record in OpenAlex and so could not be included. These missing reviewers were more likely to be from older articles and more likely to be co-reviewers.</p><p>Descriptive statistics on the included reviews are in Table <ref type="table" target="#tab_0">2</ref>. The reviewers were cited at least once in 13% of the articles and 6% of the reviews included a self-citation. Most reviews recommended "Approved" (54%), with only 8% recommending "Not approved" which is low compared with many journals; however, 40 to 50% of submissions are rejected before articles are sent for peer review (personal communication, F1000 staff). The reviewers were relatively experienced, with a median number of papers of 55. The binary predictor for citations of "any versus none" had a generally better fit to the data compared to the linear predictor (Supplement S.3). This indicates that for most reviewers receiving any citation is important, and there is no linear increase for two or more citations. The following results are for the binary predictor "any versus none", with the results using a linear predictor in Supplement S.4.</p><p>Reviewers who were cited were more likely to approve the article, but only after version 1 (Fig 2</p><p>and Table <ref type="table" target="#tab_1">3</ref>). If a reviewer was cited in any versions after version 1, the odds ratio for recommending Approved versus Reservations or Not approved was 1.61 (adjusted 99.4% CI 1.16 to 2.23). Reviewers who included a citation to their own articles were much less likely to approve the article for all versions (Fig 3 and Table 3). The odds ratio for recommending Approved versus Reservations or Not approved was 0.57 (99.4% CI 0.44 to 0.73) for version 1 and strengthened to 0.15 (99.4% CI 0.08 to 0.30) for versions 2+. The less favourable recommendation was only for the approval of the article and the odds ratios for Approved or Reservations versus Not approved were much closer to 1.</p><p>In an unplanned analysis, we examined the behaviour of reviewers in the first two versions of the article. We examined the 441 reviews where the reviewer was not cited in version 1 of the article and included a citation to their own articles in their first review. The reviewers who were then cited in version 2 recommended approval for 92% compared to 76% for reviewers who were not cited (odds ratio = 3.5, 95% CI: 2.0 to 6.1). This analysis did not use matching.</p><p>In an unplanned analysis, we examined whether the reviewers' recommendations depended on whether their review included citations to articles other than their own. Reviewers who included citations in their review were much more likely not to approve the article (Figure <ref type="figure" target="#fig_3">4</ref>), which was similar to the association with citations to reviewers' own articles (Figure <ref type="figure" target="#fig_2">3</ref>). However, reviewers who included citations to articles other than their own were also much more likely to recommend "Not approved", as shown by the lower odds of "Approved" or "Reservations" versus "Not approved". This association was not seen using citations to reviewers' own articles (Figure <ref type="figure" target="#fig_2">3</ref>)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sensitivity analyses</head><p>The odds ratios when including co-reviewers with reviewers were similar to the odds ratios when using reviewers only (Supplement S.5).</p><p>We found no evidence that the reviewers' publication numbers or country confounded the associations between citations and recommendations (Supplement S.6). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text analyses of reviewers' comments</head><p>A random sample of how reviewers included citations to their own articles found some vague justifications (Supplement S.7); for example, "Here are some additional publications you might consider referencing". Other sentences adhered to the publisher's guidelines for reviewers, as specific reasoning was provided for citations to their own articles <ref type="bibr" target="#b6">[7]</ref>. One reviewer thanked the authors for a previous citation. Three reviews did not have a relevant sentence. One reviewer almost certainly used AI to write their review as it included the phrase "Certainly! Here are some potential review questions for the manuscript" <ref type="bibr" target="#b42">[43]</ref>; this review included six self-citations with no justifications.</p><p>Reviewers who included a citation to their own articles or other articles were more likely to use the words "need" and "please" when not approving the article (Figure <ref type="figure" target="#fig_4">5</ref>). In contrast, the words "genome" and "well" were the most strongly associated with the reviewers' approval. To examine how often open peer reviews were viewed, we took a random sample of 200 reviews from the four journals and found that, on average, they were viewed just 1.2 times per year (Supplement S.8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Our results provide evidence that some reviewers have a transactional view of peer review, with their final approval dependent on citations to their work. Some reviewers may be exploiting the pressure on authors to "publish or perish". Under this pressure, many authors may oblige and add the suggested citations, especially since adding another citation may only require a minor edit to their article <ref type="bibr" target="#b43">[44]</ref>. Both sides gain from this transaction, as the authors get an indexed publication and the reviewer gets a citation.</p><p>A key question is whether citations to a reviewer's own articles are justified as they may highlight important errors or missing context in the article. Citations to a reviewer's own articles can be justified when the authors have made a "large scholarly oversight" <ref type="bibr" target="#b7">[8]</ref>. To investigate this, we compared the recommendations and wording of reviewers who included citations to their own articles to reviewers who included citations to other articles. The language used by the reviewers of these two groups was similar, with a higher use of "please" and "need" when not approving the article (Figure <ref type="figure" target="#fig_4">5</ref>). However, there was a difference between groups in their recommendations, as reviewers including citations to other articles were more likely to recommend "Not approved" (Figure <ref type="figure" target="#fig_3">4</ref>) whereas this association was not observed for reviewers including citations to their own articles (Figure <ref type="figure" target="#fig_2">3</ref>). This indicates that missing citations to other articles were considered more serious than missing citations to the reviewer's articles. Reviewers who cited their own articles may have been more inclined to give authors a chance to update their article and thus potentially include the "missing" citation(s).</p><p>Examining the context of the citations to reviewers' own articles, we found vague or non-existent justifications (Supplement S.7), showing that some reviewers ignored the journals' guidelines to state their reasoning when including citations to their own articles. However, these examples of poor justifications do not mean that all self-citations are coercive.</p><p>For both research questions, the effects were stronger for the second and later versions of the article than for the first version. Reviewers may understand that authors may be more willing to compromise on later versions when they are closer to obtaining an indexed publication. Most researchers understand that the peer review system is imperfect and that they sometimes have to make compromises to be successful <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b44">45]</ref>. Another difference to consider is that later versions will include more articles with disagreements between reviewers and more that were not "Approved" in the first version as articles where two or more reviewers recommended "Approved" may not have needed a second version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Potential improvements to peer review</head><p>Journals could give stronger guidance to reviewers and authors on coercive citations <ref type="bibr" target="#b3">[4]</ref>.</p><p>However, given the limited time for peer review and the many differences in guidelines between journals <ref type="bibr" target="#b45">[46]</ref>, most authors may not read peer review instructions. Hence, guidance alone may have limited impact.</p><p>One suggestion is that reviewers declare to editors when they have recommended citations to their own work <ref type="bibr" target="#b46">[47]</ref>. A useful innovation would be for all reviews that contain citations to the reviewer's own articles to be automatically flagged to the editors who could check if the citations are justified. We are aware of one journal where this is already happening (personal communication, Benno Torgler). F1000 have recently introduced checks to prevent reviewers from publishing a review with three or more citations to the reviewer's own articles. If the reviewers continue to request more than three, then the review is examined, and if the citations are deemed inappropriate and the reviewer declines to remove them, then the review is declined.</p><p>Open peer review has been suggested as a way to reduce coercive citations <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b46">47]</ref>. However, our results from four journals that use open review show that it is not a perfect antidote, although the problem could be worse in journals using blinded peer review. The transparency of open peer review should prevent reviewers from leaving self-serving comments; however, we found some dubious justifications for self-citations and blatant use of AI (Supplement S.7). These reviewers may have rationalised that although their words are public, they are rarely scrutinised (Supplement S.8); hence, it was worth the risk. The assumed additional quality assurance from open peer review <ref type="bibr" target="#b47">[48]</ref> may often be absent.</p><p>A more radical change to peer review is that the reviewers initially see a version of the article with all references blinded and no reference list; for example, "A strong association between increased cleaning and reduced hospital infection is well established [x]". Reviewers are asked to give an initial recommendation and comments, and then are shown the version with the full references and asked if they need to update their recommendation or provide additional comments. However, this involves more administrative work and demands more from peer reviewers. This approach could be used for particularly consequential or controversial articles.</p><p>Some journals already require authors to partially blind their articles to maintain anonymous peer review; for example, the instructions from Taylor &amp; Francis include blinding the authors' names in the reference list <ref type="bibr" target="#b48">[49]</ref>.</p><p>An argument could be made for using large language models to provide peer review that is unmoved by citation flattery. However, peer review is an inherently human task by peers, and instead we need to improve peer review rather than abdicating this often difficult and time-consuming task to machines <ref type="bibr" target="#b49">[50]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related research</head><p>Previous cross-sectional studies of self-citations in reviews found at least one self-citation in 3% at a journal that used blinded peer review <ref type="bibr" target="#b16">[17]</ref>, 12% at a journal that used blinded peer review <ref type="bibr" target="#b50">[51]</ref>, and 12% at a journal that used open peer review <ref type="bibr" target="#b51">[52]</ref>. A related study found that 15% of reviews included a self-citation and that the self-citations were highest when the reviewer recommended "major revisions" <ref type="bibr" target="#b52">[53]</ref>. These figures are comparable with the 6% found here and indicate that most reviews do not include self-citations.</p><p>Previous surveys estimated that 14% and 20% of authors had experienced a coercive citation request from an editor <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b54">55]</ref>, and 7% and 23% had experienced coercive citation pressure from a reviewer <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b55">56]</ref>. The frequency with which researchers interact with peer review means that many will encounter coercive citations at some point in their career.</p><p>A study of conference submissions estimated that reviewers who were cited gave submissions much higher scores <ref type="bibr" target="#b17">[18]</ref>. A study of journal peer review estimated that cited reviewers scored the article higher, but with potential confounding by the quality of the article <ref type="bibr" target="#b16">[17]</ref>.</p><p>A survey of authors concluded that accepting an editor's request for citations improved the chances of being accepted <ref type="bibr" target="#b11">[12]</ref>. Requests in later versions were more strongly associated with acquiescence, and we found a related pattern in our analysis, with reviewers who included citations to their own articles being much less likely to recommend approval for later versions (Figure <ref type="figure" target="#fig_2">3</ref>). A study examining open peer review found that requests to cite the reviewer's articles were more likely to be included than other suggested citations, indicating that many authors wanted to please the reviewer or felt pressure to do so <ref type="bibr" target="#b51">[52]</ref>.</p><p>A survey of journal editors found that only 5% objected to reviewers citing their own articles, and that this should be expected as reviewers are likely to have done related work <ref type="bibr" target="#b7">[8]</ref>.</p><p>A cross-sectional study found that reviewers citations to their own articles were more likely to have no rationale compared to other citations, suggesting that they are more likely to be unwarranted <ref type="bibr" target="#b50">[51]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strengths and limitations</head><p>This is an observational study meaning we cannot rule out unmeasured confounding and should be cautious in interpreting the results.</p><p>To our knowledge, this is the first analysis to use a matched design and analysis when examining reviewer citations, and hence strongly control for any confounding by the characteristics of the authors or articles. We compared reviewers who examined an identical article; hence, the differences we found should be due to the reviewers.</p><p>Our models include measurement error, as some citations to the reviewers' work will be missed by our data collection, and some captured citations will be inaccurate <ref type="bibr" target="#b56">[57]</ref>. We performed random data checks that showed good accuracy (Supplement S.9); however, we also found valid citations that were not captured by our data extraction for conference proceedings and technical reports, which are less likely to have a DOI. This measurement error would most likely underestimate a true association, as it reduced the variance in citation counts and created a regression dilution <ref type="bibr" target="#b57">[58]</ref>. Our estimates will be biased if the associations between citations and reviewers' recommendations are different for publications that do not have a DOI. Reviewers should be equally happy with any citation to their work; however, some reviewers may prefer citations to indexed articles, as these are more likely to count toward their h-indices <ref type="bibr" target="#b58">[59]</ref>.</p><p>We examined whether citing a reviewer altered their recommendation, but did not examine the sentiment of the citation <ref type="bibr" target="#b59">[60]</ref>. Some citations would likely have been critical of the reviewer's articles, and we would expect these to reduce the chances of a favourable recommendation. An analysis that included the sentiment of the citation would be useful, although previous research found that most citations are neutral or positive <ref type="bibr" target="#b59">[60]</ref>.</p><p>We did not examine the authors' responses to the reviewers but these could include important information on why a citation was included or not in a revised version of the article. A detailed analysis examining the text used in the interactions between authors and reviewers could provide valuable information about the peer review process.</p><p>Our results may not be generalisable to journals that use blinded peer review or journals that use the traditional peer review model rather than the publish-review-curate model studied here. A previous study found that asking reviewers to consent to an open review had no important effect on the quality of the review or the reviewers' recommendation <ref type="bibr" target="#b60">[61]</ref>. Another potential difference is that the journals in our sample often asked the authors to suggest peer reviewers; however, this is relatively common in other journals <ref type="bibr" target="#b7">[8]</ref>.</p><p>We found a bias in our sample, as co-reviewers and reviewers from older articles were more likely to be excluded due to not having an OpenAlex record (Supplement S.6). We therefore lost more junior reviewers who were less likely to be cited. The percentage of reviews lost was 5% (2,026 of 39,113), which is hopefully small enough to avoid a large bias.</p><p>The elastic net retained two predictors. The date of the article had an odds ratio of 1.09 per year increase, which means that more recent articles were more likely to be retained, likely because the reviewer's information was more current. Referees were more likely to be retained compared to co-referees with an odds ratio of 1.79, likely because co-referees were often relatively junior and some may not have any publications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.3 Model fit</head><p>Table S.1: Comparing the two alternatives for the citation predictor variables using either a linear variable or a binary "any versus none" variable. A vs R/N = Approved vs Reservations/Not approved, A/R vs N = Approved/Reservations vs Not approved. Co-reviewers AIC included Version Outcome Linear Binary Difference No 1 A vs R/N 5940.9 5937.4 3.6 No 1 A/R vs N 1930.3 1929.8 0.5 No 2+ A vs R/N 1952.4 1941.9 10.5 No 2+ A/R vs N 572.1 571.9 0.2 Yes 1 A vs R/N 5978.4 5975.4 3.0 Yes 1 A/R vs N 1941.1 1940.8 0.3 Yes 2+ A vs R/N 1963.1 1951.4 11.7 Yes 2+ A/R vs N 572.6 572.8 -0.2 No 1 A vs R/N 5932.3 5911.1 21.2 No 1 A/R vs N 1934.1 1935.6 -1.5 No 2+ A vs R/N 1881.4 1876.0 5.4 No 2+ A/R vs N 573.4 572.8 0.6 Yes 1 A vs R/N 5967.9 5944.9 23.0 Yes 1 A/R vs N 1945.4 1946.6 -1.2 Yes 2+ A vs R/N 1917.3 1904.1 13.2 Yes 2+ A/R vs N 573.1 573.5 -0.5</p><p>The AIC (Akaike Information Criterion) is a trade-off of model fit and complexity. The smaller the AIC, the better the fit. Differences of 10 are considered large <ref type="bibr" target="#b34">[35]</ref>.</p><p>In most cases, the difference between the linear and binary variables was small (under 5). There were four comparisons out of 16 in which the linear variable had a smaller AIC than the binary variable and all differences were small (under 2). There were four comparisons where the AIC for the binary variable was over 10 units smaller than the linear variable, indicating a large difference in model fit. In summary, using a binary predictor variable is a generally better fit to the data than using a linear variable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.4 Results from using a linear predictor</head><p>The figure shows the estimates for the two research questions using a linear dose-response for citation counts instead of the binary predictor of any citation versus none. The strongest effect was a greatly reduced odds of "Approved" for increasing citations to the reviewer's own articles.</p><p>However, these estimates should be viewed with caution, as the binary predictor generally better fits the data (Supplement S.3). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.5 Including co-reviewers</head><p>Some reviews were performed by reviewers together with co-reviewers, who were usually less experienced. Our primary analysis excluded co-reviewers, but we included them in a sensitivity analysis where we created combined versions of the two independent variables using the sum of citations to reviewers and co-reviewers, and the sum of citations to their own articles from the reviewers and co-reviewers. The results examining whether the reviewers gave a more favourable recommendation when cited (research question 1) were very similar (Figure S.3). The results examining whether the reviewers gave a more favourable recommendation when they included citations to their own articles (research question 2) were mostly very similar (Figure S.4). Two noticeable differences were two odds ratios where including co-reviewers somewhat reduced the strength of the association. This was for article versions 2+ and examining Approved vs Reservations or Not approved. Despite the noticeable change in the odds ratio, the interpretation remains similar in that there was a strong reduction in the odds of a favourable recommendation when the reviewers included citations to their own articles. The plot is designed to directly compare paired odds ratios with or without co-reviewers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.6 Potential confounding by the reviewers' characteristics</head><p>Any confounding by the characteristics of the articles was controlled by the matched design, but confounding by the characteristics of the reviewers remains possible <ref type="bibr" target="#b17">[18]</ref>. We considered the potential confounders of the reviewer's experience and reviewer's country. More experienced reviewers will likely be cited more often (on average) and could be more or less strict in their recommendations. The reviewer's country is a potential confounder due to large differences in citation counts by country <ref type="bibr" target="#b61">[62]</ref> and potential differences in recommendations by country <ref type="bibr" target="#b62">[63]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reviewers' experience</head><p>We used the reviewer's number of published articles as a proxy for their experience. This association could be non-linear; for example, a diminishing effect for more experienced reviewers, so we examined six fractional polynomials of the reviewers' number of articles and used the AIC to select the best fit <ref type="bibr" target="#b63">[64]</ref>. For most models, the best fit was achieved using a log-transformation.</p><p>There was little evidence of any confounding by the reviewers' publication counts as the odds ratios were similar for both research questions (Figures S.5 and S.6). A fractional polynomial of -2 tended to show the largest difference compared to the odds ratios with no confounders; however, this transformation was not the best fit and the differences were relatively small.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reviewers' countries</head><p>We planned to use a frailty model to test for confounding by the reviewers' countries <ref type="bibr" target="#b64">[65]</ref>.</p><p>However, this model often failed to converge, potentially because there were many countries and some countries had relatively small numbers of reviewers. Hence, we instead used a leave-one-out analysis for each of the top ten most common countries and determined if the results were noticeably different.</p><p>The results were generally similar regardless of which country was left-out. Leaving out the USA, which was the largest country, had a relatively large effect on the odds of recommending Approved or Reservations vs Not approved for versions 2+ when using the "none vs any   S.8 Views of reviews We randomly sampled 200 reviews from our sample and collected the number of times the review had been viewed online. A histogram of view counts is shown in Figure S.9, which had a strong positive skew with most reviews having 10 or fewer views. We used a Poisson model to estimate the annual number of views per year, accounting for the reviews' publication dates. The mean number of views per year was 1.24 with a 95% credible interval of 1.20 to 1.28. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.9 Data validation</head><p>We randomly selected reviews from our analysis data and manually verified the accuracy of our automated data extraction. We checked the accuracy of:</p><p>• Reviewers that were cited</p><p>• Reviewers that were not cited</p><p>• Reviewers that included citation(s) to their own articles in their review</p><p>We used a Bayesian calculation to estimate the error rates of our data extraction. We started with a vaguely informative Beta <ref type="bibr">(1, 3.32)</ref> prior, which had a 90% probability that the error rate was under 0.5. This vague prior was used to exclude high error rates which were unlikely given our testing of the code during the construction of the data extraction. We created posterior estimates for the error rates using the observed counts of errors from manual checks. We calculated the 90% limits for the posterior distributions as an upper estimate of the error rates.  Table S.3: Number of errors found in our data extraction algorithm from manual checks and the estimated 90% limit for the error rate Check Number Errors Pr(Error rate ≤ x) checked found = 90% Reviewer not cited 100 2 0.051 Reviewer cited 100 1 0.037 Reviewer's citation to their own articles 80 4 0.094</p><p>The two errors for reviewers not being cited were for citations to a book and a conference paper that did not have a DOI. All four errors in capturing self-citations were where the number captured was fewer than the true number, for example, we extracted 1 self-citation when the true number was 3.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Graphical summary of the study design for research question 1 showing a dummy article and two reviews.In the first version of the article, the reviewer Smith (blue) is cited whilst Jones (purple) is not. For the second version of the article, the authors are now aware that Jones is a reviewer and Jones has been cited. The reviewers' recommendations are the outcome and are colour-coded as Not approved (red), Reservations (orange) and Approved (green). We tested whether citations to the reviewer in the article influenced their recommendation. The matched design means that only reviewers of the same article are compared (here, Smith and Jones) and the overall effect is estimated by aggregating over multiple matched comparisons. Research question 2 used the same design but examined citations to the reviewers' articles in their reviews.</figDesc><graphic coords="4,116.93,616.89,361.42,155.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure2: Odds ratios and probabilities for reviewers giving a more or less favourable recommendation depending on whether they were cited in the article. Top left: Odds ratios for reviewers giving a more favourable (Approved) or less favourable (Reservations or Not approved) recommendation depending on whether they were cited in the article. Reviewers cited in later versions (blue) were more likely to make a favourable recommendation (odds ratio = 1.61; adjusted 99.4% CI: 1.16 to 2.23), whereas being cited in the first version (green) did not improve their recommendation (odds ratio = 0.84; adjusted 99.4% CI: 0.69 to 1.03). Top right: Same results as top left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which they are not cited (0.51; adjusted 99.4% CI: 0.49 to 0.52); a version 1 article in which they are cited (0.46; adjusted 99.4% CI: 0.41 to 0.51); a version 2 (or higher) article in which they are not cited (0.48; adjusted 99.4% CI: 0.45 to 0.51); and a version 2 (or higher) article in which they are cited (0.60; adjusted 99.4% CI: 0.53 to 0.65). Bottom left: Same estimates as top left except that a more favourable recommendation is now Approved or Reservations and a less favourable is Not approved. There was no clear association for cited reviewers in version 1 (odds ratio = 0.84; adjusted 99.4% CI: 0.57 to 1.23) or later versions (odds ratio = 1.12; adjusted 99.4% CI: 0.59 to 2.13). Bottom right: Same results as bottom left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which they are not cited (0.51; adjusted 99.4% CI: 0.48 to 0.53); a version 1 article in which they are cited (0.47; adjusted 99.4% CI: 0.35 to 0.55); a version 2 (or higher) article in which they are not cited (0.50; adjusted 99.4% CI: 0.43 to 0.55); and a version 2 (or higher) article in which they are cited (0.53; adjusted 99.4% CI: 0.34 to 0.63). This figure is based on an analysis of 12,051 articles and 24,677 reviews for version 1 and 6090 articles and 10,196 reviews for version 2+. In all panels a dot or square represents a mean, and a horizontal line represents an adjusted 99.4% confidence interval.</figDesc><graphic coords="6,116.93,347.05,361.44,345.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure3: Odds ratios and probabilities for reviewers giving a more or less favourable recommendation if they included a citation to their own articles in their review. Top left: Odds ratios for reviewers giving a more favourable (Approved) or less favourable (Reservations or Not approved) recommendation depending on whether their review included a citation to their own articles. Reviewers including a citation to their own articles were less likely to make a favourable recommendation for version 1 (green; odds ratio = 0.57; adjusted 99.4% CI: 0.44 to 0.73) and later versions (blue; odds ratio = 0.15; adjusted 99.4% CI: 0.07 to 0.30). Top right: Same results as top left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which their review did not include a citation (0.51; adjusted 99.4% CI: 0.50 to 0.53); a version 1 article in which in which their review included a citation (0.37; adjusted 99.4% CI: 0.29 to 0.44); a version 2 (or higher) article in which their review did not include a citation (0.51; adjusted 99.4% CI: 0.49 to 0.53); and a version 2 (or higher) article in which in which their review included a citation (0.14; adjusted 99.4% CI: 0.01 to 0.30). Bottom left: Same estimates as top left except that a more favourable recommendation is now Approved or Reservations and a less favourable is Not approved. There was no clear association for reviewers who included a citation to their own articles in version 1 (odds ratio = 1.11; adjusted 99.4% CI: 0.77 to 1.60) or later versions (odds ratio = 0.80; adjusted 99.4% CI: 0.37 to 1.74). Bottom right: Same results as bottom left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which their review did not include a citation (0.50; adjusted 99.4% CI: 0.48 to 0.52); a version 1 article in which their review included a citation (0.53; adjusted 99.4% CI: 0.43 to 0.60); a version 2 (or higher) article in which their review did not include a citation (0.51; adjusted 99.4% CI: 0.46 to 0.54); and a version 2 (or higher) article in which their included a citation (0.45; adjusted 99.4% CI: 0.12 to 0.61). This figure is based on an analysis of 12,078 articles and 24,732 reviews for version 1 and 6101 articles and 10,213 reviews for version 2+. In all panels a dot or square represents a mean, and a horizontal line represents an adjusted 99.4% confidence interval.</figDesc><graphic coords="7,116.93,358.01,361.44,345.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure4: Odds ratios and probabilities for reviewers giving a more or less favourable recommendation depending on if they included citations to articles other than their own in their review. Top left: Odds ratios for reviewers giving a more favourable (Approved) or less favourable (Reservations or Not approved) recommendation depending on whether their review included a citation to articles other than their own. Reviewers including citations to other articles were less likely to make a favourable recommendation for version 1 (green; odds ratio = 0.53; adjusted 99.4% CI: 0.44 to 0.64) and later versions (blue; odds ratio = 0.18; adjusted 99.4% CI: 0.10 to 0.30). Top right: Same results as top left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which their review did not cite other articles (0.53; adjusted 99.4% CI: 0.51 to 0.54); a version 1 article in which their review cited other articles (0.37; adjusted 99.4% CI: 0.31 to 0.42); a version 2 (or higher) article in which their review did not cite other articles (0.52; adjusted 99.4% CI: 0.50 to 0.54); and a version 2 (or higher) article in which in which their review cited other articles (0.17; adjusted 99.4% CI: 0.02 to 0.30). Bottom left: Same estimates as top left except that a more favourable recommendation is now Approved or Reservations and a less favourable is Not approved. Reviewers including citations to other articles were less likely to make a favourable recommendation for version 1 (odds ratio = 0.62; adjusted 99.4% CI: 0.46 to 0.84) and later versions (odds ratio = 0.34; adjusted 99.4% CI: 0.16 to 0.73). Bottom right: Same results as bottom left displayed as conditional probabilities. From the top, the lines show the within-strata probability of a reviewer approving: a version 1 article in which their review did not cite other articles (0.52; adjusted 99.4% CI: 0.49 to 0.54); a version 1 article in which their review cited other articles (0.41; adjusted 99.4% CI: 0.31 to 0.48); a version 2 (or higher) article in which their review did not cite other articles (0.52; adjusted 99.4% CI: 0.47 to 0.55); and a version 2 (or higher) article in which their review cited other articles (0.27; adjusted 99.4% CI: 0.02 to 0.45). This figure is based on an analysis of 12,078 articles and 24,732 reviews for version 1 and 6101 articles and 10,213 reviews for version 2+. In all panels a dot or square represents a mean, and a horizontal line represents an adjusted 99.4% confidence interval.</figDesc><graphic coords="9,116.93,404.34,361.44,345.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: Words in the reviewers' comments that were associated with approving the article or not for reviewers who included a citation to their own articles (n = 2, 025) and reviewers who included citations to other articles (n = 4, 350). The words were selected using an elastic net that started with the 100 most commonly used review words. The estimates from the elastic net are shown as empty circles and the mean estimates and 95% credible intervals from a Bayesian model are shown as a solid circle and horizontal line. Words are shown if the probability of a non-zero mean was over 0.95 for either reviewers who cited their own articles or reviewers who cited other articles. Four words were selected by the elastic net for the reviewers who cited other articles but not by the elastic net for reviewers who cited their own articles. The axis label shows the stemmed word and most common whole word in brackets.</figDesc><graphic coords="10,127.56,372.37,340.15,353.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure S. 2 :</head><label>2</label><figDesc>Figure S.2: Estimated odds ratios for using linear citations as the predictor. The reference point is zero citations.</figDesc><graphic coords="16,116.93,207.54,361.42,342.73" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure S. 3 :</head><label>3</label><figDesc>Figure S.3: Results with or without co-reviewers for research question 1. Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation if they were cited. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version. The plot is designed to directly compare paired odds ratios with or without co-reviewers.</figDesc><graphic coords="17,116.93,252.36,361.41,361.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure S. 4 :</head><label>4</label><figDesc>Figure S.4: Results with or without co-reviewers for research question 2. Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation when they included a citation to their own articles. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version.The plot is designed to directly compare paired odds ratios with or without co-reviewers.</figDesc><graphic coords="18,116.93,286.79,361.41,361.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure S. 5 :</head><label>5</label><figDesc>Figure S.5: Examining potential confounding by reviewers' publication counts for research question 1. Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation when they were cited. We used fractional polynomials to examine a potentially non-linear association between reviewers' publication counts and recommendation. The results for "None" are the results without the potential confounder. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version. Results are missing when the model did not converge.</figDesc><graphic coords="19,116.93,407.68,361.41,361.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure S. 6 :</head><label>6</label><figDesc>Figure S.6: Examining potential confounding by reviewers' publication counts for research question 2. Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation when they included a citation to their own articles. We used fractional polynomials to examine a potentially non-linear association between reviewers' publication counts and recommendation. The results for "None" are the results without the potential confounder. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version. Results are missing when the model did not converge.</figDesc><graphic coords="20,116.93,297.75,361.41,361.41" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><figDesc>citations" predictor (Figure S.7) and on the odds of recommending Approved or Reservations vs Not approved for versions 2+ when using the "none vs any citations" predictor (Figure S.8). However, neither change was substantively different from the results including all countries.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure S. 7 :</head><label>7</label><figDesc>Figure S.7: Leave-one-country-out sensitivity analyses for research question 1. Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation when they were cited. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version.</figDesc><graphic coords="21,106.30,306.63,382.65,372.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure S. 8 :</head><label>8</label><figDesc>Figure S.8: Leave-one-country-out sensitivity analyses for research question 2. Odds ratios and adjusted 99.4% confidence intervals for whether the reviewer gave a more or less favourable recommendation when they included a citation to their own articles. The results are shown for the combinations of predictor variables (linear or any vs none), outcome (Approved → Reservations → Not approved) and article version.</figDesc><graphic coords="22,106.30,275.87,382.65,372.31" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure S. 9 :</head><label>9</label><figDesc>Figure S.9: Histogram of online view counts of published reviews. The bins are in tens starting at [0, 10).</figDesc><graphic coords="24,159.45,206.99,276.37,245.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><figDesc>The distributions are plotted in Figure S.10 and the error rates are shown in TableS.<ref type="bibr" target="#b2">3</ref>. The errors are proportions, with 0 for no errors and 1 for all errors. The highest error rate was for citation(s) to their own articles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure S. 10 :</head><label>10</label><figDesc>Figure S.10: Distributions of the error rates. Vaguely informative prior and posteriors for errors for not cited reviewers, cited reviewers and self-citations. The dashed vertical lines are at Pr(error ≤ x) = 90%.</figDesc><graphic coords="25,148.82,355.98,297.62,223.22" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="14,148.82,293.07,297.65,341.06" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2 :</head><label>2</label><figDesc>Descriptive statistics for the articles and peer reviews. Q1 = first quartile, Q3 = third quartile.</figDesc><table><row><cell>Variable</cell><cell>Level / Statistics</cell><cell>Result</cell></row><row><cell>Number of reviews</cell><cell>n</cell><cell>37,332</cell></row><row><cell>Year</cell><cell>Median [Q1, Q3]</cell><cell>2022 [2019, 2024]</cell></row><row><cell>Journal, n (%)</cell><cell>F1000Research</cell><cell>24,132 (65)</cell></row><row><cell></cell><cell cols="2">Wellcome Open Research 8697 (23)</cell></row><row><cell></cell><cell>Open Research Europe</cell><cell>2789 (7)</cell></row><row><cell></cell><cell>Gates Open Research</cell><cell>1714 (5)</cell></row><row><cell>Role, n (%)</cell><cell>Reviewer</cell><cell>34,904 (93)</cell></row><row><cell></cell><cell>Co-reviewer</cell><cell>2428 (7)</cell></row><row><cell>Reviewer's</cell><cell>Approved</cell><cell>19,984 (54)</cell></row><row><cell>recommendation, n (%)</cell><cell>Reservations</cell><cell>14,379 (38)</cell></row><row><cell></cell><cell>Not approved</cell><cell>2969 (8)</cell></row><row><cell>Article version, n (%)</cell><cell>1</cell><cell>26,474 (71)</cell></row><row><cell></cell><cell>2</cell><cell>8995 (24)</cell></row><row><cell></cell><cell>3+</cell><cell>1863 (5)</cell></row><row><cell>Number of papers cited in article</cell><cell>Median [Q1, Q3]</cell><cell>24 [14, 38]</cell></row><row><cell>Any citations to reviewer, n (%)</cell><cell>No</cell><cell>32,375 (87)</cell></row><row><cell></cell><cell>Yes</cell><cell>4957 (13)</cell></row><row><cell cols="2">Any papers cited by reviewer, n (%) No</cell><cell>31,546 (84)</cell></row><row><cell></cell><cell>Yes</cell><cell>5786 (16)</cell></row><row><cell>Any citations to the</cell><cell>No</cell><cell>35,023 (94)</cell></row><row><cell>reviewer's articles</cell><cell>Yes</cell><cell>2309 (6)</cell></row><row><cell>Reviewer's publication count</cell><cell>Median [Q1, Q3]</cell><cell>55 [24, 118]</cell></row><row><cell>Reviewer's country</cell><cell>USA</cell><cell>7655 (21%)</cell></row><row><cell>(top five only)</cell><cell>United Kingdom</cell><cell>4137 (11%)</cell></row><row><cell></cell><cell>India</cell><cell>2472 (7%)</cell></row><row><cell></cell><cell>Italy</cell><cell>1368 (4%)</cell></row><row><cell></cell><cell>Australia</cell><cell>1349 (4%)</cell></row><row><cell>Number of words in the review</cell><cell>Median [Q1, Q3]</cell><cell>202 [67, 411]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 :</head><label>3</label><figDesc>Odds ratios for reviewers giving a more (OR &gt; 1) or less (OR &lt; 1) favourable recommendation depending on whether they were cited in the article (question 1) or included citations to their own articles (question 2). All models were split by article version.</figDesc><table><row><cell>Research question</cell><cell cols="2">Article version Outcome</cell><cell>OR (Adjusted 99.4% CI)</cell></row><row><cell></cell><cell>Version = 1</cell><cell>Approved vs Reservations/Not approved</cell><cell>0.84 (0.69, 1.03)</cell></row><row><cell>1. Reviewer cited by</cell><cell>Version = 1</cell><cell>Approved/Reservations vs Not approved</cell><cell>0.84 (0.57, 1.23)</cell></row><row><cell>authors</cell><cell cols="2">Versions = 2+ Approved vs Reservations/Not approved</cell><cell>1.61 (1.16, 2.23)</cell></row><row><cell></cell><cell cols="2">Versions = 2+ Approved/Reservations vs Not approved</cell><cell>1.12 (0.59, 2.13)</cell></row><row><cell></cell><cell>Version = 1</cell><cell>Approved vs Reservations/Not approved</cell><cell>0.57 (0.44, 0.73)</cell></row><row><cell>2. Reviewer cited</cell><cell>Version = 1</cell><cell>Approved/Reservations vs Not approved</cell><cell>1.11 (0.77, 1.60)</cell></row><row><cell>their own articles</cell><cell cols="2">Versions = 2+ Approved vs Reservations/Not approved</cell><cell>0.15 (0.08, 0.30)</cell></row><row><cell></cell><cell cols="2">Versions = 2+ Approved/Reservations vs Not approved</cell><cell>0.80 (0.37, 1.74)</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>Thanks to all four journals for making all their data openly available and easily accessible.</p><p>Thanks to <rs type="person">Robin Blythe</rs>, staff from F1000 and Paper-Wizard <ref type="url" target="https://paper-wizard.com/">https://paper-wizard.com/</ref> for providing helpful feedback on a draft of this paper.</p></div>
			</div>
			<div type="funding">
<div><p>started Field(s) of research funded by <rs type="grantNumber">F1000Research 2012</rs> All disciplines No restriction <rs type="programName">Wellcome Open Research 2016</rs> Medicine, <rs type="programName">Genomics Wellcome Gates Open Research 2017</rs> Medicine The <rs type="programName">Gates Foundation Open Research Europe 2021</rs> All disciplines <rs type="funder">European Commission</rs></p><p>The peer review process used by F1000 journals differs from most standard journals.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_2mjYxpt">
					<idno type="grant-number">F1000Research 2012</idno>
					<orgName type="program" subtype="full">Wellcome Open Research 2016</orgName>
				</org>
				<org type="funding" xml:id="_dCeUEha">
					<orgName type="program" subtype="full">Genomics Wellcome Gates Open Research 2017</orgName>
				</org>
				<org type="funding" xml:id="_pnK5NVQ">
					<orgName type="program" subtype="full">Gates Foundation Open Research Europe 2021</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary material S.1 Sample size</head><p>We aimed for a sample size of approximately 5,000 articles and assumed that half would be the first version, giving a sample size of 2,500 articles for the analysis using the first version only <ref type="bibr" target="#b39">[40]</ref>.</p><p>In 1,000 simulations, this gave an 89.1% power to detect an odds ratio of 1.5 using conditional logistic regression for a reviewer who recommended a higher category (Approved → Reservations → Not approved) when they were cited. We assumed that 15% of articles would include a citation to the reviewer. Eighty percent of the simulated articles had two reviews, and the remaining 20% had three reviews. Based on preliminary data from two journals, we assumed that the reviewers' recommendations would have a ratio for Approved:Reservations:Not approved of 70:24:6. The flow chart shows the loss of articles and reviews during the data collection process. More than 3,500 articles did not have reviewers as they had yet to be peer reviewed or were Faculty Reviews that are commissioned and use a different peer review model. More than 2,000 reviewers did not have an OpenAlex record and therefore were excluded from the analyses. We examined the potential bias in the lost reviews by comparing their characteristics with those of the retained reviews. We used a multiple regression model with reviewer lost (yes/no) as the binary dependent variable and predictors of article version, article date, referee or co-referee, and reviewer's country. We expected many of these predictors to have little effect; therefore, we used an elastic net to reduce the number of predictors <ref type="bibr" target="#b37">[38]</ref>. We used the 'glmnet' package in R <ref type="bibr" target="#b38">[39]</ref>. For the binary dependent variable, 39,455 reviews were retained and 2082 (5%) were lost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S.2 Included and excluded reviews</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table S.2:</head><p>Example sentences that reviewers used when suggesting citations to their own articles using a random sample of 20 reviews. The first column shows the number of citations suggested. We have removed any references to names using <ref type="bibr">[xxxx]</ref>. The results are ordered by text length.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Citations suggested Reviewer's text</head><p>Also, the introduction, main discussion, and conclusion must be redrawn to highlight NO as a treatment option, the clinical trials discussion, the use of several NORMS (NORM-1, NORM-2, etc), the effect of NO-carriage system, Natural NO-sources, synthetic NO-sources with limitations, Inorganic versus organic forms, etc (eg., in the review publications as given The term 'true bugs' applies to the monophyletic Heteroptera, which does include the species presented here (Acanthosoma haemorrhoidale), while aphids and mealybugs belong to the distinct lineage Sternorrhyncha, sometimes (formerly) regarded as a part of the paraphyletic Homoptera (see, for example, Figure <ref type="figure">2</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">RETRACTION: Origin of the distinct site occupations of H atom in hcp Ti and Zr/Hf</title>
		<author>
			<persName><forename type="first">F.-X</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijhydene.2024.10.197</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Hydrogen Energy</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="page" from="933" to="941" />
			<date type="published" when="2024-11">Nov. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Self-citations as strategic response to the use of metrics for career decisions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Seeber</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.respol.2017.12.004</idno>
		<ptr target="https://doi.org/10.1016/j.respol.2017.12.004" />
	</analytic>
	<monogr>
		<title level="j">Research Policy</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="478" to="491" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Citations Rule Everything Around Me</title>
		<author>
			<persName><forename type="first">S</forename><surname>Cranford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R E A</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.matt.2020.04.025</idno>
	</analytic>
	<monogr>
		<title level="j">Matter</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1343" to="1347" />
			<date type="published" when="2020-06">June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Cite me! Perspectives on coercive citation in reviewing</title>
		<author>
			<persName><forename type="first">S</forename><surname>Burton</surname></persName>
		</author>
		<idno type="DOI">10.1108/jsm-08-2024-0387</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Services Marketing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="809" to="815" />
			<date type="published" when="2024-09">Sept. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The ethics of peer and editorial requests for self-citation of their work and journal</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Teixeira Da Silva</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.mjafi.2016.11.008</idno>
		<ptr target="https://doi.org/10.1016/j.mjafi.2016.11.008" />
	</analytic>
	<monogr>
		<title level="j">Medical Journal Armed Forces India</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="183" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<idno type="DOI">10.24318/cope.2019.3.1</idno>
		<ptr target="http://dx.doi.org/10.24318/cope.2019.3.1" />
	</analytic>
	<monogr>
		<title level="j">Committee on Publication Ethics</title>
		<imprint>
			<date type="published" when="2019-01">Jan. 2019</date>
		</imprint>
	</monogr>
	<note>Citation manipulation</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Reviewer-coerced citation: case report, update on journal policy and suggestions for future prevention</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Wren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Valencia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kelso</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btz071</idno>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="3217" to="3218" />
			<date type="published" when="2019-01">Jan. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Meta-Research: Journal policies and editors&apos; opinions on peer review</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Hamilton</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.62529</idno>
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">62529</biblScope>
			<date type="published" when="2020-11">Nov. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Unnoticed Issue of Coercive Citation Behavior for Authors</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mehregan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moghiman</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12109-024-09994-0</idno>
	</analytic>
	<monogr>
		<title level="j">Publishing Research Quarterly</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="164" to="168" />
			<date type="published" when="2024-06">June 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Whither research integrity? Plagiarism, self-plagiarism and coercive citation in an age of research assessment</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.respol.2013.03.011</idno>
	</analytic>
	<monogr>
		<title level="j">Research Policy</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1005" to="1014" />
			<date type="published" when="2013-06">June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">From Excessive Journal Self-Cites to Citation Stacking: Analysis of Journal Self-Citation Kinetics in Search for Journals, Which Boost Their Scientometric Indicators</title>
		<author>
			<persName><forename type="first">P</forename><surname>Heneberg</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0153730</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">153730</biblScope>
			<date type="published" when="2016-04">Apr. 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Accommodating coercion: Authors, editors, and citations</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Patnayakuni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Wilhite</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.respol.2023.104754</idno>
	</analytic>
	<monogr>
		<title level="j">Research Policy</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">104754</biblScope>
			<date type="published" when="2023-06">June 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Two-thirds of researchers report &apos;pressure to cite&apos; in Nature poll</title>
		<author>
			<persName><forename type="first">D</forename><surname>Singh Chawla</surname></persName>
		</author>
		<idno type="DOI">10.1038/d41586-019-02922-9</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<date type="published" when="2019-10">Oct. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Perceptions of Ethical Problems with Scientific Journal Peer Review: An Exploratory Study</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Resnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gutierrez-Ford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Peddada</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11948-008-9059-4</idno>
	</analytic>
	<monogr>
		<title level="j">Science and Engineering Ethics</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="305" to="310" />
			<date type="published" when="2008-03">Mar. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Elsevier investigates hundreds of peer reviewers for manipulating citations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Singh Chawla</surname></persName>
		</author>
		<idno type="DOI">10.1038/d41586-019-02639-9</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">573</biblScope>
			<biblScope unit="page">174</biblScope>
			<date type="published" when="2019-09">Sept. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Editorial Ruminations: Publishing Kyklos</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eichenberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Frey</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-6435.2009.00428.x</idno>
	</analytic>
	<monogr>
		<title level="j">Kyklos</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="160" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Are Reviewers&apos; Scores Influenced by Citations to Their Own Work? An Analysis of Submitted Manuscripts and Peer Reviewer Reports</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Schriger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Kadera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Elm</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.annemergmed.2015.09.003</idno>
		<ptr target="https://doi.org/10.1016/j.annemergmed.2015.09.003" />
	</analytic>
	<monogr>
		<title level="j">Annals of Emergency Medicine</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="401" to="406" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Cite-seeing and reviewing: A study on citation bias in peer review</title>
		<author>
			<persName><forename type="first">I</forename><surname>Stelmakh</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0283980</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2023-07">July 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Praise the bridge that carries you over: Testing the flattery citation hypothesis</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Frandsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nicolaisen</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.21503</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="807" to="818" />
			<date type="published" when="2011-03">Mar. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Peer Review: A Flawed Process at the Heart of Science and Journals</title>
		<author>
			<persName><forename type="first">R</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1177/014107680609900414</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Society of Medicine</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="178" to="182" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Health and medical researchers are willing to trade their results for journal prestige: results from a discrete choice experiment</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Bohorquez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prometheus</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Bias in peer review</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.22784</idno>
		<ptr target="https://doi.org/10.1002/asi.22784" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="17" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Ten considerations for open peer review</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="DOI">10.12688/f1000research.15334.1</idno>
	</analytic>
	<monogr>
		<title level="j">F1000Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">969</biblScope>
			<date type="published" when="2018-06">June 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The limitations to our understanding of peer review</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Tennant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ross-Hellauer</surname></persName>
		</author>
		<idno type="DOI">10.1186/s41073-020-00092-1</idno>
	</analytic>
	<monogr>
		<title level="j">Research Integrity and Peer Review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020-04">Apr. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The present and future of peer review: Ideas, interventions, and evidence</title>
		<author>
			<persName><forename type="first">B</forename><surname>Aczel</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2401232121</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2025-01">Jan. 2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">From 2015 to 2023, eight years of empirical research on research integrity: a scoping review</title>
		<author>
			<persName><forename type="first">B</forename><surname>Vendé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barberousse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ruphy</surname></persName>
		</author>
		<idno type="DOI">10.1186/s41073-025-00163-1</idno>
	</analytic>
	<monogr>
		<title level="j">Research Integrity and Peer Review</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2025-04">Apr. 2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Currie</surname></persName>
		</author>
		<ptr target="https://elifesciences.org/inside-elife/dc24a9cd/open-science-what-is-publish-review-curate" />
		<title level="m">Open Science: What is publish, review, curate?</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
		<ptr target="https://f1000research.com/for-authors/tips-for-finding-referees" />
		<imprint>
			<date type="published" when="1000">1000. 2025</date>
			<publisher>Research</publisher>
		</imprint>
	</monogr>
	<note>Finding Article Reviewers</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Guidelines For Article Reviewers</title>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
		<ptr target="https://f1000research.com/for-referees/guidelines" />
		<imprint>
			<date type="published" when="1000">1000. 2025</date>
			<publisher>Research</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Publication Bias: A Problem in Interpreting Medical Data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Begg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Berlin</surname></persName>
		</author>
		<idno type="DOI">10.2307/2982993</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series A (Statistics in Society)</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">419</biblScope>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Ethical Guidelines for Peer Reviewers</title>
		<author>
			<orgName type="collaboration">Committee</orgName>
		</author>
		<idno type="DOI">10.24318/cope.2019.1.9</idno>
		<imprint>
			<date type="published" when="2017-09">Sept. 2017</date>
		</imprint>
	</monogr>
	<note>Publication Ethics</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Reference coverage analysis of OpenAlex compared to Web of Science and Scopus</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Culbert</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11192-025-05293-3</idno>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2475" to="2492" />
			<date type="published" when="2025-04">Apr. 2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Priem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Piwowar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Orr</surname></persName>
		</author>
		<author>
			<persName><surname>Openalex</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.01833</idno>
		<title level="m">A fully-open index of scholarly works, authors, venues, institutions, and concepts</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>cs.DL</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">openalexR: An R-Tool for Collecting Bibliometric Data from OpenAlex</title>
		<author>
			<persName><forename type="first">A</forename><surname>Massimo</surname></persName>
		</author>
		<idno type="DOI">10.32614/RJ-2023-089</idno>
	</analytic>
	<monogr>
		<title level="j">The R Journal</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="167" to="180" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach</title>
		<author>
			<persName><forename type="first">K</forename><surname>Burnham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Statistics notes: Matching</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Bland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Altman</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmj.309.6962.1128</idno>
	</analytic>
	<monogr>
		<title level="j">BMJ</title>
		<imprint>
			<biblScope unit="volume">309</biblScope>
			<biblScope unit="page">1128</biblScope>
			<date type="published" when="1994-10">Oct. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Applied Logistic Regression</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hosmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lemeshow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sturdivant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wiley Series in Probability and Statistics</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Regularization and Variable Selection Via the Elastic Net</title>
		<author>
			<persName><forename type="first">H</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9868.2005.00503.x</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series B: Statistical Methodology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="301" to="320" />
			<date type="published" when="2005-03">Mar. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Elastic Net Regularization Paths for All Generalized Linear Models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v106.i01</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Research -reviewer citation study</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Barnett</surname></persName>
		</author>
		<ptr target="https://aspredicted.org/rn8vg.pdf" />
		<imprint>
			<date type="published" when="1000-05">1000. May 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">R: A Language and Environment for Statistical Computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/" />
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Code and data for the analysis of the association between citations and peer review recommendations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Barnett</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.16551814</idno>
		<ptr target="https://github.com/agbarnett/cited_reviewers" />
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Peer Review Report For: COVID-19 Vaccine: Predicting Vaccine Types and Assessing Mortality Risk Through Ensemble Learning Algorithms [version 2</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename></persName>
		</author>
		<idno type="DOI">10.5256/f1000research.153740.r257039</idno>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>peer review: 2 approved, 2 approved with reservations</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The review mills, not just (self-)plagiarism in review reports, but a step further</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Á</forename><surname>Oviedo-García</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11192-024-05125-w</idno>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5805" to="5813" />
			<date type="published" when="2024-08">Aug. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The Perverse Effects of Competition on Scientists&apos; Work and Relationships</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Anderson</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11948-007-9042-5</idno>
	</analytic>
	<monogr>
		<title level="j">Science and Engineering Ethics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="437" to="461" />
			<date type="published" when="2007-11">Nov. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">How do journals of different rank instruct peer reviewers? Reviewer guidelines in the field of management</title>
		<author>
			<persName><forename type="first">M</forename><surname>Seeber</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11192-019-03343-1</idno>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1387" to="1405" />
			<date type="published" when="2020-01">Jan. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A solution to inappropriate self-citation via peer review</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Thombs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Razykov</surname></persName>
		</author>
		<idno type="DOI">10.1503/cmaj.120597</idno>
	</analytic>
	<monogr>
		<title level="j">Canadian Medical Association Journal</title>
		<imprint>
			<biblScope unit="volume">184</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page">1864</biblScope>
			<date type="published" when="2012-10">Oct. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Survey on open peer review: Attitudes and experience amongst editors, authors and reviewers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Ross-Hellauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Deppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0189311</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2017-12">Dec. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Anonymous peer review: How to make your article ready for double-anonymous peer review</title>
		<author>
			<persName><forename type="first">Francis</forename><surname>Taylor</surname></persName>
		</author>
		<ptr target="https://authorservices.taylorandfrancis.com/publishing-your-research/peer-review/anonymous-peer-review/" />
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">AI, peer review and the human activity of science</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Bergstrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bak-Coleman</surname></persName>
		</author>
		<idno type="DOI">10.1038/d41586-025-01839-w</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<date type="published" when="2025-06">June 2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Potentially coercive self-citation by peer reviewers: A cross-sectional study</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Thombs</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jpsychores.2014.09.015</idno>
		<ptr target="https://doi.org/10.1016/j.jpsychores.2014.09.015" />
	</analytic>
	<monogr>
		<title level="j">Journal of Psychosomatic Research</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A retrospective study investigating requests for self-citation during open peer review in a general medicine journal</title>
		<author>
			<persName><forename type="first">E</forename><surname>Peebles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Scandlyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Hesp</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0237804</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2020-08">Aug. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Citation gamesmanship: testing for evidence of ego bias in peer review</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Sugimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cronin</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11192-012-0845-z</idno>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="851" to="862" />
			<date type="published" when="2012-09">Sept. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Authorship and citation manipulation in academic research</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Wilhite</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0187394</idno>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2017-12">Dec. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Coercive Citation in Academic Publishing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Wilhite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Fong</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1212540</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">335</biblScope>
			<biblScope unit="page" from="542" to="543" />
			<date type="published" when="2012-02">Feb. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Views on the peer review system of biomedical journals: an online survey of academics from high-ranking universities</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-M</forename></persName>
		</author>
		<idno type="DOI">10.1186/1471-2288-13-74</idno>
	</analytic>
	<monogr>
		<title level="j">BMC Medical Research Methodology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2013-06">June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">How accurate are citations of frequently cited papers in biomedical literature?</title>
		<author>
			<persName><forename type="first">V</forename><surname>Pavlovic</surname></persName>
		</author>
		<idno type="DOI">10.1042/cs20201573</idno>
	</analytic>
	<monogr>
		<title level="j">Clinical Science</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="671" to="681" />
			<date type="published" when="2021-03">Mar. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Underestimation of Risk Associations Due to Regression Dilution in Long-term Follow-up of Prospective Studies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Clarke</surname></persName>
		</author>
		<idno type="DOI">10.1093/oxfordjournals.aje.a010013</idno>
	</analytic>
	<monogr>
		<title level="j">American Journal of Epidemiology</title>
		<imprint>
			<biblScope unit="volume">150</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="341" to="353" />
			<date type="published" when="1999-08">Aug. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Over-optimization of academic publishing metrics: observing Goodhart&apos;s Law in action</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="DOI">10.1093/gigascience/giz053</idno>
		<ptr target="http://dx.doi.org/10.1093/gigascience/giz053" />
	</analytic>
	<monogr>
		<title level="j">GigaScience</title>
		<idno type="ISSN">2047-217X</idno>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2019-05">May 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">What do citation counts measure? An updated review of studies on citations in scientific documents published between 2006 and 2018</title>
		<author>
			<persName><forename type="first">I</forename><surname>Tahamtan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bornmann</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11192-019-03243-4</idno>
	</analytic>
	<monogr>
		<title level="j">Scientometrics</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1635" to="1684" />
			<date type="published" when="2019-09">Sept. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Effect of open peer review on quality of reviews and on reviewers&apos; recommendations: a randomised trial</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rooyen</surname></persName>
		</author>
		<author>
			<persName><surname>Van</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmj.318.7175.23</idno>
	</analytic>
	<monogr>
		<title level="j">BMJ</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="page" from="23" to="27" />
			<date type="published" when="1999-01">Jan. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Leading countries in global science increasingly receive more citations than other countries doing similar research</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Herman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Parigi</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-022-01351-5</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="919" to="929" />
			<date type="published" when="2022-05">May 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Reviewer recommendations and editors&apos; decisions for a conservation journal: Is it just a crapshoot? And do Chinese authors get a fair shot?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Campos-Arceiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Primack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Koh</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.biocon.2015.02.025</idno>
		<ptr target="https://doi.org/10.1016/j.biocon.2015.02.025" />
	</analytic>
	<monogr>
		<title level="j">Biological Conservation</title>
		<imprint>
			<biblScope unit="volume">186</biblScope>
			<biblScope unit="page" from="22" to="27" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">The use of fractional polynomials to model continuous risk variables in epidemiology</title>
		<author>
			<persName><forename type="first">P</forename><surname>Royston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ambler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sauerbrei</surname></persName>
		</author>
		<idno type="DOI">10.1093/ije/28.5.964</idno>
	</analytic>
	<monogr>
		<title level="j">International Journal of Epidemiology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="964" to="974" />
			<date type="published" when="1999-10">Oct. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Modeling Survival Data: Extending the Cox Model</title>
		<author>
			<persName><forename type="first">T</forename><surname>Therneau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Grambsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistics for Biology and Health</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
