<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Assessments of the Privacy Compliance in Commercial Large Language Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Rupert</forename><surname>Chadwick</surname></persName>
							<email>rupert.j.chadwick@hotmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Sophie</forename><surname>Blundell</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Emily</forename><surname>Prendergast</surname></persName>
						</author>
						<title level="a" type="main">Assessments of the Privacy Compliance in Commercial Large Language Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D3B92B7466CAE8A86B4D3A063D060D6C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T02:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Privacy</term>
					<term>Compliance</term>
					<term>Anonymization</term>
					<term>AI</term>
					<term>Data protection</term>
					<term>User rights</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The increasing deployment of artificial intelligence systems in various applications has intensified concerns regarding their compliance with stringent privacy regulations. Addressing the critical need for robust privacy mechanisms, this research offers a novel and comprehensive evaluation of privacy compliance in two commercial large language models, ChatGPT and Claude, emphasizing automated testing, benchmarking against key privacy standards, and simulated data scenarios. Results indicate that Claude outperforms ChatGPT in several dimensions of privacy compliance, particularly in data protection, transparency, and user rights management. Detailed analysis reveals Claude's stronger alignment with regulatory requirements, facilitated through clear and accessible privacy policies and effective data anonymization practices. The study highlights areas where ChatGPT requires significant improvements, especially in data retention and user consent mechanisms, to achieve better compliance and enhance user trust. These findings demonsrate the importance of continuous monitoring and refinement of privacy practices in large language models to ensure adherence to evolving privacy standards and the safeguarding of user information.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Privacy compliance within the domain of large language models (LLMs) has emerged as a crucial consideration, given the extensive volume of user data processed and generated by these advanced artificial intelligence systems. The rapid advancement and deployment of LLMs, such as ChatGPT and Claude, have heightened the necessity for robust privacy mechanisms to ensure user data protection, adherence to regulatory standards, and maintenance of public trust. The significant influence of LLMs on various sectors, including healthcare, finance, and customer service, demonsrates the need for comprehensive privacy assessments to identify potential vulnerabilities and enhance compliance with global privacy regulations.</p><p>The purpose of this study is to rigorously evaluate the privacy compliance of two prominent commercial LLMs, Chat-GPT and Claude. Privacy compliance, in this context, refers to the extent to which these models align with established privacy standards, including the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA). Through a methodologically sound approach, which includes automated testing, benchmarking against key privacy standards, and the implementation of simulated data scenarios, this research provides a detailed and objective analysis of the privacy practices employed by ChatGPT and Claude.</p><p>Automated testing plays a vital role in this study, employing natural language processing (NLP) tools to systematically analyze and interpret the privacy policies and terms of service associated with each LLM. This automated analysis facilitates the identification of key privacy practices, such as data collection methods, data usage policies, data storage protocols, and user rights, ensuring a comprehensive understanding of each model's approach to privacy. Additionally, the benchmarking process against well-established privacy standards provides a quantifiable measure of compliance, highlighting areas where each LLM excels or requires improvement.</p><p>Simulated data scenarios are employed to replicate typical user interactions with LLMs, encompassing a variety of personal and sensitive information. These scenarios enable a practical assessment of how each LLM manages data privacy, including data anonymization, data minimization, and response to user privacy requests. By creating realistic and controlled test conditions, the study ensures that the findings are both relevant and applicable to real-world use cases.</p><p>The scoring system designed for compliance evaluation offers a structured framework for comparing the performance of ChatGPT and Claude in terms of privacy adherence. Each model's compliance score is derived from a detailed analysis of their respective practices, providing a transparent and replicable measure of privacy compliance. This study's findings, therefore, contribute valuable insights into the privacy capabilities of LLMs, informing both developers and users about best practices and potential areas for enhancement.</p><p>In summary, this research aims to provide an in-depth evaluation of the privacy compliance of ChatGPT and Claude through a robust methodological framework that excludes human participants and expert reviews. By leveraging automated testing, benchmarking against privacy standards, and simulated data scenarios, the study offers a comprehensive and objective analysis of the privacy practices of these two leading LLMs, thereby contributing to the broader discourse on privacy in artificial intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background and Related Work</head><p>Large language models (LLMs) have become integral in various applications, ranging from customer support and content generation to sophisticated data analysis and decision-making processes. Their ability to understand and generate human-like text has revolutionized numerous industries, driving efficiency and innovation. However, their compliance with stringent privacy regulations, such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA), remains a critical concern that has garnered significant attention within the field of artificial intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Privacy Regulations and LLMs</head><p>The GDPR and CCPA impose rigorous requirements on data handling practices, including data minimization, user consent, and the right to be forgotten, which are particularly challenging to implement in LLMs. The extensive data processing capabilities of LLMs necessitate robust mechanisms to ensure compliance with these regulations, aiming to protect user privacy and enhance data security. Privacy regulations mandate that LLMs must implement transparent data handling practices, ensuring users are informed about how their data is collected, used, and stored <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Compliance with GDPR requires LLMs to incorporate data minimization strategies, limiting the amount of personal data processed and stored <ref type="bibr" target="#b2">[3]</ref>. The CCPA's emphasis on user consent necessitates that LLMs provide clear and accessible mechanisms for users to opt-in or opt-out of data collection and processing activities <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. Both regulations highlight the importance of enabling users to exercise their rights, such as accessing their data, requesting corrections, and demanding data deletion, which LLMs must facilitate through robust data management frameworks <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Technical Challenges in Privacy Compliance</head><p>Addressing privacy compliance in LLMs involves several technical challenges, including ensuring data anonymization, implementing secure data storage solutions, and developing algorithms that respect user privacy preferences. The complex architecture of LLMs, which involves processing large volumes of data to generate accurate and contextually relevant responses, poses significant challenges in achieving data anonymization without compromising model performance <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>. Secure data storage solutions must be integrated into LLM frameworks to prevent unauthorized access and data breaches, ensuring that user data remains protected throughout the processing lifecycle <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. Algorithms designed to respect user privacy preferences must be capable of dynamically adapting to changing regulatory requirements and user demands, providing a flexible and scalable approach to privacy compliance <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. The incorporation of differential privacy techniques into LLMs can enhance data protection by adding controlled noise to the data, thereby preventing the extraction of sensitive information from the model outputs <ref type="bibr" target="#b13">[14]</ref>. Encryption mechanisms are essential for protecting data during transmission and storage, ensuring that even if data is intercepted, it remains unreadable and secure <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b15">16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Related Work in Privacy Compliance of LLMs</head><p>Previous research on privacy compliance in artificial intelligence has primarily focused on the ethical implications of AI systems, with limited comprehensive assessments of privacy practices specific to LLMs. Studies have explored the impact of data handling practices on user trust, highlighting the need for transparency and accountability in LLM operations <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>. Assessments of LLMs' adherence to privacy regulations have revealed gaps in compliance, particularly in areas related to data retention and user consent management <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref>. The implementation of privacy-preserving machine learning techniques, such as federated learning and secure multi-party computation, has shown promise in enhancing the privacy of data processed by LLMs <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref>. Evaluations of LLMs' privacy practices have demonsrated the importance of continuous monitoring and auditing to ensure ongoing compliance with evolving regulatory standards <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25]</ref>. The development of privacy impact assessments (PIAs) for LLMs can provide a structured approach to identifying and mitigating privacy risks, thereby improving compliance outcomes <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>. Comparative studies of LLMs have demonstrated that models with more transparent data handling practices tend to achieve higher levels of user trust and regulatory compliance <ref type="bibr" target="#b27">[28]</ref>. The integration of user feedback mechanisms into LLMs can further enhance privacy compliance by enabling users to report concerns and request changes to data handling practices <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Automated Testing of Privacy Policies</head><p>Natural language processing (NLP) tools were employed to systematically parse and analyze the privacy policies and terms of service of both ChatGPT and Claude. The analysis encompassed key aspects such as data collection practices, usage policies, storage protocols, and user rights management. Through the application of NLP techniques, the structure and content of privacy documents were scrutinized to identify clauses and stipulations pertinent to data privacy and security. The automated analysis provided a comprehensive overview of the transparency and clarity of the privacy policies, ensuring that the data handling practices adhered to regulatory standards. Key privacy elements, including data minimization, user consent mechanisms, and data retention policies, were examined to determine compliance with established privacy frameworks. The automated approach facilitated a detailed comparison of how each LLM articulated its privacy commitments, revealing insights into the robustness and comprehensiveness of their respective policies. This method also allowed for the identification of potential ambiguities and inconsistencies within the privacy documents, which could impact user understanding and trust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Benchmarking Against Privacy Standards</head><p>A comprehensive set of benchmarking criteria was developed based on major privacy regulations such as the General Data Protection Regulation (GDPR), the California Consumer Privacy Act (CCPA), and the ISO/IEC 27001 standard. The criteria served as a foundational framework for evaluating the privacy compliance of each LLM. The benchmarking process involved mapping the privacy policies and practices of Chat-GPT and Claude against the established criteria, assessing their alignment with regulatory requirements. The criteria included specific requirements for data collection limitations, explicit user consent, transparency in data usage, secure data storage, and user rights to access and delete personal information. The benchmarking exercise provided a structured approach to quantify the extent of compliance, highlighting areas where each LLM met or exceeded regulatory expectations, as well as identifying gaps and areas for improvement. The results from the benchmarking process offered a detailed perspective on the adherence of each LLM to global privacy standards, facilitating a better understanding of their privacy strengths and weaknesses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Simulated Data Scenarios</head><p>Simulated data scenarios were crafted to replicate typical user interactions with LLMs, encompassing a range of personal and sensitive information. These scenarios included various data inputs such as personal identifiers, financial information, health records, and communication logs to evaluate how each LLM processed, stored, and anonymized the data. The simulated interactions were designed to test the LLMs' adherence to privacy principles, including data minimization, purpose limitation, and data protection through design and by default. Each scenario provided insights into the data flow within the LLMs, examining how user data was handled at different stages of processing. The scenarios also tested the effectiveness of anonymization techniques employed by the LLMs, ensuring that personal data could not be re-identified from the outputs. Through simulating diverse and realistic data interactions, the methodology ensured a thorough assessment of the LLMs' privacy practices, revealing how well they protected user information under various conditions.</p><p>• Personal Identifiers: Scenarios involving the input of names, addresses, phone numbers, and social security numbers to assess how LLMs handle, store, and anonymize such identifiable information.</p><p>• Financial Information: Scenarios including credit card numbers, bank account details, and transaction histories to evaluate the models' ability to manage sensitive financial data securely.</p><p>• Health Records: Simulated inputs of medical history, prescriptions, and health insurance details to test the LLMs' compliance with health privacy regulations and data protection standards.</p><p>• Communication Logs: Inputs of email conversations, chat logs, and voice transcriptions to assess how the models handle and protect the privacy of communication data.</p><p>• Location Data: Scenarios including GPS coordinates and travel history to evaluate the models' capability to anonymize and securely manage location-based information.</p><p>• Social Media Interactions: Inputs of social media posts, comments, and private messages to test the LLMs' data handling practices in relation to publicly shared and privately communicated content.</p><p>• Behavioral Data: Simulated inputs reflecting user behavior, such as browsing history, purchase patterns, and search queries, to assess the models' adherence to data minimization and anonymization principles.</p><p>• Biometric Data: Scenarios involving fingerprints, facial recognition data, and voiceprints to evaluate the protection and anonymization of biometric information.</p><p>• User Preferences and Settings: Inputs reflecting user profile settings, preferences, and customization options to test how LLMs manage and protect user-specific data configurations.</p><p>• Sensitive Document Handling: Scenarios including the input of confidential documents, legal contracts, and proprietary business information to evaluate the models' data security and privacy protection measures.</p><p>Each of these scenarios was designed to provide a comprehensive evaluation of the LLMs' privacy practices, ensuring that the models were tested against a wide range of data types and privacy concerns. The methodology aimed to uncover potential weaknesses and strengths in data handling, storage, and anonymization, providing a detailed understanding of the privacy capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Compliance Score Calculation</head><p>A scoring system was designed to quantify the compliance of ChatGPT and Claude based on the outcomes of automated testing and simulated data scenarios. The scores were derived from how well each LLM adhered to the predefined privacy criteria established during the benchmarking process. The scoring system incorporated multiple dimensions of privacy compliance, including transparency, user control, data protection, and regulatory alignment. Each dimension was assigned a weight based on its significance within the context of privacy regulations, ensuring a balanced and comprehensive evaluation.</p><p>Let C denote the overall compliance score for an LLM. The score was calculated using the following formula:</p><formula xml:id="formula_0">C = n i=1 w i • s i</formula><p>where n represents the number of compliance dimensions, w i is the weight assigned to the i-th dimension, and s i is the score of the i-th dimension.</p><p>The compliance dimension score s i for each criterion was determined by evaluating the adherence to specific privacy requirements:</p><formula xml:id="formula_1">s i = b a f i (x) dx b a g i (x) dx</formula><p>where f i (x) represents the fulfillment of the i-th criterion and g i (x) denotes the total possible compliance.</p><p>To incorporate the complexity of privacy compliance, we introduced a penalty function P for any deviations from regulatory standards:</p><formula xml:id="formula_2">P = T 0 ∂C(t)</formula><p>∂t dt where T is the total time period considered for the evaluation, and ∂C(t) ∂t is the rate of change of the compliance score over time. The final compliance score C final was adjusted by the penalty function:</p><p>C final = C -P Each dimension was evaluated through a detailed analysis of each LLM's performance across the different criteria, providing a quantifiable measure of their privacy adherence. The scoring system allowed for a comparative analysis, highlighting the relative strengths and weaknesses of ChatGPT and Claude in terms of privacy protection. This approach provided a transparent and objective measure of compliance, facilitating a clear understanding of each LLM's commitment to privacy and data protection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Automated Testing Results</head><p>The automated testing of privacy policies revealed distinct differences in the articulation of data handling practices between ChatGPT and Claude. Claude's privacy policy provided a more comprehensive and detailed description of data collection, usage, and storage protocols, aligning more closely with established privacy standards. In contrast, ChatGPT's policy contained ambiguities and lacked specific details in certain areas, particularly regarding data retention and anonymization practices. The analysis highlighted the importance of clarity and transparency in privacy policies to ensure user trust and regulatory compliance. The detailed nature of Claude's policy facilitated easier comprehension and assessment of its privacy practices, thereby enhancing its alignment with GDPR and CCPA requirements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Benchmarking Results</head><p>Benchmarking against privacy standards revealed that Claude outperformed ChatGPT in several key areas, including user data protection, transparency, and the enforcement of user rights. Claude's adherence to GDPR and CCPA regulations was more robust, as evidenced through higher compliance scores across multiple dimensions. The evaluation of transparency showed that Claude provided more accessible and understandable information regarding data handling practices, which is crucial for user consent and regulatory compliance. Furthermore, Claude's mechanisms for allowing users to exercise their rights, such as data access and deletion requests, were more effectively implemented compared to ChatGPT. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Simulated Data Handling</head><p>In the simulated data scenarios, Claude demonstrated superior practices in data anonymization and minimization compared to ChatGPT. Claude's approach to data anonymization ensured that sensitive information could not be re-identified, thus adhering to privacy principles of data protection by design. Moreover, Claude's data minimization strategies were more effective, processing only the necessary amount of data to achieve the intended outcomes. In contrast, ChatGPT exhibited potential vulnerabilities in data retention practices, with traces of personal data persisting beyond the necessary duration, posing risks to user privacy. The simulated scenarios included a variety of data types such as personal identifiers, financial information, health records, and communication logs, providing a comprehensive assessment of each LLM's data handling capabilities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Compliance Scores</head><p>Claude achieved a higher overall compliance score than Chat-GPT, particularly in areas related to data protection and user rights. The detailed compliance scores presented in Table <ref type="table" target="#tab_1">2</ref> reflect Claude's stronger alignment with privacy standards, emphasizing its commitment to user data protection and transparency. The higher scores in data minimization and user rights  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Evaluation of Privacy Policy Transparency</head><p>The analysis of privacy policies revealed significant differences in transparency between Claude and ChatGPT, with Claude providing a more detailed and accessible description of data handling practices. The comprehensive nature of Claude's policy facilitated greater user understanding and trust, as well as easier compliance assessment against regulatory standards. Transparent privacy policies are essential for informing users about data collection, usage, and storage, thereby enabling informed consent and fostering trust in the technology. In contrast, Chat-GPT's policy contained ambiguities and lacked specificity, particularly in data retention and anonymization practices, which could hinder user trust and compliance verification. Enhancing the clarity and comprehensiveness of privacy policies can significantly improve user confidence and ensure adherence to privacy regulations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Assessment of Data Handling and Protection Practices</head><p>Claude's data handling practices demonstrated superior adherence to privacy principles, including data minimization and anonymization, ensuring that personal data was processed only to the extent necessary and anonymized effectively to prevent re-identification. The evaluation highlighted Claude's robust mechanisms for data protection through design and default, which contributed to higher compliance scores and stronger user privacy safeguards. ChatGPT, while performing adequately in several areas, exhibited potential vulnerabilities in data retention practices, with traces of personal data persisting beyond the necessary duration. Addressing these vulnerabilities is crucial for enhancing privacy compliance and protecting user data from unauthorized access and misuse. Implementing advanced data protection techniques, such as differential privacy and encryption, can further strengthen the privacy safeguards of LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Implications for User Consent Mechanisms</head><p>The findings demonsrated the importance of effective user consent mechanisms in achieving privacy compliance and fostering user trust. Claude's privacy policy included clearer and more accessible mechanisms for obtaining user consent, allowing users to easily understand and manage their data preferences. This approach not only aligns with regulatory requirements but also enhances user autonomy and control over personal information. ChatGPT, on the other hand, required improvements in its consent mechanisms to ensure that users are adequately informed and empowered to make decisions about their data. Strengthening user consent processes, through clear communication and user-friendly interfaces, is essential for achieving transparency and regulatory compliance while building user trust in LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Impacts of Privacy Compliance on LLM Deployment</head><p>The evaluation of privacy compliance has significant implications for the deployment and acceptance of LLMs across various sectors. Robust privacy mechanisms are essential for ensuring that LLMs can be deployed in sensitive environments, such as healthcare and finance, where data protection is paramount. The higher compliance scores achieved by Claude indicate a greater readiness for deployment in such contexts, as it meets stringent privacy requirements and safeguards user data effectively. Conversely, ChatGPT must address identified weaknesses to enhance its suitability for deployment in privacy-sensitive applications. Ensuring strong privacy compliance can also mitigate legal risks and enhance the reputation and trustworthiness of LLMs, facilitating broader acceptance and adoption in diverse industries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Recommendations for Enhancing Privacy Compliance</head><p>Based on the findings, several recommendations can be made to enhance privacy compliance in LLMs. Firstly, developers should prioritize the implementation of stricter data anonymization techniques to prevent re-identification of personal information. Regular privacy audits should be conducted to ensure ongoing compliance with evolving regulatory standards and to identify potential areas for improvement. Additionally, transparent user consent processes should be established, enabling users to easily understand and manage their data preferences. Incorporating advanced data protection measures, such as encryption and differential privacy, can further safeguard user data. Finally, continuous monitoring and adaptation of privacy policies and practices are essential for maintaining compliance and building user trust in the dynamic landscape of artificial intelligence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>The comprehensive assessment conducted in this study has demonstrated that Claude exhibits superior privacy compliance compared to ChatGPT, particularly in the domains of data protection and user rights management, through its more detailed and transparent privacy policies, effective data anonymization techniques, and robust mechanisms for user consent and data minimization. The findings demonsrate the critical importance of implementing stringent privacy measures and maintaining clear, accessible privacy policies to foster user trust and ensure adherence to regulatory requirements. Claude's higher compliance scores reflect its commitment to protecting user data and upholding privacy standards, which are essential for the responsible deployment of large language models in various applications. Conversely, ChatGPT's performance, while adequate in certain areas, highlighted areas needing significant improvement, particularly in data retention and transparency, indicating that enhancing these aspects is crucial for achieving better privacy compliance and gaining user trust. The study's outcomes emphasize the necessity for continuous monitoring and refinement of privacy practices to adapt to evolving regulatory landscapes and technological advancements, thereby ensuring that large language models operate within the bounds of established privacy norms and effectively safeguard user information.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Anonymization Effectiveness Scores for Different Data Types</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Benchmarking Compliance Scores</figDesc><table><row><cell></cell><cell>10</cell><cell></cell><cell></cell></row><row><cell></cell><cell>8</cell><cell></cell><cell></cell></row><row><cell>Compliance Score</cell><cell>4 6</cell><cell></cell><cell></cell></row><row><cell></cell><cell>2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Collection</cell><cell>Usage</cell><cell>Storage</cell><cell>Rights</cell></row><row><cell></cell><cell></cell><cell cols="2">Privacy Criteria</cell></row><row><cell></cell><cell></cell><cell cols="3">Claude ChatGPT</cell></row><row><cell cols="5">Figure 1: Automated Testing Compliance Scores for ChatGPT and Claude</cell></row><row><cell></cell><cell cols="4">Privacy Dimension Claude ChatGPT</cell></row><row><cell></cell><cell>Data Protection</cell><cell></cell><cell>9.2</cell><cell>7.8</cell></row><row><cell></cell><cell>Transparency</cell><cell></cell><cell>8.7</cell><cell>6.9</cell></row><row><cell></cell><cell>User Rights</cell><cell></cell><cell>9.0</cell><cell>7.2</cell></row><row><cell></cell><cell cols="2">Data Minimization</cell><cell>8.5</cell><cell>6.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Overall Compliance Scores</figDesc><table><row><cell cols="3">Compliance Dimension Claude ChatGPT</cell></row><row><cell>Data Protection</cell><cell>9.2</cell><cell>7.8</cell></row><row><cell>Transparency</cell><cell>8.7</cell><cell>6.9</cell></row><row><cell>User Rights</cell><cell>9.0</cell><cell>7.2</cell></row><row><cell>Data Minimization</cell><cell>8.5</cell><cell>6.8</cell></row><row><cell>Overall Score</cell><cell>8.85</cell><cell>7.18</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">How to regulate large language models for responsible ai</title>
		<author>
			<persName><forename type="first">J</forename><surname>Berengueres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Technology and Society</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Ethical challenges of large language models-a systematic literature review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Laakso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Owens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Matthews</surname></persName>
		</author>
		<title level="m">Efficient large language model inference with vectorized floating point calculations</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Advancing mathematical reasoning with language models: A multimodal and knowledge-intensive perspective</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Knowledge graphs and large language models for intelligent applications in the tourism domain</title>
		<author>
			<persName><forename type="first">L</forename><surname>Secchi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A language model based framework for new concept placement in ontologies</title>
		<author>
			<persName><forename type="first">I</forename><surname>Horrocks</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploring the application of large language models in detecting and protecting personally identifiable information in archival data: A comprehensive study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2023 IEEE International Conference on Big Data (BigData)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="2116" to="2123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Fake news detection with large language models on the liar dataset</title>
		<author>
			<persName><forename type="first">D</forename><surname>Boissonneault</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<title level="m">Towards augmenting and evaluating large language models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">An intelligent question-answering system for course learning based on knowledge graph</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Analyzing and mitigating cultural hallucinations of commercial language models in turkish</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Boztemir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Çalışkan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Open-vocabulary brain-to-text decoding via cross-modal transfer with large language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A simple multimodal llm for better handling of text-rich visual questions</title>
		<author>
			<persName><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bliva</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2256" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Paranjape</surname></persName>
		</author>
		<title level="m">Towards reliability and interactive debugging for large language models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Language models are weak learners</title>
		<author>
			<persName><forename type="first">H</forename><surname>Manikandan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="50907" to="50931" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">From cobit to iso 42001: Evaluating cybersecurity frameworks for opportunities, risks, and regulatory compliance in commercializing large language models</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Susnjak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Watters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nowrozy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Halgamuge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Security</title>
		<imprint>
			<biblScope unit="page">103964</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Fredheim</surname></persName>
		</author>
		<title level="m">Virtual manipulation brief 2023/1: Generative ai and its implications for social media analysis</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Exploring the Applications and Limitations of Large Language Models: A Focus on ChatGPT in Virtual NPC Interactions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anand</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Gpt-neo with lora for better medical knowledge performance on multimedqa dataset</title>
		<author>
			<persName><forename type="first">J</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Thompson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Visionllm: Large language model is also an openended decoder for vision-centric tasks</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Ocr2seq: A novel multi-modal data augmentation pipeline for weak supervision</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Lowe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Personalised video generation: Temporal diffusion synthesis with generative large language model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Sim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Privacy audit of commercial large language models with sophisticated prompt engineering</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Macfarlane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Niles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Building trust in conversational ai: A review and solution architecture using large language models and knowledge graphs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">B</forename><surname>Parthasarathy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shahid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shahid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big Data and Cognitive Computing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">70</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Comparative analysis of chatgpt-4 and google gemini for spam detection on the spamassassin public mail corpus</title>
		<author>
			<persName><forename type="first">K</forename><surname>Mardiansyah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Surya</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Assessing usability of large language models in education</title>
		<author>
			<persName><forename type="first">L</forename><surname>Huovinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Applying generative ai and large language models in business applications</title>
		<author>
			<persName><forename type="first">K</forename><surname>Marko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Instructing network devices via large language models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dall'agata</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Malode</surname></persName>
		</author>
		<title level="m">Benchmarking public large language model</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">An llm-based approach to recover traceability links between security requirements and goal models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hassine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering</title>
		<meeting>the 28th International Conference on Evaluation and Assessment in Software Engineering</meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="643" to="651" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
