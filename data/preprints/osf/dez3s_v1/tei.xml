<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Identifying Secondary School Students&apos; Misconceptions about Machine Learning: An Interview Study</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Erik</forename><surname>Marx</surname></persName>
							<email>erik.marx@tu-dresden.de</email>
						</author>
						<author>
							<persName><forename type="first">Clemens</forename><surname>Witt</surname></persName>
							<email>clemens.witt@tu-dresden.de</email>
						</author>
						<author>
							<persName><forename type="first">Thiemo</forename><surname>Leonhardt</surname></persName>
							<email>leonhardt@cs.rwth-aachen.de</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Data and Artificial Intelligence (. AI )</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Identifying Secondary School Students&apos; Misconceptions about Machine Learning: An Interview Study</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C53BCA328F77519C78F98923D5FEC6C5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>• Social and professional topics → K-12 education</term>
					<term>Computer science education</term>
					<term>Computational thinking</term>
					<term>• Computing methodologies → Machine learning</term>
					<term>Artificial intelligence students conceptions, mental models, machine learning, artificial intelligence, interview study, qualitativ research</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Since students are familiar with machine learning (ML)-based applications in their everyday lives, they already construct mental models of how these systems work. This can result in misconceptions that influence the learning of correct ML concepts. Therefore, this study investigates the misconceptions students hold about the functionality of ML-based applications. To this end, we conducted semi-structured interviews with five students, focusing on their understanding of facial recognition and ChatGPT. The interviews were analyzed using an inductively developed code system and qualitative content analysis. This process identified six key misconceptions held by students: "Programmed Behavior," "Exactness," "Data Storage," "Continuous Learning," "User-trained Model," and "Autonomous Data Acquisition". These misconceptions include the notion that AI learns continuously during application or that training data is saved and reused later. This paper presents the identified misconceptions and discusses their implication for the design and evaluation of effective learning activities in the context of ML.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A considerable number of publications have appeared on the subject of ML education in which the desired learning objectives, competencies and corresponding curricula are presented <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b33">34]</ref>. However, divergent opinions exist regarding the extent to which ML concepts are understandable for students. Sanusi et al. posit that AI is challenging to convey due to the abstract nature of many concepts <ref type="bibr" target="#b25">[26]</ref>. Conversely, various studies indicate that children are capable of learning basic ML concepts <ref type="bibr" target="#b7">[8]</ref>.</p><p>One aspect that affects the learning of new concepts is the existence of mental models <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b28">29]</ref>. It can be expected that students already possess mental models of ML when they come into contact with the subject at school. Students construct mental models based on everyday experiences <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b36">37]</ref>. They frequently encounter ML applications, such as facial recognition on smartphones, recommendation systems on platforms like TikTok, or even when completing assignments with ChatGPT. Additionally, analogies to familiar concepts are used when constructing mental models <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>, so general conceptions of AI need to be considered. Finally, these mental models are related to existing computer science knowledge. For instance, students resort to classical computational thinking (CT) concepts when unable to explain the functionality of ML applications <ref type="bibr" target="#b7">[8]</ref>. However, the domain of ML is distinct, representing a paradigm shift that deviates from established concepts of classical computational thinking <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b36">37]</ref>, potentially hindering understanding due to existing knowledge <ref type="bibr" target="#b19">[20]</ref>. For example, according to Tedre et al., ML problems entail different notions of correctness, as programs are no longer evaluated based on the correctness of a pre-designed algorithm but rather on their level of confidence determined and assessed by developers using appropriate metrics. Additionally, ML problems differ in employed problem-solving and debugging strategies as well as in their transparency <ref type="bibr" target="#b32">[33]</ref>.</p><p>Ultimately, the question arises as to what pre-instructional mental models do students bring into the classroom, particularly those that can influence the learning of ML. In a comprehensive scoping review, we identified that considerable research gaps still exist in this area. Previous studies have solely taken a superficial look at the subject area of AI. Additionally, investigations into the mental models students hold regarding specific applications and the misconceptions that may arise remain scarce. Furthermore, we found that a traditional method of conception research, interviews, has been underutilized <ref type="bibr" target="#b15">[16]</ref>. In this study, we aim to address these existing research gaps guided by the following research question: What misconceptions arise from students' mental models on machine learning?</p><p>In the following, we will first present related work and clarify the theoretical foundations by presenting a theoretical overview over mental model theory and the technological foundations. Next, we will outline the methodology of our interview study and the data analysis procedure. Subsequently, we will present the misconceptions identified regarding the research question and discuss their implications for designing learning activities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In our scoping review we found that the majority of mental model research in the field of ML is focused on general conceptions of AI, yet resulting misconceptions and their influence on the learning process remain underexplored <ref type="bibr" target="#b15">[16]</ref>. As scoping reviews provide only an overview of research approaches, we will summarize the relevant results of related work below.</p><p>The applications students associate with AI or ML include recommender systems <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3]</ref>, knowledge-based systems <ref type="bibr" target="#b11">[12]</ref>, cookies/web browsers <ref type="bibr" target="#b11">[12]</ref>, computers <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37]</ref>, voice assistants <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b35">36]</ref>, and smartphones <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b25">26]</ref>. In addition to everyday applications, numerous studies have also identified entertainment media, films, and science fiction as influential factors <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b29">30]</ref>. It is generally associated with AI that: AI is programmable or programmed <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b35">36]</ref>, requires internet access or a cloud <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b36">37]</ref> and is capable of learning <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b35">36]</ref>. More specific results can be found on the learning process. For example, learning is understood as repeated attempts to improve the system or increase the range of features <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b19">20]</ref>. There are also references to the idea that data is stored during learning <ref type="bibr" target="#b11">[12]</ref> or that human behavior is learned <ref type="bibr" target="#b2">[3]</ref>, but these are research outlines rather than fully-fledged studies. Finally, there is also the opposite idea that AI systems cannot learn at all, but their behavior is hard-coded <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18]</ref>.</p><p>In addition to the assumption of learning human behavior, there are other findings pertaining the anthropomorphization of AI. For example, it is assumed that AI functions like a human brain or acts like a human <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b29">30]</ref>. The existence of consciousness, emotions and general characteristics of a strong AI have also been assessed <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17]</ref>. Results on conceptions of the data used by ML systems also exist, albeit sporadically. For example, Kim et al. identified the notions that AI can use any form of data and only needs a large amount of data <ref type="bibr" target="#b10">[11]</ref>. Similarly, Sanusi et al. observed the notion that more data increases the accuracy of the system <ref type="bibr" target="#b25">[26]</ref>. Finally, it is important to consider the findings on controllability and explainability. For instance, there are ideas that AI is (completely) controllable or (completely) uncontrollable <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b29">30]</ref>. Additionally, AI is sometimes perceived as impartial, fair, or objective <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b13">14]</ref>.</p><p>At this point, we focus on the studies which were explicitly concerned with identifying misconceptions in AI or ML (also called naive conceptions by Kim et al. <ref type="bibr" target="#b10">[11]</ref>). Mertala &amp; Fagerlund conducted a qualitative online questionnaire with 195 Finnish 5th and 6th graders to identify their misconceptions about AI. The questionnaire included five open-ended questions for the children to answer. The authors then identified three categories of misconceptions. The first category included misconceptions in which the term AI was not understood as a technical term and therefore reflected a complete lack of knowledge about the concept. The second and most prevalent category of misconceptions pertained to anthropomorphic AI, wherein AI was ascribed human capabilities or behaviors. The third misconception was that AI possessed knowledge or intelligence that had been pre-installed by developers <ref type="bibr" target="#b16">[17]</ref>. An interesting counterpoint is made by Mühling &amp; Große-Bölting, who found no profound misconceptions in their study, only anthropomorphizing statements made by students, which they explicitly did not classify as misconceptions. We take up the discussion of anthropomorphizing language in section 5.</p><p>Schaper et al. identified three key misconceptions in their analysis of drawings and accompanying explanations by 11 Danish eighth graders about the use of technology and ML in the future <ref type="bibr" target="#b26">[27]</ref>. First, some students assumed that every robot uses ML. Second, some students assumed that devices connected to a computer use the Internet and therefore also use ML. Third, some students assumed that AI works without human input.</p><p>Kim et al. qualitatively analyzed learning artifacts and videos from 14 6th-8th graders who participated in a summer camp on AI, and presented the progression of their beliefs. They identified five themes of naive conceptions, such as that AI can use any data, or that AI is the same as automation and robots <ref type="bibr" target="#b10">[11]</ref>.</p><p>As can be observed, the studies to date do not delve deeply into the specifics of AI or ML. Consequently, technological foundations or a conceptual model are not employed to assess the presence of misconceptions, presumably because the ideas identified are typically so superficial that no uniform model can be applied. From this vantage point, it is only possible to identify ideas that are characterized by a strong lack of knowledge or which cannot be classified as generally incorrect. The survey methods used also left little room for understanding students' specific thought processes in detail. As a result, only limited hypotheses can be derived from these studies' findings regarding the impact of these misconceptions on the learning of ML concepts. Therefore, the objective of our study is to identify specific misconceptions that relate more directly to individual steps of the ML workflow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">THEORETICAL BACKGROUND</head><p>The field of student conceptions research is rich in both theory and terminology. A foundational theory in this field is that of mental models, which has significantly shaped research on student conceptions <ref type="bibr" target="#b20">[21]</ref>. Mental models are based on the constructivist premise that knowledge cannot simply be transmitted in a passive manner, but must be independently "constructed" by learners, integrating it into their existing cognitive framework <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b31">32]</ref>. Mental models are cognitive representations of situations or domains that aid in reasoning, learning, inference, or prediction <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. They are used to transfer phenomena from the external world into a mental representation. Mental models retain the structure and dynamics of the phenomenon (spatial, temporal, causal) and are available for mental operations (sometimes referred to as "simulation"). Since they have the same structure as the actual phenomenon, conclusions about the phenomenon can be drawn by manipulating the model <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21]</ref>. One challenge in investigating mental models is the relationship between language and cognition, which is intricate and multifaceted. Language affects cognitive processes and vice versa. The precise manner in which language interacts with cognition remains largely unknown <ref type="bibr" target="#b22">[23]</ref>. Nevertheless, interpretive analysis of interviews is a a well-established tool in mental model research <ref type="bibr" target="#b4">[5]</ref>.</p><p>The exact properties and functionalities of mental models depend on the theoretical viewpoint being considered. The field of mental models is characterized by two somewhat divergent understandings of mental models. Greca &amp; Moreira refer to these as the "theoretical approach" and the "instructional approach" <ref type="bibr" target="#b5">[6]</ref>. The objective of the theoretical approach is to present a unified theory capable of explaining various cognitive phenomena, such as reading and language comprehension <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21]</ref>. According to this perspective, mental models are constructs formed temporarily at the moment of their utilization to accomplish tasks in the present moment <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b20">21]</ref>. The instructional approach describes the knowledge that individuals develop about physical or technological systems, or in other words knowledge-rich domains, without the goal of proposing a universally applicable theory <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Thus, mental models represent subjective functional models for specific domains <ref type="bibr" target="#b20">[21]</ref>. In practice, however, there is less distinction made between them <ref type="bibr" target="#b20">[21]</ref>, and many theories regarding student conceptions and conceptual change derived from these incorporate characteristics of both approaches. Therefore, at this point, we do not intend to further differentiate but rather consider the characteristics arising from both approaches.</p><p>Primarily, mental models are subjective, as already inferred from the constructivist theory <ref type="bibr" target="#b5">[6]</ref>. In addition, Norman introduces several important properties of mental models. Mental models are incomplete and lack clearly defined boundaries. Consequently, they do not fully represent a problem domain, and similar systems are often confused with each other <ref type="bibr" target="#b21">[22]</ref>. This is consistent with the observation that the less similar two systems are at a surface level, the poorer the transfer between mental models, even if the systems are isomorphic <ref type="bibr" target="#b27">[28]</ref>. Additionally, mental models are also unscientific, meaning they reflect "superstitious" beliefs or conceptions that may not necessarily be factually correct <ref type="bibr" target="#b21">[22]</ref>. Therefore, they can yield both incorrect and correct results <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. Furthermore, according to the theoretical approach, mental models are abstract, dynamic, adaptive, and continuously adjusted <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b23">24]</ref>. Finally, attention should be drawn to the "parallelism" of mental models. Individuals may possess multiple mental models pertaining to a given topic as mental models lack clearly defined boundaries. Furthermore, these models may conflict with one another, particularly for complex problems (like ML) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref>.</p><p>As demonstrated , mental models are intricate and often challenging to clearly characterize. However, given the relevance of both the theoretical and instructional approach for didactic research, there are various theories in conceptual change research that integrate the two <ref type="bibr" target="#b20">[21]</ref>. Given these numerous interconnections, it is not surprising that terms from conceptual change research like "conception" are often used synonymously with mental models and in many cases can be regarded as such <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25]</ref>. Some authors posit that the two concepts can be considered distinct levels of abstraction <ref type="bibr" target="#b19">[20]</ref>. However, Franco et al. argue that there is no universally applicable relationship between the two terms, but that they are highly domain-specific <ref type="bibr" target="#b3">[4]</ref>. In the following, we define the term "mental model" as the respondents' internal cognitive framework. In relation to this, under the term "conception" we summarize the observable results of the use of mental models (e.g. in the form of students' responses). Finally, we specify the term "misconception", which is also referred to as "alternative" or "naive conception" by some authors. While Bewersdorf et al. refer to misconceptions as "flawed mental models" <ref type="bibr" target="#b0">[1]</ref>, we wish to provide a more concrete definition with the use of a conceptual model. A conceptual model is a precise and complete representation that is coherent with scientifically accepted knowledge <ref type="bibr" target="#b5">[6]</ref>. This can range from a simple analogy to a complex explanation <ref type="bibr" target="#b27">[28]</ref>. Conceptual models are mostly used by educators to promote the construction of favorable mental models <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b21">22]</ref>. We consider statements to be a misconception when they are not compatible with our chosen conceptual model of the ML workflow. Despite the wide variety of technical approaches employed in the field of ML, a number of overarching commonalities in the ML process can be identified. The term ML-Workflow represents an abstraction of the problem-solving steps in the field of ML (figure <ref type="figure" target="#fig_0">1</ref>). Zimmerman presents the prototypical ML-Workflow in seven steps <ref type="bibr" target="#b38">[39]</ref>. The initial step of problem identification precedes the actual problem-solving process. It involves evaluating the suitability of ML methods as a potential solution for the given problem. If ML methods prove to be an adequate approach, the subsequent step would be the aggregation of data by the developers. Once a sufficient quantity and quality of data has been acquired, the data is checked for inconsistencies, redundancies, and errors, and is accordingly cleaned for training (step data preparation). Prior to the initiation of the training process, it is essential to select the model to be trained, the training algorithm and the training parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The ML-Workflow as a Conceptual Model</head><p>While training a statistical model is fitted to the data. Upon completion of the training, the performance of the model is evaluated using previously unseen data. In the event that the performance of a trained model does not meet the specified requirements, it is necessary to adjust the selection of data or the learning parameters, often in repeated iterations. The model is only released for use in the intended application scenarios once the adaptations have led to desired model behavior. No further modifications are made to the model during its application. Any subsequent alterations are only implemented once the model is retrained and the ML workflow is initiated anew.</p><p>The didactic potential of the ML workflow has been widely discussed in several publications in the field of AI education. For example, Tedre et al. emphasize its importance in illustrating the differences between problem-solving processes in ML compared to classical computer science problems <ref type="bibr" target="#b32">[33]</ref>. In their competency framework, Long &amp; Magerko identify the comprehension of the steps of the ML-Workflow and the associated practices and challenges as a central competency for learners engaging with AI <ref type="bibr" target="#b14">[15]</ref>. Furthermore, Michaeli et al. delineate a number of competences within the domain of ML that can be attributed to the ML-Workflow <ref type="bibr" target="#b18">[19]</ref>. Similarly, Touretzky et al. provide guidelines for the third Big Idea in the field of AI -Learning. Here, the authors highlight "essential insights" of the ML-Workflow as specific competency development goals <ref type="bibr" target="#b33">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Technological Background</head><p>The objective of facial recognition systems is to identify, authenticate or classify individuals. To achieve this, the individual must first be recognized in a picture or video frame. Secondly, in order to normalize a face when it deviates from the focal point, the algorithm must be trained to identify general facial features and then center the face. In a third step key features are extracted from the image by a convolutional neural network (CNN). In the fourth step, a person is authenticated by comparing the extracted features with the ones saved during setup, typically using a Euclidean distance matrix in a one-to-one comparison <ref type="bibr" target="#b1">[2]</ref>. In conclusion, it is essential to emphasize that when facial recognition is set up by the user, no machine learning (ML) model is trained; rather, only pre-trained models are utilised to extract a feature vector, which is later used to authenticate the individual in question.</p><p>Another area in which ML is employed is the use of large language models (LLM). These models utilize a specialized type of neural network known as a transformer specifically developed for processing sequences, such as text or code. Mechanisms, such as attention, are employed by the model to enable it to recognize and focus on important elements within an input text. This technique is particularly useful for understanding context and retaining information over longer sections of a sequence <ref type="bibr" target="#b34">[35]</ref>. The model is trained in two phases. In the initial phase, training is conducted through self-supervised learning on a large body of text data. During this stage, the statistical relationships inherent in language, such as spelling and grammar, are trained. In the subsequent phase, the model is trained for a specific task using transfer learning and a smaller data set selected for this purpose <ref type="bibr" target="#b8">[9]</ref>. In the case of ChatGPT, for example, this could be the conversational style of a chatbot. In both steps, model parameters, such as weights, are modified during training, resulting in a change in the model's structure. Conversely, this is not the case when the user interacts with the model, as using the model does not alter its underlying structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">METHODOLOGY</head><p>A semi-structured interview format was chosen to explore students' thoughts on ML, which is a classic instrument for investigating mental models that has been used sparingly to date in the area of ML, although it allows for in-depth exploration of students' thought processes <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b15">16]</ref>. Due to the vast and largely abstract nature of the field of ML, we decided to explore the topic through ML-based technologies, because everyday experiences were identified as one influencing factor. Furthermore, Jones et al. have demonstrated that respondents' answers are more nuanced and detailed when they have direct interaction with the phenomenon under investigation <ref type="bibr" target="#b9">[10]</ref>. The selected applications were facial recognition in smartphones and ChatGPT. Both applications were therefore presented to the participants, who interacted with them with the goal of stimulating reflection on their functionality. The specific choice of these two applications warrants further explanation. The advantage of these applications is that the students are already familiar with them. In addition, their functionality is straightforward to understand and demonstrate, in contrast to other applications such as recommendation systems. Finally, as described earlier, conceptions of AI represent another potential influencing factor in mental model construction. We, therefore, used these two applications to moderate the influence of AI conceptions by selecting one application that is strongly associated with AI (ChatGPT) and one in which the use of ML is more concealed (Facial Recognition) <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Participants</head><p>In March 2023, we interviewed five German students who were recruited from an internship at the faculty or through an extracurricular program, indicating their inherent interest in the subject. Despite this shared interest in computer science, the participants exhibited varying levels of prior knowledge in ML. One student had previously attended a ML workshop, while two others had observed such a workshop during their internship. The two remaining students lacked formal education in AI or ML. Their knowledge, if any, likely stemmed from informal engagement with these topics during their free time. These diverse backgrounds provided valuable insights into how newly acquired concepts can influence explanations. In total, the study involved one female (age 14) and four male participants (ages 10, 15, 15 and 17). The interviews ranged in duration from 44 to 69 minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Interview Structuring</head><p>A structured interview guide, developed beforehand, served as a framework for the interview. The interview guide was composed of questions and potential follow-up inquiries designed to elicit in-depth explanations from the participants<ref type="foot" target="#foot_1">1</ref> . When formulating questions for the interview guide, emphasis was placed on developing "generative questions," open-ended prompts that encouraged extended explanations and in-depth reflections <ref type="bibr" target="#b20">[21]</ref>. Whenever feasible, the teach-back technique was employed, in which the interviewer reformulates the respondent's response to facilitate reflection and correction <ref type="bibr" target="#b15">[16]</ref>. The ML-Workflow also served as a guiding framework for clarifying students responses, particularly regarding the distinction between the learning and application phases, as well as the evaluation process.</p><p>The themes discussed in the interview were derived from the presumed influencing factors that shape mental models of ML. These factors included traditional CT concepts, such as correctness, debugging, and problem-solving as described by Tedre et al. <ref type="bibr" target="#b32">[33]</ref>. Additionally, questions were tailored to align with the common associations that students hold regarding AI. These inquiries delved into the students' understanding of programming requirements Well, let's assume that it has now hypothetically found 30 tabs where you have something with "Mail" and "Apply for student internship" ... then it extracts the information from them or simply drags it over ... in here [points to chat GPT tab] and then perhaps writes it up nicely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human-like Cognition</head><p>Inner workings are explained in terms of human cognition.</p><p>It's like: "no, the answer wasn't quite right", or "yes", then I [the AI] think about it again. So I think about: "What could I say next time?" or something like that. Or: "How do I do it differently?", "How can I do it better?"</p><p>Algorithmic Thinking Problem-solving strategies are described algorithmically.</p><p>Maybe you could imagine it a bit like Scratch with this if-then command. So "if this and this", meaning if all the features match, then "access allowed to the mobile phone" or "unlock".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data-based Thinking</head><p>Pattern-based Processing Information derived from data is used for problem solving.</p><p>The smartphone scans -or rather, the camera scans the face for various features that have been saved for the image -and this allows you to unlock the phone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Raw Data Processing</head><p>Raw data is used to solve a problem.</p><p>The image is already saved and that's essentially the only thing it needs to access when it compares the two images to unlock [the smartphone]. <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b35">36]</ref>, the necessity of internet connectivity <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b36">37]</ref>, the concept of consciousness in AI systems <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b24">25]</ref>, and the data handling practices of ML applications <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>. The first application discussed was facial recognition. Initially, the technology was demonstrated to the students, followed by a walk through of the setup. Subsequently, the students were engaged in a structured interview to explore their understanding of the application's functioning. Accordingly, to minimize the influence of any preconceived notions or biases associated with AI when facial recognition would maybe not be recognized as such, students were not informed that the interview would focus on AI. As an example of an open question, students were asked to consider whether the facial recognition system could accurately identify the interviewer without glasses or recognize their twin.</p><p>After the students had thoroughly explained their understanding of facial recognition, the topic of AI was openly introduced, and they were briefly questioned about their general perception of AI. Subsequently, they were asked to reflect on whether, based on their own understanding, they would classify facial recognition as an AI application and to draw connections between their notions of AI and the specific characteristics of facial recognition technology. Finally, the students were engaged in a structured discussion about the functioning of ChatGPT. As with facial recognition, an example was presented at the outset, showcasing ChatGPT's ability to generate an email for applying to a student internship. Afterwards, the same questions were asked but adapted to ChatGPT with help of the interview guide.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Analysis and Code System</head><p>The recorded interviews were digitally transcribed and subsequently analyzed using the method of qualitative content analysis <ref type="bibr" target="#b12">[13]</ref>, aided by the software MAXQDA24. The systematic description of the verbalized concepts of the Participants is best achieved by qualitative content analysis, as it offers a reproducible and systematic approach <ref type="bibr" target="#b12">[13]</ref>. In preparation for the analysis, we followed Kuckartz's suggestion and used main categories derived from the interview guide in the first phase of our analysis, aiming to inductively refine these categories <ref type="bibr" target="#b12">[13]</ref>. Examples of these categories included themes such as "Anthropomorphism" and "Programming". Subsequently, initial coding of the transcribed interviews was conducted individually by two researchers. To enhance the quality of the coding, discrepancies between the coders were meticulously addressed through a second round of consensus coding <ref type="bibr" target="#b12">[13]</ref>. Throughout this iterative process, the category system underwent continuous refinement, with main categories further subdivided and refined, and new categories being inductively incorporated. During the coding stage of the third interview, there was increased agreement among coders and minimal requirement for adjustments to the coding system. Consequently, the last two interviews were initially processed by a single coder. In the subsequent consensus coding step, both researchers also read the other interview and focused on codings that warranted discussion, based on the experience from the first three interviews. The category system developed delineates two key dimensions for analyzing students' conceptions on ML: General Perspectives on ML (table <ref type="table" target="#tab_0">1</ref>) and System Perspective (table <ref type="table" target="#tab_1">2</ref>).</p><p>General perspectives on ML. This group comprises three categories, each addressing different dimensions on the perception of ML systems. Anthropomorphic Thinking groups notions that the behavior of ML systems resembles human actions (Human-like Acting) or arises from processing mechanisms similar to human cognition (Human-like Cognition). Algorithmic Thinking refers to considerations of ML systems akin to traditional computer systems, whose problem-solving strategies can be algorithmically described. The codes categorized under Data-based Thinking elucidate the foundational role of data in the development of ML systems. They comprise notions that the functionality of these systems hinges on either the direct processing of unaltered data (Raw Data Processing) or the extraction of patterns and information from provided data (Pattern-based Processing).</p><p>System perspective. The codes in this group encompass central technical and structural characteristics of ML systems. The No, [the instruction keywords] don't have to be learned [...] that's provided, that information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Development Stage</head><p>A software learns during its development.</p><p>Actually, [self-driving cars] want to learn on their own. At first in the learning phase, so before they are used for actual traffic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Application Stage</head><p>A software learns while in use.</p><p>Well, in a sense, the smartphone learns to know the owner, so to speak ... if you save your face there ... and then it knows a bit what they look like. I would say it learns the entire time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Aggregation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>User-provided</head><p>The user provides data to enable the functionality of a software.</p><p>The data that was saved right at the beginning during the setup of the app.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Developer-provided</head><p>The developer provides data to develop a software.</p><p>In this case, Open AI provided [the data], meaning the developer of the AI.</p><p>Autonomous Acquisition A software purposefully collects new data to solve a problem.</p><p>You can write questions or requests as a message and it [...] searches for information from the whole Internet, so to speak, and summarizes it for the respective topic that you want.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Programmability</head><p>Non-programmed Parts of a software are explicitly not programmed.</p><p>So the questions are not programmed by the programmer, I think. And the answers are definitely</p><p>[not] either.</p><p>Hard-coded Specific features of a software are programmed entirely by developers.</p><p>I believe that it was in fact programmed by the developers themselves so that it always knows that it is itself an AI.</p><p>Foundational Code Specific features of a software are programmed by developers and extended or enhanced by the software itself.</p><p>It simply develops from the foundational code into a large intelligence that can then provide information well, safely and quickly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Architecture</head><p>Data Storage Data (images, texts ...) is saved and may be reused later.</p><p>Well, I would think that the cell phone would then simply compare the two pictures -that is, what is currently in front of the camera with the picture already taken [during setup] -and then see if they match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Processing rules are saved or changed.</p><p>And with chat GPT, it's mainly characters, the letters and these rules that it memorizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data characteristics</head><p>Variance of Data Data exists in various forms (e.g. different nose shapes, eye colors, ...)</p><p>Faces change a bit over the years and so that you don't have to reconfigure it every three months, there's a tolerance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quality of Data</head><p>Data exists in varying quality (e.g. blurred images)</p><p>So the tolerance arises [...] from flawed images [...] and from imperfect scanning of the photos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Amount of Data Data exists in various quantities</head><p>But also with the memory part, there is an extremely large amount of data stored there. There are millions of data, billions, quadrillions, in other words gigantic amounts of data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Forms of Data</head><p>Data exists in various forms (e.g. video, image, text)</p><p>But with the right face recognition, it has a 3D model and the dots. With [this application here] it depends on the pixels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confidence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exactness</head><p>The solution to a problem can be determined exactly.</p><p>Well, because if [...] there's a little shadow from above or a light from the side, then it says: "No, there's light here, it's not 100%, so it's not you."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Uncertainty</head><p>The result of software is subject to a degree of uncertainty.</p><p>So the AI is supposed to function like a human and humans are not always <ref type="bibr">[predictable]</ref>. So that means the AI will also have this randomness at some point. Especially one of this size.</p><p>category Adaptation/Learning groups statements regarding the timing of potential adaptation processes (Development Stage vs. Application Stage) or contrary statements on Immutability. The codes within the category Data Aggregation relate to statements about the data sources used by ML systems to solve problems. They cover the concepts that ML systems receive necessary data either from users (User-provided), developers (Developer-provided), or through autonomous acquisition from various sources (Autonomous Acquisition). The category Programmability examines perceptions regarding the extent to which the functionalities of ML systems can be implemented through methods of traditional programming. The boundaries of this notion encompass views that ML systems are either fully programmed like regular software (Hard-coded) or that certain aspects of them are not programmable at all (Nonprogrammed). Within this spectrum of perceptions, learners may believe that developers provide a foundational codebase that the system autonomously adjusts and extends (Foundational Code). Architecture directs attention to the structure of ML systems: Data Storage refers to the assumption that ML systems store data such as texts or images and retrieve them as required later on. Conversely, Model emphasizes the idea that ML systems store processing rules derived from data and may adjust them later if needed. As described in Section 2, the functionality and applicability of ML systems are decisively influenced by the characteristics of the data used in their creation: They can vary in terms of quantity (Amount of Data) and exist in different formats (Forms of Data), particularly differing in their quality (Quality of Data) and the manifestation of specific features (Variance of Data). The category Confidence comprises notions regarding the reliability of results from ML systems. Since their decisions are based on statistical assumptions, they are inherently associated with a degree of uncertainty (Uncertainty). A prevalent, contrasting notion is the assumption that ML systems are capable of precisely determining solutions to considered problems (Exactness).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RESULTS</head><p>In terms of participants' familiarity with the selected applications, it was evident that all interviewees were acquainted with them. Additionally, ChatGPT was unanimously recognized as AI by all participants. All in all we assigned 638 codes across all interviews.</p><p>During the consensus coding and the development of the code system, six misconceptions were identified by the two coders. Subsequently, both researchers independently reviewed and analyzed the corresponding codes. The resulting interpretations were then compiled again in a joint discussion. The six identified misconceptions are presented below, along with exemplary statements from the participants. Programmed Behavior. Students mistakenly assumed that all behaviors or features are directly programmed by developers, overlooking the nature of ML, where decision rules emerge through model training, not explicit programming. This misunderstanding particularly affects the training step of the ML workflow, as well as aspects of data collection and data cleaning, since these may not be considered at all. Additionally, it impairs the step of problem identification, as understanding which problems can be directly implemented is crucial for deciding on the benefits or downsides of using ML.</p><p>This misconception is evident in statements suggesting that developers program the rules for facial recognition or the grammar in ChatGPT. It is reflected in codes from the Programmability group and the Algorithmic Thinking code. For example, Student A states, "Grammar and spelling are fixed rules that have been determined by algorithms. Therefore, a [dictionary] can also be specified directly." For facial recognition, Student C describes, "There is a lot of programming involved, and we have to program it. For example, these buttons and how [the application] should respond to the face." In its strongest form, this misconception may include the belief that the program cannot learn at all, but that its entire behavior is programmed, as Student C further elaborates: "You program it like that.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[...] That's why the app cannot learn."</head><p>A novel finding, which we term "foundational code", reveals that students integrate classical programming with concepts of intelligence and learnability. They view some parts of a program as fixed, while others as developed by the AI. To illustrate, student A states that "the grammar is an algorithm. It has nothing to do with intelligence. It's just the way it is, it's done that way. The content is determined by the intelligence." An alternative interpretation is that AI requires programmed guidelines under which it operates. When asked how ChatGPT knows how to structure an email, Student A responded that the program needs a template with rules, because when the AI "puts things together" itself, it is prone to errors. He further explains that the rules for spelling and grammar must therefore be programmed. However, not all students share this view. For instance, Student E explicitly states, "If a new language is added [...] then it must first learn how this language works."</p><p>Exactness. According to this misconception, the outcomes of ML systems can be determined with absolute precision, which is contrary to the nature of ML. This contradicts the training step in the ML workflow, where a statistical model is fitted to the data. These models make predictions and decisions based on probabilities. Statements reflecting this misconception are found in the Exactness code. For instance, in face recognition, Student E states, "No, there's light here, it's not 100%, so it's not you." For ChatGPT, Student C says, "I think it has different options [of answers] and chooses one of them. [...] I think it takes the very best one." The notion varies: some think a single, certain solution exists, while others recognize multiple potential solutions but believe one can be identified as optimal. This view persists even when acknowledging uncertainty, as illustrated when Person A notes, "So when I put my face into the app, it compares it with the pictures I took at the beginning. And then it works in 99 percent of cases. So it only doesn't work if there were impurities in the pictures I put in or if the camera is blocked." This implies the notion that the software can compare two faces with exact precision and that only external factors, such as user error, cause inaccuracies. The examples also show that notions of exactness often coincide with ideas about programming. This is also reflected in the response of Student B who states, "Maybe you can imagine it a bit like with Scratch with this if-then command. So 'if this and that, ' if all the features match, then 'access allowed to the phone' or 'unlock'." Lastly, it should be noted that students are aware that ML are subject to uncertainty. However, when considering statements in the Uncertainty codes, this is not always attributed to the inherent architecture of the ML-models but rather to the complexity of ML problems, which precludes finding an optimal solution. Student A explains, "[ChatGPT] has to somehow figure out how to structure it. What is the content? It has to generate all that anew. And it's unlikely that exactly the same thing that it has already generated will be generated again." Notions of exactness are almost exclusively found in face recognition. ChatGPT is more often associated with uncertainty or randomness by the respondents. Student D summarizes this by saying, "AI is supposed to function like a human, and humans are also random. So that means the AI will also have this randomness at some point."</p><p>Data Storage. In this misunderstanding, students erroneously assume that raw data utilized in learning is permanently stored and later reused. For example, they believe that facial recognition software stores images from the setup phase to be used for comparison during the unlocking process. In reality, during the Training step of the ML workflow, a model is generated from the training data, which approximates these data. The training data are relevant only before the training step; afterwards, the generated model is used (steps Evaluation and Application).</p><p>This misconception is reflected in the codes Data Storage and Raw Data Processing. Students believe that data is saved in various forms and later reused. For instance, Student C states, "And it simply stores your face on the phone, so it has it in the memory card." Student B, referring to ChatGPT, responds, "Then it would look in the saved things that it learned and stored itself and then search further on the internet." The type of data presumed to be stored varies. Thus, original data is assumed to be saved, as Student C replies when asked what ChatGPT stores: "All the questions that were asked [and the answers]." Additionally, information derived from the data is believed to be stored such as face features or keywords. Student A says, "[Images of the face] are stored, and some features of the face are scanned and stored and remembered." Lastly, the storage of rules is also mentioned (Student D: "It develops rules from what it writes and from the people who respond. [...] It also stores that."). The storage of derived data and rules cannot be directly classified as a misconception as this is essentially what occurs during the training step, even if the "storage" in the form of, for example, weights in neural networks is no longer directly understandable to developers. However, the storage of raw data for the ML training process does not occur. The use of raw data is highlighted in the Raw Data Processing code. For example, Student B says, "The phone simply compares the two pictures -that is, the one currently in front of the front camera -with the already taken picture from the recognition and then checks if they match." Regarding image generation, he further states the application selects various individual images and skillfully combines them. The autonomous search for data is further explored in the misconception Autonomous Data Acquisition .</p><p>Continuous Learning. This misconception involves the belief that an application continuously learns and improves during use, as succinctly expressed by Student D: "I would say it learns all the time." This view conflicts with the ML workflow, which clearly distinguishes between training and application phases. During the training phase, ML models adjust structures and weights through an iterative process. After training, the model is deployed for use but does not adapt or "learn" further on its own. While data collected during use can improve the model, this requires a separate training phase. As Heuer et al. argue, although ML systems can learn during use through a process known as "online learning," such instances are rare and typically not relevant to the applications or algorithms students encounter daily or in educational settings <ref type="bibr" target="#b6">[7]</ref>. Misconceptions about continuous improvement during the application phase are common, particularly when paired with the code Autonomous Acquisition. For example, Student B stated, "And then at some point it will have understood, perhaps, how it works with forming sentences, because it had these examples and models on the Internet of how to do the whole thing when it was looking for information."</p><p>Many respondents believe that ChatGPT continuously learns, but their understanding of how this learning occurs varies. Student B believes learning happens through constant observation of the environment. He states, "Every time it unlocks, it memorizes the face a bit better, finds new features to recognize, and compares it faster and better, thus learning and improving its performance." He associates this with the application's ability to reflect. Similarly, Student E explains that an AI "can think independently and ask questions, thus learning on its own." The autonomy of the application is frequently emphasized. Student D asserts, "So it has to learn independently." Student D attended one of the ML workshops, where the distinction between the training and application phases was specifically addressed. However, this did not dispel his misconception; instead, he integrated it into his existing mental model. In the interview, he says, "The AI is actually constantly in the learning phase," indicating the persistence of the misconception. Finally, Student A describes learning as a result of action and reaction: "Continuous development based on decisions, action, and reaction." He adds that through his interactions, he has contributed to ChatGPT's learning process. Learning through user interaction will be examined in more detail in the next section.</p><p>User-trained Model. With this misconception it is assumed that ML models are generated using the user's data during application, similar to the continuous learning misconception. Both stem from a misunderstanding of the ML workflow, where models are actually trained in a dedicated training phase by developers, not during user interaction. This misconception is reflected in the codes related to the application phase, often combined with the code User-provided (Data).</p><p>For the two applications, the misconception manifests differently. For ChatGPT, the continuous learning misconception persists, with user interaction seen as an additional learning opportunity. Student A expresses this idea, saying "I have actually contributed a tiny bit to the learning. I tried to recreate a relatively old text-based game somehow. [...] And then I said no, that sounds wrong, I actually start there. It then saw, 'Oh yes, that's how it starts'." Student E highlights another form of user feedback: "Here [points to the generated response] there are buttons Thumbs up, Thumbs down. [...] You can indicate whether it is correct or incorrect, or add notes." The first example refers to ChatGPT's ability to adapt to conversational contexts, while the second points to the built-in feedback feature. In both cases, structural learning of the application, as assumed by the students, does not actually occur.</p><p>The second variant of this misconception is that the application learns directly from the data provided by the user, with the user training the model themselves instead of the developers. This is particularly evident in facial recognition. Student B explains: "Well, in a sense, the phone kind of learns to recognize the owner when you store your face and it sees what you look like." Student E describes this process more concretely: "Yes, you take these pictures. So, recordings of the face [holds his hand in front as if holding a phone and moves his head in all directions to 'scan' his face] [...] Now you are training the AI. This is how the AI gets it."</p><p>Autonomous Data Acquisition. This misconception suggests that the application is capable of autonomously searching and selecting data based on its own metrics and using it for learning. However, according to the ML workflow, data is gathered in the development phase. In reality, it is the responsibility of developers to collect, clean, and prepare data for training ML models. Even in applications not covered by this study, such as reinforcement learning (RL), where an agent might interact autonomously with its environment, developers still determine which data is collected and how it is processed. This misconception is not limited to the concept of learning. For instance, Student C asserts, "I believe that when we enter the question, it just asks Google and takes the text from there and simply writes it." This assertion implies that the participant is aware of the significance of data, yet sees the application's role as merely finding data. Building on this, Student B describes the possibility that the application uses internet searches to verify its own statements: "ChatGPT could, for example, check the internet before it writes something to see if it is okay." He later adds the capability of learning, stating, "And then it will have understood at some point, maybe, how it works with forming sentences, because it had these templates and models on the internet, how to do it all, when it was searching for information." This illustrates how closely this misconception is linked to the idea of continuous learning.</p><p>This misconception emerged primarily with ChatGPT and once when Student A described Google Lens functionality and its dependence on internet searches. Notably, participants did not consider the possibility of facial recognition autonomously capturing images. This highlights the connection between this misconception and a system's internet access and underscores the distinct perceptions between the two applications. Some respondents believe ChatGPT uses internet data not only to complete tasks but also for independent learning and self-reflection. Student B says, "It could be possible in the near future, if it finds reports on the internet about why something is the way it is and then adapts and learns and asks itself this question." Additionally, the misconception of data storage appears here, such as in Student C's statement that ChatGPT searches its internal memory, where all questions and the generated answers are stored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">DISCUSSION</head><p>When analysing for misconceptions anthropomorphic statements were of particular interest. Mertala et al. classify these as misconceptions <ref type="bibr" target="#b16">[17]</ref>. Mühling &amp; Große-Bölting argue that the use of anthropomorphic language does not necessarily indicate a lack of understanding, but may instead reflect a lack of technical vocabulary <ref type="bibr" target="#b19">[20]</ref>. This is also supported by the that AI experts also use anthropomorphic language <ref type="bibr" target="#b24">[25]</ref>. In our coding system, we distinguish between User-like Acting and Human-Like Cognition within the "Anthropomorphic Thinking" category. While the former is clearly linked to misconceptions such as Autonomous Data Acquisition , the latter's classification is not as straightforward. Consider Student B, who described the program as actively improving itself with questions like, "What did I just do?", "How can I do this better?", and "How can I apply this somewhere else to make the other thing better?". The first two thoughts are compatible with the training step in the ML-Workflow. However, whether the last statement is correct depends on the context and the type of application. In our view, relying on human cognition as a means of communication does not directly express a misconception. However, anthropomorphic language may indicate a misconception when attempting to explain the functioning of a system in terms of human behavior.</p><p>Our findings regarding misconceptions in ML education have significant implications for the design of learning activities and curricula. Currently, various approaches to teaching ML have been proposed with the central question being whether and how to teach learners about the inner workings of ML models and algorithms <ref type="bibr" target="#b37">[38]</ref>. Our findings contribute to a more nuanced discussion on this topic. To illustrate this, we will examine the popular unplugged activity "Hexapawn", used by Mühling &amp; Große-Bölting <ref type="bibr" target="#b19">[20]</ref> in their study.</p><p>Mühling &amp; Große-Bölting argue "it may not be necessary to 'open the black box' in a K12 setting in order to counter hard-toerase misconceptions of 'real intelligence' happening in machines", as their study showed a positive shift in students' understanding of "learning" in ML systems through the activity Hexapawn. In this activity, students engage in a simple 3×3 chess game against a set of matchboxes. After each game, the matchboxes are adjusted to improve their performance. This interaction risks reinforcing misconceptions rather than dispelling them. The matchboxes' improvement after each game can reinforce the idea that the AI continuously learns (Continuous Learning ). Additionally, the system learns through user interaction, potentially reinforcing the Usertrained Model misconception. Therefore, to effectively use this game in a learning setting, the system's training phase must be clearly distinguished from the application phase. Learners must understand that the unplugged activity simulates the training phase. This is particularly crucial in RL, where many learning activities explain the RL concepts through interaction with the learner. Another hurdle in RL is, that the agent collects data independently, potentially reinforcing the Autonomous Data Acquisition misconception. It is important to emphasize that even in RL, developers define data selection and processing. Accordingly, students should be able to define and modify data aggregation parameters to counter this misconception, as is also proposed by Touretzky et al. <ref type="bibr" target="#b33">[34]</ref>. Finally, we want to emphasize that this activity is by no means unsuitable for conveying ML concepts. It is also perfectly adequate to address the probably most critical but also easiest to change misconception, Programmed Behavior , as it largely stems from a lack of understanding of the process itself. It is, therefore, essential to emphasize that an understanding of potential misconceptions is vital in order to utilize specific teaching concepts effectively. Nevertheless, we support the view that ML black boxes need to be opened, as our analysis shows that even after a seemingly successful intervention, significant misconceptions might still be present. In summary, the results presented here contain a series of new insights. Through the use of semi-structured interviews, we were able to identify and characterize six misconceptions in detail. This supports the development and evaluation of appropriate learning interventions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">LIMITATIONS AND OUTLOOK</head><p>The interview study is subject to the typical limitations of qualitative research. The results presented here cannot be generalized and primarily serve to develop theories and hypotheses. In addition, the sample size of five people is relatively small and heterogeneous. Although we have only presented conceptions that were evident across several respondents, it is unclear how these vary across the full range of possible prior knowledge and age and how representative they are. A further limitation of this study is that the interview guide was not pilot tested prior to the main study. Consequently, the interview procedure could not be adapted before the main study, for example by changing the order of questions.</p><p>The results of this interview study can be explored in more depth, for example by investigating the extent to which mental models are dependent on the respective application. Moreover, concepts which are valid for the entire field of ML can be derived from the presented misconceptions and serve as structuring aids for the construction of appropriate mental models. Finally, the results presented here can also be verified quantitatively by means of a questionnaire in which the misconceptions serve as distractors and with which learning activities can be evaluated.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The ML-Workflow</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Codebook for Dimension "General Perspectives on ML"</figDesc><table><row><cell>Code</cell><cell>Definition</cell><cell>Example</cell></row><row><cell>Blackbox</cell><cell>Certain parts of a question cannot be an-</cell><cell>I don't know exactly, it's in my laptop at home. So ... I don't know exactly</cell></row><row><cell></cell><cell>swered due to a lack of knowledge.</cell><cell></cell></row><row><cell>Anthropomorphic Thinking</cell><cell></cell><cell></cell></row><row><cell>User-like Acting</cell><cell>Inner workings are explained in terms of hu-</cell><cell></cell></row><row><cell></cell><cell>man behavior.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Codebook for Dimension "System Perspective"</figDesc><table><row><cell>Code</cell><cell>Definition</cell><cell>Example</cell></row><row><cell>Adaption/Learning</cell><cell></cell><cell></cell></row><row><cell>Immutability</cell><cell>A software or explicit parts of a software do</cell><cell></cell></row><row><cell></cell><cell>not change.</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>WiPSCE '24, September 16 -September 18, 2024, Munich, GER Erik Marx, Clemens Witt, and Thiemo Leonhardt</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1"><p>The interview guide as well as the untranslated original transcripts can be found at https://osf.io/uf3an/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Myths, Mis-and Preconceptions of Artificial Intelligence: A Review of the Literature</title>
		<author>
			<persName><forename type="first">Arne</forename><surname>Bewersdorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaoming</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claudia</forename><surname>Nerdel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.caeai.2023.100143</idno>
		<ptr target="https://doi.org/10.1016/j.caeai.2023.100143" />
	</analytic>
	<monogr>
		<title level="j">Computers and Education: Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">100143</biblScope>
			<date type="published" when="2023-01">2023. Jan. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multi-Column Deep Neural Networks for Image Classification</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ciresan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Meier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2012.6248110</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2012.6248110" />
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Providence, RI</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="3642" to="3649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Why Are We Not Teaching Machine Learning at High School? A Proposal</title>
		<author>
			<persName><forename type="first">Ignacio</forename><surname>Evangelista</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Germán</forename><surname>Blesio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Emanuel</forename><surname>Benatti</surname></persName>
		</author>
		<idno type="DOI">10.1109/WEEF-GEDC.2018.8629750</idno>
		<ptr target="https://doi.org/10.1109/WEEF-GEDC.2018.8629750" />
	</analytic>
	<monogr>
		<title level="m">2018 World Engineering Education Forum -Global Engineering Deans Council (WEEF-GEDC)</title>
		<meeting><address><addrLine>Albuquerque, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">From Scientists&apos; and Inventors&apos; Minds to Some Scientific and Technological Products: Relationships between Theories, Models, Mental Models and Conceptions</title>
		<author>
			<persName><forename type="first">Creso</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henrique</forename><surname>Lins De Barros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dominique</forename><surname>Colinvaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonia</forename><surname>Krapas</surname></persName>
		</author>
		<idno type="DOI">10.1080/095006999290705</idno>
		<ptr target="https://doi.org/10.1080/095006999290705" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Science Education</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="291" />
			<date type="published" when="1999-03">1999. March 1999</date>
		</imprint>
	</monogr>
	<note>Glória Queiroz, and Fátima Alves</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mental Models, Psychology Of</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gentner</surname></persName>
		</author>
		<idno type="DOI">10.1016/B0-08-043076-7/01487-X</idno>
		<ptr target="https://doi.org/10.1016/B0-08-043076-7/01487-X" />
	</analytic>
	<monogr>
		<title level="m">International Encyclopedia of the Social &amp; Behavioral Sciences</title>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="9683" to="9687" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mental Models, Conceptual Models, and Modelling</title>
		<author>
			<persName><forename type="first">Ileana</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Greca</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Marco</forename><surname>Antonio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moreira</forename></persName>
		</author>
		<idno type="DOI">10.1080/095006900289976</idno>
		<ptr target="https://doi.org/10.1080/095006900289976" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Science Education</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2000-01">2000. Jan. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<author>
			<persName><forename type="first">Hendrik</forename><surname>Heuer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juliane</forename><surname>Jarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Breiter</surname></persName>
		</author>
		<idno type="DOI">10.1177/20539517211017593</idno>
		<ptr target="https://doi.org/10.1177/20539517211017593" />
	</analytic>
	<monogr>
		<title level="m">Machine Learning in Tutorials -Universal Applicability, Underinformed Application, and Other Misconceptions</title>
		<imprint>
			<date type="published" when="2021-01">2021. Jan. 2021</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Can Children Understand Machine Learning Concepts? The Effect of Uncovering Black Boxes</title>
		<author>
			<persName><forename type="first">Tom</forename><surname>Hitron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yoav</forename><surname>Orlev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iddo</forename><surname>Wald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ariel</forename><surname>Shamir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2019 CHI Conference on Human Factors in Computing Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
	<note>Hadas Erel, and Oren Zuckerman</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Universal Language Model Finetuning for Text Classification</title>
		<author>
			<persName><forename type="first">Jeremy</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sebastian</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1031</idno>
		<ptr target="https://doi.org/10.18653/v1/P18-1031" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yusuke</forename><surname>Miyao</surname></persName>
		</editor>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Eliciting Mental Models: A Comparison of Interview Procedures in the Context of Natural Resource Management</title>
		<author>
			<persName><forename type="first">Natalie</forename><forename type="middle">A</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helen</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Timothy</forename><surname>Lynam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pascal</forename><surname>Perez</surname></persName>
		</author>
		<idno>jstor:26269480</idno>
	</analytic>
	<monogr>
		<title level="j">Ecology and Society</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note>7 pages</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Exploring Middle School Students&apos; Common Naive Conceptions of Artificial Intelligence Concepts, and the Evolution of These Ideas</title>
		<author>
			<persName><forename type="first">Keunjae</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kyungbin</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><surname>Ottenbreit-Leftwich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Haesol</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Krista</forename><surname>Glazewski</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10639-023-11600-3</idno>
		<ptr target="https://doi.org/10.1007/s10639-023-11600-3" />
	</analytic>
	<monogr>
		<title level="j">Education and Information Technologies</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="9827" to="9854" />
			<date type="published" when="2023-01">2023. Jan. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Students&apos; Conceptions of Artificial Intelligence</title>
		<author>
			<persName><forename type="first">Moritz</forename><surname>Kreinsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sandra</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.1145/3481312.3481328</idno>
		<ptr target="https://doi.org/10.1145/3481312.3481328" />
	</analytic>
	<monogr>
		<title level="m">The 16th Workshop in Primary and Secondary Computing Education</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Udo</forename><surname>Kuckartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Rädiker</surname></persName>
		</author>
		<title level="m">Qualitative Content Analysis: Methods, Practice and Software</title>
		<meeting><address><addrLine>Thousand Oaks</addrLine></address></meeting>
		<imprint>
			<publisher>SAGE Publications</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>second ed.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Developing Middle School Students&apos; AI Literacy</title>
		<author>
			<persName><forename type="first">Irene</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Safinah</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Helen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniella</forename><surname>Dipaola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cynthia</forename><surname>Breazeal</surname></persName>
		</author>
		<idno type="DOI">10.1145/3408877.3432513</idno>
		<ptr target="https://doi.org/10.1145/3408877.3432513" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 52nd ACM Technical Symposium on Computer Science Education (SIGCSE &apos;21)</title>
		<meeting>the 52nd ACM Technical Symposium on Computer Science Education (SIGCSE &apos;21)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="191" to="197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">What Is AI Literacy? Competencies and Design Considerations</title>
		<author>
			<persName><forename type="first">Duri</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Magerko</surname></persName>
		</author>
		<idno type="DOI">10.1145/3313831.3376727</idno>
		<ptr target="https://doi.org/10.1145/3313831.3376727" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems. ACM, Honolulu HI USA</title>
		<meeting>the 2020 CHI Conference on Human Factors in Computing Systems. ACM, Honolulu HI USA</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Secondary School Students&apos; Mental Models and Attitudes Regarding Artificial Intelligence -A Scoping Review</title>
		<author>
			<persName><forename type="first">Erik</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thiemo</forename><surname>Leonhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nadine</forename><surname>Bergner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.caeai.2023.100169</idno>
		<ptr target="https://doi.org/10.1016/j.caeai.2023.100169" />
	</analytic>
	<monogr>
		<title level="j">Computers and Education: Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">100169</biblScope>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Finnish 5th and 6th Graders&apos; Misconceptions about Artificial Intelligence</title>
		<author>
			<persName><forename type="first">Pekka</forename><surname>Mertala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janne</forename><surname>Fagerlund</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijcci.2023.100630</idno>
		<ptr target="https://doi.org/10.1016/j.ijcci.2023.100630" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Child-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">100630</biblScope>
			<date type="published" when="2024-03">2024. March 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Finnish 5th and 6th Grade Students&apos; Pre-Instructional Conceptions of Artificial Intelligence (AI) and Their Implications for AI Literacy Education</title>
		<author>
			<persName><forename type="first">Pekka</forename><surname>Mertala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janne</forename><surname>Fagerlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Calderon</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.caeai.2022.100095</idno>
		<ptr target="https://doi.org/10.1016/j.caeai.2022.100095" />
	</analytic>
	<monogr>
		<title level="j">Computers and Education: Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">100095</biblScope>
			<date type="published" when="2022-01">2022. Jan. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">What Students Can Learn About Artificial Intelligence -Recommendations for K-12 Computing Education</title>
		<author>
			<persName><forename type="first">Tilman</forename><surname>Michaeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ralf</forename><surname>Romeike</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stefan</forename><surname>Seegerer</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-43393-1_19</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-43393-1_19" />
	</analytic>
	<monogr>
		<title level="m">Towards a Collaborative Society Through Creative Learning</title>
		<editor>
			<persName><forename type="first">Therese</forename><surname>Keane</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Cathy</forename><surname>Lewin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Torsten</forename><surname>Brinda</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rosa</forename><surname>Bottino</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Nature Switzerland</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">685</biblScope>
			<biblScope unit="page" from="196" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Novices&apos; Conceptions of Machine Learning</title>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Mühling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregor</forename><surname>Große-Bölting</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.caeai.2023.100142</idno>
		<ptr target="https://doi.org/10.1016/j.caeai.2023.100142" />
	</analytic>
	<monogr>
		<title level="j">Computers and Education: Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Mentale Modelle</title>
		<author>
			<persName><forename type="first">Sandra</forename><surname>Nitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sabine</forename><surname>Fechner</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-662-56320-5_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-662-56320-5_5" />
	</analytic>
	<monogr>
		<title level="m">Theorien in der naturwissenschaftsdidaktischen Forschung</title>
		<editor>
			<persName><forename type="first">Dirk</forename><surname>Krüger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ilka</forename><surname>Parchmann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Horst</forename><surname>Schecker</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="69" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Some Observations on Mental Models</title>
		<author>
			<persName><forename type="first">Donald</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315802725-5</idno>
		<ptr target="https://doi.org/10.4324/9781315802725-5" />
	</analytic>
	<monogr>
		<title level="m">Mental Models</title>
		<editor>
			<persName><forename type="first">Dedre</forename><surname>Gentner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Albert</forename><forename type="middle">L</forename><surname>Stevens</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Psychology Press</publisher>
			<date type="published" when="1983">1983</date>
			<biblScope unit="page" from="15" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Language and Cognition Interaction Neural Mechanisms</title>
		<author>
			<persName><forename type="first">Leonid</forename><surname>Perlovsky</surname></persName>
		</author>
		<idno type="DOI">10.1155/2011/454587</idno>
		<ptr target="https://doi.org/10.1155/2011/454587" />
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2011</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2011">2011. 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mental Models: Theoretical Issues for Visualizations in Science Education</title>
		<author>
			<persName><forename type="first">N</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><surname>Rapp</surname></persName>
		</author>
		<idno type="DOI">10.1007/1-4020-3613-2_4</idno>
		<ptr target="https://doi.org/10.1007/1-4020-3613-2_4" />
	</analytic>
	<monogr>
		<title level="m">Visualization in Science Education</title>
		<editor>
			<persName><forename type="first">John</forename><forename type="middle">K</forename><surname>Gilbert</surname></persName>
		</editor>
		<meeting><address><addrLine>Netherlands, Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="43" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Review and Discussion of Children&apos;s Conceptions of Computers</title>
		<author>
			<persName><forename type="first">T</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niels</forename><surname>Rücker</surname></persName>
		</author>
		<author>
			<persName><surname>Pinkwart</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10956-015-9592-2</idno>
		<ptr target="https://doi.org/10.1007/s10956-015-9592-2" />
	</analytic>
	<monogr>
		<title level="j">Journal of Science Education and Technology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="274" to="283" />
			<date type="published" when="2016-04">2016. April 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Developing Middle School Students&apos; Understanding of Machine Learning in an African School</title>
		<author>
			<persName><forename type="first">Temitayo</forename><surname>Ismaila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Solomon</forename><surname>Sanusi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henriikka</forename><surname>Sunday Oyelere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jarkko</forename><surname>Vartiainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Markku</forename><surname>Suhonen</surname></persName>
		</author>
		<author>
			<persName><surname>Tukiainen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.caeai.2023.100155</idno>
		<ptr target="https://doi.org/10.1016/j.caeai.2023.100155" />
	</analytic>
	<monogr>
		<title level="j">Computers and Education: Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">100155</biblScope>
			<date type="published" when="2023-01">2023. Jan. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Five Design Recommendations for Teaching Teenagers&apos; about Artificial Intelligence and Machine Learning</title>
		<author>
			<persName><forename type="first">Marie-Monique</forename><surname>Schaper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mariana</forename><forename type="middle">Aki</forename><surname>Tamashiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Charlotte</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maarten</forename><surname>Van Mechelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ole</forename><surname>Sejer Iversen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3585088.3589366</idno>
		<ptr target="https://doi.org/10.1145/3585088.3589366" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Annual ACM Interaction Design and Children Conference</title>
		<meeting>the 22nd Annual ACM Interaction Design and Children Conference<address><addrLine>Chicago IL USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="298" to="309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Notional Machines and Introductory Programming Education</title>
		<author>
			<persName><forename type="first">Juha</forename><surname>Sorva</surname></persName>
		</author>
		<idno type="DOI">10.1145/2483710.2483713</idno>
		<ptr target="https://doi.org/10.1145/2483710.2483713" />
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computing Education</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2013-06">2013. June 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Mental Models: Concepts for Human-Computer Interaction Research</title>
		<author>
			<persName><forename type="first">Nancy</forename><surname>Staggers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Norcio</surname></persName>
		</author>
		<idno type="DOI">10.1006/imms.1993.1028</idno>
		<ptr target="https://doi.org/10.1006/imms.1993.1028" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Man-Machine Studies</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="587" to="605" />
			<date type="published" when="1993-04">1993. April 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Can You Teach Me To Machine Learn?</title>
		<author>
			<persName><forename type="first">Elisabeth</forename><surname>Sulmont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Patitsas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jeremy</forename><forename type="middle">R</forename><surname>Cooperstock</surname></persName>
		</author>
		<idno type="DOI">10.1145/3287324.3287392</idno>
		<ptr target="https://doi.org/10.1145/3287324.3287392" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th ACM Technical Symposium on Computer Science Education</title>
		<meeting>the 50th ACM Technical Symposium on Computer Science Education<address><addrLine>Minneapolis MN USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="948" to="954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">How Do Children Acquire Knowledge about Voice Assistants? A Longitudinal Field Study on Children&apos;s Knowledge about How Voice Assistants Store and Process Data</title>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Szczuka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clara</forename><surname>Strathmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalia</forename><surname>Szymczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lina</forename><surname>Mavrina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicole</forename><surname>Krämer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijcci.2022.100460</idno>
		<ptr target="https://doi.org/10.1016/j.ijcci.2022.100460" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Child-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">100460</biblScope>
			<date type="published" when="2022-01">2022. Jan. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The Nature of Student Conceptions in Science</title>
		<author>
			<persName><forename type="first">Keith</forename><forename type="middle">S</forename><surname>Taber</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-94-6300-749-8_9</idno>
		<ptr target="https://doi.org/10.1007/978-94-6300-749-8_9" />
	</analytic>
	<monogr>
		<title level="m">Science Education</title>
		<editor>
			<persName><forename type="first">Keith</forename><forename type="middle">S</forename><surname>Taber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ben</forename><surname>Akpan</surname></persName>
		</editor>
		<meeting><address><addrLine>Rotterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="119" to="131" />
		</imprint>
	</monogr>
	<note>SensePublishers</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">CT 2.0</title>
		<author>
			<persName><forename type="first">Matti</forename><surname>Tedre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><surname>Denning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tapani</forename><surname>Toivonen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3488042.3488053</idno>
		<ptr target="https://doi.org/10.1145/3488042.3488053" />
	</analytic>
	<monogr>
		<title level="m">21st Koli Calling International Conference on Computing Education Research. ACM, Joensuu Finland</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Machine Learning and the Five Big Ideas in AI</title>
		<author>
			<persName><forename type="first">David</forename><surname>Touretzky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christina</forename><surname>Gardner-Mccune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Seehorn</surname></persName>
		</author>
		<idno type="DOI">10.1007/s40593-022-00314-1</idno>
		<ptr target="https://doi.org/10.1007/s40593-022-00314-1" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Artificial Intelligence in Education</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1" to="34" />
			<date type="published" when="2022-10">2022. Oct. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">Lewis</forename><surname>Tunstall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leandro</forename><surname>Von Werra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<title level="m">Natural Language Processing with Transformers: Building Language Applications with Hugging Face</title>
		<meeting><address><addrLine>O&apos;Reilly Media, Sebastopol, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">AI Teaches Itself&quot;: Exploring Young Learners&apos; Perspectives on Artificial Intelligence for Instrument Development</title>
		<author>
			<persName><forename type="first">Jessica</forename><surname>Vandenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bradford</forename><surname>Mott</surname></persName>
		</author>
		<idno type="DOI">10.1145/3587102.3588778</idno>
		<ptr target="https://doi.org/10.1145/3587102.3588778" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1. ACM</title>
		<meeting>the 2023 Conference on Innovation and Technology in Computer Science Education V. 1. ACM<address><addrLine>Turku Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="485" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Machine Learning for Middle Schoolers: Learning through Data-Driven Design</title>
		<author>
			<persName><forename type="first">Henriikka</forename><surname>Vartiainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tapani</forename><surname>Toivonen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ilkka</forename><surname>Jormanainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Juho</forename><surname>Kahila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matti</forename><surname>Tedre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teemu</forename><surname>Valtonen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijcci.2021.100281</idno>
		<ptr target="https://doi.org/10.1016/j.ijcci.2021.100281" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Child-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">100281</biblScope>
			<date type="published" when="2021-09">2021. Sept. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Towards a Framework for Learning Content Analysis in K-12 AI/ML Education</title>
		<author>
			<persName><forename type="first">Jane</forename><surname>Waite</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ethel</forename><surname>Tshukudu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Veronica</forename><surname>Cucuiat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robert</forename><surname>Whyte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sue</forename><surname>Sentance</surname></persName>
		</author>
		<idno type="DOI">10.1109/FIE58773.2023.10343368</idno>
		<ptr target="https://doi.org/10.1109/FIE58773.2023.10343368" />
	</analytic>
	<monogr>
		<title level="m">2023 IEEE Frontiers in Education Conference (FIE)</title>
		<meeting><address><addrLine>College Station, TX, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Teaching AI: Exploring New Frontiers for Learning</title>
		<author>
			<persName><forename type="first">Michelle</forename><surname>Zimmerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internation Society for Technology in Education</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<pubPlace>Portland, Oregon</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
