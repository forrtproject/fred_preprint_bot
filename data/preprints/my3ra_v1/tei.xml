<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Uncovering Heart Rate Response Patterns to Threat Pictures through Deep Latent Representation Learning with a Variational Autoencoder</title>
				<funder ref="#_VSaKcfY">
					<orgName type="full">Agencia Española de Investigación</orgName>
					<orgName type="abbreviated">AEI</orgName>
				</funder>
				<funder>
					<orgName type="full">Ministerio de Ciencia, Innovación y Universidades of the Spanish government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>PhD</roleName><forename type="first">Stephan</forename><surname>Moratti</surname></persName>
							<email>smoratti@ucm.es</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Experimental Psychology</orgName>
								<orgName type="institution">Complutense University of Madrid</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Cognitive and Computational Neuroscience C3N</orgName>
								<orgName type="laboratory">Emotional Processing Laboratory (EPL)</orgName>
								<orgName type="institution">Complutense University of Madrid</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sergio</forename><surname>Felipe</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Calvo</forename><surname>García</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Experimental Psychology</orgName>
								<orgName type="institution">Complutense University of Madrid</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Center for Cognitive and Computational Neuroscience C3N</orgName>
								<orgName type="laboratory">Emotional Processing Laboratory (EPL)</orgName>
								<orgName type="institution">Complutense University of Madrid</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Experimental Psychology</orgName>
								<orgName type="laboratory">Emotional Processing Laboratory</orgName>
								<orgName type="institution">Complutense University of Madrid (Madrid)</orgName>
								<address>
									<addrLine>Campus Somosaguas</addrLine>
									<postCode>C3N, 28223</postCode>
									<settlement>Pozuelo de Alarcón</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Uncovering Heart Rate Response Patterns to Threat Pictures through Deep Latent Representation Learning with a Variational Autoencoder</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">62FE7DA52272D6CF975C1C2C9DD38374</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-21T13:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Heart Rate</term>
					<term>Threat</term>
					<term>Orienting</term>
					<term>Defense</term>
					<term>Deep Learning</term>
					<term>Variational</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Group-level averaging of psychophysiological data often obscures meaningful individual differences, masking response patterns that may explain variability in behavior and central nervous system activity. Identifying such patterns is particularly relevant in heart rate (HR) responses to threat, where subtle variations may reflect distinct coping mechanisms such as orienting or defense. Machine learning techniques that learn latent representations, particularly variational autoencoders (VAEs), offer powerful tools for revealing such hidden structures. This methodological report introduces a simple VAE-based approach for characterizing HR responses to threat pictures in 165 participants. To validate the method, simulations first demonstrated that the model accurately separated noisy sine and cosine waveforms. The VAE was then applied to empirical HR responses, mapping them into a two-dimensional latent space for subsequent cluster analysis, which was compared to clustering based directly on raw HR waveforms.</p><p>The VAE revealed three distinct response profiles: (1) strong decelerators (fear bradycardia), (2) weak decelerators with late acceleration, and (3) immediate accelerators without a decelerative phase. In contrast, clustering raw HR waveforms identified only two groups. Clusters derived from the latent space were more coherent and exhibited greater within-group consistency. Finally, applying the pre-trained autoencoder to a small fear-conditioning dataset enabled characterization of distinct HR response patterns despite limited sample size. These findings show that even a basic autoencoder enhances the categorization of psychophysiological response patterns, offering a framework for linking individual autonomic variability to broader models of affective and defensive behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>Corresponding Python script VAE and BGMM simulated data AutoencoderVAE_1dConv_sim.py VAE and BGMM real HR data (AUT) AutoencoderVAE_1dConv_HR.py BGMM direct on HR data (ATP) BaysGMM_clustering_allTimePoints.py Comparison of cluster performance Comparisons.py</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Humans and animals flexibly react to threats depending on threat imminence, which can be defined as the spatial or psychological proximity of the threatening stimulus <ref type="bibr" target="#b13">(Gladwin et al., 2016;</ref><ref type="bibr" target="#b25">Löw et al., 2015;</ref><ref type="bibr" target="#b28">Mobbs et al., 2020;</ref><ref type="bibr" target="#b37">Roelofs, 2017)</ref>. Thereby, two fundamental response strategies have been identified: orienting and defense <ref type="bibr" target="#b14">(Graham &amp; Clifton, 1966;</ref><ref type="bibr" target="#b34">Pavlov, 1927;</ref><ref type="bibr" target="#b44">Sokolov, 1963)</ref>. Critically, these strategies involve distinct physiological and behavioral response patterns that are highly adaptive depending on threat imminence, reflecting either sympathetic or parasympathetic dominance. Distant threat cues typically elicit a parasympathetically dominated orienting response, which inhibits ongoing behavior, increases attention toward the potential threat, and facilitates its sensory processing <ref type="bibr" target="#b12">(Echegaray &amp; Moratti, 2021;</ref><ref type="bibr" target="#b24">Lojowska et al., 2015;</ref><ref type="bibr" target="#b26">Martín et al., 2025;</ref><ref type="bibr" target="#b33">Moratti et al., 2004;</ref><ref type="bibr" target="#b38">Roelofs et al., 2010)</ref>. This provides the basis for model-based, flexible action planning. In contrast, imminent counter-strike situations are best encountered by rapid, hard-wired, model-free responses <ref type="bibr" target="#b28">(Mobbs et al., 2020)</ref>. These evoke sympathetically dominated defensive responses, characterized by action preparation and "sensory rejection" <ref type="bibr" target="#b26">(Martín et al., 2025;</ref><ref type="bibr" target="#b37">Roelofs, 2017;</ref><ref type="bibr" target="#b44">Sokolov, 1963)</ref>.</p><p>Studies using fear conditioning and inherently threatening visual stimuli have shown that humans differ considerably in the extent to which orienting versus defensive response patterns are evoked by the same threat cue. For example, the same fearconditioned stimuli elicit heart rate (HR) acceleration in some participants and HR deceleration (fear bradycardia) in others <ref type="bibr" target="#b3">(Battaglia et al., 2024;</ref><ref type="bibr" target="#b15">Hamm &amp; Vaitl, 1996;</ref><ref type="bibr" target="#b17">Hodes et al., 1985;</ref><ref type="bibr" target="#b32">Moratti et al., 2006;</ref><ref type="bibr" target="#b31">Moratti &amp; Keil, 2005;</ref><ref type="bibr" target="#b40">Sevenster et al., 2015)</ref>.</p><p>Critically, in fear conditioning, HR accelerators engage their defense system, as evidenced by potentiated startle responses to the fear-conditioned cue; a pattern not observed in HR decelerators <ref type="bibr" target="#b15">(Hamm &amp; Vaitl, 1996;</ref><ref type="bibr" target="#b40">Sevenster et al., 2015)</ref>. Similarly, inherently threat-related pictures, such as mutilation or attack scenes, typically evoke fear bradycardia in most participants, which has been interpreted as an orienting response to motivationally significant cues <ref type="bibr" target="#b7">(Bradley, 2009;</ref><ref type="bibr" target="#b9">Bradley et al., 2012)</ref>. However, HR acceleration is also observed in a subset of participants who report stronger fear of mutilation or who avoid approaching threat pictures more quickly than HR decelerators <ref type="bibr" target="#b21">(Klorman et al., 1977;</ref><ref type="bibr" target="#b26">Martín et al., 2025)</ref>.</p><p>Together, these findings demonstrate that subjectively perceived threat imminence modulates HR patterns that index either parasympathetically dominated orienting or sympathetically dominated defense. Interestingly, HR-indexed orienting has been associated with increased visual processing in the visual cortex and reduced excitatory cortical motor-circuit preparation, whereas HR-indexed defense shows the opposite pattern <ref type="bibr" target="#b12">(Echegaray &amp; Moratti, 2021;</ref><ref type="bibr" target="#b26">Martín et al., 2025)</ref>. This aligns with theoretical accounts of sensory intake during orienting and sensory rejection during defense <ref type="bibr" target="#b14">(Graham &amp; Clifton, 1966;</ref><ref type="bibr" target="#b22">Lacey &amp; Lacey, 1970;</ref><ref type="bibr" target="#b44">Sokolov, 1963)</ref>.</p><p>However, the classification of participants into HR decelerators and accelerators, and the associated strategic response type toward threat cues, also depends on the methodology used to identify the corresponding HR response patterns. Although all reported findings on subclassifications of HR accelerators and decelerators rely on some form of clustering algorithm (e.g., hierarchical clustering in <ref type="bibr" target="#b32">Moratti et al., 2006;</ref><ref type="bibr" target="#b31">Moratti &amp; Keil, 2005)</ref>; k-means clustering of predefined time windows in <ref type="bibr" target="#b15">Hamm &amp; Vaitl, 1996;</ref><ref type="bibr" target="#b17">Hodes et al., 1985;</ref><ref type="bibr" target="#b40">Sevenster et al., 2015</ref>; a simple zero-threshold approach in <ref type="bibr" target="#b12">Echegaray &amp; Moratti, 2021</ref>; or k-means on all time bins in <ref type="bibr" target="#b26">Martín et al., 2025)</ref>, a purely data-driven method that captures the full richness of HR response waveforms at the individual level would be ideal.</p><p>Recent advances in machine learning for time-series classification are promising in this regard. For example, autoencoders can learn to reduce a time series into a lowdimensional latent space and then reconstruct the series from that space. These approaches have typically been used to detect artifacts or anomalies, based on a pretrained autoencoder trained on "ideal" data <ref type="bibr" target="#b18">(Hu et al., 2024;</ref><ref type="bibr">Mathworks/Anomaly-Detection-Using-Variational-Autoencoder-VAE-, 2020</ref><ref type="bibr">/2024;</ref><ref type="bibr" target="#b47">Yang &amp; Paparrizos, 2025;</ref><ref type="bibr" target="#b48">Yu et al., 2023)</ref>. Here, we propose using a simple variational autoencoder to encode HR response waveforms to threat stimuli into a two-dimensional latent space and then decode these response patterns from that space. This allows each participant to be located within a two-dimensional Cartesian space. Subsequently, cluster analysis can be applied to this latent space to identify groups of participants with similar HR waveform shapes. Another advantage is that, once an autoencoder has been trained on a sufficiently large sample, it can be applied to new, smaller samples to classify participant groups showing different HR response patterns.</p><p>Here, we present a methodological approach that combines an autoencoder with a Bayesian Gaussian Mixture Model (BGMM) clustering procedure to demonstrate the usefulness of autoencoders for identifying groups of HR responders to threat stimuli.</p><p>First, the approach is introduced using simulated data (sine and cosine waveforms with added noise) to show that the autoencoder, together with BGMM clustering, can successfully identify different types of time series based on ground-truth data. Second, the autoencoder is applied to real HR change response waveforms obtained from three independent samples of two previous studies and of one ongoing study (N = 165, <ref type="bibr" target="#b12">Echegaray &amp; Moratti, 2021;</ref><ref type="bibr" target="#b26">Martín et al., 2025;</ref><ref type="bibr">Calvo García et al., in preparation)</ref>.</p><p>Finally, we compare the performance of the autoencoder in clustering participants with similar HR change waveforms against our previous approach of applying clustering directly to all time bins <ref type="bibr" target="#b26">(Martín et al., 2025)</ref>. Because one-dimensional convolutional layers in an autoencoder are expected to capture the richness of individual HR change waveforms, we hypothesize that the autoencoder will outperform clustering applied directly to the raw data. Importantly, all data, statistical analysis and code for performing the analysis presented in this methodological report are available and can be re-used for future research (https://osf.io/k58uy/).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>All participants were sampled from two published studies <ref type="bibr" target="#b12">(Echegaray &amp; Moratti, 2021;</ref><ref type="bibr" target="#b26">Martín et al., 2025)</ref> and one ongoing study <ref type="bibr">(Calvo Garcia et al., in</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure and Stimuli</head><p>After having received instructions about the experimental tasks, all participants were shown an example of mutilation and attack scenes (that were not later presented during the experiment) to decide whether they wished to participate. All participants then signed an informed consent form. Following completion of the experiments, participants were fully debriefed about the purposes of the study.</p><p>In all three experiments, threat-related pictures (mutilation and attack scenes) and neutral pictures (neutral faces and household objects) were taken from the International Affective Picture System (IAPS; <ref type="bibr" target="#b23">Lang et al., 2005)</ref>. In the study by <ref type="bibr" target="#b12">Echegaray &amp; Moratti (Echegaray &amp; Moratti, 2021)</ref>, 20 threat and 20 neutral pictures were selected, with mean normative valence ratings of 2.76 (SD = 0.19) and 4.87 (SD = 0.05), respectively. Mean normative arousal ratings were 7.33 (SD = 0.13) for threat scenes and 2.80 (SD = 0.13) for neutral pictures. In the study by <ref type="bibr" target="#b26">Martín et al. (Martín et al., 2025)</ref>, 40 threat and 40 neutral pictures were used, with mean normative valence ratings of 2.02 (SD = 0.46) and 4.75 (SD = 0.25), respectively. Mean normative arousal ratings were 6.71 (SD = 0.37) for threat scenes and 2.65 (SD = 0.36) for neutral pictures. For each participant, 20 threat and 20 neutral pictures were randomly selected from the original pool of 40 per category.</p><p>Pictures were presented in two experimental blocks with different pseudo-randomized sequences (with no more than three pictures of the same category presented consecutively), resulting in a total of 40 threat and 40 neutral pictures. In the ongoing study <ref type="bibr">(Calvo Garcia et al., in preparation)</ref>, the same 40 threat and 40 neutral IAPS pictures as in the <ref type="bibr" target="#b26">Martín et al. (2025)</ref> study were used, but without selecting a subset of 20 per category. Thus, participants viewed all 40 threat and all 40 neutral pictures in pseudorandomized order across two experimental blocks (again with no more than three pictures of the same category presented consecutively) and without repetitions. Mean valence and arousal ratings correspond to those reported in the <ref type="bibr" target="#b26">Martín et al. (2025)</ref> study.</p><p>Across all experiments, all pictures were matched for luminance and contrast using the SHINE toolbox (version 0.0.4; <ref type="bibr" target="#b4">Ben, 2019)</ref> in MATLAB <ref type="bibr">(MathWorks™, R2021b)</ref>. Pictures were presented centrally on a screen (refresh rate: 60 Hz), subtending a visual angle of 10° horizontally and 7.5° vertically. Participants were instructed to maintain fixation on a central cross (visual angle: 1.6° horizontally and vertically), which remained visible throughout the entire experiment (during both picture presentation and inter-trial intervals, ITIs). To evoke steady-state visual evoked fields (ssVEFs) or potentials (ssVEPs), pictures flickered for 4 s at 10 Hz in the studies by <ref type="bibr" target="#b12">Echegaray &amp; Moratti (2021)</ref> and <ref type="bibr" target="#b26">Martín et al. (2025)</ref>, whereas in the ongoing study the flicker rate was 15 Hz. The ITI following each picture presentation was randomly chosen between 8 s and 12 s in all three studies. In <ref type="bibr">Echegaray &amp; Moratti's report (2021)</ref>, the task consisted of passive viewing of emotional pictures. By contrast, in the <ref type="bibr" target="#b26">Martín et al. (2025)</ref> report and the ongoing study, picture size started to gradually increase after the 4 s presentation, and participants were required to terminate picture presentation by pressing a button to indicate how close they allowed the pictures to approach (results not reported here). After the second block of picture presentations, all participants in all three studies rated valence and arousal using the Self-Assessment Manikin scale (SAM; <ref type="bibr" target="#b23">(Lang et al., 2005)</ref>).</p><p>However, the SAM ratings of eight participants were lost due to technical problems resulting in SAM ratings of 157 participants. The experiments were controlled using the Pychtoolbox <ref type="bibr" target="#b20">(Kleiner et al., 2007)</ref> in MATLAB <ref type="bibr">(Mathworks™)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data acquisition and processing of the Electrocardiogram (ECG) data</head><p>As MEG and EEG data from the three studies have been reported elsewhere <ref type="bibr" target="#b12">(Echegaray &amp; Moratti, 2021;</ref><ref type="bibr" target="#b26">Martín et al., 2025)</ref> and will be reported for the ongoing study in the future, only ECG acquisition and processing are described here. In all studies, ECG was recorded using Ag/AgCl electrodes filled with electrolytic gel. In <ref type="bibr" target="#b12">Echegaray &amp; Moratti (2021)</ref>, electrodes were placed at the right mid-clavicle and lower left rib, sampled at 600 Hz with a 0.1-200 Hz online band-pass filter using the MEG-integrated EEG amplifier <ref type="bibr">(VectorView©, Elekta Neuromag Oy, Helsinki, Finland, 2005)</ref>. <ref type="bibr" target="#b26">Martín et al. (2025)</ref> used the same montage but with a 1000 Hz sampling rate, a 0.1-100 Hz bandpass filter, and an additional 50 Hz notch filter. In the ongoing study <ref type="bibr">(Garcia Calvo at el., in preparation)</ref>, recordings were obtained with two active, pre-amplified electrodes placed at the right and left mid-clavicles, using a BrainAmp amplifier (BrainProducts©) with a 1000 Hz sampling rate and a 0.1-100 Hz band-pass filter plus a 50 Hz notch filter.</p><p>Ground electrodes differed across studies: the left earlobe in the MEG study and AFz in the two EEG studies.</p><p>Before heartbeat detection (R-peak identification), ECG data were down-sampled to 250 Hz and filtered offline with a FIR band-pass filter (0.1-40 Hz, 60 dB stopband attenuation). In the MEG study <ref type="bibr" target="#b12">(Echegaray &amp; Moratti, 2021)</ref>, R-peaks were detected using a simple Schmitt trigger. In the study by <ref type="bibr" target="#b26">Martín et al. (2025)</ref>, a pre-trained long short-term memory (LSTM) network (available in the MATLAB Deep Learning Toolbox; see <ref type="bibr" target="#b26">Martín et al., 2025</ref> for details) was used to identify the QRS complex and corresponding R-peaks. In the ongoing study, R-peaks were detected using the opensource MATLAB toolbox R-DECO (version 1.0.0; https://physionet.org/content/r-deco/1.0.0/), which applies an envelope-based method combined with an adapted Pan-Tompkins algorithm <ref type="bibr" target="#b29">(Moeyersons et al., 2019)</ref>.</p><p>Across all studies, R-peak detections were visually inspected for artifacts such as noise or ectopic beats, and contaminated trials were omitted from further analysis. For each participant and picture category (threat and neutral), inter-beat intervals (IBIs) derived from R-peaks during a 2 s pre-stimulus and 4 s post-stimulus interval were transformed into beats per minute (bpm) in 0.5 s steps using weighted averages (Reyes del Paso &amp; Vila, 1998), implemented with code from the open-source MATLAB toolbox KARDIA <ref type="bibr" target="#b35">(Perakakis et al., 2010)</ref>; https://sourceforge.net/projects/mykardia/). Finally, HR change waveforms were baseline-corrected using the 2 s pre-stimulus interval. To improve the autoencoder learning performance, HR data was scaled (-1 to 1) and smoothed using a Gaussian one-dimensional filter (s = 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generation of simulated data</head><p>To obtain ground truth data for testing the autoencoder (see below), 160 simulated datasets were generated. Specifically, 80 sine and 80 cosine waveforms (amplitude range:</p><p>-1 to 1) were created using nine time bins, matching the post-stimulus HR data that also consisted of nine time bins from 0 s to 4 s post-stimulus. Random noise drawn from a normal distribution (mean = 0.1, SD = 0.3) was then added to each sine and cosine waveform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Construction of the variational autoencoder (VAE)</head><p>A VAE was implemented in Keras/ TensorFlow (https://keras.io; https://www.tensorflow.org/) to learn two dimensional latent representations of the simulated data and heart rate change waveforms. The encoder consisted of three one-dimensional convolutional layers with kernel size 3, leaky rectified linear unit activation functions, and progressively increasing filter sizes (4, 16, and 32). Convolutional outputs were down-sampled using a max-pooling layer (pool size = 3, padding = "same") and flattened. Two fully connected layers generated the mean (zmean) and log-variance (zlogvar ) of a two-dimensional latent Gaussian distribution. Latent variables were sampled using reparameterization:</p><formula xml:id="formula_0">z = zmean + exp(0.5 • zlogvar) • epsilon;</formula><p>where epsilon is drawn from a standard normal distribution. This allows gradients to </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clustering of simulated and HR change waveforms using a Bayesian Gaussian Mixture Model (BGMM)</head><p>To identify clusters of sine and cosine time series (simulated data) and participants with similar heart rate waveforms (real data), we applied a Bayesian Gaussian Mixture Model (BGMM) as implemented in the python module scikit-learn. The BGMM is a clustering method that groups data based on the assumption that it comes from a mixture of several Gaussian distributions. Unlike the standard Gaussian Mixture Model (GMM), the BGMM automatically determines how many clusters are needed by placing a Bayesian prior on the mixture weights. This allows it to "turn off" unnecessary components, making it more flexible when the true number of clusters is unknown <ref type="bibr" target="#b6">(Bishop, 2006)</ref>.</p><p>For simulated data, the BGMM was applied to the two-dimensional latent space learned by the autoencoder. If this space adequately captured the sine and cosine waveforms, the BGMM was expected to identify two corresponding clusters. Latent vectors were z-transformed (μ = 0, σ = 1), and the BGMM was initialized with 10 clusters and 500 iterations. To account for sensitivity to the covariance prior, values between 0.01 and 5.1 (step size 0.1) were tested, and the solution with the highest Silhouette score was selected. The same procedure was applied to the encoded latent space of HR change waveforms evoked by threatening pictures. With respect to HR data, we refer to this method as the AUT approach (autoencoder). For comparison, BGMM clustering was also performed directly on the nine-dimensional HR time series (0-4 s post-stimulus time bins), which were reduced to two components for visualization using principal component analysis (PCA) as implemented in the sklearn.decomposition module. With respect to HR data, we refer to this method as the ATP approach (all time points).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparing clustering performance</head><p>To evaluate the performance of the two clustering approaches (AUT and ATP) for the HR data, we compared the Silhouette and Calinski-Harabasz scores. Both are widely used indicators of cluster quality: the Silhouette score reflects the similarity of an observation to its own cluster <ref type="bibr" target="#b39">(Rousseeuw, 1987)</ref>, whereas the Calinski-Harabasz index quantifies overall cluster separation versus cohesion <ref type="bibr" target="#b10">(Caliński &amp; Harabasz, 1974)</ref>. In addition, we assessed the similarity of HR change waveforms within clusters using cosine similarity (CS) scores (implemented in the sklearn.metrics.pairwise module), defined as the normalized dot product between two time series. For each participant, we computed the CS of their HR waveform relative to all other participants within the same cluster. To enable statistical comparison between the AUT and ATP approaches -and to address issues related to unequal cluster numbers as well as dependence versus independence of observations -CS scores were averaged across the clusters obtained for each approach.</p><p>Because the distributions of CS scores were skewed (see Results, Figure <ref type="figure" target="#fig_15">7</ref>), group comparisons were performed using the Wilcoxon signed-rank test and complemented by a Bayesian paired-samples t-test with a scaled Cauchy prior (r = 0.7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical comparison between HR responses to threating and neutral picture content</head><p>As in previous reports (e. g. <ref type="bibr" target="#b26">Martín et al., 2025)</ref>, each time bin of the HR responses to threat and neutral pictures was compared using paired parametric t-tests, and additionally with Bayesian paired t-tests using a scaled Cauchy prior (r = 0.7), since Bayesian comparisons do not require correction for multiple comparisons. The p-values from the paired parametric t-tests were corrected using the false discovery rate (FDR) procedure by <ref type="bibr" target="#b5">Benjamini &amp; Yekutieli (Benjamini &amp; Yekutieli, 2001)</ref> to account for dependence. First, HR change waveforms were compared between neutral and threat picture categories across the entire sample (N = 165) to replicate previously reported fear bradycardia in response to threatening or unpleasant complex emotional scenes <ref type="bibr" target="#b8">(Bradley et al., 2001)</ref>. The same comparisons were then performed within the clusters obtained using the AUT and ATP approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Application to a fear conditioning data set of small sample size</head><p>To evaluate whether the pre-trained autoencoder, together with the pre-trained BGMM, can contribute to identifying distinct HR response patterns to fear-relevant stimuli in a small sample and generalize to simple visual stimuli that had been fear The fear-relevant CS+ HR response waveforms were submitted to the pre-trained autoencoder to obtain their representations in the two-dimensional latent space.</p><p>Subsequently, the means, covariances, and weights of the pre-trained BGMM were applied to these latent representations to form the corresponding clusters. Finally, the mean HR change from baseline for the CS+ and CS-was calculated for each resulting cluster and compared using the same statistical approach described above. As this is a method contribution Table <ref type="table" target="#tab_0">1</ref> below lists the corresponding Python scripts for each analysis protocol that can be found on the Open Science Framework server (https://osf.io/k58uy/): </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SAM ratings</head><p>Threat pictures were rated as less pleasant (M = 2.14, SD = 0.81) than neutral pictures (M = 5.34, SD = 0.77; t(156) = 38.41, p &lt; 0.001, Cohen's d = 3.06). Threating pictures were also rated as more arousing (M = 6.85, SD = 1.36) than neutral pictures (M = 3.08, SD = 1.36; t(157) = 30.11, p &lt; 0.001, Cohen's d = 2.40). In sum, participant's SAM ratings were in line with the normative IAPS SAM ratings (see methods).  The autoencoder separated the sine and cosine waves into two very well definable clusters within the two-dimensional latent space (see Figure <ref type="figure" target="#fig_6">2</ref>). The BGMM clustering procedure applied to the latent space indicated that two active clusters (weights &gt; 1e-2) best describe the positions of the sine and cosine waveforms in the latent space. The two clusters were obtained using a covariance prior of 0.11. This covariance prior was determined by running the BGMM procedure with priors from 0.01 to 5.01 in 0.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Autoencoder performance on simulated data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overall HR responses across all participants</head><p>Considering the overall HR response across all participants (N = 165), threat related pictures evoked increased fear bradycardia (HR deceleration) than neutral picture contents from 1.5 s to 4 s after stimulus onset (maximum t value at 4.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Autoencoder and direct BGMM clustering of HR response data</head><p>In this section we will compare between the clustering performance of a BGMM procedure in the two-dimensional latent space after encoding the HR data using an autoencoder (AUT approach) and applying the BGMM directly on the HR data in a nine-dimensional space corresponding to the nine time bins (all time points ATP approach, see methods). Corresponding to the AUT approach Figure <ref type="figure" target="#fig_10">4</ref>   The same BGMM procedure as in the simulation study was applied to the locations in the two-dimensional latent space of the autoencoder. Then, the same procedure was repeated directly using the HR change waveforms (ATP approach as done in our previous report that used Kmeans clustering, see <ref type="bibr">Martín-Gil et al., 2025)</ref>. For both approaches (AUT and ATP) the best covariance priors were determined by applying priors between 0.01 to 5.1 in 0.1 steps and selecting the prior that resulted in the greatest Silhouette score for the clusters. The locations in the two-dimensional latent space of the  The ATP method resulted in two clusters (cluster 1: N = 121, cluster 2: N = 44).</p><p>The mean HR change responses for the first cluster generated by the ATP approach were characterized by increased HR deceleration (fear bradycardia) for threat pictures in comparison to neutral images (Figure <ref type="figure" target="#fig_14">6D</ref>; increased deceleration from 1 s to 4 s after picture onset: minimum t-value at 2 s: t(120) = -7.34, pcorrected &lt; 0.001; BF10 = 3.07 • 10 8 , median d = -0.66, 95% CI: [-0.85, -0.46], maximum t-value at 1 s: t(120) = -3.57, pcorrected = 0.002, BF10 = 38.33, median d = -0.32, 95% CI: [-0.50, -0.14]). The second cluster of the ATP approach contained participants that were characterized by HR acceleration for threat pictures in comparison to neutral images (Figure <ref type="figure" target="#fig_14">6E</ref>; increased HR from 1 s to 4 s after picture onset: minimum t-value at 1 s: t( <ref type="formula">43</ref>     </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Here, we show that a simple variational autoencoder (VAE) can efficiently capture interindividual variability in heart rate (HR) responses to threat-related pictures by projecting HR time series into a two-dimensional latent space. A Bayesian Gaussian Mixture Model (BGMM) clustering procedure identified three clusters: one large HR decelerator group and two HR accelerator groups. One accelerator cluster was characterized by a small HR deceleration after stimulus onset followed by delayed HR acceleration to threat images, whereas the other included participants who exhibited an immediate HR increase without any decelerative component.</p><p>Clustering in the two-dimensional latent space representation (AUT approach) learned by the VAE yielded more coherent clusters and greater within-cluster similarity of HR change waveforms across participants, compared with BGMM clustering applied directly to the HR data (ATP approach). The ATP approach produced only two clusters:</p><p>one accelerator group and one large HR decelerator group that was nearly identical to that found with the AUT approach. The predominance of participants showing fear bradycardia (HR deceleration) when viewing threat-related pictures reflects a wellestablished statistical finding in the literature (e.g. <ref type="bibr" target="#b3">Battaglia et al., 2024;</ref><ref type="bibr" target="#b9">Bradley et al., 2012</ref> for reviews) when averaging across the whole sample without accounting for individual differences. When testing the whole sample (N = 165) without clustering, the often-reported fear bradycardia could be replicated. However, both cluster methods (AUT and ATP) resulted in a more differentiated HR response patterns to threat related visual scenes.</p><p>In our previous studies <ref type="bibr" target="#b12">(Echegaray &amp; Moratti, 2021;</ref><ref type="bibr" target="#b26">Martín et al., 2025)</ref>, using a simple threshold criterion or a k-means clustering on all data points on predefined time windows, only two clusters-HR decelerators and HR accelerators-emerged, without any differentiation between immediate and delayed HR accelerators. This is consistent with applying BGMM clustering to all post-stimulus time bins in the combined sample of the three studies here (ATP approach). However, representing the HR response in a two-dimensional space by VAE learning, the AUT approach provides a more fine-grained characterization of HR response patterns at the individual level as reflected by increased cluster performance scores and HR time series shape similarities between participants within clusters.</p><p>This resonates with findings from engineering fields such as speech recognition, biomedical imaging, and fault detection, where deep latent representation learning has been shown to substantially improve classification compared to traditional feature engineering, by capturing high-dimensional dynamics through multiple one-dimensional convolutional layers <ref type="bibr" target="#b0">(Abdelaziz Dahou Djilali et al., 2023;</ref><ref type="bibr" target="#b1">Arefeen et al., 2023;</ref><ref type="bibr" target="#b2">Baevski et al., 2020;</ref><ref type="bibr" target="#b18">Hu et al., 2024;</ref><ref type="bibr" target="#b19">Kleesiek et al., 2021;</ref><ref type="bibr">Santos-Mayo et al., 2025;</ref><ref type="bibr" target="#b43">Siddiqui et al., 2025;</ref><ref type="bibr" target="#b45">Stephen et al., 2023;</ref><ref type="bibr" target="#b47">Yang &amp; Paparrizos, 2025;</ref><ref type="bibr" target="#b48">Yu et al., 2023)</ref>. The present study demonstrates that VAEs can uncover meaningful patterns of HR responses to threatrelated pictures. Thus, clustering approaches applied to learned latent representations provide a promising strategy for disentangling heterogeneous physiological responses in psychophysiological research. Critically, representing high-dimensional dynamics in a latent space with a VAE revealed meaningful psychophysiological response patterns to threat. The long-standing assumption of a homogeneous fear bradycardia to threat, unpleasant, or fear-conditioned stimuli has already been challenged by identifying subgroups of different HR responder types <ref type="bibr" target="#b12">(Echegaray &amp; Moratti, 2021;</ref><ref type="bibr" target="#b15">Hamm &amp; Vaitl, 1996;</ref><ref type="bibr" target="#b21">Klorman et al., 1977;</ref><ref type="bibr" target="#b26">Martín et al., 2025;</ref><ref type="bibr" target="#b32">Moratti et al., 2006;</ref><ref type="bibr" target="#b31">Moratti &amp; Keil, 2005;</ref><ref type="bibr" target="#b40">Sevenster et al., 2015)</ref> Because HR deceleration and acceleration index parasympathetic and sympathetic dominance, respectively <ref type="bibr" target="#b14">(Graham &amp; Clifton, 1966;</ref><ref type="bibr" target="#b46">Turpin &amp; Siddle, 1978)</ref>, and are associated with orienting and defensive responses <ref type="bibr" target="#b13">(Gladwin et al., 2016;</ref><ref type="bibr" target="#b16">Hashemi et al., 2019;</ref><ref type="bibr" target="#b28">Mobbs et al., 2020;</ref><ref type="bibr" target="#b37">Roelofs, 2017)</ref>, the response patterns identified here offer important insights. Most participants responded with parasympathetically driven orienting (HR deceleration) to threat pictures, consistent with previous findings. This is not surprising as viewing threat pictures represent a low threat imminence situation and orienting should dominate <ref type="bibr" target="#b28">(Mobbs et al., 2020)</ref>. However, the VAE revealed smaller subgroups with distinct autonomic dynamics. One cluster exhibited a modest HR deceleration followed by a later acceleration, suggesting that initial orienting (or possibly a detection response) was followed by a defense stage, reflecting a shift from parasympathetic to sympathetic dominance. Another group showed immediate HR acceleration, indicating the absence of an orienting strategy and the initiation of a rapid defense response.</p><p>The present methodological report also demonstrates that a pre-trained autoencoder, together with a pre-trained Bayesian Gaussian Mixture Model (BGMM), can be used to identify subgroups of participants exhibiting distinct HR response patterns to learned CS+ fear relevance, even in a relatively small sample. In the original study These patterns closely resemble the HR response types obtained during VAE training on complex visual threat scenes. Thus, the pre-trained VAE not only extracted more meaningful HR response profiles associated with orienting, orienting followed by defense, and immediate defense, but also generalized successfully from complex visual scenes to simple visual stimuli (sine patches) that had acquired fear relevance. However, the cluster of participants showing immediate HR acceleration included only four individuals. Two of these participants displayed a clear early HR acceleration, whereas one showed a brief HR deceleration preceding the accelerative phase, and the fourth exhibited no HR modulation in response to the CS+. Consistent with this observation, the two participants with less clear early accelerative responses were located near the border of cluster 3. Although small sample sizes inherently produce greater variability in response patterns, examining the HR response waveforms individually-together with their corresponding locations in the latent space of a pretrained autoencoder-allows for meaningful conclusions about the underlying HR response type.</p><p>A possible concern is that the emergence of similar HR response types-like those found in the test data using simple fear conditioned visual cues-might reflect an artifact of the pretrained latent space based on threat pictures. That is, the VAE could be forcing the fear-conditioning HR responses to cluster in this way. However, the VAE is optimized not only to minimize reconstruction error but also to regularize its latent distribution toward a smooth Gaussian prior, which promotes continuity rather than discrete clustering. Thus, any cluster structure that emerges reflects genuine organization in the data, not an architectural bias of the VAE. In addition, the pretrained BGMM does not modify the latent representations; it simply identifies structure within their existing configuration. Consequently, the cluster assignments are determined by the data-driven latent representations rather than imposed upon them. Finally, the mean HR change responses analyzed after clustering are derived from the original HR time series, not from the reconstructed waveforms. In summary, the identification of three HR responder groups to the learned fear-relevant CS+-paralleling those observed for complex threat scenes-appears to reflect intrinsic structure in the fear-learning data rather than a modeling artifact.</p><p>However, the present results must be considered in the light of a relatively small sample size than normally used in machine learning. The primary goal of this methodological work was to demonstrate that VAEs can be a useful tool in psychophysiological research. By making all data and code fully accessible, we hope to encourage a broader community of psychophysiology researchers to apply deep latent representation learning and extend these findings to much larger samples.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>preparation; total N = 165; mean age = 23.2 years, range = 18 years -55 years, 111 females, 16 left-handed). All volunteers had normal or corrected-to-normal vision and provided written informed consent for participation in the corresponding experiments. Participants received course credit for their participation. Exclusion criteria included a history of epilepsy, family history of epilepsy, or self-reported psychiatric or cardiac pathology. Screening for epilepsy-related conditions was necessary because all three experiments used flickering visual stimuli to evoke steady-state visual fields or potentials (measured with MEG and EEG, respectively). However, MEG and EEG data are not reported here. All three studies were approved by the Ethics Committee of the Complutense University in accordance with the Declaration of Helsinki. Data were stored in compliance with the Spanish and European data protection laws (Ley Orgánica 15/1999 LOPD and Real Decreto 994/1999).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>propagate through the stochastic sampling step allowing differentiable training of the network. The decoder received these two-dimensional latent vectors as input. These were mapped through a fully connected layer (leaky rectified linear unit activation function), reshaped to match the convolutional input dimensions, and up-sampled (factor = 3). The reconstructed signals were generated through two one-dimensional convolutional layers (filters of 16 and 4; kernel sizes = 3; padding = "same"; leaky rectified linear unit activation function), with the final output layer using linear activation to allow continuous-valued reconstruction. The VAE decoding layer was chosen to be sparser to avoid overfitting given that the time series only consisted of nine time bins.The VAE was separately trained (epochs = 2000, batch size = 2, validation split = 0.2) for the (i) simulated time series and (ii) the HR change data to threat pictures using a loss function combining the reconstruction error and a Kullback-Leiber (KL) divergence term (that quantifies the distance to the Gaussian Normal distribution). The KL divergence terms regularized the two-dimensional latent space q("|$) by pulling the encoded latent distributions towards a standard normal distribution p(") = N(0,1).&amp;'()*+,-.(,/)* 1)++ = ! " ∑ ($ # -$ 5 # ) $ " #%! ;where $ # and $ 5 # are the original and reconstructed time series for each time bin, respectively. N is the number of time bins.KL( q("|$) || p(") ) = -! $ ∑(1 + log(; $ ) -&lt; $ -; $ );where &lt; and ; $ are the mean and variance of the encoder output. The KL term was summed over latent dimensions and averaged across batches. The final loss function was defined as the sum of the reconstruction loss and a β-weighted KL divergence term.During training, the β value was gradually increased to implement a KL annealing schedule. This ensured that, at the beginning of training (low β values), the reconstruction loss dominated, allowing the network to learn to reconstruct the signals accurately. As β increased, the KL term became more influential, guiding the network to also encode the signals in a smooth and continuous two-dimensional latent space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>conditioned, HR responses to a fear-conditioned CS+ and a CS-control stimulus from a previous study (Santos-Mayo &amp; Moratti, 2025) were analyzed. In that study, 35 participants volunteered (23 females, 32 right-handed, mean age 24.97 years, range 19-47 years). Due to technical issues only 33 datasets (21 females, 32 right-handed, mean age 25.4 years, range 20-47 years) were available for the current analysis. In the original study, HR responses were considered only up to 3 s after stimulus onset. However, to ensure compatibility with the pre-trained autoencoder used here, HR responses from 0 s (stimulus onset) to 4 s post-stimulus, with a 2 s pre-stimulus baseline correction, were analyzed. Details regarding R-peak detection can be found in Santos-Mayo and Moratti (2025).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1</head><label>1</label><figDesc>Figure 1 shows the training loss function of the autoencoder. Further, two</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: (A) The training loss function is shown. (B) A representative sinus wave (plus noise) and the reconstructed waveform from two-dimensional latent space by the autoencoder is depicted. (C) The same is shown for a representative cosine wave (plus noise). MSE = mean squared error, b = b weight, KL = Kullback-Leiber divergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>1 steps and then by selecting the prior that resulted in the highest Silhouette score (0.52). The two clusters as determined by the BGMM procedure also resulted in a Calinski Harabasz score of 167. 96 indicating coherent clusters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Locations of the 80 sine and 80 cosine waveforms in the two-dimensional space after encoding. A Bayesian Gaussian Mixture Model procedure with a covariance prior of 0.11 indicated best clustering using two clusters (Silhouette score = 0.52, Calinski Harabasz score = 167. 96). The grey shaded heat map indicates the posterior certainty derived from the Bayesian Gaussian Mixture Model clustering procedure. P (cluster | x) = maximal probability given the data.</figDesc><graphic coords="18,85.05,70.85,260.55,260.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>0 s: t(164) = -2.76, pcorrected = 0.024, BF10 = 3.35, median d = -0.21, 95% CI: [-0.36, -0.06]; minimum t value at 2 s: t(164) = -4.04, pcorrected = 0.002, BF10 = 185.81, median d = -0.31, 95% CI: [-0.46, -0.15]; see Figure 3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Mean HR changes compared to baseline for threat and neutral picture contents. The error bars represent the standard errors. * p &lt; 0.05 (corrected for multiple comparisons) and BF10 &gt;= 3.</figDesc><graphic coords="19,85.00,72.00,223.70,241.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>shows the training loss function of the autoencoder. Again 2000 training epochs were far enough, and more epochs would not have improved the loss function further. Additionally, two representative HR response waveforms and their corresponding reconstructions from a two-dimensional latent space (decoding) by the autoencoder are shown.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: (A) The training loss function is shown. (B) A representative HR waveform (participant ID: 99) and the reconstructed waveform from the two-dimensional latent space by the autoencoder is depicted. (C) The same is shown for another representative participant (ID: 66). MSE = mean squared error, b = b weight, KL = Kullback-Leiber divergence, HR = heart rate, bpm = beats per minute, ID = identity code</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>autoencoder were best fitted by 3 clusters (AUT approach Figure 5A, covariance prior = 2.11, Silhouette score = 0.56, Calinski-Harabasz score = 235.13). In contrast, the BGMM explained best the locations of the participants in the nine-dimensional time bin space by 2 clusters (ATP approach Figure 5B, covariance prior = 0.11, Silhouette score = 0.55, Calinski-Harabasz score = 197.71). Although the Silhouette scores of both approaches were similar, the Calinski-Harabasz score indicated superior clustering in the latent space of the autoencoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: (A) The locations (colored dots) of the encoded HR responses in twodimensional latent space are shown. A Bayesian Gaussian Mixture Model procedure with a covariance prior of 2.11 indicated best clustering using three clusters (Silhouette score = 0.56, Calinski-Harabasz score = 235.13). The grey heat map indicates the posterior certainty. (B) The same is shown for the two clusters in nine-dimensional (time bin) space projected by a PCA into a two-dimensional space. Here, a Bayesian Gaussian Mixture procedure with a covariance prior of 0.11 indicated best clustering using two clusters (Silhouette score = 0.55, Calinski-Harabasz score = 197.71). AUT = autoencoder approach, ATP = all time points approach. max P(cluster | x) = maximal probability of the cluster given the data.</figDesc><graphic coords="21,85.05,70.85,469.18,224.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>) = 2.79, pcorrected = 0.024, BF10 = 4.89, median d = 0.40, 95% CI: [-0.10, -0.70]; maximum t-value at 3 s: t(43) = 4.26, p = 0.001, BF10 = 379.77, median d = 0.64, 95% CI: [0.31, 0.96]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: (A) Mean heart rate (HR) changes elicited by threat and neutral pictures for the first cluster produced by the autoencoder approach are shown. (B &amp; C) show the same information for clusters 2 and 3. (D) Mean HR changes for threat and neutral picture content for the first cluster generated by directly clustering using all time points are shown. (E) The same information is shown for the second cluster. Error bars represent s. e. m. AUT = autoencoder, ATP = all time points. * pcorrected &lt;= 0.05 and BF10 &gt;= 3, ~ pcorrected = 0.06 and BF10 &gt;= 3</figDesc><graphic coords="23,85.05,70.85,424.90,306.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: The left panel shows the raincloud plot of mean cosine similarity scores across clusters for heart rate change waveforms obtained by the ATP (green) and AUT (orange) approaches. Each point corresponds to the mean similarity of a participant's HR waveform to all other participants' HR time series in a cluster (averaged across all clusters, see methods). The middle panel and right panel depict the corresponding box plots and density plots, respectively.</figDesc><graphic coords="24,85.05,70.85,424.90,287.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 8 :</head><label>8</label><figDesc>Figure 8: (A) The locations (colored dots) of the encoded HR responses in twodimensional latent space are shown. The latent representations were clustered using the model weights of the pre-trained Bayesian Gaussian Mixture procedure trained on the previous training HR data set (N = 165). The grey heat map indicates the posterior certainty. (B), (C), and (D) show the original and predicted (by the autoencoder) HR change waveforms of three representative participants pertaining to one of the three clusters. The HR change responses were evoked by the CS+ during the learning trials. max P(cluster | x) = maximal probability of the cluster given the data.</figDesc><graphic coords="25,85.05,70.85,424.90,436.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: (A) Mean heart rate (HR) changes elicited by the CS+ and CS-for the first cluster produced by the pre-trained autoencoder are shown. (B &amp; C) show the same information for clusters 2 and 3. Error bars represent s. e. m. * pcorrected &lt;= 0.05 and BF10 &gt;= 3, ~ pcorrected = 0.058 and BF10 &gt;= 3.</figDesc><graphic coords="26,85.05,411.05,424.90,156.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>(</head><label></label><figDesc><ref type="bibr" target="#b42">Santos-Mayo &amp; Moratti, 2025)</ref>, the application of k-means clustering within a predefined time window yielded one predominant group characterized by orienting responses, indexed by fear bradycardia to the CS+, and a smaller subgroup showing a defensive response associated with HR acceleration. In contrast, applying the pre-trained VAE and BGMM-trained on a larger dataset-allowed the identification of three distinct patterns: HR deceleration, HR deceleration followed by acceleration, and immediate HR acceleration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="39,70.85,126.45,324.60,324.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The analysis steps and the corresponding Python scripts are listed. VAE = variational autoencoder, BGMM = Bayesian Gaussian Mixture Model procedure, AUT = autoencoder approach, ATP = all time points approach, HR = heart rate</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements: This work was funded by the <rs type="funder">Ministerio de Ciencia, Innovación y Universidades of the Spanish government</rs> and the <rs type="funder">Agencia Española de Investigación (AEI)</rs> under the grant number: <rs type="grantNumber">PID2021-126074NB-I00</rs>.</p></div>
<div><head>Usage of AI:</head><p>For the manuscript ChatGPT was used to correct the English and assisted in developing the Python code for the analysis.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_VSaKcfY">
					<idno type="grant-number">PID2021-126074NB-I00</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data availability statement: All data and code can be downloaded at: https://osf.io/k58uy/</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">Abdelaziz</forename><surname>Dahou Djilali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Narayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Boussaid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Almazrouei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Debbah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2308.06112</idno>
		<idno type="arXiv">arXiv:2308.06112</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2308.06112" />
		<title level="m">Lip2Vec: Efficient and Robust Visual Speech Recognition via Latent-to-Latent Visual to Audio Representation Mapping. arXiv E-Prints</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Latent signal models: Learning compact representations of signal evolution for improved time-resolved, multi-contrast MRI</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Arefeen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Adalsteinsson</surname></persName>
		</author>
		<idno type="DOI">10.1002/mrm.29657</idno>
		<ptr target="https://doi.org/10.1002/mrm.29657" />
	</analytic>
	<monogr>
		<title level="j">Magnetic Resonance in Medicine</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="483" to="501" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2006.11477</idno>
		<idno type="arXiv">arXiv:2006.11477</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2006.11477" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neuropsychobiology of fear-induced bradycardia in humans: Progress and pitfalls</title>
		<author>
			<persName><forename type="first">S</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nazzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Lonsdorf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Thayer</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41380-024-02600-x</idno>
		<ptr target="https://doi.org/10.1038/s41380-024-02600-x" />
	</analytic>
	<monogr>
		<title level="j">Molecular Psychiatry</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Ben</surname></persName>
		</author>
		<idno type="DOI">10.17605/OSF.IO/AUZJY</idno>
		<ptr target="https://doi.org/10.17605/OSF.IO/AUZJY" />
		<title level="m">Luminance control of colorful images</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The control of the false discovery rate in multiple testing under dependency</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yekutieli</surname></persName>
		</author>
		<idno type="DOI">10.1214/aos/1013699998</idno>
		<ptr target="https://doi.org/10.1214/aos/1013699998" />
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1165" to="1188" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<ptr target="https://link.springer.com/book/9780387310732" />
		<title level="m">Pattern Recognition and Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>st ed.</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Natural selective attention: Orienting and emotion</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-8986.2008.00702.x</idno>
		<ptr target="https://doi.org/10.1111/j.1469-8986.2008.00702.x" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Emotion and motivation I: Defensive and appetitive reactions in picture processing</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Codispoti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Cuthbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
		<idno type="DOI">10.1037/1528-3542.1.3.276</idno>
		<ptr target="https://doi.org/10.1037/1528-3542.1.3.276" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="276" to="298" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Orienting and Emotional Perception: Facilitation, Attenuation, and Interference</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Keil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2012.00493</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2012.00493" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A dendrite method for cluster analysis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Caliński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harabasz</surname></persName>
		</author>
		<idno type="DOI">10.1080/03610927408827101</idno>
		<ptr target="https://doi.org/10.1080/03610927408827101" />
	</analytic>
	<monogr>
		<title level="j">Communications in Statistics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">Calvo</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Díaz Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Molina Blanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pampín Del Río</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sánchez Del Coral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Moratti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename></persName>
		</author>
		<title level="m">Relax and orient! Progressive muscle relaxation biases towards orienting and reduced defense responses during threat processing</title>
		<imprint/>
	</monogr>
	<note>in preparation</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Threat imminence modulates neural gain in attention and motor relevant brain circuits in humans</title>
		<author>
			<persName><forename type="first">J</forename><surname>Echegaray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moratti</surname></persName>
		</author>
		<idno type="DOI">10.1111/psyp.13849</idno>
		<ptr target="https://doi.org/10.1111/psyp.13849" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">58</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ready and waiting: Freezing as active action preparation under threat</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Gladwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Van Ast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roelofs</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neulet.2016.03.027</idno>
		<ptr target="https://doi.org/10.1016/j.neulet.2016.03.027" />
	</analytic>
	<monogr>
		<title level="j">Neuroscience Letters</title>
		<imprint>
			<biblScope unit="volume">619</biblScope>
			<biblScope unit="page" from="182" to="188" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Heart-rate change as a component of the orienting response</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">K</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Clifton</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0023258</idno>
		<ptr target="https://doi.org/10.1037/h0023258" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="305" to="320" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Affective learning: Awareness and aversion</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Hamm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Vaitl</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-8986.1996.tb02366.x</idno>
		<ptr target="https://doi.org/10.1111/j.1469-8986.1996.tb02366.x" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="698" to="710" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Hashemi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Gladwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>De Valk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kaldewaij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Van Ast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B J</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Klumpers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roelofs</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-019-40917-8</idno>
		<ptr target="https://doi.org/10.1038/s41598-019-40917-8" />
	</analytic>
	<monogr>
		<title level="m">Neural Dynamics of Shooting Decisions and the Switch from Freeze to Fight</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">4240</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Individual Differences in Autonomic Response: Conditioned Association or Conditioned Fear?</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Hodes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-8986.1985.tb01649.x</idno>
		<ptr target="https://doi.org/10.1111/j.1469-8986.1985.tb01649.x" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="545" to="560" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Real-Time Bearing Fault Diagnosis Model Based on Siamese Convolutional Autoencoder in Industrial Internet of Things</title>
		<author>
			<persName><forename type="first">H.-X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z.-Z</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1109/JIOT.2023.3307127</idno>
		<ptr target="https://doi.org/10.1109/JIOT.2023.3307127" />
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="3820" to="3831" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Discovering Digital Tumor Signatures-Using Latent Code Representations to Manipulate and Classify Liver Lesions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kleesiek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kersjes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ueltzhöffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Köthe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-P</forename><surname>Schlemmer</surname></persName>
		</author>
		<idno type="DOI">10.3390/cancers13133108</idno>
		<ptr target="https://doi.org/10.3390/cancers13133108" />
	</analytic>
	<monogr>
		<title level="j">Cancers</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page">3108</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">What&apos;s new in Psychtoolbox 3?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kleiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Brainard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Individual Differences in Fear and Autonomic Reactions to Affective Stimulation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Klorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Weissberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Wiesenfeld</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-8986.1977.tb01154.x</idno>
		<ptr target="https://doi.org/10.1111/j.1469-8986.1977.tb01154.x" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="45" to="51" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Some autonomic-central nervous system interrelationships</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Lacey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Lacey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Physiological Correlates of Emotion</title>
		<imprint>
			<publisher>Academmic Press</publisher>
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Cuthbert</surname></persName>
		</author>
		<idno>A-6</idno>
		<title level="m">International affective picture system (IAPS): Affective ratings of pictures and instruction manual</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>University of Florida</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Freezing promotes perception of coarse visual features</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lojowska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Gladwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Roelofs</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000117</idno>
		<ptr target="https://doi.org/10.1037/xge0000117" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1080" to="1088" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">When Threat Is Near, Get Out of Here: Dynamics of Defensive Behavior During Freezing and Active Avoidance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Löw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weymar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">O</forename><surname>Hamm</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797615597332</idno>
		<ptr target="https://doi.org/10.1177/0956797615597332" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1706" to="1716" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">How Orienting and Defence Drives Oscillatory Responses in Human Visual and Motor Cortical Circuits During Viewing of Threat Pictures: Evidence From ssVEPs and Beta-Band Desynchronization</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Martín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F C</forename><surname>García</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Del Corral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Del Río</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moratti</surname></persName>
		</author>
		<idno type="DOI">10.1111/ejn.70157</idno>
		<ptr target="https://doi.org/10.1111/ejn.70157" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">70157</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<ptr target="https://github.com/mathworks/Anomaly-detection-using-Variational-Autoencoder-VAE" />
		<title level="m">MathWorks</title>
		<editor>
			<persName><forename type="first">/Anomaly-Detection-Using-Variational-Autoencoder-Vae-</forename><surname>Mathworks</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2024. 2020</date>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<author>
			<persName><forename type="first">D</forename><surname>Mobbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Headley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2019.12.016</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2019.12.016" />
	</analytic>
	<monogr>
		<title level="m">Space, Time, and Fear: Survival Computations along Defensive Circuits</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="228" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">R-DECO: An open-source Matlab based graphical user interface for the detection and correction of R-peaks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Moeyersons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Huffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Willems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Varon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title/>
		<idno type="DOI">10.7717/peerj-cs.226</idno>
		<ptr target="https://doi.org/10.7717/peerj-cs.226" />
	</analytic>
	<monogr>
		<title level="j">PeerJ. Computer Science</title>
		<imprint>
			<biblScope unit="page" from="5" to="e226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Cortical activation during Pavlovian fear conditioning depends on heart rate response patterns: An MEG study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moratti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Keil</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogbrainres.2005.07.006</idno>
		<ptr target="https://doi.org/10.1016/j.cogbrainres.2005.07.006" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Brain Research</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="459" to="471" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fear but not awareness predicts enhanced sensory processing in fear conditioning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moratti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Keil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1464-8986.2006.00386.x</idno>
		<ptr target="https://doi.org/10.1111/j.1464-8986.2006.00386.x" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="216" to="226" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Motivated attention in emotional picture processing is reflected by activity modulation in cortical attention networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moratti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Keil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stolarova</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2003.10.030</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2003.10.030" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="954" to="964" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">P</forename><surname>Pavlov</surname></persName>
		</author>
		<title level="m">Conditioned reflexes</title>
		<imprint>
			<publisher>Dover</publisher>
			<date type="published" when="1927">1927</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">KARDIA: A Matlab software for the analysis of cardiac interbeat intervals</title>
		<author>
			<persName><forename type="first">P</forename><surname>Perakakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joffily</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Guerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vila</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cmpb.2009.10.002</idno>
		<ptr target="https://doi.org/10.1016/j.cmpb.2009.10.002" />
	</analytic>
	<monogr>
		<title level="j">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="89" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The continuing problem of incorrect heart rate estimation in psychophysiological studies: An off-line solution for cardiotachometer users</title>
		<author>
			<persName><forename type="first">Reyes</forename><surname>Del Paso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Vila</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno type="DOI">10.1016/S0301-0511(98)00039-8</idno>
		<ptr target="https://doi.org/10.1016/S0301-0511(98)00039-8" />
	</analytic>
	<monogr>
		<title level="j">Biological Psychology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="269" to="279" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Freeze for action: Neurobiological mechanisms in animal and human freezing</title>
		<author>
			<persName><forename type="first">K</forename><surname>Roelofs</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2016.0206</idno>
		<ptr target="https://doi.org/10.1098/rstb.2016.0206" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<date type="published" when="1718">2017. 1718. 20160206</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Facing Freeze: Social Threat Induces Bodily Freeze in Humans</title>
		<author>
			<persName><forename type="first">K</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Hagenaars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stins</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797610384746</idno>
		<ptr target="https://doi.org/10.1177/0956797610384746" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1575" to="1581" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Silhouettes: A graphical aid to the interpretation and validation of cluster analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rousseeuw</surname></persName>
		</author>
		<idno type="DOI">10.1016/0377-0427(87)90125-7</idno>
		<ptr target="https://doi.org/10.1016/0377-0427(87)90125-7" />
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="53" to="65" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Heart rate pattern and resting heart rate variability mediate individual differences in contextual anxiety and conditioned responses</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sevenster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hamm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Beckers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kindt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijpsycho.2015.09.004</idno>
		<ptr target="https://doi.org/10.1016/j.ijpsycho.2015.09.004" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="567" to="576" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Concept2Brain: An AI model for predicting subject-level neurophysiological responses to text and pictures</title>
		<author>
			<persName><forename type="first">A</forename><surname>Santos-Mayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mirifar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Tebbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Keil</surname></persName>
		</author>
		<idno type="DOI">10.1101/2025.08.04.668476v1</idno>
		<ptr target="https://www.biorxiv.org/content/10.1101/2025.08.04.668476v1" />
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">How fear conditioning affects the visuocortical processing of context cues in humans. Evidence from steady state visual evoked responses</title>
		<author>
			<persName><forename type="first">A</forename><surname>Santos-Mayo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moratti</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2024.11.005</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2024.11.005" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="21" to="37" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A latent diffusion approach to visual attribution in medical imaging</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tirunagari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Windridge</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-024-81646-x</idno>
		<ptr target="https://doi.org/10.1038/s41598-024-81646-x" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">962</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Perception and the conditioned reflex</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Sokolov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1963">1963</date>
			<pubPlace>Pergamon</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Latent neural dynamics encode temporal context in speech</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Metzger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Oganian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.heares.2023.108838</idno>
		<ptr target="https://doi.org/10.1016/j.heares.2023.108838" />
	</analytic>
	<monogr>
		<title level="j">Hearing Research</title>
		<imprint>
			<biblScope unit="volume">437</biblScope>
			<biblScope unit="page">108838</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Cardiac and forearm plethysmographic responses to high intensity auditory stimulation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Turpin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A T</forename><surname>Siddle</surname></persName>
		</author>
		<idno type="DOI">10.1016/0301-0511(78)90029-7</idno>
		<ptr target="https://doi.org/10.1016/0301-0511(78)90029-7" />
	</analytic>
	<monogr>
		<title level="j">Biological Psychology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="267" to="281" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">SPARTAN: Data-Adaptive Symbolic Time-Series Approximation</title>
		<author>
			<persName><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Paparrizos</surname></persName>
		</author>
		<idno type="DOI">10.1145/3725357</idno>
		<ptr target="https://doi.org/10.1145/3725357" />
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Manag. Data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="220" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Quantum stacked autoencoder fault diagnosis model for bearing faults</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1784/insi.2023.65.11.631</idno>
		<ptr target="https://doi.org/10.1784/insi.2023.65.11.631" />
	</analytic>
	<monogr>
		<title level="j">Insight -Non-Destructive Testing and Condition Monitoring</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="631" to="638" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
