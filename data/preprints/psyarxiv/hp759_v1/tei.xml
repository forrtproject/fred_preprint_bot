<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F4D053A5513A7268A7FC9CABC7C14937</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T02:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Was this Registered Report pilot tested? Examination of Vaidis</term>
					<term>Sleegers</term>
					<term>Van Leeuwen</term>
					<term>DeMarree</term>
					<term>Saetrevik</term>
					<term>Ross</term>
					<term>... &amp; Priolo</term>
					<term>D. (2024) Vaidis</term>
					<term>D. C.</term>
					<term>Sleegers</term>
					<term>W. W.</term>
					<term>Van Leeuwen</term>
					<term>F.</term>
					<term>DeMarree</term>
					<term>K. G.</term>
					<term>Saetrevik</term>
					<term>B.</term>
					<term>Ross</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>R. M., ... &amp; Priolo, D. (2024), published in AMPPS, included 104 authors from 39 research teams attempting to replicate the induced-compliance paradigm in study 1 Croyle and Cooper (1983). The study was preregistered and receives public marks for transparency and rigor. Yet, one thing that is transparently missing is any mention of pilot or pretesting the study to make sure it works before having the 39 labs try to replicate with those materials. This leaves the entire effort open to small problems, since it is also the first time most of the teams were trying a study like this. Thus, we ask what piloting mechanisms if any were employed, and suggest to the community more generally that it makes sense to make sure a protocol is working before sending it out to e.g., 39 places.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr">Vaidis et al., (2024)</ref> <p>brought together 39 teams to try and replicate the induced-compliance paradigm in study 1 <ref type="bibr" target="#b3">Croyle and Cooper (1983)</ref>. The study is reported as a failure with the authors reporting that, 'The primary analyses failed to support the core hypothesis'... and that 'Overall, the results call into question whether the induced-compliance paradigm provides robust evidence for cognitive dissonance' (abstract). While the paper scores highly for transparency, the paper or registration documents do not report any pre or pilot testing of the study before having e.g., 39 teams try it, which is curious and deserves more attention.</p><p>The basic argument is that it makes sense to pilot test and make sure the study is really working before trying it across 39 teams. This will also help improve the replicability rate of the field. If the project was 'properly' pilot tested, it should have worked at least once and this should be transparently reported. Conversely, if the goal is to show that the study does not work, having 39 teams try for their first time using an unpiloted protocol is also not the best way.</p><p>Single failed replication projects that do not include pilot testing or multiple attempts are less ideal than 'positive' replications which are able to 'certify' that something does or will work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>If the materials were piloted, it should be reported that it worked at least one time</head><p>The project has a significant focus on transparency, which makes it surprising that they do not report trying to make sure it works before sending it out to the 39 teams. If the materials were pilot tested it should be reported to have worked at least once, or if the materials did not work, they could have changed it so that it does work.</p><p>Piloting the work once to make sure everything is running smoothly before trying it across e.g., 39 sites simply makes sense. Registered Reports work to establish a new level of transparency and quality in the mind sciences, and this should include high quality piloting protocols, and these should be reported in the transparent (registered) report. These tests will prevent such large scale failures to replicate, and help the field have a better 'replicability rate'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Does it make sense to try it in 39 places if we cannot get it to work in a single place?</head><p>If the effect cannot be produced in a single place, then it is probably not worth examining whether it works across 39 sites. Still, we hope the community agrees that testing it at a single site should be a prerequisite for testing it across 39 sites. The way that the study was designed suggests that the authors believed that the study would work but forgot to test it before sending it out. This suggests a small methodological error, rather than that the entire field is not true. These questions are not idle, and there have been convincing examples of small errors that set a whole series of replications on the wrong track. One of the best known examples is <ref type="bibr">Wagenmakers et al., (2015)</ref> and the resulting Many Smiles Collaboration <ref type="bibr">(Coles, 2019)</ref>.</p><p>Wagenmakers led 17 labs in trying to replicate the facial feedback hypothesis <ref type="bibr" target="#b6">(Strack, Martin, &amp; Stepper, 1988)</ref>. For transparency and ease they decided to videotape participants, but this was later shown to be important in determining whether the effect appeared or not <ref type="bibr" target="#b4">(Noah, Schul, Mayo, 2018)</ref>. Finally the Many Labs effect confirmed the existence of a small but real facial feedback mechanism existing, despite the failure to replicate from <ref type="bibr">Wakenmakers et al., (2015)</ref>.</p><p>Especially when the 39 studies fail, the fact that it was not piloted becomes a significant problem for the research team, because they (should) then have to explain why it did not work and why they did not pilot it. It is literally designing a process without having done it well before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Piloting matters even in and especially for registered reports</head><p>Some may argue that they should not need to pilot a study if they do not make substantial changes to the original report (which could in theory act as a pilot). This is not a strong argument because there are many things where even with very clear instructions, many people cannot do it, for instance putting furniture together or making fire with sticks. We additionally know that there are important details about the methods which are not actually and explicitly mentioned in the methods section of published papers <ref type="bibr" target="#b0">(Brenninkmeijer, Derksen, &amp; Rietzschel, 2019)</ref>.</p><p>Especially if we will treat the results of the study as particularly definitive, the study should be done to the highest standards, and this probably includes some pilot testing to make sure everything is working before the big effort replication. Unfortunately, and this is not the only instance of it <ref type="bibr">(Wagenmakers et al., 2015)</ref>, this study appears to have been done without having been piloted, perhaps in part leading to its failure.</p><p>The question is whether this registered report is really testing the replicability of the effect, or the replicability of the effect on one's first unpiloted attempt.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Who gets better results, 39 people doing it the first time or one person doing it 39 times?</head><p>Another way to think about this study is e.g., making shoes. This project brought together 39 teams who had never made e.g., a particular pair of shoes before (i.e., forced compliance paradigm), even if they make belts, purses, or even other shoes in their normal jobs -they all went to school together and have similar degrees.</p><p>Notably, these 39 teams came together to replicate the best results produced by a team that was working on the project for some years. That is, their first, even non-piloted, efforts are being compared to the best that the original researchers can produce, those they chose to send to high impact journals. In addition to it being the replication team's first time trying to make this pair of shoes/ effect, the set of instructions and materials for making the effect had never actually been used before being sent out, meaning that the instructions could be flawed.</p><p>The question is who will get 'better' results, the team that tried some times and submits their best results or the group of 39 that each tried once. We believe the team that was able to do it a few times and learn between the trials will produce better and more true results. In the end it is an empirical question, but it is notable that the Many Labs project have asked people to try a single time and report on their results. The results might be different if teams are able to try a few times while learning before reporting their 'best estimate' results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Using big effort replications to indicate what really works rather than what might not</head><p>Given their expense, Registered Replications are probably better used as a 'gold standard' for a field in terms of registering that something is going to work across many sites and circumstances. This would mean that the study and set of materials should work in e.g., a high school classroom and could thus be used to teach the field. This would naturally include some pilot testing to ensure that everything is working smoothly before sending it out to the big time test and hopefully successful report. Such will also produce a better 'reproducibility' rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion -Especially large scale studies should be piloted before their 'best estimate'</head><p>Large scale replication efforts are setting new standards for quality and excellence but should still be pilot tested, especially before the big/ best effort replication attempt across e.g., 39 teams. Not only should piloting prevent many of the major failures from happening, thus improving the replicability rate of the field, it will give the researchers a basis from which to start investigating why it failed, if it does (since we know it worked at least once).</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Informal laboratory practices in psychology</title>
		<author>
			<persName><forename type="first">J</forename><surname>Brenninkmeijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Derksen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rietzschel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Collabra: Psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">45</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Coles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>March</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Marmolejo-Ramos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Arinze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">L</forename><surname>Ndukaihe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A multi-lab test of the facial feedback hypothesis by the Many Smiles Collaboration</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Liuzza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1731" to="1742" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Dissonance arousal: physiological evidence</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Croyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality and social psychology</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">782</biblScope>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">When both the original study and its failed replication are correct: Feeling observed eliminates the facial-feedback effect</title>
		<author>
			<persName><forename type="first">T</forename><surname>Noah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Schul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mayo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">657</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reflection on the smiling registered replication report</title>
		<author>
			<persName><forename type="first">F</forename><surname>Strack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="929" to="930" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Inhibiting and facilitating conditions of the human smile: A non obtrusive test of the facial feedback hypothesis</title>
		<author>
			<persName><forename type="first">F</forename><surname>Strack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stepper</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.54.5.768</idno>
		<ptr target="http://dx.doi.org/10.1037/0022-3514.54.5.768" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="768" to="777" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Vaidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Sleegers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Leeuwen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Demarree</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Saetrevik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A multilab replication of the induced-compliance paradigm of cognitive dissonance</title>
		<author>
			<persName><forename type="first">D</forename><surname>Priolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Methods and Practices in Psychological Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">25152459231213375</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Beek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dijkhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">F</forename><surname>Gronau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Adams</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Zwaan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Registered replication report: strack, martin, &amp; stepper</title>
		<imprint>
			<date type="published" when="1988">2016. 1988</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="917" to="928" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
