<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hierarchical surprise signals in naturalistic violation of expectations</title>
				<funder>
					<orgName type="full">Max Planck Society</orgName>
				</funder>
				<funder>
					<orgName type="full">Barbara-Wengeler-Foundation</orgName>
				</funder>
				<funder ref="#_BVasB6h">
					<orgName type="full">Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Vincent</forename><surname>Plikat</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Centre for Integrative Neuroscience</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Max-Planck Institute for Biological Cybernetics</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pablo</forename><forename type="middle">R</forename><surname>Grassi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Centre for Integrative Neuroscience</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Max-Planck Institute for Biological Cybernetics</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Julius</forename><surname>Frack</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Rocket Magic</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Andreas</forename><surname>Bartels</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Centre for Integrative Neuroscience</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Max-Planck Institute for Biological Cybernetics</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Hierarchical surprise signals in naturalistic violation of expectations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">02B81DE3CB1C57EB060719D0342F3EE8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-23T06:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>surprise</term>
					<term>magic</term>
					<term>predictive coding</term>
					<term>violation of expectation</term>
					<term>intuitive physics</term>
					<term>fMRI Word count: Abstract: 250</term>
					<term>Introduction: 900</term>
					<term>Discussion: 1818</term>
					<term>Total: ca</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Surprise responses signal both, high-level cognitive alerts that information is missing, and increasingly specific back-propagating error signals that allow updates in processing nodes.</p><p>Studying surprise is hence central for cognitive neuroscience to understand internal world representations and learning. Yet, only few prior studies used naturalistic stimuli targeting our high-level understanding of the world. Here, we use magic tricks in an fMRI experiment to investigate neural responses to violations of core assumptions held by humans about the world. We showed participants naturalistic videos of three types of magic tricks, involving objects appearing, changing color, or disappearing, along with control videos without any violation of expectation. Importantly, the same videos were presented with and without prior knowledge about the tricks' explanation. Results revealed generic responses in frontoparietal areas, together with responses specific to each of the three trick types in posterior sensory areas. A subset of these regions, the midline areas of the default mode network (DMN), showed surprise activity that depended on prior knowledge. Equally, sensory regions showed sensitivity to prior knowledge, reflected in differing decoding accuracies. These results suggest a hierarchy of surprise signals involving three processing stages: first, generic processing of violation of expectations in frontoparietal areas. Second, surprise signals in sensory regions that are specific to the processed feature, demonstrating propagation of surprise signals to mid-level visual areas. Third, priorknowledge dependent processing of surprise signals in parts of the DMN, showing its involvement in internal state monitoring and in making sense of events as they unfold in time.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Prior experience and "intuitive" knowledge about the physical world guide our perception and allow for a meaningful interaction with the environment. They set up constraints on our expectations based on what we believe to be possible in the world. For example, prior world-knowledge informs us that objects do not vanish of existence if occluded (object permanency), that objects tend to keep their features (feature constancy), that objects cannot pass through other objects (solidity), that objects to not appear out of the blue, and so forth. Informed expectations based on these intuitive physical priors allow us to quickly make sense of incoming sensory information. Such expectations have been shown to strongly modulate perception <ref type="bibr" target="#b15">(de Lange et al., 2018)</ref>. For example, a "light-from-above" prior constrains depth perception from shading <ref type="bibr" target="#b1">(Adams et al., 2004)</ref>, and knowledge that objects cannot occupy the same place at the same time explains our inability to perceive two objects simultaneously in bistable perception <ref type="bibr" target="#b35">(Hohwy et al., 2008)</ref>.</p><p>Accordingly, perception can be understood as an inferential process in which top-down informed expectations are matched with incoming sensory information <ref type="bibr" target="#b22">(Friston, 2010</ref><ref type="bibr" target="#b23">(Friston, , 2005;;</ref><ref type="bibr" target="#b42">Lee and Mumford, 2003;</ref><ref type="bibr" target="#b54">Rao and Ballard, 1999)</ref>. In this "predictive processing" framework deviations between expectations and incoming data (i.e., prediction errors) are used to update an internal model of the world at different levels of complexity and abstraction. Higher-level priors (like object permanency) represent more abstract aspects of the world and constrain lower-level inferences that represent more immediate features of the world (like a particular object) <ref type="bibr" target="#b11">(Clark, 2013;</ref><ref type="bibr" target="#b33">Hohwy, 2014)</ref>. In this context, intuitive physical knowledge can be thought of as an internal model representing different aspects of the causal structure of the physical world, not unsimilar to a "physics engine" in a virtual environment <ref type="bibr" target="#b9">(Battaglia et al., 2013)</ref>.</p><p>This prior knowledge of physical principles can be studied using events that seemingly violate them. For example, evidence from developmental psychology using so-called violation of expectation (VOE) paradigms suggest that infants acquire important aspects about the workings of the physical world during the first year of life, such as object permanency and solidity <ref type="bibr" target="#b32">(Hespos et al., 2009;</ref><ref type="bibr" target="#b72">Wang, 2004;</ref><ref type="bibr" target="#b75">Wynn, 1992)</ref>. However, it is largely unclear how surprise-responses relating to intuitive physical principles are represented in the human brain. Most previous neuroimaging studies investigated responses to lower-level VOE, e.g. using paradigms involving infrequent (and thus unexpected) stimuli (e.g., <ref type="bibr" target="#b16">Egner et al., 2010;</ref><ref type="bibr">Kok et al., 2012a;</ref><ref type="bibr" target="#b68">Todorovic et al., 2011;</ref><ref type="bibr" target="#b73">Wessel et al., 2012)</ref>, or omission of expected stimuli <ref type="bibr">(Kok et al., 2012b;</ref><ref type="bibr" target="#b58">SanMiguel et al., 2013;</ref><ref type="bibr">e.g., Wacongne et al., 2011)</ref>. These studies revealed lower-level stimulus-specific prediction errors in modality-and feature-specific areas. In contrast, studies investigating VOE of higher-level physical principles using more complex stimuli such as computer generated animations <ref type="bibr" target="#b7">(Bardi et al., 2017;</ref><ref type="bibr" target="#b43">Liu et al., 2024)</ref> or naturalistic videos showing magic tricks <ref type="bibr" target="#b14">(Danek et al., 2015;</ref><ref type="bibr" target="#b49">Parris et al., 2009</ref>) revealed higher-level surprise signals in frontoparietal areas. This is in line with a frontoparietal role in the representation of physical concepts <ref type="bibr" target="#b19">(Fischer et al., 2016;</ref><ref type="bibr" target="#b62">Schwettmann et al., 2019)</ref>. However, higher-level VOE studies have hitherto not observed VOErelated activity in sensory areas.</p><p>Here, we set out to unify and resolve this longstanding divergence of results between highlevel and low-level VOE paradigms by using a novel VOE paradigm. Our paradigm was designed to uncover hierarchical VOE signals of the brain's internal world model. It contained a battery of standardized magic videos that we presented to human participants while measuring fMRI responses to investigate: 1) which regions are generally involved when viewing natural videos that violate physical principles, 2) whether specific types of violations, like appearance of objects, or changes of color, modulate sensory areas known to process the feature concerned, 3) whether knowledge of the explanation of a given magic trick modulates the observed VOE activity.</p><p>To this aim, we created and validated videos for a naturalistic VOE paradigm showing either dedicated magic tricks (to create the illusion of seemingly impossible events to actually occur, cf. <ref type="bibr" target="#b26">Grassi and Bartels, 2021)</ref> or matched control actions that involved no violation of physical principles. The VOE videos were designed to evoke surprise responses related to unexpected object appearance, disappearance of objects, and feature change (color-changing objects). They were performed by a professional magician (Julius Frack), and each trick-type was performed using three common objects (balls, playing cards and pencils). Each trick was presented before and after revealing the method of the tricks. This allowed us to compare responses with and without VOE using identical videos.</p><p>Univariate analyses revealed a hierarchy of surprise signals: frontoparietal areas, including areas of the default mode network (DMN), were involved when perceiving events violating physical principles regardless of the type of trick used. In contrast, posterior sensory areas were modulated specifically by the type of expectation-violation, such as color-processing medial fusiform cortex by color change, and object selective LOC by the appearance of objects. Controls indicate that their modulation is due to the feature-specific surprise and not due to the feature-change. Multivariate analyses extended the results: information about the specific types of expectationviolations was exclusively encoded in posterior regions, and significantly decodable down to the earliest levels of cortical visual processing (V1-V3). Additionally, decoding accuracy significantly decreased with prior knowledge, revealing a reduction in surprise signals. Together, our results demonstrate a generic response in frontoparietal areas to violation of physical principles, along with concurrent representations of specific expected information in early sensory areas.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We performed fMRI on 27 subjects. Three subjects were excluded from data analysis due to excessive movement and/or sleepiness during the scanning sessions. Data from a total of 24 subjects were analyzed (16 female; 8 male; mean age 24.4 ± 4.3 SD years). All subjects had normal or corrected to normal vision, no history of neurological impairments nor contraindication for fMRI. Participants had no expertise as magicians and were naive to the magic tricks used. Participants provided written informed consent prior to the experiment. The study was approved by the ethics committee of the University Clinic Tübingen and was conducted in accord with the Declaration of Helsinki.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VOE stimuli</head><p>Video recordings. A set of 63 videos were created for the VOE study. In accord with previous work <ref type="bibr" target="#b49">(Parris et al., 2009)</ref>, we created videos for three different conditions: the videos showed either magic tricks (magic condition, 18 videos), similar actions without a magic event (control condition, 18 videos) or unusual actions with the objects used in the magic tricks (unusual condition, 9 videos). We included the unusual condition to investigate neural correlates of surprise in a similar setting while not violating any physical concept (cf. <ref type="bibr" target="#b49">Parris et al., 2009)</ref>. We further created explanation videos showing how each of the magic tricks was achieved (18 videos).</p><p>All videos were performed by professional illusionist Julius Frack in a standardized setting consisting of a black background and a black table (see Figure <ref type="figure" target="#fig_0">1A</ref> for an example). To investigate the effect of specific VOE, we presented magic tricks showing three different violations of physical principles: appearances (A) (i.e., a red object appears), color changes (C) (i.e., a red object changes color to blue) and vanishes (V) (i.e., a red object disappears) (see Figure <ref type="figure" target="#fig_0">1C</ref>). To generalize across objects, we used three easily distinguishable objects: balls, playing cards and thick pencils. Each object was used equally often in each trick type. Finally, we created two versions of each type of VOE for each object (e.g., two different videos showing a red ball changing to a blue ball using different methods). Full set of stimuli. Each of these magic tricks had a matched control video that showed the same sequences of actions as the trick, but without VOE (e.g., following the same actions a ball would not change its color). Thus, we had a total of 18 magic videos (3 type of VOEs × 3 objects × 2 methods), with 18 matching control videos and nine unusual videos (3 unusual actions per used object). As the solutions to the magic tricks were revealed in distinct sets throughout the experiment, we used a variety of different methods for each type of VOE. This ensured that participants were only able to infer trick solutions they were intended to understand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Luminance and durations.</head><p>Tricks were recorded in a standardized setting under the same lighting conditions. To balance out remaining inequalities, custom MATLAB (MathWorks, Natick, MA) scripts were used to standardize the videos (resolution of 1920 x 1080 with 25 frames per second), which were filmed on different days and had different lengths. We manually applied white-balance using 5 to 10 selected white-pixels for all videos of a same day, matched the luminance and contrast of the videos based their first frame, and shortened the videos to be no longer than 14 seconds. The final duration of the videos was 12.8 s ± 1.08 s (mean ± SD). Stimulus presentation. Stimuli were presented using MATLAB 2019b using Psychtoolbox3 (version 3.0.16 <ref type="url" target="http://psychtoolbox.org/">http://psychtoolbox.org/</ref>) on a Linux computer and back-projected to a translucent screen mounted at the rear of the scanner bore using a VPIXX Pro projector (VPixx Technologies, Saint-Bruno-de-Montarville, Canada) at a frame rate of 144 Hz. Participants viewed the screen (26.1 x 14.7 visual degrees) via a mirror mounted on the 64-channel head coil (Siemens, Erlangen, Germany) at a distance of 105 cm. To center the stimulus presentation, we cropped 160 pixels from the left and right side of the videos that only showed a black background. Accordingly, the shown part of the videos covered 21.8 x 14.7 visual degrees (1600 x 1080 pixels). Behavioral evaluation of stimuli. Prior to the fMRI experiment we performed two psychophysics experiments with a total of 18 subjects (nine subjects in each experiment) to ensure the suitability of our stimuli and to select the magic tricks to be used in the fMRI experiment (see results in Supplementary Section Behavioral evaluation of stimuli). Participants were shown the videos using the same design as in the fMRI experiment (see Figure <ref type="figure" target="#fig_0">1B</ref>). Participants were surprised when viewing the magic videos, even though they knew they were observing tricks <ref type="bibr" target="#b27">(Grassi et al., 2024)</ref> and systematically reported to be more surprised when viewing the magic videos compared to the matched controls. Moreover, surprise responses to the VOE shown in the magic videos were reduced after providing an explanation to the tricks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental design and procedure</head><p>fMRI runs. Each run consisted of a total of 24 video trials: two repetitions of the six unique magic videos of one object (three types of VOE, each type recorded in two versions), resulting in 12 magic trick presentations; the six matching control videos (shown once); and two repetitions of three additional unusual videos, resulting in six unusual video presentations (see Figure <ref type="figure" target="#fig_0">1D</ref>). The resulting 24 video trials were presented in a pseudo-random order that avoided repetitions of identical videos (different randomizations across runs). Paradigm. The fMRI experiment consisted of three sets with four experimental fMRI runs each. Each set presented videos of only one object (i.e., balls, playing cards or pencils). The presentation order of the object sets was counterbalanced across subjects. After the first two fMRI runs in a set (pre-revelation runs) the method behind each magic trick in the set was revealed by showing the participants each of the magic tricks again together with the matching revelation video. Subjects could watch the videos as often as they wished and were asked to confirm per button press that they understood how each of the tricks was achieved. Thereafter, two more runs showing the same videos were performed (post-revelation runs). Together, each set consisted of two fMRI runs before and two fMRI runs after the explanation of the tricks. A visualization of the experimental design is shown in Figure <ref type="figure" target="#fig_0">1E</ref>. We hypothesized that providing the explanation of the tricks would decrease VOE responses because participants would adjust their expectations (e.g., knowing where the seemingly disappearing objects were concealed). Consequently, our experimental design allowed us to compare responses with and without VOE using identical stimuli. Individual trials. Each video trial was presented for 14 seconds. In case a video was shorter (e.g., 13 seconds), the last frame of the video was shown for the remaining time (e.g., for 1 second). Participants were informed about this. Moreover, the first 500 ms of each video showed a central cue (1.3 visual degrees) indicating whether the video was going to be a magic (M) or a non-magic (X) video (i.e., control or unusual actions). After each video presentation participants were asked to rate from 1 to 5 how surprising the content of the video was (1 = not surprising, 5 = very surprising). They had two seconds to respond, after which the next trial started (total trial duration = 16 seconds, see Figure <ref type="figure" target="#fig_0">1B</ref>). Behavioral surprise ratings were given by the subjects using a button-box with five keys. Trial cues. We included the cue (M or X) at the beginning of the trial to prevent participants from being surprised by contextual or serial effects. For example, since we tried to create control and magic videos that are visually as similar as possible, one could easily mistake a control video for a magic trick at the beginning of the video. The missing magic trick could then be surprising for participants expecting one. Yet, this was not the kind of surprise we wanted to investigate. We hypothesized that prior knowledge about the content of a trial (magic vs. no-magic) should prevent this from happening. Moreover, to reduce predictability of video content we flipped each video on every second presentation of the same video horizontally. For example, if the magician performed a color changing card trick on his left-hand side in the first presentation of the video, the next presentation of the same video showed the color changing card trick on his right-hand side. Pre-scan instructions. Before scanning, we instructed subjects about the task and design of the experiment (i.e., the set design, meaning of trial cues, explanation videos, etc.). Participants were informed that videos would show either magic tricks, control actions or unusual actions. Moreover, participants were shown a magic and matching control example video (not used in the actual experiment) to give them an impression about the kind and duration of the videos they were about to see. Further, to prevent participants from watching the videos in a "problem-solving" attitude, we instructed them to passively watch and enjoy the videos without trying to get behind the method of the tricks, as these would be explained during the experiment. shown is the timeline of a single trial. Every video started with a central cue lasting 500 ms indicating whether the video will show a magic trick (M) or not (X). Each video presentation lasted 14 seconds, if a video happened to be shorter than 14 s, the last frame of the video was shown until the total duration was 14 s as a static image. After the video, subjects had 2 seconds to answer how surprising the video's content was. Note that the text was displayed in one line and did not cover the whole screen. C, shown are the three different types of VOE used (i.e., "magic events"). We created videos showing magic tricks using three objects (balls, playing cards and pencils) that showed either an unexpected object appear (Ap), change color (from red to blue) (Ch) or vanish (Va). For each object-VOE combination, we created two tricks (i.e., we had two color-changing card tricks). D, schematic example of a single experimental set.</p><p>One set consisted of four runs -two before and two after explanation runs (i.e., pre and post revelation). Between preand post-revelation runs we showed participants videos explaining the magic tricks performed during the corresponding set. Each run showed 24 videos with a pseudo-randomized order ensuring that the same video was not presented in two consecutive trials (twelve magic videos [M], six matched controlled videos [C] and six unusual actions [U]). E, complete experimental design showing all three sets. The experiment was divided into three sets, one for each of the objects. Each set was divided into four experimental runs, where each run showed all the videos of an object but in a randomized order. After the second fMRI run the methods behind the tricks shown in the set were revealed, dividing the runs into before and after the explanation of the tricks (pre-and post-revelation, respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>fMRI data acquisition</head><p>fMRI data were acquired in a 3 Tesla Siemens Prisma scanner with a 64-channel head coil (Siemens, Erlangen, Germany). Functional images were acquired using an accelerated T2*-weighted gradient-echo echoplanar imaging (EPI) sequence (multiband factor = 2, repetition time (TR) = 2000 ms, echo time (TE) = 30 ms, flip angle (FA) = 75°, 62 slices with an isotropic voxel size of 2 × 2 × 2 mm) using GRAPPA (GRAPPA = 2). Each run consisted of 198 images (total duration = 6 minutes and 36 seconds). Moreover, a high-resolution T1-weighted structural scan with whole-brain coverage was performed for each participant (TR = 2000 ms, TE = 3.06 ms, inversion time (TI) = 1100 ms, FA = 9°, 192 slices and an isotropic voxel size of 1×1×1 mm). The structural scan was measured during the explanation of the tricks in the first set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>fMRI data preprocessing</head><p>Functional MRI images were preprocessed first by removing thermal noise from the magnitude EPI images using NORDIC, a PCA-based algorithm <ref type="bibr" target="#b69">(Vizioli et al., 2021)</ref> in MATLAB. Then, we discarded the first five volumes of each run to allow for T1 equilibration effects. Using SPM12 we further performed motion correction (realigned to the first image), slice-time correction (using middle slices as reference) and co-registration to the structural scan. Finally, functional MRI data for whole-brain analyses were normalized to the Montreal Neurological Institute template brain (MNI152) and spatially smoothed with a Gaussian kernel of full width at half-maximum of 6 mm for univariate whole brain analyses. Region-of-interest (ROI) analyses were performed on unsmoothed data in native space. Moreover, for the generation of subject-specific ROIs, we generated inflated individual brain surfaces using Freesurfer 7.1.1 <ref type="bibr" target="#b13">(Dale et al., 1999)</ref> using a dedicated docker container (<ref type="url" target="https://hub.docker.com/r/freesurfer/freesurfer">https://hub.docker.com/r/freesurfer/freesurfer</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Univariate whole-brain data analysis</head><p>To investigate differences in neural activity during high-level VOE in the human brain, we performed whole-brain and ROI univariate analyses. We had three specific aims: 1) to investigate neural responses to violations of physical principles in naturalistic stimuli, comparable to previous reports using magic tricks <ref type="bibr" target="#b14">(Danek et al., 2015;</ref><ref type="bibr">cf. Parris et al., 2009)</ref>, 2) to investigate differential responses between different VOE (i.e., magic trick types) and 3) to investigate the role of prior knowledge in the perception of events violating physical principles by comparing responses to the very same videos before and after revelation.</p><p>For these analyses, we created two event-related general linear models (GLM) using the canonical hemodynamic response function and high-pass filtered data with a cut-off at 128s in SPM12. In the first GLM (aim 1), we modelled responses using only three regressors of interest in each run (magic, control, and unusual stimuli conditions). In a second, extended GLM, we investigated possible differential responses to different forms of violation of expectations (aim 2), using seven regressors of interest that modelled BOLD responses of the three magic types, three matching controls and unusual actions for each run. As in previous reports, we modelled individual trials within a regressor using discrete event times based on the moment of surprise <ref type="bibr" target="#b14">(Danek et al., 2015;</ref><ref type="bibr">cf. Parris et al., 2009)</ref>. The definition of the event times was done by averaging the independent selection of a suitable frame done by two authors (VP and PRG). For magic videos, timing was decided based on when the "magic" (i.e., VOE) happened. For matching control videos, the corresponding time point was selected, i.e., the moment in which one would expect to see a magic event in the magic videos. For the videos showing unusual actions, timing was selected based on the onset of the unusual actions. Moreover, we included participants' response times, six movement parameters and a column of ones as nuisance regressors in both GLMs. We additionally computed the same analyses modelling the whole video durations (14 s) and report these in the supplementary Tables S11-13 and supplementary Figure <ref type="figure">S7</ref>). We used these models to address our three aims as follows.</p><p>Aim 1: to identify brain areas preferentially involved in signaling high-level VOE we compared responses to magic and matching control videos in all six pre-revelation runs (i.e., two runs from each object set) using the pooled regressors (from the first GLM). First-level contrasts Magicpre &gt; Controlpre were used for second-level random-effect analyses with non-parametric permutations tests using the non-parametric mapping toolbox SnPM13 <ref type="bibr" target="#b45">(Nichols and Holmes, 2002)</ref> for SPM12.</p><p>Aims 1 and 2: to investigate generic and violation-specific responses to high-level VOE before the explanation of the tricks, we used a second-level, 2 (magic, control) x 3 (appear, change, vanish) repeated measures ANOVA to conduct four conjunction analyses <ref type="bibr" target="#b24">(Friston et al., 2005)</ref>. To find common responses to all VOE, we contrasted each magic trick type with its corresponding control condition before the explanation of the tricks (i.e., MagicA_pre &gt; ControlA_pre) and used those contrasts to perform a conjunction (across all three VOE types) with a threshold of punc ≤ 0.001 and a cluster threshold of k = 10. For each VOE type separately, we further performed a conjunction analysis on the responses of one VOE type against the others. For example, responses specific to an appearing object were investigated by means of the conjunction of the contrasts MagicA_pre &gt; MagicC_pre ∩ MagicA_pre &gt; MagicV_pre.</p><p>Aim 3: to identify brain areas generally involved in the perception of magic and affected by prior knowledge we compared responses to magic after providing the explanation of the tricks Magicpost &gt; Controlpost and additionally compared the interaction between the revelation and magic (Magicpre &gt; Controlpre) &gt; (Magicpost &gt; Controlpost) using permutations tests. Finally, we compared the same contrasts for each magic type separately using the second, extended GLM, e.g., (MagicA_pre &gt; ControlA_pre) &gt; (MagicA_post &gt; ControlA_post). Please note that these contrasts are controlling for potential time confounds.</p><p>All non-parametric permutation tests were performed using 5000 permutations, a clusterforming threshold of punc = 0.001 and family-wise error correction (FWE, α = 0.05). We report clusters that do not survive FWE-correction but exceed k = 10 voxels. Conjunction analyses based on parametric statistics were performed using an uncorrected threshold of p ≤ 0.001 and a cluster threshold of k = 10. Brain areas in whole brain analyses were first identified using the atlasreader toolbox <ref type="bibr" target="#b46">(Notter et al., 2019)</ref>, applying the Automated Anatomical Labeling atlas 3 (AAL3) <ref type="bibr" target="#b57">(Rolls et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Univariate whole-brain control analyses</head><p>We performed two control analyses for the whole-brain univariate results. First, it is possible that the conjunction analyses examining differences between the magic trick types are confounded by differences in the visual content of the videos at specific time-points. This is because we are not only comparing videos showing "appearances", "color changes" and "vanishes", but also videos showing "red objects", "blue objects" and "no objects" at a specific time point, respectively (see Figure <ref type="figure" target="#fig_0">1C</ref>). To control for this possible stimulus-driven confound we compared responses between magic and control videos showing similar visual contents at specific time points. We contrasted responses to magic appearances with the control videos for vanishing tricks (as both videos show a "red object" at the specific moments), and magic vanishes with the control videos for tricks showing something appear (as both videos show no objects at the specific moments). No similar match was possible for the color-changing videos. Responses similar to that of the original contrasts, which used control videos showing similar actions, would be indicative that the observed differential activity reflects specific surprise responses and not differences in the visual content of the videos.</p><p>Second, we looked for condition-independent time effects in our whole-brain results. We performed a mixed-effects model using the average beta estimates of the magic tricks of each run, using the significant clusters of the prior-knowledge dependent contrast (Magicpre &gt; Controlpre) &gt; (Magicpost &gt; Controlpost). We hypothesized that any prior-knowledge dependent modulation should show high activity in the runs before the explanation of the tricks and decreased activity afterwards. In contrast, any results driven by either a general or set-wise drop in alertness should show a gradual drop in the magic estimates across all runs of the experiment or within a set, respectively. Accordingly, we used four predictors in the mixed model to explain the 12 magic estimates based on their presentation order: one predictor modelled the revelation condition (i.e., 1, 1, -1, -1, etc.), one predictor modelled the run number (i.e., 5.5 to -5.5 in 12 steps) and two predictors modelled a decay in activity either before (i.e., 1, -1, 0, 0, etc.) or after the revelation of the tricks (i.e., 0, 0, 1, -1, etc.). We expect the last three regressors to account for any timedependent variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ROI definition</head><p>For the ROI analyses, we defined 26 hypothesis-driven ROIs, separated into two groups.</p><p>First, we defined a set of 16 ROIs based on significant responses to magic videos from previous experiments <ref type="bibr" target="#b14">(Danek et al., 2015;</ref><ref type="bibr" target="#b49">Parris et al., 2009)</ref>. The authors from <ref type="bibr" target="#b14">Danek et al., (2015)</ref> kindly provided us with the corresponding parametric maps from their study which were used to guide the ROI definition. We combined individual labels from a multi-modal parcellation of the human cortex <ref type="bibr" target="#b25">(Glasser et al., 2016)</ref> to define the following 14 frontal and parietal ROIs that showed increased activity when viewing magic tricks: a posterior part of the dorsal anterior cingulate cortex (pdACC), an anterior part of the dorsal ACC (adACC), ventral ACC (vACC), inferior frontal junction (IFJ), left inferior frontal sulcus (IFS), Brodman area 6 (BA6), inferior premotor subdivision (6r), 8BM, anterior insula (AI), anterior ventral insula (AVI), inferior temporal gyrus temporo-occipital division (PH), left BA 46, left BA 8 and left inferior parietal cortex (IPC). The remaining two subcortical ROIs (caudate nucleus and left amygdala) were defined using the Freesurfer automatic parcellation <ref type="bibr" target="#b20">(Fischl et al., 2002)</ref>. A detailed list of the parcellations used to define these ROIs is in the supplementary section Surprise-related region of interest definition.</p><p>Second, we used a probabilistic map of visual fields <ref type="bibr" target="#b71">(Wang et al., 2015)</ref> to define ten visual ROIs: primary visual cortex (V1), secondary visual cortex (V2), V3, V3A, V3B, human V4 (hV4), lateral occipital and ventral complex (LO and VO, respectively), intraparietal sulcus (IPS) and frontal eye-fields (FEF). All ROIs were defined in native space.</p><p>We included these visual ROIs to use in the decoding of the VOE type (i.e., appear, change and vanishing, see below) and to test for differences evoked by the different VOE types and the effect of prior knowledge. For example, areas of the ventral visual cortex are known to be responsive to color <ref type="bibr" target="#b8">(Bartels and Zeki, 2000)</ref>, while the lateral occipital complex is responsive to objects <ref type="bibr" target="#b30">(Grill-Spector et al., 2001)</ref>. As predictive coding approaches predict feature-specific prediction errors in functionally specialized regions, we expect unexpected color changes to affect color-responsive ROIs (e.g., hV4, VO and PH), and unexpected object appearances to affect object-responsive areas LO and VO, in line with recent imaging evidence <ref type="bibr" target="#b38">(Jiang et al., 2016;</ref><ref type="bibr" target="#b56">Richter et al., 2018;</ref><ref type="bibr" target="#b66">Stefanics et al., 2019)</ref>. Early visual areas (V1, V2, V3) were included to investigate possible top-down effects of prior knowledge in lower-level areas, when comparing the exact same videos before and after revelations, while the parietal (IPS) and prefrontal ROIs (FEF) were included due to their involvement in top-down voluntary attention <ref type="bibr" target="#b12">(Corbetta and Shulman, 2002)</ref>. See Figure <ref type="figure" target="#fig_4">5A</ref> for a depiction of all 26 ROIs in an exemplary subject.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multivariate pattern analysis (MVPA)</head><p>Apart from the univariate analyses testing for net signal differences, we further wanted to investigate which areas of the brain carry pattern information about the different types of VOE (unexpected appearance, feature change, and omission). To do so, we performed a series of multivariate pattern analyses (MVPA) on the 26 hypothesis-driven ROIs and a control ROI.</p><p>For the decoding analyses we computed a GLM in which every trial (i.e., video presentation) was modeled as a separate regressor to increase the number of data points for training and testing. All analyses were performed using a shrinkage linear discriminant analysis (LDA) on the de-meaned beta estimates of the individual trials (by the mean over all estimates, i.e., all trials, within each voxel) using the Python (version 3.8.13) package scikit-learn's class LinearDiscriminantAnalysis <ref type="bibr" target="#b50">(Pedregosa, 2011)</ref>. To examine if any of the ROIs contained information about the different types of VOE (appear, color change, and vanish) we trained and tested a shrinkage LDA to predict the VOE types following a three-fold cross-validation scheme to ensure generalization across objects. We trained on the data of two objects (i.e., estimates from two sets, 48 trials) and tested on the third object (i.e., estimates from the third set, 24 trials). Significance testing of the decoding accuracies was done using a permutation analysis (1000 permutations) implementing the max statistic correction to correct for multiple comparisons <ref type="bibr" target="#b45">(Nichols and Holmes, 2002)</ref>. A control ROI (third ventricle) was included in the analysis, which should carry no information and thus reflect chance level.</p><p>Decoding analyses were performed separately for data before and after explanations of the magic tricks. Permutation-based corrected significance thresholds were 36.98% and 36.92% before revelation and after revelation, respectively. As both analyses were conducted using estimates based on the very same videos, we hypothesized that any significant difference in decoding accuracies between data before and after revelation would be indicative of decodable prior-knowledge dependent surprise signals. We tested for differences in decoding accuracies using paired t-tests between decoding using pre-revelation data and decoding using postrevelation data, only in those ROIs that showed significant decoding (corrected) using prerevelation data.</p><p>Additionally, as an exploratory approach we performed a similar whole-brain searchlight analysis using a sphere to decode the magic types (4 mm radius), separately for data before and after explanation of the tricks using the SearchLight class implemented in nilearn <ref type="bibr" target="#b0">(Abraham et al., 2014)</ref>. The searchlight whole-brain accuracy maps were spatially smoothed with a 4 mm Gaussian kernel. A permutation-bootstrap hybrid method (in which each randomly generated accuracy map was also smoothed with a 4 mm Gaussian kernel) was used for significance testing and correction for multiple comparisons <ref type="bibr" target="#b67">(Stelzer et al., 2013)</ref> using custom-made Python code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral data</head><p>To test for differences in surprise ratings between videos before and after the explanation of the tricks we performed a 2 (before/after explanation) x 3 (magic, unusual and control videos) repeated measures ANOVA. We expected to see higher surprise ratings for magic videos compared to control videos and higher ratings for magic videos before compared to after the revelation of the methods. We also wanted to test if videos of magic and of unusual actions led to similarly high surprise ratings. Only this would allow us to use the unusual action videos as secondary comparison points for magic. Moreover, we tested for differences in surprise ratings of the magic videos for different objects and VOE types in 2 x 3 repeated-measures ANOVAs (rmANOVA) with the factors revelation (before/after) and object (ball/card/pencil) or VOE type (appear/change/vanish), respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Eye tracking</head><p>Data acquisition and preprocessing. Gaze positions were measured using an MR-compatible Eyelink 1000 (SR-Research, Ottawa, Canada) positioned at the rear end of the scanner bore at a 1000 Hz recording rate. Calibration of the eye tracker was performed at the beginning of the experiment and drift correction was performed at the beginning of each run. If necessary, recalibration was performed at the beginning of a new run.</p><p>Eye tracking data (i.e., gaze position, blinks, and saccades) from 23 participants were analyzed. Data from one participant was excluded because of technical problems during data acquisition. Monocular gaze path data (x, y coordinates) were cleaned by removing values 150 ms before and after blinks, linearly interpolating the missing data (with an interpolation limit of 500 ms) and downsampling the data from 1000 Hz to 25 Hz (i.e., the framerate of our videos). Identification of blinks and saccades was performed automatically using the Eyelink online parser with default parameters (saccade detection threshold was 22 degrees/s).</p><p>Eye tracking data was used to examine if fMRI responses could be confounded by systematic differences in gaze traces, saccades, or blinks during viewing of the videos. We focused our eye tracking analyses to values within a -1 to +2 s window centered around the event time from each video. We performed two types of tests. First, we used rmANOVAs to test for differences in blink or saccade numbers across conditions. Second, we used correlation analyses to test for differences in gaze traces. Gaze trace analysis. To test for differences in gaze traces before and after the revelation of the methods used in the magic tricks, we correlated the x and y positions of each video presentation (eight presentations per video -two per run, two runs pre and post revelation) within a subject, for each video separately (resulting in two 8 × 8 correlation matrices per video -one for x, one for y.). Then, the correlation coefficients were transformed using the Fisher-z transformation and averaged for the x and y traces. We pooled all values from comparisons between presentations before and after the revelation of the tricks (i.e., the bottom left quadrant of the matrix) and those within presentation before and after the revelation (see Figure <ref type="figure" target="#fig_1">2E</ref> for an example) of the tricks within a subject. The pooled correlation coefficients were then compared using paired t-tests. Blink and Saccade analysis. Finally, to test for differences in blinks and saccades as a factor of video condition, prior knowledge, and VOE, we compared the mean number of blinks and saccades using two rmANOVAs, for blinks and saccades separately. The first rmANOVA had video (magic and control) and revelation (before and after) condition as factors. The second rmANOVA used magic data and had the VOE types (appear, color change, and vanish) and revelation (before and after) as factors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inference statistics</head><p>Effect sizes for repeated measures ANOVAs and paired tests are presented as partial eta squared (η 2 ) and Cohen's d, respectively. Sphericity of rmANOVAs was tested using the Mauchly test. If sphericity was violated, degrees of freedom were adjusted using the Greenhouse-Geisser correction, the corresponding ɛ-correction factor is provided. Normality of data was assessed using the Shapiro-Wilk test (for paired tests and post-hoc tests). In case that data was normally distributed, we performed paired t-tests, otherwise we performed non-parametric Wilcoxon signedrank tests instead. Correction for multiple comparison was performed using a step-down Holm-Bonferroni correction. Please note that in the post-hoc tests we corrected for each hypothesis separately (i.e., p-values for post-hoc tests of one factor are corrected independent of another factor or an interaction). In general, corrected p-values (pcorr) are reported in text, uncorrected pvalues (punc) are reported in the corresponding tables. The threshold for statistical significance was set to 0.05 for all tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral surprise ratings</head><p>Behavioral data was first tested for differences in surprise ratings for video condition (magic, control, and unusual videos) and revelation condition (before and after revelation) using a 2 x 3 rmANOVA (see Figure <ref type="figure" target="#fig_1">2A</ref>). In sum, this analysis revealed that magic tricks were perceived as more surprising than the control videos, and that surprise ratings dropped after explanation of the tricks. In detail: the analysis revealed significant main effects for both factors (video condition: F(2,46) = 57.494, punc &lt; 0.001, η 2 = 0.478, ɛ = 0.932, revelation: F(1,23) = 103.242, punc &lt; 0.001, η 2 = 0.211, ɛ = 1) and interaction: F(2,46) = 43.081, punc &lt; 0.001, η 2 = 0.134, ɛ = 0.641). As expected, post-hoc Wilcoxon signed-rank tests revealed that magic videos were more surprising than control and unusual videos, before (W = 1, pcorr &lt; 0.001, Cohen's d = 4.07 and W = 8, pcorr &lt; 0.001, Cohen's d = 2.06, respectively) and after explanation of the tricks (W = 5, pcorr &lt;0.001, Cohen's d = 1.55 and W = 26, pcorr &lt; 0.001, Cohen's d = 0.812, respectively), and that all video conditions were more surprising before compared to after the revelation (all three video conditions: pcorr &lt;= 0.001). Unusual videos were more surprising than control videos pooled across runs (W = 42, pcorr = 0.006, Cohen's d = 0.59), but significantly so only in the first two runs (W = 26, pcorr = 0.002, Cohen's d = 0.71) (see Supplementary Table <ref type="table">S1</ref> for a detailed report of all post-hoc tests). Because of the large and significant differences in surprise ratings between the magic and unusual videos that preclude a meaningful comparison of corresponding neural responses, we report here no further analysis of the data from the unusual videos. For completeness, we show corresponding contrasts in the supplementary results (see supplementary Figure <ref type="figure" target="#fig_2">S3</ref> and Tables <ref type="table">S3-6</ref>).</p><p>Average surprise ratings of magic videos were consistently high before the explanation of the tricks (all group means &gt; 3) and decreased afterwards (all group means &lt; 2.5) (see Figure <ref type="figure" target="#fig_1">2A</ref>, <ref type="figure">B</ref> and <ref type="figure">C</ref>). We further performed two rmANOVAs using only ratings from magic videos, to test for possible differences in VOE types and the objects used. Both rmANOVAs included the revelation condition as a factor and showed a significant decrease in surprise rating after the revelation of the tricks (as expected from the previous analysis). We additionally found a significant main effect for the magic type (F(2,46) = 13.8, punc &lt; 0.001, η 2 = 0.032, ɛ = 0.848) and an interaction of magic type and revelation condition (F(2,46) = 11.02, punc &lt; 0.001, η 2 = 0.018, ɛ = 0.795) (see Figure <ref type="figure" target="#fig_1">2B</ref>). Post-hoc tests showed that appearances were rated less surprising than color changes and disappearances pre revelation (W = 12, pcorr &lt; 0.001, Cohen's d = -0.835 and W = 35.5, pcorr = 0.002, Cohen's d = -0.631, respectively). No difference between color change and vanish magic tricks was observed (see Supplementary Table <ref type="table" target="#tab_1">S2</ref>). No main effect for objects nor an interaction of object and revelation condition were found (all F-values &lt; 2, all punc &gt; 0.15 and η 2 &lt; 0.012) (see Figure <ref type="figure" target="#fig_1">2C</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Eye-tracking results</head><p>Eye-tracking data were tested for systematic differences in gaze traces, saccades, and blinks during viewing of the videos (see also Supplementary section Eye-tracking results and Figure <ref type="figure" target="#fig_1">S2</ref>). First, for each magic video we computed the correlation of gaze path between video presentations in all subjects. We then averaged the transformed values (using Fisher-z transformation) of correlations between pre-and post-revelation presentations and within pre-and post-revelation presentations and tested for differences using paired t-tests. Gaze traces between pre-and postrevelation runs were similar (see an example visualization in Figure <ref type="figure" target="#fig_1">2D</ref>) and no significant difference of correlations of gaze traces was observed (all punc &gt; 0.2) (see Figure <ref type="figure" target="#fig_1">2E</ref> for an example). Moreover, the number of saccades and blinks around the VOE times were similar between experimental conditions and only revealed small differences we deem unlikely to have affected the imaging results. VOE types (B) and across objects (C). Surprise ratings before the revelations of the magic tricks (red) were consistently higher than after the revelations (blue). D, Exemplary group gaze positions for the same magic video in the moment a ball appears, before (left) and after (right) the revelation of the trick. E, Correlation matrix for gaze positions around the moment of magic (-1 s and +2 s) from an exemplary video. To test for differences between gaze paths before and after the revelation of the tricks, we compared the average Fisher z-transformed correlations between gaze paths of all combinations of presentations (from presentation Nr. 1 to Nr. 8) between pre-and post-presentations (marked green) and those within pre-and within post-presentations (marked blue), as shown in the bar plot.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Univariate whole-brain analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Whole-brain surprise responses</head><p>To investigate neural correlates of high-level VOE when viewing seemingly impossible events, we first compared whole-brain responses to the magic and matched control videos before the revelation of the magic tricks (Magicpre &gt; Controlpre). This contrast revealed several clusters of activity in frontal and parietal cortices, as well as subcortical areas, such as the caudate nucleus, largely in line with previous studies <ref type="bibr" target="#b14">(Danek et al., 2015;</ref><ref type="bibr" target="#b49">Parris et al., 2009)</ref> (see Figure <ref type="figure" target="#fig_2">3A</ref> and Table <ref type="table">1</ref>). In particular, large clusters of activity were observed in the medial part of Brodmann area 8 (preSMA), the dorsal and ventral anterior cingulate cortex (dACC and vACC), caudate nucleus (CN), and the posterior parietal cortex (PPC, especially the superior parietal lobe and the precuneus). No lower-level sensory area was differentially modulated in view of the unexpected events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generic surprise responses</head><p>To specifically test for generic surprise responses in the brain showing a significant involvement of all three types of VOE, we performed a conjunction analysis combining all different VOE types before the revelation of the tricks (MagicA_pre &gt; ControlA_pre ∩ MagicC_pre &gt; ControlC_pre ∩ MagicV_pre &gt; ControlV_pre). While no cluster survived FWE correction, using a voxel-wise uncorrected threshold of p ≤ 0.001 and k = 10 we found small clusters in the dorsal anterior cingulate cortex (dACC) bilaterally and posterior parietal cortex (precuneus) revealing generic responses (see Figure <ref type="figure" target="#fig_2">3B</ref>, left and Table <ref type="table">1</ref>). Also, using a more liberal threshold of punc ≤ 0.005 (and k = 10), we further observed generic activity in the vACC/mPFC. Table <ref type="table">1</ref>. Significant clusters of activity from the whole-brain contrast comparing responses between magic videos and matched controls (Magicpre &gt; Controlpre, thresholded at p ≤ 0.001 and k = 10, uncorrected) and the conjunction analysis testing for common areas involved in the processing of violation of expectations (thresholded at punc ≤ 0.001 and k = 10, uncorrected). P-values show cluster statistics. k = cluster size, T = t statistic at peak voxel, x, y, z = peak voxel MNI coordinates <ref type="bibr">[mm]</ref>. dAAC: dorsal anterior cingulate cortex; PFC: prefrontal cortex; vACC: ventral ACC; mPFC: medial PFC; PCC: posterior cingulate cortex; DLPFC: dorso-lateral prefrontal cortex; preSMA: supplementary motor area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Brain region AAL atlas labels p(FWE) p(unc) k T x y z</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Magicpre &gt; Controlpre</head><p>Posterior parietal cortex Occipital_Mid_L 0.0004 &lt;0.0001 1871.0 7.16 -34 -82 34 Precuneus_R ---6.87 4 -68 52 Precuneus_L ---6.48 -10 -68 44 dAAC Cingulate_Ant_L 0.0048 0.0005 886.0 6.46 -6 30 20 Cingulate_Ant_R ---6.05 4 32 Cingulate_Mid_R ---5.51 2 24 L. Parieto-occipital sulcus Cuneus_L 0.0594 0.0082 162.0 6.18 -14 -62 Calcarine_L ---4.21 -12 -60 R. Intraparietal sulcus Occipital_Mid_R 0.1752 0.0284 74.0 5.53 36 -80 L. anterior PFC Frontal_Sup_2_L 0.1982 0.0332 67.0 5.41 -26 58 L. anterior intraparietal Postcentral_L 0.0548 0.0074 172.0 5.2 -46 -36 Parietal_Inf_L ---4.47 -42 -38 vACC/mPFC Cingulate_Ant_L 0.0548 0.0074 172.0 5.13 -4 48 L. Superior frontal gyrus Frontal_Sup_2_L 0.0522 0.007 179.0 5.02 -22 12 Frontal_Sup_2_L ---3.7 -22 0 L. anterior middle frontal gyrus Frontal_Mid_2_L 0.1722 0.028 75.0 5.01 -34 54 L. PCC no_label 0.5014 0.1159 25.0 5.01 10 -36 L. Thalamus Thalamus_L 0.5456 0.1334 22.0 4.86 -6 -6 L. Hippocampus no_label 0.5158 0.1214 24.0 4.76 -18 -22 -10 L. Caudate nucleus Caudate_L 0.5946 0.1558 19.0 4.73 -12 16 L. Postcentral gyrus Postcentral_R 0.1134 0.0173 103.0 4.71 52 -16 Postcentral_R ---4.07 52 -18 Postcentral_R ---3.72 46 -22 R. Superior frontal gyrus Frontal_Sup_2_R 0.2394 0.0417 57.0 4.61 28 10 L. PCC no_label 0.2832 0.0511 49.0 4.48 -2 -30 R. Thalamus Thalamus_R 0.7188 0.2273 13.0 4.17 12 -8 L. Fusiform gyrus Fusiform_L 0.6338 0.1754 17.0 4.16 -24 -54 -16 Cerebelum_6_L ---3.75 -24 -62 -18 L. Ventral occipital cortex Lingual_L 0.7188 0.2273 13.0 4.1 -2 -78 -8 L. Anterior intraparietal Parietal_Inf_L 0.5306 0.1277 23.0 3.84 -40 -50 L. DLPFC Frontal_Mid_2_L 0.762 0.2623 11.0 3.81 -36 26 Conjunction of Magicpre -Controlpre per VOE type dACC/preSMA Supp_Motor_Area _L 0.722 0.096 38 4.02 -4 16 Precuneus Precuneus_L 0.885 0.162 26 3.99 -8 -68 Precuneus_R 0.722 0.096 38 3.94 8 -68 dACC Cingulum_Mid_L 0.966 0.254 17 3.7 -6 18 Cingulum_Mid_L ---3.31 -4 26 R. Postcentral gyrus Precentral_R 0.986 0.318 13 3.5 46 -14</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specific surprise responses 1</head><p>After establishing what areas are generally involved in the processing of violation of expectations 2 (i.e., commonly active in seemingly impossible appearances, disappearances, and color 3 changes), we looked for VOE type specific differential activity in the brain (e.g., areas responsive 4 to something unexpected appearing but not disappearing or changing color). Beyond the 5 systematic generic activation of frontoparietal areas described above, all three types of VOE 6 evoked differential responses in posterior visual areas, but in a segregated and even partially opposite manner (see Figure <ref type="figure" target="#fig_2">3C</ref> and Supplementary Table <ref type="table">S8</ref>). For example, while appearances and color changes evoked an increase of activity in ventral visual areas, the disappearance of objects reduced activity in overlapping regions. To better visualize this diverse modulation of sensory areas by the different VOE, we tested which areas were significantly more activated by one type of VOE than by the other two using a conjunction test (e.g., test for appear-specific responses: MagicA_pre &gt; MagicC_pre ∩ MagicA_pre &gt; MagicV_pre) (see Figure <ref type="figure" target="#fig_2">3D</ref> and <ref type="figure">E</ref> and Supplementary Table <ref type="table">S7</ref>). As hypothesized, activity related to objects appearing were observed in early visual areas and in higher-level visual areas of the lateral occipito-temporal cortex (peak coordinates: x = 30,y = -88, z = 22 and x = -22, y = -78, z = 44), whilst activity related to color changes were observed specifically in color-responsive ventral areas of the fusiform gyrus (FFG, peak coordinates: x = -30, y = -50, z = -16 and x = 32, y = -54, z = -14). Finally, vanishing objects evoked significant responses -among others -in the anterior parts of the calcarine sulcus, close to the parieto-occipital sulcus (peak coordinates: x = -20, y = -64, z = 12 and x = 18, y = -76, z = 8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Control analysis for visual content</head><p>As these VOE type-specific patterns of activity are located predominantly in visual processing areas, they are potentially related to general visual differences between the conditions tested. The compared videos are not only showing "appearances", "color changes" and "vanishes", but also "red objects", "blue objects" or "no objects", respectively. To test if these VOE type-specific responses are confounded by different visual input, we performed a control analysis comparing neural responses between 1) videos showing red objects, either as the product of a magic trick (appearances) or as a control to other tricks (vanishes) (MagicA_pre &gt; ControlV_pre) and 2) between videos showing no object, either as the product of a magic trick (vanishes) or as a control to the other tricks (appearances) (MagicV_pre &gt; ControlA_pre). Differential responses in posterior visual areas to these control contrasts were similar to the results of the corresponding conjunction analyses (for appearances and vanishes), suggesting that violation-specific responses observed in posterior visual areas are unlikely to be driven merely by visual content (see overlays in Supplementary Figure <ref type="figure" target="#fig_4">S5</ref>). However, if these signals in visual areas reflect specific prediction errors based on different VOE, we would additionally expect them to be modulated by prior knowledge and to show decreased responses after the explanation of the tricks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prior-knowledge dependent whole-brain responses</head><p>To investigate the effect of prior knowledge on brain responses, we provided participants with the methods behind the magic tricks. Surprisingly, neural activity after explanation of the tricks (Magicpost &gt; Controlpost) were similar to that before the explanation of the tricks (see Figure <ref type="figure" target="#fig_3">4A</ref> and Supplementary Table <ref type="table">S10</ref>). Thus, areas related to the processing of surprising events remained significantly active in view of VOE also after the explanation of the tricks (i.e., dACC, caudate nucleus, anterior insula). The interaction contrast comparing surprise responses before and after providing the explanations (Magicpre &gt; Controlpre) &gt; (Magicpost &gt; Controlpost) revealed only a small number of areas showing prior-knowledge dependent modulations (see Figure <ref type="figure" target="#fig_3">4B</ref> and <ref type="figure">C</ref> and Table <ref type="table" target="#tab_1">2</ref>). We observed higher activation in a large cluster of the medial prefrontal cortex (mPFC) and ventral ACC (peak coordinates: x = 2, y = 46, z = -10) and right posterior cingulate cortex (PCC) with FWE-correction (peak coordinates: x = 6, y = -46, z = 8). These regions hence decreased magic-related activity after the revelation. These areas overlap with and constitute of subset of the activity observed with Magicpre &gt; Controlpre before the revelation of the tricks.</p><p>Interestingly, the observed decrease of activity in the vACC/mPFC and PCC after revelation of the tricks coincides with the midline core areas of the default mode network (DMN), whilst parietal areas of the dorsal attention network (DAN) showed increased activity. This indicates that our findings are unlikely a result of a decrease in attention, as the DAN is known to direct top-down attention <ref type="bibr" target="#b12">(Corbetta and Shulman, 2002)</ref>. A visualization of these patterns of activity, together with the DMN and DAN is shown in Figure <ref type="figure" target="#fig_3">4C</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>No prior-knowledge dependency of trick-specific modulations</head><p>While prior-knowledge driven signals overlapped with neural activations to unspecific VOE (Magicpre &gt; Controlpre), none of the previously observed trick-specific visual areas showed a modulation as factor of prior knowledge (even when using a more liberal threshold of p &lt; 0.001 uncorrected, and a cluster size of k = 10, see Table <ref type="table" target="#tab_1">2</ref> and Figure <ref type="figure" target="#fig_3">4B</ref> and <ref type="figure">C</ref>). Further, the contrasts investigating the effect of prior knowledge for each VOE type separately revealed similar response patterns to those reported in the main contrasts (see supplementary Figure <ref type="figure" target="#fig_3">S4</ref>). This indicates that visual areas responsive to a specific VOE (e.g., an object changing color) were not modulated by prior knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Controlling for time effects in net responses</head><p>To rule out possible time confounds in results comparing responses before and after revelation of the tricks, we inspected how the individual values changed across time as a control analysis. We extracted betas estimates corresponding to all magic and matched control presentations from the suprathreshold clusters from the prior-knowledge interaction contrast, averaged them over subjects and calculated the same contrast within each run separately. We then ran a mixed-effects model on the contrast values with four predictors: a pre-post predictor (i.e. 1, 1, -1, -1 for each set), a constant decay predictor over all 12 fMRI runs (i.e. 5.5 to -5.5 in 12 steps) and two timedecay predictors for values before and after revelation separately (i.e. 1, -1, 0, 0 and 0, 0, 1, -1, for each set). We hypothesized that areas showing prior-knowledge dependent activity should have a significant pre-post predictor. The pre-post predictor was significant in all clusters (all pcorr &lt; 0.05). However, in some clusters a significant amount of variance was also explained by the time-decay regressors, showing that the activity in some clusters had a contribution of time. Yet, the fact that in all clusters the pre-post regressor remained significant despite inclusion of the timeregressor shows that knowledge-dependent effects were true (see supplementary Figure <ref type="figure">S6</ref> and Table <ref type="table">S9</ref>). after (blue) explanation of the magic tricks. Both contrasts reveal a consistent activation of surprise related areas, such as the dorsal ACC (dACC), caudate nucleus (CN), and posterior parietal cortex (PPC). B, the difference of both contrasts (i.e., the interaction between video condition and revelation) revealed only few areas that were significantly more active before the explanation of the tricks: the posterior cingulate cortex (PCC), the ventral ACC/medial prefrontal cortex (vACC/mPFC) and left Hippocampus. Threshold at punc &lt; 0.001 and k = 10. C, shown are the interaction testing for prior-knowledge dependent responses (thresholded from t = 2 to t = 4, red to yellow and t = -2 to t = -4, dark blue to light blue) and the default mode network (DMN) and the dorsal attention network (DAN) as transparent overlay projected on to an average brain surface (fsaverage). The network overlays are provided by <ref type="bibr" target="#b76">(Yeo et al., 2011)</ref>. Abbreviations: AI: anterior insula; aPFC: anterior prefrontal cortex; LH: left hemisphere; PCUN: precuneus; preSMA: supplementary motor area; RH: right hemisphere; SFG: superior frontal gyrus; THA: thalamus. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Univariate ROI analysis</head><p>To complement the whole-brain analysis, we defined a set of 26 hypothesis-driven regions-ofinterest (ROIs) from which we extracted and analyzed parameter estimates (10 visual and 16 surprise-related ROIs based on prior literature) from unsmoothed data in native space and tested them with paired tests (correcting for the number of ROIs). Overall, our ROI-based analyses confirmed our above whole-brain findings. None of the lower-level visual cortices showed a significant increase of neural responses during the magic compared to the matched control condition before the explanation of the tricks (all punc &gt; 0.24). In contrast, significant responses to magic were observed in the visual parietal ROI IPS (t(23) = 2.746, punc= 0.012, Cohen's d = 0.53), as well as in several higher-level surprise-related ROIs, especially in adACC (t(23) = 5.32, pcorr = 0.001, Cohen ′ s d = 0.917), as well as in vACC, pvACC, BA6, BA46 and caudate nucleus (all punc &lt; 0.05, see detailed results in supplementary Table <ref type="table">S14</ref> <ref type="bibr">-17)</ref>. Only two ACC ROIs (adACC and vACC) and 8BM (directly superior to the adACC) showed a decrease of activity after the revelation of the tricks (t(23) = 3.43, punc = 0.002, Cohen's d = 0.41, W = 79, punc = 0.042, Cohen's d = 0.42 and t(23) = 2.54, punc = 0.01, Cohen's d = 0.41, respectively). None of the visual ROIs showed a similar response pattern. In contrast, VOE-specific responses were largely constrained to visual ROIs (see supplementary section univariate ROI results).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multivariate pattern analysis</head><p>Our univariate analyses revealed generic responses (modulated by prior knowledge) in frontoparietal areas, while showing trick-specific responses in posterior sensory areas (unaffected by prior knowledge). However, differences in specific VOE and prior-knowledge modulations might also be reflected in activation patterns and not only in net signal differences. Accordingly, we complemented our univariate analysis by a multivariate pattern analysis to investigate if specific information about VOE types were present in the activity patterns of our surprise-related frontoparietal ROIs (which showed only generic responses to magic). Further, we performed this analysis separately for data before and after the explanation of the tricks, to investigate if posterior sensory areas (which showed trick-specific effects) might show a difference in decoding accuracies before and after revelation of the tricks. We followed a three-fold cross-decoding approach to generalize each magic type across objects: we trained a linear classifier to classify specific VOE types, appear (A), color change (C), and vanishes (V), based on the estimates of the magic videos from two objects (48 trials, from two sets) and tested on the estimates of the remaining object (24 trials, from one set).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visual ROIs</head><p>Decoding of the specific VOE types across objects was possible in all posterior visual ROIs (V1, V2, V3, hV4, V3A, V3B, LO, VO, IPS) before the explanation of the magic tricks (all corrected pvalues &lt; 0.001; corrected using a permutation maximal statistic, <ref type="bibr" target="#b45">Nichols and Holmes, 2002)</ref>. After revelation of the method behind the magic tricks, decoding accuracies significantly dropped in most ROIs (V1, V2, V3, LO and IPS) (all pcorr &lt;= 0.05; Holm-Bonferroni corrected for the number of visual ROIs), being below threshold in LO and IPS (see Figure <ref type="figure" target="#fig_4">5B</ref> and supplementary Table <ref type="table" target="#tab_1">S20</ref>). Additionally, we found uncorrected significant differences in hV4 and V3B (punc = 0.05 and punc = 0.016, respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Surprise related ROIs</head><p>In contrast, no surprise-related ROI (nor the control ROI) showed significant above-chance decoding accuracies between VOE types using the permutation-max statistic for correction, except for the PH ROI (pcorr &lt; 0.001), an area located in the inferior temporal sulcus (temporo-occipital division), using data before revelation of the tricks. Uncorrected significant above chance decoding (chance level = 33%) was observed in IFJ, AI, pdACC, BA6, BA8, and BA46 using data before revelation. Differences in decoding accuracies before and after revelation were observed only in PH (pcorr = 0.005, Holm-Bonferroni corrected for the number of ROIs that could significantly decode before revelation) (see Figure <ref type="figure" target="#fig_4">5B</ref> and supplementary Table <ref type="table" target="#tab_1">S20</ref>) and in BA8 (corrected for the number of ROIs that could not significantly decode the VOE type using pre-revelation data, i.e., 16 ROIs) (see Figure <ref type="figure" target="#fig_4">5B</ref> and supplementary Table <ref type="table" target="#tab_1">S21</ref>).</p><p>Therefore, while frontoparietal areas showed a generic and surprise-dependent involvement in processing VOE in the univariate analyses, they carried no or only weak information <ref type="bibr">(i.e.,</ref><ref type="bibr">in BA8)</ref> as to what exactly happened. In contrast, information about specific VOE were observed in all posterior sensory areas across the visual hierarchy. An in-depth view of the informative ROIs is shown in the confusion matrices in Figure <ref type="figure" target="#fig_4">5C</ref>. They reveal that appearances and color-changes were consistently decodable above chance and that most confusions happened between them and less so with vanishing events.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Searchlight analysis</head><p>To complement the ROI decoding analysis that used hypothesis-driven visual and surprise-related ROIs, we performed a whole-brain searchlight analysis to better visualize the results and explore if additional brain areas differentially respond to specific VOE. As in the ROI decoding analysis, we trained linear classifiers to classify specific VOE (i.e., appear, change, vanish) in a three-fold approach separately for both, magic estimates before and after revelation of the tricks. Results of the whole-brain searchlight analysis revealed that only posterior visual areas of the brain could significantly decode the magic type in both conditions (using a permutation-bootstrap hybrid correction method, <ref type="bibr" target="#b67">Stelzer et al., 2013)</ref>. As shown in Figure <ref type="figure" target="#fig_4">5D</ref>, significant decoding was possible in large areas of the visual cortex, including most of the occipital cortex and small parts of the temporal and parietal cortex. Crucially, decoding accuracies before the explanation of the magic tricks were significant in more voxels and larger clusters compared to after explanation. Significant decoding before the explanation of the tricks extends to parts of temporal and parietal cortex, whereas significant decoding after revelation is largely restricted to posterior visual areas. In sum, and in contrast to the univariate results that showed no net modulation as a function of prior knowledge (and surprise) in visual areas, the differences in decoding accuracies using data before and after explanation of the tricks suggests that visual areas are indeed sensitive to changes in knowledge and encode specific expectations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Controlling for time effects in pattern activity</head><p>Arguably, suprathreshold decoding of magic effects in posterior sensory areas may reflect general stimulus differences in the moment of magic between the different magic trick types independent of the object used, as appear videos systematically showed red objects, color changing videos blue objects and vanishing videos no object. However, the observed significant differences in decoding accuracy before and after revelation suggest surprise-dependent modulations of activity patterns, as these differences are present in view of the very same videos. Yet, these differences could reflect time-and/or design-related confounds, such as a general decrease of attention and alertness over time. However, since we did not find any significant changes in univariate comparisons in posterior visual areas and we observed a general increase in parts of the dorsal attention network, we believe that our results are not confounded by time and/or design related factors. Nonetheless we performed control analyses comparing decoding accuracy of objects present or absent in control videos in the pre vs post revelation phase. These analyses showed no modulation of time in control videos (detailed results can be found in the Supplementary Materials Section MVPA control analyses). left, all of which (except for the inferior temporal area PH) were defined using a probabilistic map of visual areas <ref type="bibr" target="#b71">(Wang et al., 2015)</ref>. Surprise-related ROIs presented on the right panel were defined based on previous results <ref type="bibr" target="#b14">(Danek et al., 2015;</ref><ref type="bibr" target="#b49">Parris et al., 2009)</ref> using a multimodal parcellation atlas <ref type="bibr" target="#b25">(Glasser et al., 2016)</ref>, except for frontal eye field (FEF), which was also defined using the probabilistic atlas from <ref type="bibr" target="#b71">Wang et al., (2015)</ref> (see supplementary section Surpriserelated region of Interest definition for more information). The two subcortical ROIs, caudate nucleus, and left amygdala were defined using the Freesurfer automatic parcellation <ref type="bibr" target="#b20">(Fischl et al., 2002)</ref>. B, shown are the decoding accuracies for decoding the VOE types over objects in a three-fold cross-decoding approach in our theory-driven ROIs (left: ROIs that significantly decoded the VOE type using pre-revelation data, right: ROIs that did not significantly decode the VOE type using pre-revelation data). Decoding was performed with data before (red) and after (blue) revelation. All statistics were corrected for multiple tests by using the max-statistic correction across all ROIs <ref type="bibr" target="#b45">(Nichols and Holmes, 2002)</ref> C, confusion matrices from decoding VOE types before revelation for ROIs that could significantly decode VOE types before revelation. It appears that VOEs due to unexpected color changes are predicted best, while the VOEs due to objects vanishing is predicted less than VOEs due to objects appearing and changing. D, whole-brain searchlight decoding results. We can significantly decode VOE types in the majority of visual cortex before revelation and less so after revelation (correcting using a permutation-bootstrap hybrid method, <ref type="bibr" target="#b67">Stelzer et al., 2013)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In this fMRI study, we used naturalistic video stimuli showing magic tricks and matched control actions to investigate responses to violation of expectations (VOE) of deeply held beliefs about the physical world. We used three distinct magic types (object appearance, object disappearance, and feature-change) that were presented with and without prior knowledge about the underlying deceptive methods (i.e., sleights-of-hand). Each magic type was presented using three distinct objects to allow for object-invariant classification of magic types. We looked for 1) generic prediction error responses to perceived violation of physical principles, 2) specific responses to the different magic types and, 3) effects of the viewers' prior knowledge on prediction error processing, for both generic and specific responses.</p><p>Our results revealed a hierarchy of surprise signals. First, we observed generic effects of world-model VOE (i.e. common to all magic types) in several clusters of the prefrontal and parietal cortex (such as the dorsal and ventral ACC and the posterior parietal cortex). Then, differential activity specific to the different types of magic was evoked predominately in posterior visual areas of the occipital and parietal cortex. These specific prediction error signals were evident in the univariate analyses and in decoding of the magic types, both of which were confined to posterior areas across the visual hierarchy. Finally, following explanation of the tricks, responses were largely unaffected by participants knowledge and only decreased in select parts of the network showing generic effects of VOE (midline areas of the default mode network). While net activity in visual areas was not significantly modulated by the prior knowledge, decoding of VOE typespecific signals was sensitive to changes in the participants knowledge, showing decreased decoding when participants knew the tricks. These results suggest that higher-level predictive information affects even the earliest levels of cortical visual processing (V1-V3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generic responses to violation of expectations</head><p>Witnessing magic events that violate intuitive physical principles evoked activity in a large network of frontoparietal (dACC, vACC/mPFC and posterior parietal cortex) and subcortical (caudate nucleus) areas, with no involvement of lower-level sensory areas. This pattern of activity is consistent with that observed in a recent large meta-analysis of surprising events <ref type="bibr" target="#b21">(Fouragnan et al., 2018)</ref> and with previous experiments investigating surprise responses using naturalistic videos, such as magic tricks <ref type="bibr" target="#b14">(Danek et al., 2015)</ref>, computer generated animations <ref type="bibr" target="#b7">(Bardi et al., 2017)</ref> or learned sequences of movements <ref type="bibr" target="#b59">(Schiffer and Schubotz, 2011)</ref>. Accordingly, our results add to prior evidence showing the key role of the dACC in processing incongruent information <ref type="bibr">(Alexander and</ref><ref type="bibr">Brown, 2019, 2011)</ref> and of the caudate nucleus in signaling unexpected and rewarding events <ref type="bibr" target="#b61">(Schultz et al., 1997;</ref><ref type="bibr" target="#b74">Wittmann et al., 2008;</ref><ref type="bibr" target="#b78">Zink et al., 2003)</ref>. Most importantly, our results suggest that higher-level VOE in view of seemingly impossible events are processed similarly to breaches of lower-level expectations, such as the presence of infrequent stimuli or unlikely events (cf. <ref type="bibr" target="#b26">Grassi and Bartels, 2021)</ref>. This suggests the existence of a dedicated frontoparietal network signaling the detection of incongruent information in the human brain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specific responses to violation of expectations</head><p>Complementing the generic frontoparietal involvement in processing naturalistic violations of physical principles, we further looked into the specific effects of the different types of VOE (appear, change, vanish). Specific responses evoked by the different VOE in net activity and multivariate activation patterns (i.e., allowing for a distinction between trick-types) were observed exclusively in posterior sensory areas. In contrast, frontal areas revealed no or only weak specific VOE responses. Since this divergent pattern of net activity was only observable when looking into the individual VOE, it is possible that previous studies failed to report the involvement of sensory areas because of pooling responses to different types of VOE <ref type="bibr" target="#b14">(Danek et al., 2015;</ref><ref type="bibr" target="#b43">Liu et al., 2024;</ref><ref type="bibr" target="#b49">Parris et al., 2009)</ref>.</p><p>Previous results using dynamically occluded stimuli report the neural representation of occluded objects in posterior visual areas <ref type="bibr" target="#b18">(Erlikhman and Caplovitz, 2017;</ref><ref type="bibr" target="#b36">Hulme and Zeki, 2007;</ref><ref type="bibr" target="#b47">Olson et al., 2004)</ref> and in neurons of the inferotemporal cortex of macaque monkeys <ref type="bibr" target="#b51">(Puneeth and Arun, 2016)</ref> at different levels of complexity (e.g., occluded faces selectively engaged the fusiform face areas, <ref type="bibr" target="#b36">Hulme and Zeki, 2007)</ref>. The observed differential activity in visual areas using naturalistic stimuli in the present study are likely VOE type-specific surprise signals when violating said representations.</p><p>The following reasons support this interpretation: First, net responses were not driven by differences in visual content (because they were evident across distinct objects, and additional control contrasts ruled content-driven responses out). Second, decoding did not work in the absence of VOE when we used similar sensory occurrences using data from the matched control videos. Third, prior knowledge significantly reduced decoding accuracies. And finally, the observed responses occurred in functionally specialized regions of the visual cortex. For example, the unexpected appearance of objects evoked activity in the object-responsive LOC and the perception of unexpected colors evoked activity in the ventral color areas of the fusiform gyrus. Both of which are compatible with prior evidence showing increased activity in the LOC upon perceiving unexpected objects <ref type="bibr" target="#b56">(Richter et al., 2018)</ref> and in color areas when viewing unexpected colors <ref type="bibr" target="#b38">(Jiang et al., 2016;</ref><ref type="bibr" target="#b66">Stefanics et al., 2019)</ref>. Hence, our results suggest that memory-based expectations related to higher-level principles affect visual processing already at the earliest cortical visual processing areas: they encode information about the presence, absence, and features of objects.</p><p>Please note that the specific responses observed may additionally be related to attentional mechanisms engaged in processing the feature-specific VOE. Indeed, attentional mechanisms are likely entangled with processing of VOE, to enhance model updating <ref type="bibr" target="#b34">(Hohwy, 2012)</ref>. However, differences in attention are unlikely the sole account of our VOE-specific results, as we observed an enhanced involvement of the dorsal attention network (DAN) post-explanation compared to pre-explanation, while the VOE-type specific activity remained constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hierarchical prediction errors in naturalistic perception</head><p>The observation of surprise-related information in posterior visual areas is in line with a variety of higher-level memory-based signals that have been reported in visual areas, such as memory color <ref type="bibr" target="#b6">(Bannert and Bartels, 2013)</ref>, scene context <ref type="bibr" target="#b44">(Muckli et al., 2015)</ref>, scene segmentation <ref type="bibr" target="#b28">(Grassi et al., 2018</ref><ref type="bibr" target="#b29">(Grassi et al., , 2017;;</ref><ref type="bibr" target="#b60">Scholte et al., 2008)</ref>, expected visual stimuli <ref type="bibr" target="#b17">(Ekman et al., 2017)</ref> and working memory <ref type="bibr" target="#b31">(Harrison and Tong, 2009)</ref>. Importantly, these signals have been interpreted as evidence of recurrent predictive signals from higher-level areas, as they encoded information that is not thought to originate from V1 (such as memory color, 3D or Gestalt and scene information). Consistent with this, further studies located corresponding signals in superficial and/or deeper layers of the cortex using laminar fMRI <ref type="bibr" target="#b2">(Aitken et al., 2020;</ref><ref type="bibr" target="#b41">Lawrence et al., 2018;</ref><ref type="bibr" target="#b44">Muckli et al., 2015)</ref> or electrophysiological measurements in monkeys (e.g., <ref type="bibr" target="#b48">Papale et al., 2022;</ref><ref type="bibr" target="#b63">Self et al., 2013)</ref>.</p><p>Together, the current results fall in line with predictive coding theories and extend them to VOE regarding higher-level world models <ref type="bibr" target="#b23">(Friston, 2005;</ref><ref type="bibr" target="#b42">Lee and Mumford, 2003;</ref><ref type="bibr" target="#b54">Rao and Ballard, 1999)</ref>. We show a clear dissociation: generic responses to VOE in higher-level frontoparietal areas and segregated surprise responses in functionally specialized lower-level sensory areas (involved in the processing of the expected information). This reflects the hierarchical structure of our internal world model <ref type="bibr" target="#b11">(Clark, 2013;</ref><ref type="bibr" target="#b33">Hohwy, 2014)</ref>, with frontoparietal areas involved in representing more abstract aspects of the world (such as object permanency), while sensory areas represent lower-level inferences about the immediate and detailed features (such as color and shapes). Accordingly, the observed surprise-related responses in lower-level sensory areas can be thought of the product of a mismatch between top-down predictions ("a red ball") fed back to lower-level areas to be compared with incoming sensory evidence ("a blue ball") <ref type="bibr" target="#b26">(Grassi and Bartels, 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledge-dependent modulations</head><p>To further investigate these hierarchical VOE responses, we probed how prior knowledge affected them. We hypothesized that providing the participants with knowledge about the mechanics of the trick for each video would avert VOE: why should we be surprised when viewing a disappearing ball when we know how and that the magician is actually hiding it behind his hands? Surprisingly, while participants subjective surprise ratings were significantly reduced after providing them with the explanation of the tricks, net brain responses were almost indistinguishable: areas involved in the processing of unexpected events, such as the dACC, anterior insula and caudate nucleus <ref type="bibr" target="#b21">(Fouragnan et al., 2018)</ref> were systematically active when observing the magic videos even after participants had rational explanations for the tricks. As neural responses were reminiscent to those signaling surprise, it suggests that repeated viewing of explainable events did not prevent VOE. This intriguing observation likely reflects that people can be moved by things they know to be unreal, such as fictions (i.e., the "paradox of fiction", see <ref type="bibr" target="#b52">Radford and Weston, 1975)</ref> or magic illusions (i.e., the "paradox of theatrical magic", see <ref type="bibr" target="#b27">Grassi et al., 2024)</ref>. This is akin to how we still perceive visual illusions, even if we know how they work. For example, when a magician convincingly saws someone in half on stage, the audience is genuinely moved by the illusion (i.e., surprised), but do not attempt to prevent it nor call the police (because they know it is unreal). Our results suggest that the compelling perceptual illusions that magic provides are initially appraised as surprising, even with existing prior-information (cf. <ref type="bibr" target="#b27">Grassi et al., 2024)</ref>.</p><p>In turn, the only areas whose activity decreased following the explanation of the tricks were two midline core areas of the default mode network (DMN), the ventral ACC/mPFC and the posterior cingulate cortex. The modulation of midline core areas of the DMN by prior knowledge is consistent with recent reports showing their involvement in processing surprising events in movies <ref type="bibr" target="#b10">(Brandman et al., 2021)</ref>, jokes <ref type="bibr" target="#b37">(Jääskeläinen et al., 2016)</ref> and structured events unfolding in time <ref type="bibr" target="#b5">(Baldassano et al., 2018;</ref><ref type="bibr" target="#b55">Regev et al., 2013;</ref><ref type="bibr" target="#b64">Simony et al., 2016)</ref>. Based on these findings, it has been suggested that the DMN is not to be understood exclusively as an "intrinsic" network (as originally proposed, cf. <ref type="bibr" target="#b53">Raichle, 2015)</ref>, but as a dynamic "sense-making" network involved in the creation of rich models of events by integrating incoming information with prior knowledge as they unfold over time instead <ref type="bibr" target="#b65">(Stawarczyk et al., 2021;</ref><ref type="bibr" target="#b77">Yeshurun et al., 2021)</ref>.</p><p>Here, we show that areas of the "sense-making" network may be sensitive to the rational explanation of magic tricks, whereas all other identified surprise-related regions continued to be sensitive to the VOE (even once the tricks were understood). The decreased involvement of areas of the DMN, together with an increase of activity in frontoparietal areas of the dorsal attention network (DAN), is consistent with a reduction in prediction error (surprise) signals related to narrative understanding (engaging the DMN) and an increase of top-down attention after explanation of the tricks (engaging the DAN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>We used a naturalistic paradigm to violate deeply held beliefs of our physical world, involving three types of expectation violations (object appearance, color change, and object disappearance). Our results show a hierarchy of surprise signals: generic responses to unexpected events in frontoparietal areas, and responses specific to the type of VOE in distinct functionally specialized sensory areas. Our results suggest that world-model VOE are processed similarly to other surprising events in dedicated areas of the prefrontal cortex and striatum, and that core midline areas of the default-mode network decrease their involvement once rational understanding is established. Most importantly, we show that early and functionally specialized areas of the visual cortex encode memory-based predictions about the presence, absence, and features of objects.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. A, example of a color-changing card magic trick (left) and its corresponding matched control video (right). B,</figDesc><graphic coords="7,70.10,169.18,470.30,213.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Shown are behavioral surprise ratings separated for the different video types (A), for magic videos across</figDesc><graphic coords="16,70.10,291.53,470.30,283.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. A, shown are active regions during viewing magic tricks compared to matched control videos before the participants knew how the tricks were performed (thresholded at punc &lt; 0.001 and k =10, uncorrected). B, shown are results from the conjunction analyses testing for generic activity (left, yellow) (at punc &lt; 0.005). Only the dorsal ACC and preSMA and the precuneus (PCUN) revealed generic responses to high-level VOE at punc &lt; 0.001. C, VOE specific activity revealing several posterior visual areas responsive to appearances (red), color changes (blue) and objects disappearing (green). D, overview of all conjunctions results in the MNI152 template volume (upper) and of the VOEspecific responses projected on an average surface (fsaverage) (lower). E, shown are VOE-specific conjunction results. Abbreviations: ACC: anterior cingulate cortex; dACC: dorsal ACC; vACC: ventral ACC; CN: caudate nucleus; aPFC: anterior prefrontal cortex; FFG: fusiform gyrus; IPL: interior parietal lobe; IPS: intraparietal sulcus; MT+: motion area MT; mPFC: ventral prefrontal cortex; PCC: posterior cingulate cortex; PCUN: precuneus; POS: parieto-occipital sulcus; PPC: posterior parietal cortex; SFG: superior frontal gyrus; SMA: supplementary motor area; SPL: superior parietal lobe; THA: thalamus; TPOJ: temporo-parietal-occipital junction. LH: left hemisphere; RH: right hemisphere.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Prior knowledge dependent modulation of brain responses. A, overlay of Magic &gt; Control before (red) and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Results of decoding analyses A, regions of interest (ROIs) used in the experiment. Visual ROIs are shown</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="22,70.10,398.22,470.30,216.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results of contrasts comparing neural responses to VOEs before and after explanation of the tricks (thresholded at punc &lt; 0.001 and k = 10, uncorrected). P-values show permutation-based cluster statistics. K = cluster size, T = t statistic at peak voxel, x, y, z = peak voxel MNI coordinates[mm]. ACC: anterior cingulate cortex; vACC: ventral ACC; mPFC: medial prefrontal cortex; POS: parieto-occipital sulcus; PCC: posterior cingulate cortex; dACC: dorsal ACC.</figDesc><table><row><cell>Brain region</cell><cell>AAL atlas labels</cell><cell>p(FWE)</cell><cell>p(unc)</cell><cell>k</cell><cell>T</cell><cell>x</cell><cell>y</cell><cell>z</cell></row><row><cell>vACC/mPFC</cell><cell>Frontal_Med_Orb_R</cell><cell>0.0068</cell><cell>0.0007</cell><cell>538.0</cell><cell>5.72</cell><cell>2</cell><cell>46</cell><cell>-10</cell></row><row><cell></cell><cell>Frontal_Med_Orb_L</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>4.96</cell><cell>-10</cell><cell>42</cell><cell>-6</cell></row><row><cell>R. Cuneus (V3)</cell><cell>Cuneus_R</cell><cell>0.25</cell><cell>0.0385</cell><cell>52.0</cell><cell>5.23</cell><cell>8</cell><cell>-86</cell><cell>34</cell></row><row><cell>L. POS</cell><cell>Precuneus_L</cell><cell>0.1082</cell><cell>0.014</cell><cell>101.0</cell><cell>4.99</cell><cell>-8</cell><cell>-56</cell><cell>8</cell></row><row><cell>L. PCC</cell><cell>Calcarine_L</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>4.31</cell><cell>-6</cell><cell>-48</cell><cell>4</cell></row><row><cell>R. PCC</cell><cell>Precuneus_R</cell><cell>0.0424</cell><cell>0.005</cell><cell>185.0</cell><cell>4.91</cell><cell>6</cell><cell>-46</cell><cell>8</cell></row><row><cell></cell><cell>no_label</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>4.59</cell><cell>-4</cell><cell>-30</cell><cell>6</cell></row><row><cell></cell><cell>no_label</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>4.56</cell><cell>8</cell><cell>-36</cell><cell>4</cell></row><row><cell>L. Temporal pole</cell><cell>Temporal_Pole_Sup_L</cell><cell>0.7558</cell><cell>0.2264</cell><cell>12.0</cell><cell>4.67</cell><cell>-32</cell><cell>14</cell><cell>-28</cell></row><row><cell>L. dACC</cell><cell>Cingulate_Ant_L</cell><cell>0.6462</cell><cell>0.1596</cell><cell>17.0</cell><cell>4.53</cell><cell>-10</cell><cell>38</cell><cell>14</cell></row><row><cell>L. Hippocampus</cell><cell>Hippocampus_L</cell><cell>0.665</cell><cell>0.1695</cell><cell>16.0</cell><cell>4.21</cell><cell>-22</cell><cell>-32</cell><cell>-6</cell></row><row><cell>L. Hippocampus</cell><cell>Hippocampus_L</cell><cell>0.5714</cell><cell>0.1262</cell><cell>21.0</cell><cell>4.14</cell><cell>-24</cell><cell>-18</cell><cell>-14</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported by <rs type="funder">Barbara-Wengeler-Foundation</rs>, the <rs type="funder">Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)</rs> project number <rs type="grantNumber">465409366</rs>, and by the <rs type="funder">Max Planck Society</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_BVasB6h">
					<idno type="grant-number">465409366</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data accessibility</head><p>Code (for preprocessing, analysis and visualisations) and preprocessed data for group analyses can be found at <ref type="url" target="https://osf.io/kn2af/?view_only=067b698a4567441e93b01518a88860a0">https://osf.io/kn2af/?view_only=067b698a4567441e93b01518a88860a0</ref>. Raw MRI data can be provided upon reasonable request.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CRediT author statement</head><p>Vincent Plikat: conceptualization, formal analysis (lead), investigation (equal), visualisation, writing -original draft, writing -review and editing. Pablo R. Grassi: conceptualization (lead), formal analysis (supporting), investigation (equal), methodology, supervision (equal), visualization, writing -original draft, writing -review and editing. Julius Frack: resources. Andreas Bartels: conceptualization, methodology, supervision (equal), writing -review and editing.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Machine learning for neuroimaging with scikit-learn</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Eickenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gervais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kossaifi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<idno type="DOI">10.3389/fninf.2014.00014</idno>
	</analytic>
	<monogr>
		<title level="j">Front Neuroinform</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Experience can change the &quot;light-from-above&quot; prior</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Graf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ernst</forename><surname>Mo</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn1312</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1057" to="1058" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Prior expectations evoke stimulus-specific activity in the deep layers of the primary visual cortex</title>
		<author>
			<persName><forename type="first">F</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Menelaou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Warrington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Koolschijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Corbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pbio.3001023</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">3001023</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Role of the Anterior Cingulate Cortex in Prediction Error and Signaling Surprise</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Brown</surname></persName>
		</author>
		<idno type="DOI">10.1111/tops.12307</idno>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="119" to="135" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Medial prefrontal cortex as an action-outcome predictor</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Alexander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Brown</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.2921</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1338" to="1344" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Representation of Real-World Event Schemas during Narrative Perception</title>
		<author>
			<persName><forename type="first">C</forename><surname>Baldassano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0251-18.2018</idno>
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="9689" to="9699" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Decoding the yellow of a gray banana</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bannert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bartels</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2013.09.016</idno>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2268" to="2272" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Brain activation for spontaneous and explicit false belief tasks overlaps: New fMRI evidence on belief processing and violation of expectation</title>
		<author>
			<persName><forename type="first">L</forename><surname>Bardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Desmet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nijhof</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Wiersema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brass</surname></persName>
		</author>
		<idno type="DOI">10.1093/scan/nsw143</idno>
	</analytic>
	<monogr>
		<title level="j">Social Cognitive and Affective Neuroscience</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="391" to="400" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The architecture of the colour centre in the human visual brain: New results and a review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bartels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zeki</surname></persName>
		</author>
		<idno type="DOI">10.1046/j.1460-9568.2000.00905.x</idno>
	</analytic>
	<monogr>
		<title level="j">European Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="172" to="193" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Simulation as an engine of physical scene understanding</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1306572110</idno>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="18327" to="18332" />
			<date type="published" when="2013">2013</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The surprising role of the default mode network in naturalistic perception</title>
		<author>
			<persName><forename type="first">T</forename><surname>Brandman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Malach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Simony</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42003-020-01602-z</idno>
	</analytic>
	<monogr>
		<title level="j">Commun Biol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Whatever next? Predictive brains, situated agents, and the future of cognitive science</title>
		<author>
			<persName><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X12000477</idno>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="181" to="204" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Control of goal-directed and stimulus-driven attention in the brain</title>
		<author>
			<persName><forename type="first">M</forename><surname>Corbetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Shulman</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn755</idno>
	</analytic>
	<monogr>
		<title level="j">Nature reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="201" to="215" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Cortical Surface-Based Analysis</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Sereno</surname></persName>
		</author>
		<idno type="DOI">10.1006/nimg.1998.0395</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="179" to="194" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">An fMRI investigation of expectation violation in magic tricks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Danek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Öllinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fraps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Grothe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Flanagin</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2015.00084</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How Do Expectations Shape Perception?</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Heilbron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2018.06.002</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="764" to="779" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Expectation and surprise determine neural population responses in the ventral visual stream</title>
		<author>
			<persName><forename type="first">T</forename><surname>Egner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.2770-10.2010</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="16601" to="16608" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Time-compressed preplay of anticipated events in human primary visual cortex</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename></persName>
		</author>
		<idno type="DOI">10.1038/ncomms15276</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Decoding information about dynamically occluded objects in visual cortex</title>
		<author>
			<persName><forename type="first">G</forename><surname>Erlikhman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Caplovitz</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2016.09.024</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="778" to="788" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Functional neuroanatomy of intuitive physical inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Mikhael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1610344113</idno>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<date type="published" when="2016">2016</date>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Whole Brain Segmentation</title>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Salat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Busa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dieterich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Haselgrove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der Kouwe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Killiany</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klaveness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Montillo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Makris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Dale</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0896-6273(02)00569-X</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="341" to="355" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Separate neural representations of prediction error valence and surprise: Evidence from an fMRI meta-analysis</title>
		<author>
			<persName><forename type="first">E</forename><surname>Fouragnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Retzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Philiastides</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.24047</idno>
	</analytic>
	<monogr>
		<title level="j">Hum Brain Mapp</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2887" to="2906" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The free-energy principle: A unified brain theory?</title>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn2787</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="127" to="138" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A theory of cortical responses</title>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2005.1622</idno>
	</analytic>
	<monogr>
		<title level="j">Philosophical transactions of the Royal Society of London Series B, Biological sciences</title>
		<imprint>
			<biblScope unit="volume">360</biblScope>
			<biblScope unit="page" from="815" to="836" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Conjunction revisited</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Penny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Glaser</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2005.01.013</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="661" to="667" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A multi-modal parcellation of human cerebral cortex</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Glasser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Coalson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Hacker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yacoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ugurbil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jenkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Van Essen</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature18933</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">536</biblScope>
			<biblScope unit="page" from="171" to="178" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Magic, Bayes and wows: A Bayesian account of magic tricks</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Grassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bartels</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neubiorev.2021.04.001</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroscience &amp; Biobehavioral Reviews</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="515" to="527" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">How can we be moved by magic?</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Grassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Plikat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Wong</surname></persName>
		</author>
		<idno type="DOI">10.1093/aesthj/ayad026</idno>
	</analytic>
	<monogr>
		<title level="j">British Journal of Aesthetics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="187" to="204" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Generic Mechanism for Perceptual Organization in the Parietal Cortex</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Grassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zaretskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bartels</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0436-18.2018</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="7158" to="7169" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Scene segmentation in early visual cortex during suppression of ventral stream regions</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Grassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Zaretskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bartels</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2016.11.024</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">146</biblScope>
			<biblScope unit="page" from="71" to="80" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The lateral occipital complex and its role in object recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Grill-Spector</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kourtzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0042-6989(01)00073-6</idno>
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="1409" to="1422" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Decoding reveals the contents of visual working memory in early visual areas</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tong</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature07832</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">458</biblScope>
			<biblScope unit="page" from="632" to="635" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Five-Month-Old Infants Have Different Expectations for Solids and Liquids</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hespos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Ferry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Rips</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-9280.2009.02331.x</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="603" to="611" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">The Predictive Mind</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hohwy</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780199682737.001.0001</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>OUP Oxford</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Attention and conscious perception in the hypothesis testing brain</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hohwy</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2012.00096</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Predictive coding explains binocular rivalry: an epistemological review</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hohwy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roepstorff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2008.05.010</idno>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="687" to="701" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The Sightless View: Neural Correlates of Occluded Objects</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">J</forename><surname>Hulme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zeki</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhl031</idno>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1197" to="1205" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Brain hemodynamic activity during viewing and re-viewing of comedy movies explained by experienced humor</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">P</forename><surname>Jääskeläinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pajula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tohka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H-J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W-J</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F-H</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1038/srep27741</idno>
	</analytic>
	<monogr>
		<title level="j">Sci Rep</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">27741</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Visual Prediction Error Spreads Across Object Features in Human Visual Cortex</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Egner</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.1546-16.2016</idno>
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="12746" to="12763" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">a. Less Is More: Expectation Sharpens Representations in the Primary Visual Cortex</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jfm</forename><surname>Jehee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2012.04.034</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="265" to="270" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Attention Reverses the Effect of Prediction in Silencing Sensory Signals</title>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rahnev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jfm</forename><surname>Jehee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhr310</idno>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="2197" to="2206" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Laminar Organization of Working Memory Signals in Human Visual Cortex</title>
		<author>
			<persName><forename type="first">Sjd</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Van Mourik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Koopmans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Norris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2018.08.043</idno>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Hierarchical Bayesian inference in the visual cortex</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
		<idno type="DOI">10.1364/josaa.20.001434</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of the Optical Society of America A</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">1434</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Violations of physical and psychological expectations in the human adult brain</title>
		<author>
			<persName><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lydic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Saxe</forename><forename type="middle">R</forename></persName>
		</author>
		<idno type="DOI">10.1162/imag_a_00068</idno>
	</analytic>
	<monogr>
		<title level="j">Imaging Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Contextual Feedback to Superficial Layers of V1</title>
		<author>
			<persName><forename type="first">L</forename><surname>Muckli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vizioli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Petro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">W</forename><surname>Ugurbil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yacoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2015.08.057</idno>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2690" to="2695" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Nonparametric permutation tests for functional neuroimaging: A primer with examples</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Holmes</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.1058</idno>
	</analytic>
	<monogr>
		<title level="j">Human Brain Mapping</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">AtlasReader: A Python package to generate coordinate tables, region labels, and informative figures from statistical MRI images</title>
		<author>
			<persName><forename type="first">M</forename><surname>Notter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Markello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M-L</forename><surname>Notter-Bielser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Whitaker</surname></persName>
		</author>
		<idno type="DOI">10.21105/joss.01257</idno>
	</analytic>
	<monogr>
		<title level="j">JOSS</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">1257</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Neuronal representation of occluded objects in the human brain</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">R</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gatenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H-C</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Skudlarski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gore</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0028-3932(03)00151-9</idno>
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="95" to="104" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Feedback brings scene information to the representation of occluded image regions in area V1 of monkeys and humans</title>
		<author>
			<persName><forename type="first">P</forename><surname>Papale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gilhuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Petro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Muckli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Roelfsema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Self</surname></persName>
		</author>
		<idno type="DOI">10.1101/2022.11.21.517305</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Imaging the impossible: An fMRI study of impossible causal relationships in magic tricks</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Parris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Mizon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Benattayallah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Hodgson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2008.12.036</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="1033" to="1039" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A neural substrate for object permanence in monkey inferotemporal cortex</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Puneeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Arun</surname></persName>
		</author>
		<idno type="DOI">10.1038/srep30808</idno>
	</analytic>
	<monogr>
		<title level="j">Sci Rep</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">30808</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">How Can We Be Moved by the Fate of Anna Karenina?</title>
		<author>
			<persName><forename type="first">C</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Weston</surname></persName>
		</author>
		<idno type="DOI">10.1093/aristoteliansupp/49.1.67</idno>
	</analytic>
	<monogr>
		<title level="j">Aristot Soc Suppl</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="67" to="94" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">The Brain&apos;s Default Mode Network</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Raichle</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-neuro-071013-014030</idno>
	</analytic>
	<monogr>
		<title level="j">Annu Rev Neurosci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="433" to="447" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Predictive coding in the visual cortex: A functional interpretation of some extraclassical receptive-field effects</title>
		<author>
			<persName><forename type="first">Rpn</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
		<idno type="DOI">10.1038/4580</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="79" to="87" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Selective and Invariant Neural Responses to Spoken and Written Narratives</title>
		<author>
			<persName><forename type="first">M</forename><surname>Regev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Honey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Simony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hasson</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.1580-13.2013</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="15978" to="15988" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Suppressed Sensory Response to Predictable Object Stimuli throughout the Ventral Visual Stream</title>
		<author>
			<persName><forename type="first">D</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename><surname>De Lange</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.3421-17.2018</idno>
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="7452" to="7461" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Automated anatomical labelling atlas 3</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Rolls</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C-C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C-P</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Joliot</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2019.116189</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">206</biblScope>
			<biblScope unit="page">116189</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Hearing Silences: Human Auditory Processing Relies on Preactivation of Sound-Specific Brain Activity Patterns</title>
		<author>
			<persName><forename type="first">I</forename><surname>Sanmiguel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Widmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bendixen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Trujillo-Barreto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schroger</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.5821-12.2013</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8633" to="8639" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Caudate Nucleus Signals for Breaches of Expectation in a Movement Observation Paradigm</title>
		<author>
			<persName><forename type="first">A-M</forename><surname>Schiffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Schubotz</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2011.00038</idno>
	</analytic>
	<monogr>
		<title level="j">Front Hum Neurosci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Feedforward and recurrent processing in scene segmentation: Electroencephalography and functional magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Scholte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jolij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Fahrenfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Vaf</forename><surname>Lamme</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn.2008.20142</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="2097" to="2109" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A neural substrate of prediction and reward</title>
		<author>
			<persName><forename type="first">W</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Montague</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.275.5306.1593</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">275</biblScope>
			<biblScope unit="page" from="1593" to="1599" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Invariant representations of mass in the human brain</title>
		<author>
			<persName><forename type="first">S</forename><surname>Schwettmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.46619</idno>
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">46619</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Distinct Roles of the Cortical Layers of Area V1 in Figure-Ground Segregation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Self</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Van Kerkoerle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Supèr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Roelfsema</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2013.09.013</idno>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="2121" to="2129" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Dynamic reconfiguration of the default mode network during narrative comprehension</title>
		<author>
			<persName><forename type="first">E</forename><surname>Simony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Honey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lositsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yeshurun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wiesel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hasson</surname></persName>
		</author>
		<idno type="DOI">10.1038/ncomms12141</idno>
	</analytic>
	<monogr>
		<title level="j">Nat Commun</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12141</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Event Representations and Predictive Processing: The Role of the Midline Default Network Core</title>
		<author>
			<persName><forename type="first">D</forename><surname>Stawarczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bezdek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<idno type="DOI">10.1111/tops.12450</idno>
	</analytic>
	<monogr>
		<title level="j">Top Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="164" to="186" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Feature-specific prediction errors for visual mismatch</title>
		<author>
			<persName><forename type="first">G</forename><surname>Stefanics</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heinzle</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2019.04.020</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">196</biblScope>
			<biblScope unit="page" from="142" to="151" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysis (MVPA): Random permutations and cluster size control</title>
		<author>
			<persName><forename type="first">J</forename><surname>Stelzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Turner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2012.09.063</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="69" to="82" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Prior expectation mediates neural adaptation to repeated sounds in the auditory cortex: An MEG study</title>
		<author>
			<persName><forename type="first">A</forename><surname>Todorovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Van Ede</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maris</forename><forename type="middle">E</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">P</forename></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.1425-11.2011</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="9118" to="9123" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Lowering the thermal noise barrier in functional brain mapping with magnetic resonance imaging</title>
		<author>
			<persName><forename type="first">L</forename><surname>Vizioli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Moeller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dowdle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Akçakaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Yacoub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Uğurbil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename></persName>
		</author>
		<idno type="DOI">10.1038/s41467-021-25431-8</idno>
	</analytic>
	<monogr>
		<title level="j">Nat Commun</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">5181</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Evidence for a hierarchy of predictions and prediction errors in human cortex</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wacongne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Labyt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Van Wassenhove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bekinschtein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Naccache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1117807108</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page" from="20754" to="20759" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Probabilistic maps of visual topography in human cortex</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reb</forename><surname>Mruczek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Arcaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kastner</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhu277</idno>
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="3911" to="3931" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Young infants&apos; reasoning about hidden objects: evidence from violation-of-expectation tasks with test trials only</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2003.09.012</idno>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="167" to="198" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Surprise and Error: Common Neuronal Architecture for the Processing of Errors and Novelty</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Wessel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Danielmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ullsperger</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.6352-11.2012</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="7528" to="7537" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Striatal Activity Underlies Novelty-Based Choice in Humans</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Wittmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2008.04.027</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="967" to="973" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Addition and subtraction by human infants</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wynn</surname></persName>
		</author>
		<idno type="DOI">10.1038/358749a0</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">358</biblScope>
			<biblScope unit="page" from="749" to="750" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">The organization of the human cerebral cortex estimated by intrinsic functional connectivity</title>
		<author>
			<persName><forename type="first">Btt</forename><surname>Yeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Krienen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sepulcre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lashkari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hollinshead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Roffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Smoller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zollei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Polimeni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Fischl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Buckner</surname></persName>
		</author>
		<idno type="DOI">10.1152/jn.00338.2011</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of neurophysiology</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="1125" to="1165" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">The default mode network: where the idiosyncratic self meets the shared social world</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yeshurun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hasson</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41583-020-00420-w</idno>
	</analytic>
	<monogr>
		<title level="j">Nat Rev Neurosci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="181" to="192" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Human Striatal Response to Salient Nonrewarding Stimuli</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Zink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pagnoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dhamala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Berns</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.23-22-08092.2003</idno>
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="8092" to="8097" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
