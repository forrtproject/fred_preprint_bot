<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MODEL SELECTION IN MMG-SEM</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Andres</forename><forename type="middle">F</forename><surname>Perez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jeroen</forename><forename type="middle">K</forename><surname>Vermunt</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Yves</forename><surname>Rosseel</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Ghent University</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kim</forename><surname>De Roover</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<settlement>Leuven</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Methodology and Statistics</orgName>
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<postBox>PO Box 90153</postBox>
									<postCode>5000 LE</postCode>
									<settlement>Tilburg</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MODEL SELECTION IN MMG-SEM</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D9B3E74728CAF04B91E450DA720E9ECD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>model selection</term>
					<term>mixture modeling</term>
					<term>structural relations</term>
					<term>structural equation modeling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This document is a pre-print and has not been peer reviewed yet. This research was funded by a Vidi grant [VI. Vidi.201.133]  awarded to Kim De Roover by the Netherlands Organization for Scientific Research (NWO). The code behind the simulations has been made publicly available on GitHub.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Selecting the number of clusters in Mixture Multigroup Structural Equation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling 1 Introduction</head><p>Comparing relations between unobservable or 'latent' variables (e.g., attitudes, emotions) across many groups is common in behavioral sciences. For instance, <ref type="bibr" target="#b19">Mayerl and Best (2019)</ref> studied how environmental attitudes related to environmental behavior in 30 countries. Structural Equation Modeling (SEM; <ref type="bibr" target="#b3">Bollen, 1989)</ref> allows estimating regression coefficients for relations among latent variables (LV) based on the covariances of their observed indicators, such as questionnaire items. In SEM, the regression coefficients are also called 'structural relations' and LVs are called 'factors'.</p><p>Multigroup SEM (MG-SEM) and Multilevel SEM (ML-SEM), are commonly used to compare structural relations across groups (e.g., <ref type="bibr" target="#b19">Mayerl &amp; Best, 2019)</ref>. To pinpoint differences and similarities, these approaches require pairwise comparisons of the group-specific values for the structural relations, which is a complex and daunting task when many groups are involved. For instance, for 30 groups, this would entail 435 pairwise comparisons per parameter. In ML-SEM, the group-specific parameter values are derived from random effects <ref type="bibr" target="#b15">(Hox et al., 2017)</ref>.</p><p>An intuitive solution is to find subsets of groups that share the same relations between factors using mixture modeling <ref type="bibr" target="#b20">(McLachlan et al., 2019)</ref>. However, before identifying such 'latent classes' or 'clusters', we must remember that the factors are indirectly measured via questionnaire items. Before comparing structural relations between groups, we must ensure that the measurement of the factors is the same across groups or, in other words, that 'measurement invariance' (MI; <ref type="bibr" target="#b21">Meredith, 1993)</ref> holds. This implies evaluating whether the measurement model (MM) -indicating which items measure which factors and to what extent -is invariant across groups. The MI assumption can be evaluated at several levels, focusing on different MM parameters <ref type="bibr" target="#b28">(Vandenberg &amp; Lance, 2000)</ref>. In case of many groups, invariance often does not hold for all the MM parameters.</p><p>To compare structural relations across groups, the equality of the so-called 'factor loadings' (i.e., the item-factor relations) must hold, which is called metric invariance<ref type="foot" target="#foot_0">1</ref> . Other higher-level MM differences are inconsequential for comparing structural relations if they are included in the model <ref type="bibr" target="#b9">(Chen, 2008;</ref><ref type="bibr" target="#b14">Guenole &amp; Brown, 2014)</ref>.</p><p>When looking for clusters of groups with equal structural relations, capturing the MM differences -or 'measurement non-invariances' -with group-specific parameters is important. Many existing mixture SEM methods (e.g., <ref type="bibr" target="#b17">Kim et al., 2016;</ref><ref type="bibr" target="#b29">Vermunt &amp; Magidson, 2005)</ref> force all parameters to be equal within a cluster. This implies that MM parameters can either be specified as invariant across all groups (i.e., ignoring measurement non-invariances) or as cluster-specific (i.e., enforcing MI within each cluster but not across clusters). Such mixture SEM methods capture clusters of groups with the same structural relations as well as the same MM parameters, and fail to disentangle the differences of interest (i.e., in the structural relations) from those not of interest (i.e., in the MM).</p><p>To effectively capture clusters of groups with equivalent structural relations while simultaneously accounting for measurement non-invariances, Perez <ref type="bibr">Alonso et al. (in press)</ref> proposed Mixture Multigroup SEM (MMG-SEM), which combines MG-SEM with mixture clustering. Specifically, it combines cluster-specific structural relations with measurement parameters that are partially group-specific, so that the clustering of the groups focuses only on the structural relations, which are of interest to the research question. Note that, essentially, MMG-SEM comprises two different types of LVs: (1) the continuous LVs measured by items at the individual-level, and (2) a categorical LV for the clusters at the group-level.</p><p>By gathering groups with equal structural relations in a cluster, MMG-SEM reduces the number of pairwise comparisons needed to pinpoint which relations differ among groups. However, it also introduces a problem inherent to mixture models; that is, for each data set, the appropriate number of clusters must be determined. In empirical research, the 'true' number of clusters is unknown, and the selection of the number of clusters is an important challenge. When too few clusters are selected, one fails to detect potentially interesting differences in the structural relations and, when too many clusters are retained, one ends up with an overly complex model. Perez <ref type="bibr">Alonso et al. (in press)</ref> showed that MMG-SEM performs well when the correct number of clusters is specified, but did not address the model selection problem. In their empirical application, they applied a model selection approach recommended for related mixture methods <ref type="bibr">(e.g., De Roover et al., 2022;</ref><ref type="bibr" target="#b18">Lukočienė &amp; Vermunt, 2009;</ref><ref type="bibr" target="#b18">Lukočienė et al., 2010)</ref>, but they did not evaluate how commonly used model selection approaches perform for MMG-SEM in different conditions or which approach is best for MMG-SEM.</p><p>Several approaches to address the model selection problem are available (see <ref type="bibr" target="#b1">Akogul &amp; Erisoglu, 2016)</ref>. For instance, the Bayesian Information Criterion (BIC; <ref type="bibr" target="#b26">Schwarz, 1978)</ref> and Akaike Information Criterion (AIC; <ref type="bibr" target="#b0">Akaike, 1974)</ref> integrate model fit and a penalty based on model complexity. Hence, a model that minimizes the criteria is assumed to have a good balance between model fit and parsimony. Another way of finding this balance is using the Convex Hull method <ref type="bibr" target="#b7">(Ceulemans &amp; Kiers, 2006)</ref>, which is a generalized scree test. Alternatively, the Integrated Completed Likelihood (ICL; <ref type="bibr" target="#b2">Biernacki et al., 2000)</ref> also considers the cluster separation; that is, it penalizes models that offer poorly-defined clusters (i.e., clusters that are too similar). This aligns with the fact that substantive researchers likely regard minor differences in structural relations to be trivial.</p><p>Numerous simulation studies have compared different model selection methods (e.g., <ref type="bibr" target="#b1">Akogul &amp; Erisoglu, 2016;</ref><ref type="bibr" target="#b12">De Roover et al., 2022;</ref><ref type="bibr" target="#b18">Lukočienė &amp; Vermunt, 2009;</ref><ref type="bibr" target="#b18">Lukočienė et al., 2010;</ref><ref type="bibr" target="#b22">Nylund et al., 2007)</ref>, showing different results depending on the conditions and mixture models evaluated. For instance, for mixture models combined with factor analysis, <ref type="bibr" target="#b5">Bulteel et al. (2013) and</ref><ref type="bibr" target="#b11">De Roover (2021)</ref> found that BIC and Convex Hull outperformed AIC. In the context of latent class analysis, <ref type="bibr" target="#b18">Lukočienė and Vermunt (2009)</ref> found that AIC 3 (i.e., a modified AIC with a larger penalty) performed better than other model selection methods.</p><p>These contradictory results emphasize the importance of evaluating and comparing model selection approaches for MMG-SEM specifically, which is the aim of this paper. By means of a simulation study, we will compare different approaches in conditions that mimic the ones found in social sciences. For instance, in empirical data, it is likely that certain groups have very similar -but not identical --regression parameters. Gathering these groups in the same cluster may still be desirable, for the sake of parsimony, and because researchers are often not interested in such trivial differences. Therefore, the simulated conditions will include different levels of small differences in structural relations within a cluster, to evaluate how this affects the model selection.</p><p>The remainder of this paper is organized as follows: MMG-SEM and relevant model selection methods are described in the Method section. A Simulation Study then evaluates the performance of the model selection methods in the context of MMG-SEM. The paper concludes with a Discussion section highlighting the most relevant results and limitations of the study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Mixture Multigroup Structural Equation Modeling</head><p>Mixture Multigroup Structural Equation Modeling (MMG-SEM; Perez Alonso et al., in press) combines mixture modeling with MG-SEM. In general, the mixture multigroup approach <ref type="bibr" target="#b11">(De Roover, 2021;</ref><ref type="bibr" target="#b12">De Roover et al., 2022)</ref>, aims to find a clustering that focuses on specific parameters of interest. In MMG-SEM, the clustering focuses on the structural relations, while MM differences are accounted for by group-specific parameters, so they do not affect the clustering.</p><p>For its estimation, Perez Alonso et al. (in press) used the 'Structural-After-Measurement' (SAM; Rosseel &amp; Loh, 2022) approach, which estimates a SEM model in two steps. In the first step, the MM is estimated, whereas the structural model (SM; including the structural relations) is estimated in the second step. The estimation of MMG-SEM is briefly described below (for more details, see Perez Alonso et al., in press).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Step 1: Measurement Model</head><p>The MM defines how the LVs are measured; that is, which items measure which factor and to what extent. When studying multiple groups (e.g., countries), the MM is often estimated using Multigroup Confirmatory Factor Analysis (MG-CFA). If we consider individuals n g = 1, . . . , N g within groups g = 1, . . . , G, items j = 1, . . . , J, and factors q = 1, . . . , Q, MG-CFA defines the vector of observed scores x ng of individual n g as follows</p><formula xml:id="formula_0">x ng = τ g + Λ g η ng + ϵ ng , (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>where τ g is a J-dimensional vector of group-specific intercepts, Λ g denotes a J × Q matrix of group-specific factor loadings, η ng is a Q-dimensional random vector of factor scores, and ϵ ng is a J-dimensional random vector of residuals. Note that MG-CFA imposes a pattern of zero and non-zero loadings on Λ g , and that, in this paper, we center the observed variables per group to remove the mean structure, which is equivalent to estimating the group-specific τ g , but computationally more efficient. We assume that, (1)</p><p>η ng is distributed according to a multivariate normal distribution M V N (α g , Φ g ), where α g and Φ g are the mean vector and covariance matrix of the factors, respectively, and (2) ϵ ng is distributed according to M V N (0, Θ g ), where Θ g is the covariance matrix of the residuals in group g. To scale the LVs, we use the marker variable approach (i.e., fixing one loading to one per factor). If we assume that Cov(η ng , ϵ ng ) = 0, the model-implied covariance matrix of group g is given by</p><formula xml:id="formula_2">Σ g = Λ g Φ g Λ ′ g + Θ g . (2)</formula><p>In the context of MMG-SEM, one must evaluate measurement invariance (MI) before clustering groups on structural relations. As mentioned in the introduction, MI can be evaluated at different levels by focusing on different parameters. First, one must evaluate configural invariance by testing if the model in Equation 1 holds across groups. If the model's fit is satisfactory <ref type="bibr" target="#b8">(Chen, 2007)</ref>, one can assume that the same items measure the same factors across groups. Second, one must test for metric invariance by constraining the non-zero loadings in Λ g to be the same across groups. If imposing Λ g = Λ does not significantly worsen the model fit <ref type="bibr" target="#b25">(Rutkowski &amp; Svetina, 2014)</ref>, full metric invariance holds.</p><p>Metric invariance must hold, at least partially, for valid comparisons of the structural relations<ref type="foot" target="#foot_1">2</ref> . Therefore, the remaining MM parameters (i.e., τ g , Θ g , and potentially some loadings) are allowed to be group-specific in MMG-SEM. If full metric invariance holds, the model-implied covariance matrix of group g in MMG-SEM's first step is</p><formula xml:id="formula_3">Σ g = ΛΦ g Λ ′ + Θ g . (<label>3</label></formula><formula xml:id="formula_4">)</formula><p>The MM is fitted by minimizing the difference between the model-implied covariance matrix Σ g and the observed covariance matrix S. The group-specific factor covariance matrices Φ g from Equation <ref type="formula" target="#formula_3">3</ref>are the input for MMG-SEM's second step. To avoid confusion in the notation of the remaining text, the covariance matrices Φ g from step 1 will have a superscript s1 (i.e., Φ s1 g ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Step 2: Structural Model</head><p>In the second step, MMG-SEM estimates the SM and performs the mixture clustering based on the structural relations. Note that MMG-SEM operates at the group-level; that is, it finds clusters of groups instead of clusters of observations. The SM, which defines how the LVs are related, is conditional on the membership of group g to cluster k, denoted as z gk , which takes on a value of 1 or 0. Note that the true cluster memberships z gk are unknown and that the estimated ẑgk is a probability ranging from 0 to 1. Formally, the model-implied factor covariance matrix Φ gk is defined as:</p><formula xml:id="formula_5">[Φ gk |z gk = 1] = (I -B k ) -1 Ψ gk (I -B k ) -1 ′ , (<label>4</label></formula><formula xml:id="formula_6">)</formula><p>where B k is a non-symmetric Q × Q matrix containing the unstandardized cluster-specific regression coefficients between LVs, and Ψ gk is the residual factor covariance matrix. The group-and-cluster-specific nature of Ψ gk ensures that the clustering is driven only by the regression coefficients B k , and not (also) by the residual factor covariances 3 . The SM for each group-cluster combination gk is fitted by minimizing the differences between the model-implied factor covariance matrices Φ gk in step 2 and the group-specific covariance matrices Φ s1 g from step 1.</p><p>For the mixture clustering, MMG-SEM assumes that the vector of factor scores η ng is sampled from a mixture of K multivariate normal distributions and that all factor scores of group g -gathered in a matrix H g of factor scores -are sampled from the same distribution. Specifically, the formal definition for group g is the following</p><formula xml:id="formula_7">f (H g ; ϑ) = K k=1 π k f gk (H g ; ϑ gk ) = K k=1 π k Ng ng=1 M V N (η ng ; α g , Φ gk ), (<label>5</label></formula><formula xml:id="formula_8">)</formula><p>where f is the population density function, ϑ is the set of population parameters, π k is the prior probability of a group g belonging to cluster k (where K k=1 π k = 1), f gk is the density function of the group g in the kth cluster, and ϑ gk is its corresponding set of parameters.</p><p>Specifically, f gk is a multivariate normal distribution where Φ gk and α g are the factors' covariance matrix and mean vector, respectively. The covariance matrix is decomposed as indicated in Equation <ref type="formula" target="#formula_5">4</ref>, and the factor means α g are equal to zero due to the centering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Model estimation</head><p>The unknown parameters ϑ of step 2 (Equation <ref type="formula" target="#formula_7">5</ref>) are estimated by means of maximum likelihood estimation using an EM algorithm (for details, see Perez Alonso et al., in press). Specifically, the following log-likelihood function is maximized: where Φ s1 g is Step 1's factor covariance (Equation <ref type="formula" target="#formula_3">3</ref>), and Φ gk is Step 2's factor covariance (Equation <ref type="formula" target="#formula_5">4</ref>).</p><formula xml:id="formula_9">logL η = G g=1 log   K k=1 π k 1 (2π) Q/2 |Φ gk | 1/2 exp - 1 2 tr(Φ s1 g Φ -1 gk ) Ng   , (<label>6</label></formula><p>Note that the log-likelihood function in Equation 6 considers only the parameters in the SM. The log-likelihood function for the full MMG-SEM model (i.e., combining Step 1 and</p><p>Step 2) is defined as</p><formula xml:id="formula_10">logL = G g=1 log   K k=1 π k Ng ng=1 1 (2π) J/2 |Σ gk | 1/2 exp - 1 2 (x ng -µ g ) ′ Σ -1 gk (x ng -µ g )   , (<label>7</label></formula><formula xml:id="formula_11">)</formula><p>where µ g and Σ gk are the mean vector and model-implied covariance matrix of the observed items, respectively. The µ g is zero due to the centering, and the Σ gk can be reconstructed by inserting Equation <ref type="formula" target="#formula_5">4</ref>into Equation <ref type="formula" target="#formula_3">3</ref>as</p><formula xml:id="formula_12">Σ gk = Λ(I -B k ) -1 Ψ gk (I -B k ) -1 ′ Λ ′ + Θ g . (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Model Selection</head><p>A common challenge for clustering methods is selecting an appropriate number of clusters. Researchers have tried to solve this problem based on different approaches, such as balancing model fit and complexity <ref type="bibr" target="#b0">(Akaike, 1974;</ref><ref type="bibr" target="#b1">Akogul &amp; Erisoglu, 2016;</ref><ref type="bibr" target="#b26">Schwarz, 1978)</ref>, considering relative fit improvement <ref type="bibr" target="#b7">(Ceulemans &amp; Kiers, 2006)</ref>, cluster separation <ref type="bibr" target="#b2">(Biernacki et al., 2000)</ref>, and/or substantive interpretation (van den <ref type="bibr" target="#b27">Bergh et al., 2017)</ref>.</p><p>Given the popularity of clustering, new methods for model selection keep emerging.</p><p>However, we focus on commonly used approaches for model selection in the context of mixture SEM methods, which are detailed below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Akaike Information Criterion</head><p>The Akaike Information Criterion (AIC; <ref type="bibr" target="#b0">Akaike, 1974)</ref> combines the model fit (i.e., the log-likelihood) with a penalty for model complexity (i.e., number of parameters). It is defined as:</p><formula xml:id="formula_13">AIC = -2logL + 2P (<label>9</label></formula><formula xml:id="formula_14">)</formula><p>where P is the number of parameters. For MMG-SEM, P is the sum of the number of mixing proportions (minus one restriction), the number of cluster-specific regressions coefficients, the number of group-specific exogenous factor covariances, the number of group-and-cluster-specific endogenous factor covariances<ref type="foot" target="#foot_2">4</ref> , the number of loadings (minus Q fixed loadings due to factor scaling and accounting for (non-)invariant loadings), and the number of group-specific unique variances.</p><p>A number of modifications of the AIC have been presented. In this paper, we consider only one such modification: the AIC 3 <ref type="bibr" target="#b4">(Bozdogan, 1994)</ref>, which was developed specifically for determining the number of clusters in mixture models. It is defined as:</p><formula xml:id="formula_15">AIC 3 = -2logL + 3P. (<label>10</label></formula><formula xml:id="formula_16">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Bayesian Information Criterion</head><p>The Bayesian Information Criterion (BIC; <ref type="bibr" target="#b26">Schwarz, 1978)</ref> balances model fit and model complexity as follows:</p><formula xml:id="formula_17">BIC = -2logL + P log(SS),<label>(11)</label></formula><p>where the penalty of the model complexity is now weighted by the logarithm of the sample size SS. Usually, the total number of observations N is used as the SS (BIC N ), but it has been suggested to use the number of groups G instead of N (BIC G ) when selecting the number of group-level clusters <ref type="bibr" target="#b18">(Lukočienė &amp; Vermunt, 2009;</ref><ref type="bibr" target="#b18">Lukočienė et al., 2010)</ref>.</p><p>De Roover (2021) and De Roover et al. ( <ref type="formula">2022</ref>) found a superior performance of BIC G in the context of a related mixture multigroup approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Convex Hull</head><p>The convex hull procedure (CHull; <ref type="bibr" target="#b7">Ceulemans &amp; Kiers, 2006)</ref> has been shown to be a valid alternative to BIC and AIC in the context of mixtures of factor analyzers <ref type="bibr" target="#b5">(Bulteel et al., 2013)</ref>. CHull is a generalized scree test that balances model fit and model complexity by plotting the logL of the different models in function of their number of parameters P . Then, for each model on convex hull of the scree plot, a scree ratio is computed and the solution with the maximal scree ratio is selected. Specifically, the scree ratio sr d for model d is defined as:</p><formula xml:id="formula_18">sr d = logL d -logL d-1 P d -P d-1 logL d+1 -logL d P d+1 -P d , (<label>12</label></formula><formula xml:id="formula_19">)</formula><p>where d -1 refers to the previous (less complex) model on the hull and d + 1 refers to the next (more complex) model on the hull. It is worth noting that a scree ratio cannot be computed for the least complex model, so it will always select a model with at least two clusters. However, if no clear elbow in the scree plot, one may still conclude that an underlying cluster is unlikely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.4">Integrated Completed Likelihood</head><p>The Integrated Completed Likelihood (ICL; <ref type="bibr" target="#b2">Biernacki et al., 2000)</ref> is a model selection criterion developed for mixture clustering as an alternative to the BIC. The BIC does not consider an essential aspect of the mixture models; that is, the estimated cluster memberships ẑgk . Therefore, <ref type="bibr" target="#b2">Biernacki et al. (2000)</ref> proposed using the Entropy, which is a measure of the uncertainty of group g belonging to cluster k. Remember that ẑgk is a probability ranging from 0 to 1. Formally, for MMG-SEM, the Entropy can be defined as:</p><formula xml:id="formula_20">Entropy = G g=1 K k=1 (-ẑ gk )(logẑ gk )<label>(13)</label></formula><p>The complete derivation of the ICL can be found in <ref type="bibr" target="#b2">Biernacki et al. (2000)</ref>, but its approximation, based on the BIC, is rather simple. Formally, the ICL is approximated as 5 :</p><formula xml:id="formula_21">ICL = BIC + 2Entropy<label>(14)</label></formula><p>For brevity, we focus on the ICL based on BIC G in the Simulation Study, since this has been shown to perform better than BIC N in the context of group-level clustering.</p><p>5 <ref type="bibr" target="#b2">Biernacki et al. (2000)</ref> defined the ICL slightly differently as BIC -Entropy, but they defined BIC = logL -P 2 log(SS) instead of BIC = -2logL + P log(SS). Therefore, both ICL definitions will lead to the same results in terms of model selection. 6. Within-cluster differences σ β : no difference (0), small (0.05), large (0.1).</p><p>In total, the design included 2 (size of regression parameters) × 2 (number of groups) × 3 (within-group sample size) × 2 (number of clusters) × 2 (cluster size) × 3 (within-cluster differences) = 144 data generation conditions. For all conditions, 50 different data sets were generated, for a total of 7200 data sets. To evaluate the model selection measures, each data set was analyzed six times with MMG-SEM from one to six clusters, for a total of 7200 × 6 = 43200 analyses. Note that we added non-invariances to the loadings (see Data Generation for more information) and that such non-invariances are correctly modeled in MMG-SEM. All the data generation and analyses were done using R version 4.3.3 (R Core Team, 2024). The data generation procedure is described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Generation</head><p>Each data set was generated according to the SEM model in Figure <ref type="figure">1</ref>, with four LVs, each one measured by five indicators, for a total of 20 observed variables. The structural relations, which are the parameters of interest for the clustering, are represented by four regression parameters. F1 and F2 served as exogenous variables, while F3 and F4 were endogenous variables. Note that F3 acts as a 'mediator' and is, thus, an exogenous and endogenous variable at the same time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1</head><p>The model used for the data generation. F1 and F2 are exogenous variables, F3 is dependent and independent at the same time ('mediator'), and F4 is a dependent only variable.</p><p>The sample size per group N g , the number of groups G, and the number of clusters K were defined according to the manipulated factors 'within-group sample size', 'number of groups', and 'number of clusters', respectively. The number of groups per cluster was manipulated according to the 'cluster size'. In the balanced condition, the groups were equally divided per cluster. For instance, for G = 48 and K = 4, each cluster contained 12 groups. In contrast, in the unbalanced condition, there was one larger cluster with 75% of the groups, and the remaining clusters were equally sized. For example, for G = 48 and K = 4, the first cluster would contain 36 groups and the remaining three clusters would contain four groups each.</p><p>The 20 observed variables were generated from a M V N (µ g , Σ gk ), where the mean vector µ g was a vector of zeros and the covariance matrices Σ gk were generated according to Equation <ref type="formula">8</ref>. Thus, to generate the data, the parameters in Equation <ref type="formula">8</ref>(i.e., Λ, Θ g , B k , and Ψ gk ) must be defined. The Λ and Θ g matrices were generated aiming to obtain a total variance per item around 1 and a reliability (R 2 ) of 0.6 for each observed indicator. To do this, the non-zero values in Λ were set to √ 0.6 while the residual variances in Θ g were drawn from a uniform distribution U (0.3, 0.5). Note that the residual variances in Θ g were sampled for each group, allowing group-specific differences as specified in Equation <ref type="formula">8</ref>.</p><p>To evaluate the effect of loading non-invariances on the model selection, we also added between-group differences to the Λ matrices. In particular, 50% of the groups presented non-invariances. For each non-invariant group, we applied the non-invariance to the second and third loading of each factor (the first loading is fixed to 1). The non-invariances were randomly sampled from a uniform distribution around 0.4 (i.e., U (0.3, 0.5)), and it was randomly decided whether the non-invariance was added or subtracted to the original loading (i.e., √ 0.6). As a result, each non-invariant loading was different for each non-invariant group.</p><p>The setup of the regression parameters in B k can be seen in Figure <ref type="figure">2</ref>. The manipulated factor 'size of the regression parameters' (β) indicated the size of the coefficients β 1 , β 2 , β 3 , and β 4 . The difference between the clusters was created by setting one of those coefficients to zero in each cluster. Thus, the size of the regression parameters also defined the size of the difference between the clusters. Note that, when K = 2, models three and four in Figure <ref type="figure">2</ref> were not applicable. The parameters in B k were also affected by the manipulated factor 'within-cluster differences' (σ β ). To simulate empirically realistic conditions, we added small differences in the coefficients β to each group g within a cluster k. To do this, within each cluster, the regression parameter of each group was drawn from a normal distribution N (β, σ β ), where the β and the σ β acted as the mean and the standard deviation of the distribution, respectively. The values of σ β implied no within-cluster differences (σ β = 0), small differences (σ β = 0.05), or large differences (σ β = 0.1). Note that we expect 99% of the sampled values to be within three standard deviations of the mean when drawing from a normal distribution. For instance, if we consider β = 0.3 and σ β = 0.05 and we focus on β 1 (see Figure <ref type="figure">2</ref>), the values of β 1 in Cluster 1 will be sampled from N (0, 0.05), whereas they will be sampled from N (0.3, 0.05) in Cluster 2. We expect 99% of the values to lie between -0.15 and 0.15 in Cluster 1 and between 0.15 and 0.45 in Cluster 2. Thus, the small differences level (σ β = 0.05) led to almost no overlap between clusters, whereas the large level (σ β = 0.1) ensured overlap between the clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>Zero and non-zero regression parameters between the LVs depending on the cluster.</p><p>Finally, the elements in Ψ gk were defined by sampling the variance of the exogenous variables F1 and F2 from a uniform distribution U (0.75, 1.25), and their covariance from U (-0.3, 0.3) for all groups. Similarly, the total variance of the endogenous factors F3 and F4 was sampled from U (0.75, 1.25) for each group, and their residual variance depended on the cluster-specific regression parameters. For example, if the total variance of F3 for group g was V ar tot , the residual variance V ar res for group g and cluster k was</p><formula xml:id="formula_22">V ar res = V ar tot -(β 2 2 Var(F 1) + β 2 3 Var(F 2) + 2β 2 β 3 Cov(F 1, F 2)).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">R 2 Entropy</head><p>To determine the cluster separation in the simulated datasets, we applied the R 2</p><p>Entropy, an Entropy-based measure. Specifically, the R 2 Entropy indicates how well the observed responses predict the cluster memberships ẑgk (for details on its calculation, see <ref type="bibr" target="#b30">Vermunt &amp; Magidson, 2016)</ref>. It takes on a value of 1 when the clusters are perfectly separated (i.e., no classification uncertainty) and a value of 0 when there is no separation at all.</p><p>To get an overview of how the cluster separation was affected by the simulation conditions, we evaluated the R 2 Entropy at (an approximated) population level. For this, we generated data for each simulation condition with a large sample size. Given that MMG-SEM's clustering is at the group-level, the relevant sample size for the clustering and R 2 Entropy is the number of groups G, which was set to 192 groups. Subsequently, we computed the cluster memberships ẑgk based on the true parameters values for Λ, Θ g , B k , and Ψ gk (i.e., they were used as starting values in an MMG-SEM analysis where no parameter updates were performed). Per condition, 300 replications were generated. The R 2 Entropy ranged from 0.76 to 1 with an average of 0.93 across all data sets, which indicated well-separated clusters overall. The R 2 Entropy was mostly influenced by the within-cluster differences σ β , the regression coefficients β, and the within-group sample size N g . Their main effects can be seen in Table <ref type="table" target="#tab_0">1</ref>, and the interaction between σ β and β is shown in Figure <ref type="figure">3</ref>. Lower R 2 Entropy values were found in difficult conditions involving large within-cluster differences (σ β = 0.1), lower regression coefficients (β = 0.3) and/or low within-group sample size (N g = 50). It is expected that the model selection measures will struggle to choose the correct number of clusters in conditions where the clusters are not well separated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3</head><p>Approximated population R 2 Entropy in function of the within-cluster differences σ β and the size of the regression parameters β.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Before discussing the findings, it is worth noting that the evaluated model selection methods all use the log-likelihood as the measure of model fit. For MMG-SEM, we could use the log-likelihood based on the factors (Equation <ref type="formula" target="#formula_9">6</ref>) or the observed data log-likelihood (Equation <ref type="formula" target="#formula_10">7</ref>). We evaluated the measures' performance using both log-likelihoods in our simulation and found only minor differences in the results. Thus, for brevity, we present only the results using the log-likelihood in Equation <ref type="formula" target="#formula_10">7</ref>, since this considers how the full model (i.e., measurement + structural model) fits the data. The results using Equation <ref type="formula" target="#formula_9">6</ref>can be found in the Supplemental Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Model Selection</head><p>For each model selection measure, we assessed how often it correctly selected the true number of clusters. To gain a deeper understanding of each measure, we also inspected how often it over-and under-selected the number of clusters. The main effects of the manipulated factors of the simulation can be seen in Table <ref type="table" target="#tab_1">2</ref>. In total, the best-performing method was the CHull, followed by the AIC, AIC 3 , BIC G , ICL, and BIC N , with a proportion of correctly selected models of 0.77, 0.66, 0.64, 0.62, 0.61, and 0.54, respectively.</p><p>The within-group sample size N g was most influential on the model selection performance. Specifically, on average, the model selection measures were correct 47% and 74% of the times when N g = 50 and N g = 100, respectively. Such dramatic improvement did not hold when N g increased to 200, for which the measures were correct 71% of the time. The improvement from N g = 50 to N g = 100 aligns with common sample size requirements in SEM, since 100 is considered the minimum for consistent estimates <ref type="bibr" target="#b13">(Gorsuch, 1983)</ref>. The slight decrease in performance when N g = 200 can be explained by the trends of under-and over-selection of the number of clusters. Generally, when choosing the incorrect model, the measures tended to under-select. However, over-selection was more prominent in case of a large within-group sample size (N g = 200). Such results are unsurprising, considering that larger sample sizes give more power to identify smaller differences (leading to more clusters). This is more likely in case of larger within-cluster differences (σ β = 0.1), which can be identified as additional clusters.</p><p>The model selection performance was also greatly affected by the number of clusters K. On average, all model selection measures found it more difficult to identify the correct model when more clusters were underlying the data. The proportion of correctly selected models was better when K = 2 (0.82) than when K = 4 (0.46). This is due to a lower sample size within each cluster in case of more clusters, reducing the power to detect the appropriate model. The model selection was also, to a lesser extent, affected by the regression coefficients β and the cluster size. Specifically, a lower regression coefficient and unbalanced cluster sizes lowered the proportion of correctly selected models.</p><p>The interaction between the most important factors can be seen in Figure <ref type="figure">4</ref>. The plot clearly shows that more clusters and large within-cluster differences led to a dramatic decrease in the performance of all model selection measures. Specifically, the AIC, AIC 3 , BIC G , and ICL presented a substantial decrease of the correctly selected number of clusters. In contrast, the CHull and BIC N presented a lower decrease in performance when K = 4 and/or σ β = 0.1. BIC N 's performance was generally worse than all other model selection measures, however.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4</head><p>Proportion of correctly selected models in function of the number of clusters K and the within-cluster differences σ β .</p><p>From Figure <ref type="figure">4</ref>, we also learn that the performance sometimes improved when going from σ β = 0 to σ β = 0.05, especially for the CHull. For the CHull, this can be explained by the saturation effect, which happens when adding more clusters results in a negligible increase in the log-likelihood. This can lead to an artificially large scree ratio (because the denominator approaches zero, see Equation <ref type="formula" target="#formula_18">12</ref>), whereas, when looking at the scree plot, a virtually horizontal line, rather than an elbow, is visible at this point. In empirical practice, one can remedy this problem by looking for a clear elbow in the scree plot instead of just relying on the scree ratios.</p><p>The comparison between CHull and the other measures can be considered unfair, since CHull selects a model with at least two clusters. Thus, when K = 2, the other model selection measures may select a one-cluster model when the cluster separation is low, while</p><p>CHull will select at least two clusters 6 . For a fairer comparison, we also checked the results</p><p>for the other model selection measures when considering only the models from two to six clusters. In this case, AIC, AIC 3 , BIC G , ICL, and BIC N selected the right number of clusters for 66.8%, 66.7%, 65.7%, 66.2%, and 62.6% of the datasets, respectively. Thus, their performance was closer to (but still lower than) that of the CHull (77%).</p><p>Finally, for a more comprehensive understanding of the outcomes, we examined how often the model selection measures correctly identified the number of clusters when considering the two best models (e.g., how often is the correct model among the two models with the lowest AIC values). The correct model was among the two best models 82.4%, 72.4%, 73%, 72.8%, 73.5%, and 69.2% of the times for CHull, AIC, AIC 3 , BIC G , ICL, and BIC N , respectively. The BIC G , BIC N , and ICL showed the largest improvements in performance compared to when we focus only on the best model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Cluster Recovery</head><p>The previous results must be interpreted in light of the cluster recovery (i.e., to what extent MMG-SEM assigns groups to the correct clusters). To this end, we computed the Adjusted Rand Index (ARI; <ref type="bibr" target="#b16">Hubert &amp; Arabie, 1985)</ref> to the model with the true number of clusters. The ARI compares two partitions (i.e., modal assignments of the groups to a cluster), taking on a value of 1 for complete agreement and 0 when agreement does not exceed that between two random partitions. Note that it can take on negative values if the agreement is less than what is expected at random. The average ARI across all conditions was good (0.93), but it ranged from -0.08 to 1. Per model selection measure, we also inspected the average ARI across data sets depending on whether the number of clusters was under-, over-, or correctly selected (Table <ref type="table" target="#tab_2">3</ref>). Clearly, selecting the incorrect 6 As can be seen in Table <ref type="table" target="#tab_1">2</ref>, CHull never under-selects the number of clusters when K = 2 model (i.e., under-or over-selection) was related to the ARI being lower. Specifically, the average ARI was below 0.89 for all measures when the selected model was incorrect, while it was above 0.97 when the selected model was correct. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Conclusion</head><p>Before drawing conclusions, it is important to note that, strictly speaking, there are as many clusters as there are groups when σ β &gt; 0 (i.e., in case of within-cluster differences). As MMG-SEM does not capture within-cluster differences, the model selection could suggest extracting more clusters or even capturing each group as a separate cluster, especially when there is enough power to find small differences. However, in this study, we still assumed the true number of clusters to be K, since it is desirable to assign groups with very similar regression parameters to the same cluster (see Introduction). Considering every group as a separate cluster would boil back down to an MG-SEM with group-specific relations and the pesky pairwise comparisons thereof. As this is what we wanted to avoid, we did not include the MG-SEM model in this study.</p><p>In an extensive simulation study, we assessed six different model selection measures for MMG-SEM. As expected, lower within-group sample sizes (N g = 50), large within-cluster differences (σ β = 0.1), more clusters (K = 4), and unbalanced cluster sizes decreased the performance of all measures. Overall, the best-performing measure was the CHull and the worst was the BIC N . AIC, AIC 3 , BIC G , and ICL presented similar performances with minor differences depending on specific conditions.</p><p>Considering our results, we suggest using the CHull when performing model </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>When using MMG-SEM, the user must specify the appropriate number of clusters for a given data set, as is the case for all clustering techniques. However, the 'true' number of clusters is typically unknown when dealing with real-world data. Therefore, researchers often rely on model selection measures to decide on the number of clusters. Several model selection measures have been evaluated for other clustering methods, but there is no clear-cut answer to which measure is the best one. Different results were found depending on the clustering method, the conditions assessed, and the level at which the clustering is performed (i.e., observation or group level) <ref type="bibr" target="#b1">(Akogul &amp; Erisoglu, 2016;</ref><ref type="bibr" target="#b12">De Roover et al., 2022;</ref><ref type="bibr" target="#b18">Lukočienė et al., 2010;</ref><ref type="bibr" target="#b22">Nylund et al., 2007)</ref>. Considering the conflicting results and the unique properties of MMG-SEM, such as the combination of group-and cluster-specific parameters, and a clustering focused on regression parameters, prior conclusions on their model selection performance cannot be generalized to MMG-SEM. Therefore, this paper aimed to find the best-performing model selection measure for MMG-SEM through an extensive simulation study. In particular, we compared six model selection measures (i.e., CHull, AIC, AIC 3 , BIC G , ICL, and BIC N ), and included conditions that affect the cluster's separability and mimic empirically realistic conditions. In particular, the small within-cluster differences resembled the small (and trivial) differences between groups that will often be found in empirical research but that are ineffectual to the substantive conclusions on how structural relations differ.</p><p>Overall, the best-performing measure was the CHull, followed by the AIC, AIC 3 , BIC G , ICL, and BIC N . While, in general, this is in line with some previous studies (e.g., <ref type="bibr" target="#b5">Bulteel et al., 2013;</ref><ref type="bibr" target="#b11">De Roover, 2021;</ref><ref type="bibr" target="#b12">De Roover et al., 2022)</ref>, the clear difference in performance between CHull and the other measures was a remarkable find. This difference could not be explained by the fact that CHull can only select at least two clusters. CHull's advantage may result from its flexibility and lack of assumptions compared to the other measures. For instance, some argue that the true model must be among the candidates for BIC to have consistent results <ref type="bibr" target="#b31">(Vrieze, 2012)</ref>, which was, strictly speaking, not always the case in the simulation study since the 'true' model was one with group-specific (instead of cluster-specific) regression parameters in case of within-cluster differences.</p><p>The vastly inferior performance of BIC N coincides with previous results for mixture models at the group level that showed that using the number of observations N instead of G as the sample size in the BIC leads to overpenalization and, thus, under-selection <ref type="bibr" target="#b11">(De Roover, 2021;</ref><ref type="bibr" target="#b12">De Roover et al., 2022;</ref><ref type="bibr" target="#b18">Lukočienė &amp; Vermunt, 2009;</ref><ref type="bibr" target="#b18">Lukočienė et al., 2010)</ref>. More surprising was the superior performance of the AIC over the BIC G , given that previous simulations have shown a slight advantage of BIC G in latent class and mixture models <ref type="bibr" target="#b11">(De Roover, 2021;</ref><ref type="bibr" target="#b18">Lukočienė &amp; Vermunt, 2009;</ref><ref type="bibr" target="#b18">Lukočienė et al., 2010)</ref>. In other studies, AIC slightly outperformed the BIC G , however <ref type="bibr" target="#b12">(De Roover et al., 2022)</ref>.</p><p>It is worth mentioning that simulation-based research always comes with limitations. Specifically, the results cannot be straightforwardly generalized to conditions that were not assessed in the simulation. For instance, we only included data and models with continuous and normally distributed items, whereas earlier simulations showed different results depending on the type of indicator <ref type="bibr" target="#b18">(Lukočienė et al., 2010)</ref>. Since data in social sciences commonly uses ordinal indicators and often presents non-normality (e.g., skewness), it is important to extend the model selection evaluations to MMG-SEM with ordinal indicators and robust estimators for non-normality. Note that the CHull could be computed with measures of model fit other than log-likelihood (e.g., the distance between the model-implied and observed covariance matrices) and avoid the distributional assumptions that come with it. Moreover, in the Simulation Study, we focused on model selection measures that are most commonly used for mixture models in social sciences, overlooking other measures. For instance, the Kullback Information Criterion <ref type="bibr" target="#b6">(Cavanaugh, 1999</ref>) is a promising alternative for large sample conditions <ref type="bibr" target="#b1">(Akogul &amp; Erisoglu, 2016)</ref>; and the normalized information criteria <ref type="bibr" target="#b10">(Cohen &amp; Berchenko, 2021)</ref> was developed for the presence of missing data.</p><p>Finally, for MMG-SEM -which compares structural relations between groups using clusters-selecting an appropriate number of clusters is essential for the research questions. Indeed, under-or over-selecting clusters may impair the conclusions on differences and similarities in the relations of interest. When selecting too few clusters, important differences may be overlooked. When selecting too many clusters, one ends up with an overly complex model that implies more comparisons of cluster-specific regression coefficients and, thus, a higher risk of false positives. Therefore, we are happy to conclude that the model selection measures assessed in this paper offer promising solutions to the model selection problem for MMG-SEM, especially when combined (e.g., CHull and AIC).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>)3</head><label></label><figDesc>To this aim, the residual (co)variances of the endogenous factors are group-and-cluster-specific, whereas the (co)variances of the exogenous factors are group-specific. For more details, please see the original paper by Perez Alonso et al. (in press).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>The aim of the simulation study was to compare the performance of six model selection measures in selecting the number of clusters for MMG-SEM: AIC, AIC 3 , BIC G , BIC N , CHull, and ICL. To this end, we used a Monte-Carlo simulation with six manipulated factors that are expected to affect the model selection performance. The factors and their corresponding levels are described below: 1. Size of regression parameters β: 0.3, 0.4; 2. Number of groups G: 24, 48; 3. Within-group sample size N g : 50, 100, 200; 4. Number of clusters K: 2, 4; 5. Cluster size: balanced, unbalanced;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="14,164.70,249.62,282.60,291.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="17,144.90,75.19,322.20,317.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="19,115.40,75.19,381.20,206.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="22,101.75,152.23,408.51,287.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Average R 2 Entropy per level of the most influential factors.</figDesc><table><row><cell></cell><cell>N g</cell><cell></cell><cell></cell><cell>σ β</cell><cell></cell><cell>β</cell><cell></cell></row><row><cell>50</cell><cell>100</cell><cell>200</cell><cell>0</cell><cell>0.05</cell><cell>0.1</cell><cell>0.3</cell><cell>0.4</cell></row><row><cell cols="8">0.923 0.982 0.993 0.983 0.976 0.938 0.942 0.990</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Proportion of under-, over-, and correct selection of the number of clusters for all model selection measures per level of each manipulated factor. Best results are in bold.</figDesc><table><row><cell>Measure Result K N g G β Cluster size σ β Total</cell><cell>2 4 50 100 200 24 48 0.3 0.4 Bal Unb 0 0.05 0.1</cell><cell>Under 0.02 0.34 0.44 0.10 0.00 0.22 0.14 0.26 0.11 0.12 0.24 0.18 0.19 0.17 0.18</cell><cell>AIC Correct 0.82 0.50 0.56 0.76 0.66 0.64 0.68 0.61 0.71 0.73 0.58 0.80 0.81 0.37 0.66</cell><cell>Over 0.16 0.16 0.00 0.14 0.34 0.14 0.18 0.14 0.18 0.15 0.17 0.01 0.01 0.46 0.16</cell><cell>Under 0.05 0.42 0.52 0.17 0.01 0.30 0.17 0.32 0.15 0.17 0.30 0.24 0.24 0.22 0.23</cell><cell>AIC 3 Correct 0.82 0.46 0.48 0.77 0.68 0.59 0.69 0.57 0.71 0.71 0.57 0.75 0.75 0.42 0.64</cell><cell>Over 0.13 0.12 0.00 0.06 0.32 0.11 0.14 0.11 0.14 0.12 0.13 0.01 0.00 0.36 0.12</cell><cell>Under 0.07 0.46 0.57 0.20 0.01 0.31 0.21 0.35 0.18 0.19 0.33 0.28 0.27 0.24 0.26</cell><cell>BIC G Correct 0.81 0.43 0.43 0.76 0.68 0.59 0.66 0.55 0.69 0.69 0.55 0.72 0.73 0.42 0.62</cell><cell>Over 0.12 0.11 0.00 0.04 0.30 0.10 0.13 0.10 0.13 0.11 0.12 0.01 0.00 0.34 0.11</cell><cell>Under 0.17 0.70 0.74 0.41 0.15 0.49 0.38 0.57 0.30 0.36 0.51 0.43 0.44 0.43 0.43</cell><cell>BIC N Correct 0.81 0.28 0.26 0.58 0.78 0.50 0.59 0.42 0.66 0.62 0.47 0.56 0.56 0.51 0.54</cell><cell>Over 0.03 0.02 0.00 0.00 0.06 0.01 0.03 0.01 0.03 0.02 0.02 0.00 0.00 0.06 0.02</cell><cell>Under 0.00 0.16 0.12 0.05 0.07 0.09 0.07 0.11 0.06 0.05 0.12 0.03 0.04 0.17 0.08</cell><cell>Chull Correct 0.89 0.65 0.73 0.81 0.78 0.76 0.78 0.74 0.80 0.86 0.68 0.79 0.87 0.66 0.77</cell><cell>Over 0.11 0.18 0.15 0.14 0.15 0.15 0.14 0.15 0.14 0.09 0.20 0.18 0.09 0.17 0.15</cell><cell>Under 0.10 0.47 0.62 0.21 0.02 0.33 0.24 0.39 0.18 0.21 0.35 0.30 0.29 0.27 0.28</cell><cell>ICL Correct 0.79 0.43 0.37 0.76 0.70 0.58 0.65 0.53 0.70 0.68 0.55 0.70 0.71 0.42 0.61</cell><cell>Over 0.11 0.10 0.00 0.03 0.28 0.10 0.11 0.08 0.12 0.11 0.10 0.00 0.00 0.31 0.10</cell><cell>Under 0.07 0.44 0.51 0.20 0.05 0.29 0.21 0.34 0.17 0.19 0.32 0.26 0.25 0.25 0.25</cell><cell>Total Correct 0.82 0.46 0.47 0.74 0.71 0.61 0.67 0.57 0.71 0.71 0.57 0.72 0.74 0.47 0.64</cell><cell>Over 0.11 0.10 0.02 0.06 0.24 0.10 0.11 0.09 0.12 0.10 0.11 0.02 0.01 0.29 0.11</cell><cell>Note. K is the number of clusters, N</cell></row></table><note><p>g is the within-group sample size, G is the number of groups, β is the size of the regression coefficients, Bal is balanced, U nb is unbalanced, and σ β .</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Average ARI depending on the model selection results for all model selection measures.</figDesc><table><row><cell cols="4">The standard deviation is in parentheses.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Result</cell><cell>AIC</cell><cell>AIC 3</cell><cell>BIC G</cell><cell>BIC N</cell><cell>CHull</cell><cell>ICL</cell></row><row><cell>Under</cell><cell cols="6">0.83 (0.19) 0.85 (0.19) 0.86 (0.18) 0.89 (0.18) 0.72 (0.24) 0.87 (0.18)</cell></row><row><cell cols="7">Correct 0.98 (0.06) 0.98 (0.07) 0.98 (0.07) 0.98 (0.07) 0.97 (0.09) 0.98 (0.07)</cell></row><row><cell>Over</cell><cell cols="6">0.86 (0.20) 0.85 (0.20) 0.85 (0.20) 0.87 (0.20) 0.87 (0.18) 0.85 (0.21)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>selection for MMG-SEM. Since it cannot select the minimum or maximum number of clusters, we suggest also inspecting CHull's scree plot and looking for an elbow to confirm the number of clusters. If no elbow is visible, the most appropriate number of clusters is likely one or the maximum number evaluated. Furthermore, we recommend combining the Chull with at least one of the other measures (e.g., AIC, AIC 3 or BIC G ) to validate a decision (e.g., K = 1 when no elbow is found for CHull and AIC suggests a one-cluster model). If multiple measures contradict each other, it may help to consider the two best solutions for the different measures and see which number(s) of clusters is (are) most often selected. Finally, it is advisable to compare different selected solutions in terms of which differences in structural relations are found (and which clustering) and how this relates to prior theories and previous research about the matter.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>When full metric invariance does not hold (i.e., all loadings equal), partial metric invariance<ref type="bibr" target="#b5">(Byrne et al., 1989)</ref> can be pursued, where some of the loadings are allowed to be different across groups.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>For more information about the remaining MI levels, please see<ref type="bibr" target="#b28">Vandenberg and Lance (2000)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_2"><p>We only count one set of endogenous covariances for each group, given we assume each group belongs to only one cluster. The endogenous covariances (from the clusters the groups do not belong to) are nuisance parameters.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A new look at the statistical model identification</title>
		<author>
			<persName><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
		<idno type="DOI">10.1109/TAC.1974.1100705</idno>
		<ptr target="https://doi.org/10.1109/TAC.1974.1100705" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Automatic Control</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="716" to="723" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A Comparison of Information Criteria in Clustering Based on Mixture of Multivariate Normal Distributions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Akogul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erisoglu</surname></persName>
		</author>
		<idno type="DOI">10.3390/mca21030034</idno>
		<ptr target="https://doi.org/10.3390/mca21030034" />
	</analytic>
	<monogr>
		<title level="j">Mathematical and Computational Applications</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">34</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Assessing a mixture model for clustering with the integrated completed likelihood</title>
		<author>
			<persName><forename type="first">C</forename><surname>Biernacki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Celeux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Govaert</surname></persName>
		</author>
		<idno type="DOI">10.1109/34.865189</idno>
		<ptr target="https://doi.org/10.1109/34.865189" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="719" to="725" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<title level="m">Structural equations with latent variables</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mixture-Model Cluster Analysis Using Model Selection Criteria and a New Informational Measure of Complexity</title>
		<author>
			<persName><forename type="first">H</forename><surname>Bozdogan</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-94-011-0800-3_3</idno>
		<ptr target="https://doi.org/10.1007/978-94-011-0800-3_3" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First US/Japan Conference on the Frontiers of Statistical Modeling: An Informational Approach</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Bozdogan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Sclove</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Haughton</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Kitagawa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Ozaki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Tanabe</surname></persName>
		</editor>
		<meeting>the First US/Japan Conference on the Frontiers of Statistical Modeling: An Informational Approach<address><addrLine>Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="69" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Testing for the equivalence of factor covariance and mean structures: The issue of partial measurement invariance</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bulteel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Wilderjans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Tuerlinckx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ceulemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Byrne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Shavelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.105.3.456</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.105.3.456" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="456" to="466" />
			<date type="published" when="1989">2013. 1989</date>
		</imprint>
	</monogr>
	<note>Psychological Bulletin</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A large-sample model selection criterion based on Kullback&apos;s symmetric divergence</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Cavanaugh</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0167-7152(98)00200-4</idno>
		<ptr target="https://doi.org/10.1016/S0167-7152(98)00200-4" />
	</analytic>
	<monogr>
		<title level="j">Statistics &amp; Probability Letters</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="343" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Selecting among three-mode principal component models of different types and complexities: A numerical convex hull based method</title>
		<author>
			<persName><forename type="first">E</forename><surname>Ceulemans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A L</forename><surname>Kiers</surname></persName>
		</author>
		<idno type="DOI">10.1348/000711005X64817</idno>
		<ptr target="https://doi.org/10.1348/000711005X64817" />
	</analytic>
	<monogr>
		<title level="j">British Journal of Mathematical and Statistical Psychology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="133" to="150" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Sensitivity of Goodness of Fit Indexes to Lack of Measurement Invariance</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705510701301834</idno>
		<ptr target="https://doi.org/10.1080/10705510701301834" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="464" to="504" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">What happens if we compare chopsticks with forks? The impact of making inappropriate comparisons in cross-cultural research</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0013193</idno>
		<ptr target="https://doi.org/10.1037/a0013193" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1005" to="1018" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Normalized Information Criteria and Model Selection in the Presence of Missing Data</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Berchenko</surname></persName>
		</author>
		<idno type="DOI">10.3390/math9192474</idno>
		<ptr target="https://doi.org/10.3390/math9192474" />
	</analytic>
	<monogr>
		<title level="j">Mathematics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page">2474</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Finding Clusters of Groups with Measurement Invariance: Unraveling Intercept Non-Invariance with Mixture Multigroup Factor Analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>De Roover</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2020.1866577</idno>
		<ptr target="https://doi.org/10.1080/10705511.2020.1866577" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="663" to="683" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mixture multigroup factor analysis for unraveling factor loading noninvariance across many groups</title>
		<author>
			<persName><forename type="first">K</forename><surname>De Roover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Vermunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ceulemans</surname></persName>
		</author>
		<idno type="DOI">10.1037/met0000355</idno>
		<ptr target="https://doi.org/10.1037/met0000355" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="281" to="306" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Factor Analysis (2nd)</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gorsuch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>Lawrence Erlbaum</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The consequences of ignoring measurement invariance for path coefficients in structural equation models</title>
		<author>
			<persName><forename type="first">N</forename><surname>Guenole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Brown</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2014.00980</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2014.00980" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Hox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moerbeek</surname></persName>
		</author>
		<author>
			<persName><surname>Van De</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schoot</surname></persName>
		</author>
		<title level="m">Multilevel Analysis: Techniques and Applications</title>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>rd Edition</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparing partitions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Arabie</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF01908075</idno>
		<ptr target="https://doi.org/10.1007/BF01908075" />
	</analytic>
	<monogr>
		<title level="j">Journal of Classification</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="218" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Stark</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705511.2016.1196108</idno>
		<ptr target="https://doi.org/10.1080/10705511.2016.1196108" />
	</analytic>
	<monogr>
		<title level="m">Measurement Invariance Testing Across Between-Level Latent Classes Using Multilevel Factor Mixture Modeling</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="870" to="887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Simultaneous Decision(s) about the Number of Lower-and Higher-Level Classes in Multilevel Latent Class Analysis</title>
		<author>
			<persName><forename type="first">O</forename><surname>Lukočienė</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Varriale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Vermunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Lukočienė</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Vermunt</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-01044-6_22</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-01044-6_22" />
	</analytic>
	<monogr>
		<title level="m">Advances in Data Analysis, Data Handling and Business Intelligence</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Fink</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Lausen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Seidel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">A</forename><surname>Ultsch</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2010. 2009</date>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="241" to="249" />
		</imprint>
	</monogr>
	<note>Determining the Number of Components in Mixture Models for Hierarchical Data</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attitudes and behavioral intentions to protect the environment: How consistent is the structure of environmental concern in cross-national comparison?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Mayerl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Best</surname></persName>
		</author>
		<idno type="DOI">10.1080/00207659.2018.1560980</idno>
		<ptr target="https://doi.org/10.1080/00207659.2018.1560980" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Sociology</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="52" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Mclachlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">X</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Rathnayake</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-statistics-031017-100325</idno>
		<ptr target="https://doi.org/10.1146/annurev-statistics-031017-100325" />
	</analytic>
	<monogr>
		<title level="m">Finite Mixture Models</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="355" to="378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Measurement invariance, factor analysis and factorial invariance</title>
		<author>
			<persName><forename type="first">W</forename><surname>Meredith</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02294825</idno>
		<ptr target="https://doi.org/10.1007/BF02294825" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="525" to="543" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deciding on the Number of Classes in Latent Class Analysis and Growth Mixture Modeling: A Monte Carlo Simulation Study</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Nylund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Asparouhov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">O</forename><surname>Muthén</surname></persName>
		</author>
		<idno type="DOI">10.1080/10705510701575396</idno>
		<ptr target="https://doi.org/10.1080/10705510701575396" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="535" to="569" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Mixture Multigroup Structural Equation Modeling: A Novel Method for Comparing Structural Relations Across Many Groups</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Perez Alonso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Vermunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>De Roover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A structural after measurement approach to structural equation modeling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Loh</surname></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team.</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team.</orgName>
			</affiliation>
		</author>
		<idno type="DOI">10.1037/met0000503</idno>
		<ptr target="https://doi.org/10.1037/met0000503" />
	</analytic>
	<monogr>
		<title level="m">R: A Language and Environment for Statistical Computing</title>
		<imprint>
			<date type="published" when="2022">2024. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Assessing the Hypothesis of Measurement Invariance in the Context of Large-Scale International Surveys</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rutkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Svetina</surname></persName>
		</author>
		<idno type="DOI">10.1177/0013164413498257</idno>
		<ptr target="https://doi.org/10.1177/0013164413498257" />
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="57" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
		<idno type="DOI">10.1214/aos/1176344136</idno>
		<ptr target="https://doi.org/10.1214/aos/1176344136" />
	</analytic>
	<monogr>
		<title level="m">Estimating the Dimension of a Model</title>
		<imprint>
			<date type="published" when="1978">1978</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="461" to="464" />
		</imprint>
	</monogr>
	<note>Publisher: Institute of Mathematical Statistics</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Building Latent Class Trees, With an Application to a Study of Social Capital</title>
		<author>
			<persName><forename type="first">M</forename><surname>Van Den Bergh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">D</forename><surname>Schmittmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Vermunt</surname></persName>
		</author>
		<idno type="DOI">10.1027/1614-2241/a000128</idno>
		<ptr target="https://doi.org/10.1027/1614-2241/a000128" />
	</analytic>
	<monogr>
		<title level="j">Methodology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">Supplement 1</biblScope>
			<biblScope unit="page" from="13" to="22" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A Review and Synthesis of the Measurement Invariance Literature: Suggestions, Practices, and Recommendations for Organizational Research</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Vandenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Lance</surname></persName>
		</author>
		<idno type="DOI">10.1177/109442810031002</idno>
		<ptr target="https://doi.org/10.1177/109442810031002" />
	</analytic>
	<monogr>
		<title level="j">Organizational Research Methods</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="70" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Structural Equation Modeling: Mixture Models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Vermunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Magidson</surname></persName>
		</author>
		<idno type="DOI">10.1002/0470013192.bsa600</idno>
		<ptr target="https://doi.org/10.1002/0470013192.bsa600" />
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Statistics in Behavioral Science</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Everitt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Howell</surname></persName>
		</editor>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2005-10">2005, October</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Technical Guide for Latent GOLD 5.1: Basic, Advanced, and Syntax</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Vermunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Magidson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Statistical Innovations Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Model selection and psychological theory: A discussion of the differences between the Akaike information criterion (AIC) and the Bayesian information criterion (BIC)</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Vrieze</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0027127</idno>
		<ptr target="https://doi.org/10.1037/a0027127" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="228" to="243" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
