<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Misophonia is associated with heightened emotion evocation by music</title>
				<funder ref="#_gmhWpUA">
					<orgName type="full">Huron University</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Omolewa</forename><surname>Babalola</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Huron University College at Western</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kathryne</forename><surname>Van Hedger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Huron University College at Western</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology and Centre for Brain and Mind</orgName>
								<address>
									<country>Western University</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Clinical and Neurological Sciences</orgName>
								<orgName type="institution">Western University</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Stephen</forename><forename type="middle">C</forename><surname>Van Hedger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Huron University College at Western</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology and Centre for Brain and Mind</orgName>
								<address>
									<country>Western University</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">University College at Western</orgName>
								<address>
									<addrLine>1349 Western Road</addrLine>
									<postCode>N6G 1H3</postCode>
									<settlement>London</settlement>
									<region>ON</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Misophonia is associated with heightened emotion evocation by music</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1578ADC14CBCE380E04E8EE096956AED</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>misophonia</term>
					<term>auditory processing</term>
					<term>music perception</term>
					<term>emotion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Misophonia is a disorder commonly characterized by negative emotional responses to "trigger" sounds, such as chewing or tapping. It has been linked to conditions like hyperacusis and PTSD; however, the relationship between misophonia and musical processing remains underexplored.</p><p>Under the framework that misophonia stems from altered connectivity between auditory and limbic systems, we predicted that individuals with greater misophonia severity would also show stronger emotional responses to music. From a large initial screening study (n = 300), a subset of participants (low misophonia: n = 58, high misophonia: n = 40) were asked about several musical and non-musical traits. Participants in the high misophonia group scored higher than the low misophonia group on several musical measures, including active engagement with music and emotion evocation from music. Participants in the high misophonia group also scored higher than the low misophonia group on hyperacusis and PTSD tendencies, replicating prior work. The present study supports conceptualizing misophonia in terms of enhanced auditory-emotional responses, to both negative ("trigger") and positive stimuli, such as music. These findings fit within a small but growing body of research highlighting the positive emotional implications of misophonia, particularly in musical contexts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Misophonia is associated with heightened emotion evocation in music</head><p>You hear your friend sniffling next to you and are instantly enraged. Your coworker is tapping their pen on the table during a meeting, and your physiological stress response is activated. You avoid eating dinner with your family, so you don't have to hear them chewing. In human auditory processing, the response to everyday sounds, such as chewing, breathing, or keyboard tapping typically garners little attention. But for some individuals with misophonia, these everyday sounds can turn into a cacophonous nightmare, invoking a visceral and uncontrollable negative response.</p><p>Misophonia is a condition where individuals experience an exceptionally strong negative emotional response (e.g., anger, anxiety) to specific "trigger" sounds or stimuli associated with such sounds (for review see <ref type="bibr" target="#b6">Brout et al., 2018;</ref><ref type="bibr" target="#b31">Potgieter et al., 2019)</ref>. These negative responses do not seem to be elicited by general psychoacoustic features of a sound (e.g., loudness, roughness), but rather by the specific meaning to an individual <ref type="bibr" target="#b41">(Swedo et al., 2022)</ref>. Trigger sounds tend to be repetitive and generated by the body (e.g., orofacial sounds); however, any sound in principle could serve as a trigger for someone with misophonia. Although the mechanisms underlying misophonia are still debated (e.g., see <ref type="bibr" target="#b29">Palumbo et al., 2018)</ref>, one possibility is that affective brain networks are in a heightened state of excitation in response to auditory input among individuals with misophonia <ref type="bibr" target="#b27">(MÃ¸ller, 2011)</ref>. In support of this framework, <ref type="bibr" target="#b21">Kumar et al. (2017)</ref> found heightened activity and altered functional connectivity of the anterior insular cortex -a core component of the salience network -among individuals with misophonia when listening to trigger sounds.</p><p>Misophonia is distinct from other auditory processing conditions, such as hyperacusis, which is characterized by physical discomfort or pain upon hearing sounds at a level of loudness that would be tolerable for most people <ref type="bibr" target="#b15">(Henry et al., 2022)</ref>. Unlike misophonia, hyperacusis is not confined to specific trigger sounds but encompasses a wide array of everyday noises, often rendering even moderate decibel sounds unbearably loud and uncomfortable for those experiencing it. While auditory disorders, including hyperacusis, are often comorbid with misophonia <ref type="bibr" target="#b17">(Jastreboff &amp; Jastreboff, 2014)</ref>, it is worth noting that the field of audiology generally classifies misophonia as a subtype of hyperacusis, rather than a distinct disorder <ref type="bibr" target="#b43">(Tyler et al., 2014)</ref>. The potential link between experiencing misophonia and hyperacusis remains unclear. It is theorized that distressing hyperacusis might amplify anxiety and depression, heightening an individual's likelihood of developing a strong reaction to trigger sounds, as seen in misophonia <ref type="bibr" target="#b0">(Aazh et al., 2022)</ref>. Alternatively, hyperacusis could potentially divert an individuals' attention, preventing them from attending to potentially bothersome misophonic trigger sounds <ref type="bibr" target="#b0">(Aazh et al., 2022)</ref>. The relationship between misophonia and hyperacusis thus remains uncertain. There is no clear indication of whether the likelihood of experiencing misophonia is associated with hyperacusis. It is important to note that previous studies have not thoroughly examined the relationship between the impact of hyperacusis and the presence of misophonia. However, a study by <ref type="bibr" target="#b0">Aazh et al. (2022)</ref> identified that among a population seeking assistance from an audiology clinic for tinnitus (a perceived ringing or buzzing sound that does not have an external source) and/or hyperacusis, 23% were classified as also having misophonia.</p><p>Initially, misophonia was not thought to be associated with psychopathology <ref type="bibr" target="#b17">(Jastreboff &amp; Jastreboff, 2014)</ref>. However, accumulating research shows that the condition is associated with elevated anxiety and stress-related symptoms, as well as increased co-occurrence with anxiety disorders, post-traumatic stress disorder (PTSD), autism spectrum disorder (ASD), mood disorders, and attention deficit hyperactivity disorder <ref type="bibr" target="#b1">(Abramovitch et al., 2024;</ref><ref type="bibr" target="#b10">Erfanian et al., 2019;</ref><ref type="bibr" target="#b31">Potgieter et al., 2019)</ref>. Research has even found genetic correlations between misophonia and psychiatric personalities/disorders including major depression disorder, PTSD, generalized anxiety disorder, and neuroticism <ref type="bibr" target="#b38">(Smit et al., 2023)</ref>. Neuroticism is the tendency to experience frequent and intense negative emotions in response to various sources of stress. The responses include anxiety, irritability, anger, and the experience of anxious or depressive moods <ref type="bibr" target="#b4">(Barlow et al., 2014)</ref>. Anger and anxiety are common emotional responses to misophonic triggers <ref type="bibr" target="#b25">(McKay et al., 2018)</ref>, suggesting that neuroticism could be useful in understanding misophonia. It has been suggested that neuroticism may be a potential vulnerability factor for misophonia, as neurotic individuals may be prone to developing misophonic reactions to sounds they find aversive <ref type="bibr" target="#b7">(Cassiello-Robbins et al., 2020)</ref>.</p><p>Less is known about misophonia as it relates to musicianship and music processing, although there is some evidence that active musicians experience higher noise sensitivity than non-musicians <ref type="bibr" target="#b11">(FranÄk, 2009;</ref><ref type="bibr" target="#b16">Jansen et al., 2009)</ref>. Although there are anecdotal accounts of musicians who experience misophonia <ref type="bibr" target="#b20">(Kuehn, 2015)</ref>, few studies have directly examined whether musicians are more likely than non-musicians to experience misophonia. It is evident that musicians differ from non-musicians in their response to both musical and non-musical sounds, particularly affective sounds. There is overwhelming evidence that musicians process fundamental musical components such as pitch, melody, timbre, chords, and musical rhythm more efficiently than non-musicians <ref type="bibr" target="#b12">(FranÄk et al., 1991;</ref><ref type="bibr" target="#b24">Matthews et al., 2016;</ref><ref type="bibr" target="#b33">Rammsayer et al., 2012;</ref><ref type="bibr" target="#b34">Repp, 2010)</ref>. Musicians also outperform non-musicians in recognizing emotion conveyed through music, and they have more consistent, rapid, and intense experiences with both positive and negative musical emotion <ref type="bibr" target="#b2">(Akkermans et al., 2019;</ref><ref type="bibr" target="#b8">Castro &amp; Lima, 2014;</ref><ref type="bibr" target="#b30">Park et al., 2014;</ref><ref type="bibr" target="#b39">Steinbeis et al., 2006)</ref>. Musicians have been shown to have stronger emotional responses than non-musicians, with specific neural activations linked to their musical training.</p><p>For example, musicians rate sadness and fear as significantly more arousing than non-musicians, and musical training has been linked to specific neural activations in response to these emotions expressed in music <ref type="bibr" target="#b30">(Park et al., 2014)</ref>. In summary, musicians differ from non-musicians in their emotional responses to both musical and non-musical sounds; thus, if individuals higher in misophonia symptomology are also more likely to be musicians, this could be one potential explanation for why individuals with misophonia might experience heightened emotional responses to music.</p><p>Even if misophonia is not associated with greater amounts of musical training, there are other reasons to expect that misophonia might relate to the emotional processing of music. If misophonia is characterized by altered auditory-limbic connections, as has been suggested (e.g., <ref type="bibr" target="#b18">Jastreboff &amp; Jastreboff, 2023)</ref>, then individuals experiencing misophonia might demonstrate altered (heightened) affective responses to positive sounds, such as music. In support of this idea, recent work has found a positive correlation between video-induced misophonic experiences and frisson reactions to music ("chills" or "goosebumps"), indicating that listeners who experience greater misophonic reactions also have increased physiological reactions associated with emotion processing in the context of music <ref type="bibr" target="#b26">(Mednicoff et al., 2023)</ref>. These authors also find positive associations between misophonic experiences and autonomous sensory meridian response (ASMR), which is commonly described as a pleasant tingling sensation across the head or back of the neck in response to certain auditory stimuli <ref type="bibr">(Rouw &amp; Erfanian, 2018)</ref>. These studies suggest that individuals with more severe misophonia symptoms may experience overall heightened associations between sounds and affect, regardless of positive or negative valence.</p><p>The current study uses a quasi-experimental design to assess how misophonia relates to facets of auditory and emotional processing, with a specific emphasis on musical processing. A large sample of participants initially completed the Amsterdam Misophonia Scale (A-MISO-S) as part of a pre-screening study. Two groups of participants, matched on demographic variables (e.g., age, gender, education, race/ethnicity) but differing in misophonia severity, were then invited to complete the main study, which assessed participants' musicality, emotional responses to music, general auditory sensitivity and preference, and dispositional factors (e.g., anxiety, PTSD). Based on prior research, we predicted that individuals in the high misophonia group would display higher levels of anxiety, PTSD, autism traits, and hyperacusis compared to individuals in the low misophonia group. Additionally, based on the notion that misophonia represents altered connectivity between auditory and limbic pathways, we predicted that individuals in the high misophonia group would show higher levels of musicianship, and would also show stronger emotional responses to music relative to individuals in the low misophonia group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We recruited 300 participants for the initial misophonia screening. Participant eligibility for the main study was determined based on responses to the Amsterdam Misophonia Scale (A-MISO-S), in addition to data quality assessments (see Participant Inclusion for details). From this initial screening, 111 participants (low misophonia: n = 67; high misophonia: n = 44) were invited to complete the main study, with 98 participants (low misophonia: n = 58; high misophonia: n = 40) ultimately completing the study. Participants across groups were well matched in terms of demographic variables (age, gender, education, and race/ethnicity), but differed as expected on reported misophonia (Table <ref type="table" target="#tab_0">1</ref>). All participants were recruited from Amazon Mechanical Turk via CloudResearch (Litman, 2017), with all participants successfully passing internally administered attention checks from CloudResearch. Participants were treated in accordance with the Declaration of Helsinki, and the study protocol was approved by the Huron University Research Ethics Board.</p><p>[[Table <ref type="table" target="#tab_0">1</ref> about here]]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Screening</head><p>Self-reported misophonia was assessed via the A-MISO-S <ref type="bibr" target="#b36">(SchrÃ¶der et al., 2013)</ref>. The A-MISO-S consists of six questions (e.g., "How much of your time is occupied by misophonia triggers?") that are answered on a Likert-type scale of 0 (e.g., None) to 4 (e.g., Extreme: Greater than 8 hrs/day or near constant (thoughts about) triggers), with higher values representing greater severity of misophonia. The final question of the A-MISO-S is a free response item, in which individuals are asked to state what would be the worst thing to happen to them if they were unable to avoid the misophonia triggers. Prior to completing the A-MISO-S, participants were provided with a definition of misophonia and were asked (1) whether they experience misophonia on a scale from 1 (Definitely no) to 5 (Definitely yes) and (2) whether they had heard of misophonia prior to participating in the study <ref type="bibr">(Yes, No)</ref>. In the present study, the six Likerttype questions of the A-MISO-S displayed excellent reliability, Î± = .94, and the summed score from the six items significantly correlated with the single-item self-reported experience of misophonia, r(96) = .55, p &lt; .001, providing convergent validity. The final free response item from the A-MISO-S was not specifically considered in terms of misophonia severity, but rather was used as a data quality assessment (see Participant Inclusion for details). Prior to answering questions about their experiences with misophonia, participants completed a short demographic questionnaire, in which they provided age (in years), gender, level of education, employment status, proficiency with English, and race/ethnicity. The screening assessment was administered in Qualtrics (Provo, UT).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main Study</head><p>Questionnaires. Musicality was assessed via two measures: the Goldsmiths Musical Sophistication Index (Gold-MSI; <ref type="bibr" target="#b28">MÃ¼llensiefen et al., 2014)</ref> and the Barcelona Musical Reward Questionnaire (BRMQ; <ref type="bibr" target="#b23">Mas-Herrero et al., 2013)</ref>. The Gold-MSI assesses a variety of musical skills (e.g., "I can sing or play music from memory") and general musical behaviors (e.g., "I enjoy writing about music, for example on blogs and forums"). Participants rated 38 statements on a scale from 1 (e.g., Completely disagree) to 7 (e.g., Completely agree) in terms of how well each statement described themselves. The final two questions (assessing which instrument participants play best and which musical genre participants prefer) were not included in the present analyses. The Gold-MSI has five subscales: (1) Active Engagement, (2) Perceptual Abilities, (3) Musical Training, (4) Singing Abilities, and (5) Emotions. The reliability of the Gold-MSI for this sample was excellent, Î± = .94, with each subscale exhibiting good reliability (range from Î± = .71 to .88). Mean scores were calculated for the overall Gold-MSI, as well as for each factor. The BRMQ assesses the extent to which individuals find music rewarding along five factors: (1) Music Seeking, (2) Emotion Evocation, (3) Mood Regulation, (4) Social Reward, and</p><p>(5) Sensory Motor. Participants rated 20 statements (e.g., "I can become tearful or cry when I listen to a melody I like very music)" on a scale from 1 (Completely disagree) to 5 (Completely agree). Two items were reverse scored. The reliability of the BMRQ for this sample was excellent, Î± = .92, with each factor of the BRMQ exhibiting good reliability (range from Î± = .70 to .82). Summed scores were calculated for the overall scale, as well as for each factor.</p><p>Broader emotional responses to stimuli were assessed via two measures, a modified version of the ASMR-Experience Questionnaire (AEQ; <ref type="bibr" target="#b40">Swart et al., 2022)</ref> and a word aversion questionnaire (WAQ) modelled on <ref type="bibr" target="#b42">Thibodeau (2016)</ref>. The modified AEQ provided participants with a definition of ASMR and asked if they were capable of experiencing ASMR using a Likerttype scale ranging from 1 (Definitely yes) to 5 (Definitely no). The WAQ presented participants with a total of six words: three words (milk, chew, meal) broadly associated with eating and predicted to be aversive to participants with misophonia, and three minimal pair control words <ref type="bibr">(silk, new, teal)</ref>. Participants answered six questions related to each word: (1) How often they use the word in both speaking and writing, (2) How often they hear the word in everyday use, (3) How aversive the word is to them, (4) How positive versus negative the word is, (5) How exciting or attention-grabbing the word is, and (6) How easily the word brings an image to mind.</p><p>Each response was made on a 100-point slider scale. Separate mean scores for the suspected misophonic trigger words and control words were calculated for each question. In the present study, only the questions related to emotional valence (Questions 3, 4, and 5) were analyzed.</p><p>General sensitivity to sound was assessed via the Hyperacusis Handicap Questionnaire (HHQ; <ref type="bibr" target="#b32">Prabhu &amp; Nagaraj, 2020)</ref>. The HHQ consists of 21 questions (e.g., "How often do you avoid doing a certain task or going out because you have to be in a noisy place/situation?") which participants rated on a Likert-type scale ranging from 0 (Never) to 4 (Always). The HHQ is evenly divided into (1) functional, (2) social, and (3) emotional subscales of hyperacusis. The HHQ for this sample displayed good overall reliability, Î± = .87, with each subscale additionally exhibiting adequate reliability (range from Î± = .63 to .82). Mean scores were calculated for each subscale.</p><p>Personality was assessed via the Ten Item Personality Inventory (TIPI; <ref type="bibr" target="#b13">Gosling et al., 2003)</ref>. Each item of the TIPI consists of two descriptors (e.g., "Anxious, easily upset"), with participants rating how well both descriptors described themselves on a Likert-type scale ranging from 1 (Not at all) to 5 (Extremely). There were two items for each of the five personality factors (Openness, Conscientiousness, Extraversion, Agreeableness, Neuroticism). One item per factor was reverse scored. Although the TIPI is not expected to have strong reliability given that only two items compose each factor, the present administration found good reliability for two factors (Extraversion: Î± = .79; Neuroticism: Î± = .70), adequate reliability for Conscientiousness (Î± = .59), and inadequate reliability for Agreeableness (Î± = .41) and Openness (Î± = .41). Mean scores were calculated for each subscale.</p><p>Posttraumatic stress, anxiety, and depression were assessed via three measures: the National Stressful Events Survey PTSD Short Scale (NSESSS-PTSD; <ref type="bibr" target="#b22">LeBeau et al., 2014)</ref>, the Short Form State Anxiety Inventory (SF-SAI; <ref type="bibr" target="#b46">Zsido et al., 2020)</ref>, and the Patient Health Questionnaire (PHQ-9; <ref type="bibr" target="#b19">Kroenke et al., 2011)</ref>, respectively. The NSESSS-PTSD consists of nine questions that assess how bothered participants are by problems over the past seven days, triggered by an extremely stressful event or experience (e.g., "Trying to avoid thoughts, feelings, or physical sensations that reminded you of a stressful experience?"). Participants respond on a Likert-type scale ranging from 0 (Not at all) to 4 (Extremely), and mean scores were calculated as an indicator of current PTSD symptoms. The NSESSS-PTSD for this sample displayed excellent reliability (Î± = .95). The SF-SAI consists of 5 items (e.g., "I feel that difficulties are piling up so that I cannot overcome them."), which participants rate on a Likert-type scale ranging from 1 (Not at all) to 4 (Very much so). The SF-SAI for this sample displayed excellent reliability (Î± = .92), and mean scores were calculated as an indicator of current anxiety. The PHQ-9 consists of nine personal descriptors (e.g., "Feeling tired or having little energy"), which participants rate on a Likert-type scale ranging from 0 (Not at all) to 3 (Nearly every day) in terms of how often participants have felt this way over the past two weeks. The PHQ-9 for this sample displayed excellent reliability (Î± = .92), and mean scores were calculated as an indicator of current feelings of depression.</p><p>Behaviors associated with ASD were assessed via the 10-item Autism Spectrum Quotient (AQ-10; <ref type="bibr" target="#b3">Allison et al., 2012)</ref>. The AQ-10 consists of statements (e.g., "I know how to tell if someone listening to me is getting bored."), which participants rate on a Likert-type scale ranging from 1 (Definitely agree) to 4 (Definitely disagree). Six items are reverse scored (i.e., disagreeing is consistent with ASD traits). For each item, if the response is consistent with ASD traits (e.g., responding with a "3" or "4" to the example prompt), participants receive a "1"; otherwise, they receive a "0". Scores are then summed (ranging from 0-10), with scores above 6 taken to indicate potentially clinical ASD. The AQ-10 for this sample displayed adequate reliability (Î± = .67).</p><p>Sound Rating Task. Participants rated a total of 80 short (5-second) sounds on a scale from 1 (Extremely unpleasant) to 5 (Extremely pleasant). Sounds were presented in three total forms: unaltered (n = 20), time-domain scrambled (n = 30), and noise vocoded (n = 30). The unaltered sounds consisted of 10 recordings from nature (e.g., birdsong, crashing waves) and 10 recordings from urban environments (e.g., background chatter, traffic) used in prior work (e.g., <ref type="bibr">Van Hedger et al., 2019)</ref>. The time-domain scrambled and noise-vocoded sounds consisted of the same 20 nature and urban sounds, plus an additional 10 sounds widely considered to be misophonic triggers (e.g., chewing, breathing, knuckle cracking, lip smacking). We did not present these misophonic trigger sounds in their unaltered forms, as we did not want to cause undue distress in the high misophonia group. Time-domain scrambling was selected to preserve the long-term spectral profiles of each sound, while disrupting the temporal transitions critical for sound object identification <ref type="bibr" target="#b45">(Van Hedger, Nusbaum, Heald, et al., 2019)</ref>. Noise vocoding was selected to preserve the temporal profiles of each sound, while disrupting the spectral profiles (e.g., see <ref type="bibr" target="#b37">Shannon et al., 1995)</ref>. Both time-domain scrambling and noise vocoding were done through Matlab (MathWorks: Natick, MA). Scrambled sounds were chopped into a set of short (25 ms) windows with 50% overlap, tapered with a raised cosine window. The 25 ms windows were then shuffled and re-overlapped within a 250 ms radius. Noise vocoded sounds used 4 frequency bands (120 to 498 Hz, 498 to 1378 Hz, 1378 to 3426 Hz, and 3426 to 8192 Hz).</p><p>Within each band, the amplitude envelope was extracted and modelled with white noise. All sounds were normalized to -25 dB Full Spectrum. Mean rating scores were calculated for each sound type (unaltered nature, unaltered urban, scrambled nature, scrambled urban, scrambled misophonia, vocoded nature, vocoded urban, vocoded misophonia). The sound rating task was programmed in jsPsych <ref type="bibr" target="#b9">(de Leeuw, 2015)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Screening</head><p>After providing informed consent, participants answered demographic questions and an attention check, in which they were given a scale and were instructed to select a specific response option. Following the initial attention check, participants completed the A-MISO-S.</p><p>There was a second attention check embedded within the A-MISO-S (following the Likert-type responses and preceding the free response question), similar in nature to the first attention check.</p><p>Following the A-MISO-S, participants were given a unique completion code and compensated with $1.25 USD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main Study</head><p>Eligible participants were invited to complete the main study via a personalized email announcement, sent through CloudResearch. Eligible participants had 30 days to complete the main study from its launch, which occurred 4 days after the initial screening. After providing informed consent, participants completed the questionnaires (Gold-MSI, BMRQ, AEQ, WAQ, HHQ, TIPI, NSESSS-PTSD, SF-SAI, PHQ-9, AQ-10) in a randomized order. Following the questionnaires, participants were automatically redirected to the sound rating task and upon task completion participants were given a unique completion code and compensated with $10.00 USD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participant Inclusion</head><p>There were five primary considerations for participants who completed the initial screening to be invited to participate in the main study. First, participants had to pass both attention checks. Second, participants could not have completed the entire survey in under two minutes, as this represented a completion time that was over twice as fast as the average completion time of 4 minutes and 26 seconds, and was considered by the researchers to represent an insufficient amount of time to thoroughly read the prompts and response options of the A-MISO-S. The third consideration was that participants could not have skipped questions, as this either invalidated the calculation of their misophonia score or did not allow for proper demographic comparisons across the constructed misophonia groups. The fourth consideration was an inadequate or otherwise suspicious answer on the free response question of the A-MISO-S. Although we expected a large degree of variability in these free responses depending on one's self-reported misophonic severity, some participants provided a definition of misophonia accessed from a search engine or answered the question in a way that was nonsensical given the prompt. Two authors (OB and SVH) independently rated the free response answers and then discussed discrepancies (1.7% of responses) until a determination was made as to whether the free response was acceptable for inclusion. Assuming participants satisfied the first four inclusion criteria, the fifth and final consideration was participants' scores on the A-MISO-S. To be invited to the low misophonia group, participants had to score under 4 (defined as Subclinical misophonia symptoms). To be invited to the high misophonia group, participants had to score above 10 (defined as Moderate misophonia symptoms).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Analysis</head><p>Data were analyzed in R 4.3.0 (R Core Team). A series of independent samples t-tests were used to assess group differences between the low and high misophonia participants. For each analysis, we additionally calculated effect sizes (Cohen's d) using the "effsize" package.</p><p>Given the number of administered measures, we report both the uncorrected p-values and the False Discovery Rate (FDR) q-values <ref type="bibr" target="#b5">(Benjamini &amp; Hochberg, 1995)</ref>, which provides a multiple comparison correction that limits the Type I Error (i.e., false discoveries) to our specified alpha cut-off of 5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Musicality and Emotional Responses to Music</head><p>Participants in the high misophonia group scored overall higher on the Gold-MSI compared to participants in the low misophonia group, t(96) = 2.72, p = .008, q = .018, d = 0.56.</p><p>For the subscales, high misophonia participants reported greater active engagement with music, t(96) = 3.27, p = .002, q = .004, d = 0.67, as well as greater amounts of musical training, t(96) = 3.01, p = .003, q = .009, d = 0.62. No other subscale of the Gold-MSI differed across group (qs &gt; .105). In terms of experiencing musical reward, there was no overall difference between high and low misophonia participants on the BMRQ, t(96) = 1.53, p = .130, q = .244, d = 0.31. However, participants in the high misophonia group scored higher on the emotion evocation subscale of the BMRQ compared to participants in the low misophonia group, t(96) = 2.80, p = .006, q = .015, d = 0.57. No other subscale was significant (all qs &gt; .104). Figure <ref type="figure" target="#fig_0">1</ref> plots the group comparisons across all musical measures.</p><p>[[Figure <ref type="figure" target="#fig_0">1</ref> about here]]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sound Sensitivity</head><p>Participants in the high misophonia group reported a greater degree of hyperacusis compared to participants in the low misophonia condition, as measured by the overall score on the HHQ, t(96) = 7.87, p &lt; .001, q &lt; .001, d = 1.62. The functional, social, and emotional handicaps of hyperacusis were additionally higher among the high misophonia participants (all ps and qs &lt; .001), with each subscale showing a large effect size (functional: d = 1.21, social: d = 1.40, emotional: d = 1.41). Figure <ref type="figure" target="#fig_1">2</ref> plots the group comparisons across the HHQ subscales.</p><p>[[Figure <ref type="figure" target="#fig_1">2</ref> about here]]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotional Responses to Non-Musical Stimuli</head><p>For the WAQ, participants in the high misophonia group reported greater aversion to both the trigger words, t(96) = 5.21, p &lt; .001, q &lt; .001, d = 1.07, and the control words, t(96) = 4.52, p &lt; .001, q &lt; .001, d = 0.93, compared to participants in the low misophonia group. Participants in the high misophonia group also rated the trigger words, t(96) = 4.62, p &lt; .001, q &lt; .001, d = 0.95, and the control words, t(96) = 3.49, p &lt; .001, q = .002, d = 0.72, as more exciting and attentiongrabbing. There were no group differences in terms of how positive or negative the trigger and control words were rated (qs &gt; .682). For the sound rating task, we observed no differences across groups as a function of each sound category (all qs &gt; .273). Participants in the high misophonia group nominally reported a lower capacity to experience ASMR; however, the group difference was not significant after false discovery rate correction, t(96) = -2.05, p = .043, q = .095, d = 0.42.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Personality and Autistic Traits</head><p>Participants in the high misophonia group scored significantly higher on neuroticism, t(96) = 3.53, p &lt; .001, q = .002, d = 0.73, and significantly lower on conscientiousness, t(96) = -4.32, p &lt; .001, q &lt; .001, d = 0.89, compared to participants in the low misophonia group. The two groups did not differ on extraversion, openness, or agreeableness (all qs &gt; .391). In terms of autism traits, consistent with our prediction, participants in the high misophonia group scored significantly higher on the AQ-10 compared to participants in the low misophonia group, t(96) = 3.69, p &lt; .001, q = .001, d = 0.76.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PTSD, Anxiety, and Depression</head><p>Compared to participants in the low misophonia condition, participants in the high misophonia group reported significantly greater amounts of posttraumatic stress, t(96) = 6.09, p &lt; .001, q &lt; .001, d = 1.25, greater anxiety, t(96) = 5.39, p &lt; .001, q &lt; .001, d = 1.11, and greater depressive symptoms, t(96) = 5.56, p &lt; .001, q &lt; .001, d = 1.14.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The field of misophonia research faces a pressing question: Does misophonia's scope expand beyond aversive reactions to "trigger sounds" and auditory sensitivity to include heightened emotional responses to a wider range of stimuli, including music? The present study finds several factors are associated with misophonia, including musicality, emotion evocation from music, sound sensitivity, language perception, personality, autism traits, and symptoms related to PTSD, anxiety, and depression. These findings support the conceptualization of misophonia as a multifaceted construct with both positive and negative associations.</p><p>As hypothesized, individuals with misophonia reported greater active engagement with music, greater amounts of musical training, and stronger emotion evocation from music. This suggests that individuals with misophonia might seek out and engage with music more compared to those without misophonia. This additionally supports the contention that misophonia can involve heightened affective responses to positive sounds, like music, in addition to negative trigger sounds. Further research could explore whether music serves as a distraction, or coping mechanism to modulate emotional arousal, in individuals with misophonia. The finding that individuals higher in misophonia scored higher on the emotion evocation subscale of the BMRQ conceptually supports recent work examining how misophonia relates to positive emotional responses to sounds, including musical frisson <ref type="bibr" target="#b26">(Mednicoff et al., 2023)</ref> and is more broadly aligned with the framework that misophonia is characterized by altered auditory-limbic connections (cf. <ref type="bibr" target="#b18">Jastreboff &amp; Jastreboff, 2023)</ref>. However, <ref type="bibr" target="#b26">Mednicoff et al. (2023)</ref> also found that misophonia was not related to musicality and was positively associated with ASMR. In the present study, we found that misophonia related to some facets of musicality (overall musicality scores, active engagement, and musical training) and was (nominally) negatively associated with the capacity to experience ASMR. These differing results could be due to differences in study design as well as task construction. Although the musicality assessment (Gold-MSI) was the same in both studies, Mednicoff (2023) used a correlational design (i.e., examining variability in misophonia across the full range of responses) whereas we used a quasi-experimental design (constructing groups of individuals who have low and high misophonia experiences). If musicality is related to misophonia in a non-linear manner, this could potentially explain why we found associations between misophonia and musicality and <ref type="bibr" target="#b26">Mednicoff et al. (2023)</ref> did not. With respect to ASMR, the present study differed from <ref type="bibr" target="#b26">Mednicoff et al. (2023)</ref> by only assessing ASMR using a single item, self-report measure. In contrast, <ref type="bibr" target="#b26">Mednicoff et al. (2023)</ref> played ASMR-inducing videos to individuals and examined self-reported emotional responses. Thus, it is possible that individuals high in misophonia might expect to dislike ASMR videos (particularly given that the source of the sounds can be orofacial, such as whispering) but ultimately derive emotional enjoyment from them when experiencing them. Nevertheless, these divergent findings highlight the need for further research to clarify the underlying mechanisms of misophonia, ASMR, and musical frisson given that there might be some overlap or interaction between the sensory processes involved in these phenomena.</p><p>Participants in the high misophonia group reported hypersensitivity to sound and greater aversion to specific words compared to participants in the low misophonia group. Specifically, functional, social, and emotional hyperacusis handicaps were significantly elevated in the high misophonia group. This suggests that individuals with misophonia experience not only heightened aversion to specific trigger sounds, but also significant impairments in daily functioning, social interactions, and emotional well-being due to their sensitivity to sound.</p><p>Additionally, participants in the high misophonia group reported greater aversion to both the trigger words and the control words presented on the WAQ, and also found these words to be more exciting and attention-grabbing. Engaging in thoughts or imaginings involving verbalization often conjures images of forming words, a process that inherently involves the orofacial region, potentially leading to negative associations for those with misophonia. For the trigger words, this suggests that the mere anticipation of encountering a trigger, can sometimes suffice to elicit a response on its own. This suggests that the anticipation of discomfort or aversion can itself serve as a trigger, underscoring the complex interplay between cognitive processes, sensory experiences, and emotional responses. In terms of the control words, an examination of discourse on Reddit (2022) revealed discussions among individuals with misophonia concerning specific letter sounds that evoke aversive responses. This discussion informed the use of non-food related words (silk, teal, new) as control words. Notably, letters such as "p," "k," and "s" emerged as salient triggers within these conversations. This observation underscores the nuanced nature of misophonia, indicating that the condition extends beyond conventional triggers such as chewing or sniffling. The identification of phonetic elements as triggers highlights the potential for misophonia to manifest in response to a broader range of stimuli, including linguistic components intrinsic to speech production. More research should be conducted into the linguistic elements of misophonia triggers.</p><p>Participants in the high misophonia group also scored significantly higher on neuroticism, indicating a predisposition to experience negative emotions such as anxiety, irritability, and distress. Additionally, they scored significantly lower on conscientiousness, reflecting lower levels of self-discipline, organization, and reliability. These personality traits may exacerbate the emotional and behavioral responses to misophonic triggers, contributing to the overall symptom severity and impairment experienced by individuals with misophonia. Clinicians and researchers should recognize that individuals with misophonia may exhibit heightened emotional reactivity and lower self-discipline, which could influence responses to misophonic triggers and overall coping strategies. Interventions focusing on emotion regulation and coping skills may be particularly beneficial for individuals with misophonia characterized by high neuroticism and low conscientiousness.</p><p>Participants in the high misophonia group scored significantly higher on the AQ-10, indicating elevated levels of autism-related traits. This finding supports the hypothesis that there may be an overlap between misophonia and autism spectrum symptoms, characterized by difficulties in sensory processing, emotional reactivity, and repetitive behaviors. Both ASD and misophonia involve atypical sensory processing, characterized by heightened sensitivity to sensory stimuli. Individuals with ASD often experience sensory sensitivities across multiple modalities, including auditory, visual, tactile, and olfactory domains. Similarly, individuals with misophonia exhibit hypersensitivity to specific auditory, and at times visual and tactile, stimuli, which can evoke intense emotional and physiological responses. Moreover, in ASD, emotional regulation difficulties are a core feature, characterized by atypical emotional responses and difficulties in interpreting and regulating emotions. Individuals with misophonia can also experience intense emotional reactions, such as anger, anxiety, or distress, in response to trigger sounds. These shared features may explain the finding of overlap in ASD and misophonia.</p><p>Further research is needed to explore the underlying mechanisms linking misophonia and autism traits in general population samples.</p><p>Finally, those with high misophonic symptoms also reported significantly more symptoms related to PTSD, anxiety, and depression compared to the low misophonia group.</p><p>These symptoms suggested altered emotion-related functioning within these individuals, and prior research has also identified associations between misophonia and altered functional connectivity among brain networks responsible for emotion processing and regulation <ref type="bibr" target="#b21">(Kumar et al., 2017)</ref>. Prior research also indicates that PTSD and depression, along with obsessive compulsive disorder and anorexia, are common psychiatric comorbidities of misophonia <ref type="bibr" target="#b10">(Erfanian et al., 2019)</ref>. Although participants in this study were not asked to report clinical diagnoses, the presence of a higher degree of psychiatric symptoms in participants high in misophonia indicates that misophonia might be more likely to co-occur with other affective disorders.</p><p>The present study has several notable limitations. First, all data were collected via selfreport measures from an online sample of participants. While past research has shown that similar methodologies produce high quality data <ref type="bibr" target="#b14">(Hauser et al., 2023)</ref>, we cannot rule out the possibility that participants did not accurately complete the questionnaire measures used in this study. Furthermore, given the research question self-report measures are an important feature of the study design, as it is not possible to randomly assign participants to experience misophonia.</p><p>Second, the data for this study are cross-sectional and associations between study variables cannot establish causality. It is not presently known whether musical training influences the subsequent development of misophonia symptoms or whether engagement with music represents a potential coping mechanism employed by those with misophonia to manage negative affective reactions. Further research on the development of misophonia is needed to begin addressing these questions.</p><p>Despite these limitations, the presents study provides initial findings exploring the relationship between misophonia and different facets of auditory and emotional processing.</p><p>Overall, we find that individuals high in misophonia also report greater engagement with music, more emotion evocation from music, and heightened sound sensitivity, as well as higher levels of neuroticism, autism traits, and symptoms related to PTSD, anxiety, and depression compared to individuals who do not experience misophonia in their daily lives. Importantly, the findings of this study suggest that individuals with misophonia might have heightened affective responses to positive auditory stimuli, and this represents a promising direction for future research. Note. *** p &lt; .001. Education was scored on a 9-point scale, with 1 corresponding to "some high school" and 9 corresponding to "doctorate or higher". Given this scale, the mean value for both groups was between an associate's degree (4) and a bachelor's degree (5). For race/ethnicity categories participants were given the option to select all that apply, so the reported percentages do not add to 100%.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tables and Figures</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>Figure 1Responses from the Goldsmiths Musical Sophistication Inventory (Gold-MSI) and the Barcelona Musical Reward Questionnaire (BMRQ)</figDesc><graphic coords="33,127.95,121.40,356.07,522.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2Responses from the Hyperacusis Handicap Questionnaire (HHQ)</figDesc><graphic coords="34,72.00,152.29,467.70,249.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Comparison of low and high misophonia groups on misophonia screening questionnaire (A-MISO-S) and demographic variables</figDesc><table><row><cell>Measure</cell><cell>Low Misophonia (n = 58)</cell><cell>High Misophonia (n = 40)</cell></row><row><cell>A-MISO-S</cell><cell>1.90 (1.55)</cell><cell>13.95 (3.87) ***</cell></row><row><cell>Age (Years)</cell><cell>37.31 (9.08)</cell><cell>37.25 (9.75)</cell></row><row><cell>Gender</cell><cell></cell><cell></cell></row><row><cell>Women</cell><cell>43%</cell><cell>45%</cell></row><row><cell>Men</cell><cell>57%</cell><cell>55%</cell></row><row><cell>Non-Binary</cell><cell>0%</cell><cell>0%</cell></row><row><cell>Education</cell><cell>4.33 (1.30)</cell><cell>4.42 (1.17)</cell></row><row><cell>Full-Time Employment</cell><cell>74%</cell><cell>75%</cell></row><row><cell>Race/Ethnicity</cell><cell></cell><cell></cell></row><row><cell>White</cell><cell>77%</cell><cell>72%</cell></row><row><cell>Black</cell><cell>9%</cell><cell>10%</cell></row><row><cell>Asian</cell><cell>14%</cell><cell>10%</cell></row><row><cell>Hispanic</cell><cell>5%</cell><cell>5%</cell></row><row><cell>Indigenous</cell><cell>0%</cell><cell>2%</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This research was supported by a <rs type="grantName">Centre for Undergraduate Research Learning Fellowship</rs>, awarded by <rs type="funder">Huron University</rs> to OB.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_gmhWpUA">
					<orgName type="grant-name">Centre for Undergraduate Research Learning Fellowship</orgName>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Availability Statement</head><p>All data and analysis scripts are available through Open Science Framework (10.17605/OSF.IO/X2UDK)</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Disclosure of Interest</head><p>The authors report no conflict of interest.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Audiological and other factors predicting the presence of misophonia symptoms among a clinical population seeking help for tinnitus and/or hyperacusis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Aazh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erfanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Danesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C J</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2022.900065</idno>
		<ptr target="https://doi.org/10.3389/fnins.2022.900065" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A neuropsychological study of misophonia</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abramovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Etherton</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbtep.2023.101897</idno>
		<ptr target="https://doi.org/10.1016/j.jbtep.2023.101897" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavior Therapy and Experimental Psychiatry</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page">101897</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Decoding emotions in expressive music performances: A multi-lab replication and extension study</title>
		<author>
			<persName><forename type="first">J</forename><surname>Akkermans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>MÃ¼llensiefen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jakubowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Shanahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Busch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lothwesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Elvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Fischinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Schlemmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Frieler</surname></persName>
		</author>
		<idno type="DOI">10.1080/02699931.2018.1541312</idno>
		<ptr target="https://doi.org/10.1080/02699931.2018.1541312" />
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1099" to="1118" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Toward Brief &quot;Red Flags&quot; for Autism Screening: The Short Autism Spectrum Quotient and the Short Quantitative Checklist in 1,000 Cases and 3,000 Controls</title>
		<author>
			<persName><forename type="first">C</forename><surname>Allison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Auyeung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Baron-Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jaac.2011.11.003</idno>
		<ptr target="https://doi.org/10.1016/j.jaac.2011.11.003" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Academy of Child &amp; Adolescent Psychiatry</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="212" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The nature, diagnosis, and treatment of neuroticism: Back to the future</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Barlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sauer-Zavala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Carl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bullis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Ellard</surname></persName>
		</author>
		<idno type="DOI">10.1177/2167702613505532</idno>
		<ptr target="https://doi.org/10.1177/2167702613505532" />
	</analytic>
	<monogr>
		<title level="j">Clinical Psychological Science</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="344" to="365" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Controlling the false discovery rate: A practical and powerful approach to multiple testing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Benjamini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hochberg</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.2517-6161.1995.tb02031.x</idno>
		<ptr target="https://doi.org/10.1111/j.2517-6161.1995.tb02031.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="289" to="300" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Investigating misophonia: A review of the empirical literature, clinical implications, and a research agenda</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Brout</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Edelstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erfanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mannino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rouw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Rosenthal</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2018.00036</idno>
		<ptr target="https://doi.org/10.3389/fnins.2018.00036" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The mediating role of emotion regulation within the relationship between neuroticism and misophonia: A preliminary investigation</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cassiello-Robbins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mcmahon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guetta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Trumbull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kelley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Rosenthal</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyt.2020.00847</idno>
		<ptr target="https://doi.org/10.3389/fpsyt.2020.00847" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychiatry</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Age and musical expertise influence emotion recognition in music</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Lima</surname></persName>
		</author>
		<idno type="DOI">10.1525/mp.2014.32.2.125</idno>
		<ptr target="https://doi.org/10.1525/mp.2014.32.2.125" />
	</analytic>
	<monogr>
		<title level="j">Music Perception</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="142" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">jsPsych: A JavaScript library for creating behavioral experiments in a Web browser</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>De Leeuw</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-014-0458-y</idno>
		<ptr target="https://doi.org/10.3758/s13428-014-0458-y" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Misophonia and comorbid psychiatric symptoms: A preliminary study of clinical findings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Erfanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kartsonaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Keshavarz</surname></persName>
		</author>
		<idno type="DOI">10.1080/08039488.2019.1609086</idno>
		<ptr target="https://doi.org/10.1080/08039488.2019.1609086" />
	</analytic>
	<monogr>
		<title level="j">Nordic Journal of Psychiatry</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="219" to="228" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>FranÄk</surname></persName>
		</author>
		<title level="m">Is Noise Sensitivity Influenced by Musical Factors? Proceedings of the 10th WSEAS International Conference on Acoustics &amp; Music: Theory &amp; Applications</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Finger tapping in musicians and nonmusicians</title>
		<author>
			<persName><forename type="first">M</forename><surname>FranÄk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Radil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>PÃ¶ppel</surname></persName>
		</author>
		<idno type="DOI">10.1016/0167-8760(91)90022-P</idno>
		<ptr target="https://doi.org/10.1016/0167-8760(91)90022-P" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="279" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A very brief measure of the Big-Five personality domains</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Gosling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Rentfrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Swann</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0092-6566(03)00046-1</idno>
		<ptr target="https://doi.org/10.1016/S0092-6566(03)00046-1" />
	</analytic>
	<monogr>
		<title level="j">Journal of Research in Personality</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="504" to="528" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Evaluating CloudResearch&apos;s Approved Group as a solution for problematic data quality on MTurk</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Moss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rosenzweig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Jaffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Litman</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-022-01999-x</idno>
		<ptr target="https://doi.org/10.3758/s13428-022-01999-x" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3953" to="3964" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Sound tolerance conditions (hyperacusis, misophonia, noise sensitivity, and phonophobia): Definitions and clinical management</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Theodoroff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Edmonds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Zaugg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-C</forename><surname>Goodworth</surname></persName>
		</author>
		<idno type="DOI">10.1044/2022_AJA-22-00035</idno>
		<ptr target="https://doi.org/10.1044/2022_AJA-22-00035" />
	</analytic>
	<monogr>
		<title level="j">American Journal of Audiology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="513" to="527" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Noise induced hearing loss and other hearing complaints among musicians of symphony orchestras</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J M</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">W</forename><surname>Helleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Dreschler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A P M</forename><surname>De Laat</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00420-008-0317-1</idno>
		<ptr target="https://doi.org/10.1007/s00420-008-0317-1" />
	</analytic>
	<monogr>
		<title level="j">International Archives of Occupational and Environmental Health</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="164" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Treatments for decreased sound tolerance (hyperacusis and misophonia)</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Jastreboff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Jastreboff</surname></persName>
		</author>
		<idno type="DOI">10.1055/s-0034-1372527</idno>
		<ptr target="https://doi.org/10.1055/s-0034-1372527" />
	</analytic>
	<monogr>
		<title level="j">Seminars in Hearing</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="120" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The neurophysiological approach to misophonia: Theory and treatment</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Jastreboff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Jastreboff</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2023.895574</idno>
		<ptr target="https://doi.org/10.3389/fnins.2023.895574" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Kroenke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B W</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1037/t06165-000</idno>
		<ptr target="https://doi.org/10.1037/t06165-000" />
		<title level="m">Patient Health Questionnaire-9</title>
		<imprint>
			<publisher>American Psychological Association</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Misophonia: An exploration of the experience, symptoms, and treatment of selective sound sensitivity</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kuehn</surname></persName>
		</author>
		<ptr target="https://www.proquest.com/docview/1707709777/abstract/E7354140CAB54513PQ/1" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>Psy.D., John F. Kennedy University</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The brain basis for misophonia</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Tansley-Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Sedley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Winston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Callaghan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Cope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Gander</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D.-E</forename><surname>Bamiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Griffiths</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2016.12.048</idno>
		<ptr target="https://doi.org/10.1016/j.cub.2016.12.048" />
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="527" to="533" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<author>
			<persName><forename type="first">R</forename><surname>Lebeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mischel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kilpatrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Craske</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.psychres.2014.03.032</idno>
		<ptr target="https://doi.org/10.1016/j.psychres.2014.03.032" />
	</analytic>
	<monogr>
		<title level="m">Dimensional assessment of posttraumatic stress disorder in DSM-5</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">218</biblScope>
			<biblScope unit="page" from="143" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Individual Differences in Music Reward Experiences</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mas-Herrero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marco-Pallares</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Lorenzo-Seva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Zatorre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rodriguez-Fornells</surname></persName>
		</author>
		<idno type="DOI">10.1525/mp.2013.31.2.118</idno>
		<ptr target="https://doi.org/10.1525/mp.2013.31.2.118" />
	</analytic>
	<monogr>
		<title level="j">Music Perception</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="118" to="138" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The impact of instrument-specific musical training on rhythm perception and production</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N L</forename><surname>Thibodeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Gunther</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">B</forename><surname>Penhune</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2016.00069</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2016.00069" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Profile analysis of psychological symptoms associated with misophonia: A community sample</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mckay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mancusi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Storch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Spankovich</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.beth.2017.07.002</idno>
		<ptr target="https://doi.org/10.1016/j.beth.2017.07.002" />
	</analytic>
	<monogr>
		<title level="j">Behavior Therapy</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="286" to="294" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Misophonia reactions in the general population are correlated with strong emotional reactions to other everyday sensory-emotional experiences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mednicoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Barashy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Vollweiler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Benning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hannon</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/rt3bf</idno>
		<ptr target="https://doi.org/10.31234/osf.io/rt3bf" />
	</analytic>
	<monogr>
		<title level="j">OSF</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Misophonia, Phonophobia, and</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>MÃ¸ller</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-60761-145-5_4</idno>
		<ptr target="https://doi.org/10.1007/978-1-60761-145-5_4" />
	</analytic>
	<monogr>
		<title level="m">Textbook of Tinnitus</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>MÃ¸ller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Langguth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">De</forename><surname>Ridder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><forename type="middle">T</forename><surname>Kleinjung</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="25" to="27" />
		</imprint>
	</monogr>
	<note>Exploding Head&quot; Syndrome</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The Musicality of Non-Musicians: An Index for Assessing Musical Sophistication in the General Population</title>
		<author>
			<persName><forename type="first">D</forename><surname>MÃ¼llensiefen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Gingras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Musil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Stewart</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0089642</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0089642" />
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">89642</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Misophonia and potential underlying mechanisms: A perspective</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Palumbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Alsalman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>De Ridder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vanneste</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2018.00953</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2018.00953" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Differences between musicians and non-musicians in neuro-affective processing of sadness and fear expressed in music</title>
		<author>
			<persName><forename type="first">M</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gutyrchik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zaytseva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Carl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Welker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>PÃ¶ppel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blautzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Meindl</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neulet.2014.02.041</idno>
		<ptr target="https://doi.org/10.1016/j.neulet.2014.02.041" />
	</analytic>
	<monogr>
		<title level="j">Neuroscience Letters</title>
		<imprint>
			<biblScope unit="volume">566</biblScope>
			<biblScope unit="page" from="120" to="124" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Misophonia: A scoping review of research</title>
		<author>
			<persName><forename type="first">I</forename><surname>Potgieter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Partridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Cima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sheldrake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hoare</surname></persName>
		</author>
		<idno type="DOI">10.1002/jclp.22771</idno>
		<ptr target="https://doi.org/10.1002/jclp.22771" />
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical Psychology</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1203" to="1218" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Development and validation of Hyperacusis Handicap Questionnaire in individuals with tinnitus associated with hyperacusis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Prabhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Nagaraj</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.joto.2019.12.004</idno>
		<ptr target="https://doi.org/10.1016/j.joto.2019.12.004" />
	</analytic>
	<monogr>
		<title level="j">Journal of Otology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="124" to="128" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Musicians do better than nonmusicians in both auditory and visual timing tasks</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Rammsayer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Buttkus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>AltenmÃ¼ller</surname></persName>
		</author>
		<idno type="DOI">10.1525/mp.2012.30.1.85</idno>
		<ptr target="https://doi.org/10.1525/mp.2012.30.1.85" />
	</analytic>
	<monogr>
		<title level="j">Music Perception</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="85" to="96" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sensorimotor synchronization and perception of timing: Effects of music training and task experience</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Repp</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.humov.2009.08.002</idno>
		<ptr target="https://doi.org/10.1016/j.humov.2009.08.002" />
	</analytic>
	<monogr>
		<title level="j">Human Movement Science</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="200" to="213" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A Large-Scale Study of Misophonia</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rouw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erfanian</surname></persName>
		</author>
		<idno type="DOI">10.1002/jclp.22500</idno>
		<ptr target="https://doi.org/10.1002/jclp.22500" />
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical Psychology</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="453" to="479" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>SchrÃ¶der</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vulink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Denys</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0054706</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0054706" />
	</analytic>
	<monogr>
		<title level="m">Misophonia: Diagnostic Criteria for a New Psychiatric Disorder</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">54706</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Speech recognition with primarily temporal cues</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">G</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wygonski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ekelid</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.270.5234.303</idno>
		<ptr target="https://doi.org/10.1126/science.270.5234.303" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">5234</biblScope>
			<biblScope unit="page" from="303" to="304" />
			<date type="published" when="1995">1995</date>
			<pubPlace>New York, N.Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A genome-wide association study of a rage-related misophonia symptom and the genetic link with audiological traits, psychiatric disorders, and personality</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J A</forename><surname>Smit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bakker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Abdellaoui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Hoetink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Vulink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Denys</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2022.971752</idno>
		<ptr target="https://doi.org/10.3389/fnins.2022.971752" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The role of harmonic expectancy violations in musical emotions: Evidence from subjective, physiological, and neural responses</title>
		<author>
			<persName><forename type="first">N</forename><surname>Steinbeis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Koelsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Sloboda</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn.2006.18.8.1380</idno>
		<ptr target="https://doi.org/10.1162/jocn.2006.18.8.1380" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1380" to="1393" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">ASMR-Experience Questionnaire (AEQ): A data-driven step towards accurately classifying ASMR responders</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Swart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Bowling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Banissy</surname></persName>
		</author>
		<idno type="DOI">10.1111/bjop.12516</idno>
		<ptr target="https://doi.org/10.1111/bjop.12516" />
	</analytic>
	<monogr>
		<title level="j">British Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="83" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Consensus definition of misophonia: A delphi study</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Swedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Baguley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Denys</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Dixon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Erfanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fioretti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Jastreboff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rouw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Simner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Storch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R V</forename><surname>Werff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Altimus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Raver</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2022.841816</idno>
		<ptr target="https://doi.org/10.3389/fnins.2022.841816" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A Moist Crevice for Word Aversion</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Thibodeau</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0153686</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0153686" />
	</analytic>
	<monogr>
		<title level="m">Semantics Not Sounds</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">153686</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A review of hyperacusis and future directions: Part I. Definitions and manifestations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Tyler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pienkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Roncancio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Jun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brozoski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dauman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Coelho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Andersson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Keiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Cacace</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C J</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.1044/2014_AJA-14-0010</idno>
		<ptr target="https://doi.org/10.1044/2014_AJA-14-0010" />
	</analytic>
	<monogr>
		<title level="j">American Journal of Audiology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="402" to="419" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Of cricket chirps and car horns: The effect of nature sounds on cognitive performance</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Van Hedger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Nusbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Clohisy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Jaeggi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Buschkuehl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Berman</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-018-1539-1</idno>
		<ptr target="https://doi.org/10.3758/s13423-018-1539-1" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="522" to="530" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The aesthetic preference for nature sounds depends on sound object recognition</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Van Hedger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Nusbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L M</forename><surname>Heald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Kotabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Berman</surname></persName>
		</author>
		<idno type="DOI">10.1111/cogs.12734</idno>
		<ptr target="https://doi.org/10.1111/cogs.12734" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">43</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Development of the short version of the spielberger state-Trait anxiety inventory</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Zsido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Teleki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Csokasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rozsa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Bandi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.psychres.2020.113223</idno>
		<ptr target="https://doi.org/10.1016/j.psychres.2020.113223" />
	</analytic>
	<monogr>
		<title level="j">Psychiatry Research</title>
		<imprint>
			<biblScope unit="volume">291</biblScope>
			<biblScope unit="page">113223</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m">Letter sounds that trigger your misophonia</title>
		<imprint>
			<date type="published" when="2022-03-08">March 8, 2022</date>
		</imprint>
	</monogr>
	<note>Online forum post</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
