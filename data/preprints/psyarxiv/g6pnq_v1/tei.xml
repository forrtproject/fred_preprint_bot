<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reading Between the Lines: LLMs Match or Exceed Human Empathic Accuracy Using Text Alone</title>
				<funder>
					<orgName type="full">Azrieli Israel Center for Addiction and Mental Health</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Noa</forename><surname>Oded</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Matan</forename><surname>Rubin</surname></persName>
							<email>matan.rubin@mail.huji.ac.il</email>
							<affiliation key="aff0">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shir</forename><surname>Genzer</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anat</forename><surname>Perry</surname></persName>
							<email>anat.perry@mail.huji.ac.il</email>
							<affiliation key="aff0">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">The Hebrew University of Jerusalem</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Reading Between the Lines: LLMs Match or Exceed Human Empathic Accuracy Using Text Alone</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BE09977B7CD69F120016CF6486222866</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-22T14:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Empathy</term>
					<term>cognitive empathy</term>
					<term>empathic accuracy</term>
					<term>artificial intelligence</term>
					<term>Large language models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Empathy plays a central role in human emotional relationships. Empathic accuracy, the ability to accurately infer another person's emotional state, varies by informational modality and, in humans, is often intertwined with emotional and motivational processes. This study examines whether state-of-the-art Large Language Models (LLMs) -GPT-4, Claude, and Gemini -demonstrate empathic accuracy, and how their accuracy compares to that of humans when presented with only the semantic content (transcripts of recorded videos) of ecological, complex autobiographical emotional narratives. We compared the empathic accuracy of LLMs' to that of human participants (N = 127, randomly sampled students, both in-lab and online) who either read the same transcripts or watched the original videos, which enabled them to use facial and bodily expressions, as well as paralinguistic cues, in addition to semantics. LLMs were able to infer emotional states from semantic content alone with a precision that is equal to or surpasses human performance. This was true both generally and when analyzing positive and negative emotions separately. Theoretically, these findings suggest that semantic information alone can support high empathic accuracy, though humans may not fully leverage this potential. Practical implications are discussed regarding the use of LLMs in introspective and emotional contexts, while raising critical concerns about privacy, ethical risks, and the potential reshaping of emotional understanding, intimacy, and human connection in an increasingly AI-mediated world.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Empathy, the ability to recognize, understand, and share the emotional states of others, is essential for human connection <ref type="bibr" target="#b3">(Batson et al., 1991;</ref><ref type="bibr" target="#b6">Davis, 2017;</ref><ref type="bibr">Genzer et al., 2024;</ref><ref type="bibr" target="#b74">Zaki &amp; Ochsner, 2012)</ref>. While definitions vary, most scholars agree that empathy consists of three core components: Cognitive empathy, also known as perspective-taking, is the ability to understand another person's internal mental states, and frequently evaluated as an individual's accuracy in discerning another's thoughts and emotions; affective empathy refers to the capacity to share or "feel with" others' emotions; and motivational empathy, or "empathic concern" is a drive to act on behalf of the other's well-being <ref type="bibr" target="#b13">(Genzer et al., 2024;</ref><ref type="bibr" target="#b74">Zaki &amp; Ochsner, 2012)</ref>.</p><p>Research has extensively demonstrated the broad-ranging benefits of human empathy across multiple contexts. Empathy forges social bonds and sustains close relationships <ref type="bibr" target="#b1">(Anderson &amp; Keltner, 2002)</ref>, positively impacts adolescent peer relationships <ref type="bibr" target="#b16">(Gleason et al., 2009)</ref>, increases marital satisfaction <ref type="bibr" target="#b46">(Rafaeli et al., 2017;</ref><ref type="bibr" target="#b60">Sened et al., 2017)</ref>, enhances the effectiveness of medical care <ref type="bibr" target="#b30">(Larson, 2005;</ref><ref type="bibr" target="#b47">Rakel et al., 2009)</ref>, and improves psychotherapy outcomes <ref type="bibr">(Elliott et al., 2018)</ref>. Given the myriad of benefits for individual wellbeing and social cohesion, understanding the factors that enable and enhance empathy is essential. Alongside these benefits, empathy is also taxing for people and frequently avoided <ref type="bibr" target="#b5">(Cameron et al., 2019)</ref>. This fact has coincided with recent developments in the field of artificial intelligence (AI), leading many to seek emotional and empathic support from AI agents, especially given their accessibility and availability <ref type="bibr" target="#b0">(Alabed et al., 2024;</ref><ref type="bibr" target="#b20">Haensch, 2025;</ref><ref type="bibr" target="#b34">Li &amp; Zhang, 2024)</ref>. However, there are fundamental differences, both theoretical and practical, between empathy in human relationships and empathy in human-AI relationships.</p><p>First, in humans, cognitive, affective, and motivational empathy are intertwined and often align: We tend to care more for those close to us, understand them better, and are more motivated to help them <ref type="bibr" target="#b65">(van den Bedem et al., 2019)</ref>. This interconnection is further evidenced in vicarious-pain responders, who not only experience others' pain as their own but consequently demonstrate enhanced emotional understanding and stronger helping motivations <ref type="bibr" target="#b4">(Ben Adiva et al., 2024)</ref>. Furthermore, neuroscience studies on empathic accuracy-a paradigm that examines cognitive empathy-have revealed that successful perspective-taking engages both cognitive and affective neural networks simultaneously, suggesting that these components operate in concert rather than isolation <ref type="bibr" target="#b14">(Genzer et al., 2022;</ref><ref type="bibr" target="#b59">Schurz et al., 2021;</ref><ref type="bibr" target="#b74">Zaki &amp; Ochsner, 2012)</ref>. As such, although we can distinguish between the components of empathy theoretically, disentangling them from one another and examining only a single aspect, in ecological contexts where they often co-occur, remains a significant challenge.</p><p>To address this challenge, researchers frequently study clinical populations.</p><p>These include lesion studies (e.g. <ref type="bibr" target="#b43">Perry et al., 2017;</ref><ref type="bibr" target="#b62">Shamay-Tsoory et al., 2004)</ref> or individuals with disorders that theoretically affect different aspects of empathy, such as autism, schizophrenia, or psychopathy <ref type="bibr" target="#b8">(Derntl et al., 2012;</ref><ref type="bibr" target="#b27">Keysers &amp; Gazzola, 2014;</ref><ref type="bibr" target="#b63">Song et al., 2019)</ref>. However, these studies have not shown clear deficits in any one specific aspect of empathy, highlighting how interconnected these aspects are in humans and the difficulty of isolating them in order to clearly study one without the others.</p><p>In contrast, AI models, and specifically large language models (LLMs), do not integrate cognitive, affective, and motivational components of empathy. While they are capable of inferring emotions and simulating aspects of cognitive empathy, they lack consciousness, and they do not experience emotions, "feel with" others, or care about others' well-being <ref type="bibr" target="#b42">(Perry, 2023)</ref>. This difference is experienced by users, with recent research showing that the affective and motivational components of empathy are more valuable to individuals when perceived as human-authored as opposed to AI-generated, without such differences apparent in cognitive empathy <ref type="bibr" target="#b54">(Rubin et al., 2025)</ref>. This inherent distinction of aspects of empathy in LLMs presents a unique scientific opportunity: Because LLMs operate without affective or motivational components, they allow researchers to isolate and examine the informational basis of cognitive empathy in a way that is not possible in human studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Communication Channels and the Role of Semantics</head><p>Another critical distinction between human-human and human-AI interactions lies in the channels of communication. Human emotional understanding typically relies on multimodal information: verbal content, facial expressions, tone of voice, body language, and paralinguistic cues such as pitch and rhythm <ref type="bibr" target="#b19">(Gunes et al., 2008)</ref>. In contrast, as of today, most daily communication with LLMs is limited to semantic textual information <ref type="bibr" target="#b66">(Wang et al., 2024)</ref>.</p><p>Research attempting to dissect the relative contributions of these channels in humans has occasionally used Empathic Accuracy tasks, in which participants observe a target recounting an emotional experience-through video, audio, or text-and are asked to continuously or retrospectively infer the target's emotions. Accuracy is then measured by comparing participants' inferences to the target's own self-reported emotional states. These studies find that while people can identify emotions based on visual cues alone, the combination of auditory semantic information and paralinguistic vocal cues typically yields the highest empathic accuracy <ref type="bibr" target="#b14">(Genzer et al., 2022;</ref><ref type="bibr" target="#b15">Gesn &amp; Ickes, 1999;</ref><ref type="bibr" target="#b21">Hall &amp; Schmid Mast, 2007;</ref><ref type="bibr" target="#b26">Jospe et al., 2020;</ref><ref type="bibr" target="#b28">Kraus, 2017;</ref><ref type="bibr" target="#b29">Kraus &amp; Segal, 2015)</ref>. However, the specific informational value of pure semantic content remains largely unexplored.</p><p>In a study directly addressing this, <ref type="bibr" target="#b21">Hall and Schmid Mast (2007)</ref> demonstrated that participants reading only transcripts (thus avoiding any paralinguistic or visual cues) achieve relatively high empathic accuracy, though emotional inferences were further improved when paralinguistic cues were available. These results imply that semantic information carries substantial emotional content, but that paralinguistic cues contribute additional information and increase empathic accuracy.</p><p>As with the distinction of empathy components, here too the use of LLMs provides an opportunity. Since LLMs operate exclusively through semantic input, they offer a unique methodological solution to this challenge. By utilizing and examining the empathic accuracy of systems that process and generate purely textual information, researchers can more precisely isolate and evaluate the informational contribution of semantics to empathic inference, free from the confounding effects of additional communicative channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Theoretical and Practical Questions</head><p>Considering LLMs' lack of emotional experience and their reliance on textual input alone-a central question emerges: To what extent can LLMs accurately infer human emotional states based purely on semantic information? The comparison between humans' and LLMs' empathic accuracy in a naturalistic test, will both show the ability of LLMs to infer emotional states in the present moment, and also presents a unique opportunity to test two fundamental questions in empathy research: First, can LLM's achieve high levels of empathic accuracy compared to humans, without any affective experience or motivational concern? Second, is semantic information alone sufficient for accurate emotional understanding?</p><p>Answering these questions will yield valuable insights, and will have important implications, both theoretically and practically. From a theoretical perspective, understanding LLMs' and humans' empathic accuracy abilities from semantic information enables researchers to pose fundamental questions about the informational and inferential foundations of cognitive empathy, and to illuminate the distinct contributions of semantic processing in empathic understanding. Practically, the findings can inform the development of potential applications of LLMs in the realm of human-AI relationships, including current use cases, their possible value, and important risks that should be taken into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Present Research</head><p>Recent studies have begun to explore the capacity of LLMs to understand emotional states, however, accuracy in these studies was evaluated by third-party raters, and not compared to the actual rated emotions of the target <ref type="bibr" target="#b12">(Gandhi et al., 2024;</ref><ref type="bibr" target="#b31">Lee et al., 2024;</ref><ref type="bibr">D. Ong et al., 2022</ref><ref type="bibr">, Tak &amp; Gratch, 2024)</ref>. Other studies have assessed LLM's accuracy using structured tasks, such as the Reading the Mind in the Eyes Test (RMET), the Movie for the Assessment of Social Cognition (MASC), or vignette-based measures, like the Situational Test of Emotion Management (STEM) or the Geneva EMOtion Knowledge Test-Blends (GEMOK-B). These studies found that LLMs performed as well as humans or outperformed them <ref type="bibr" target="#b49">(Refoua et al., 2024</ref><ref type="bibr" target="#b20">, 2025</ref><ref type="bibr" target="#b57">, Schlegel et al., 2025)</ref>. However, the stimuli in these tasks are fabricated as opposed to naturalistic or ecological in nature. Moreover, high performance on these tasks may be partially attributable to some correct answers appearing openly in research (See for examples: <ref type="bibr">Baron-Cohen, 2003;</ref><ref type="bibr" target="#b36">MacCann &amp; Roberts, 2008;</ref><ref type="bibr" target="#b58">Schlegel &amp; Scherer, 2018)</ref>. This potentially makes them part of the LLM training data, thus influencing the answers and preventing a pure analysis of the emotions present in the stimuli. To our knowledge, the only study that specifically measured the empathic accuracy of an LLM in a naturalistic setting is <ref type="bibr" target="#b72">Yin et al. (2024)</ref>; but notably, it focused exclusively on negative scenarios in an English-speaking, western culture, examined only a single LLM (Bing Chat), and did not compare the model's performance to that of humans with access to the full video context.</p><p>The current study examines LLMs capacity to understand emotional states through an empathic accuracy task using naturalistic videos of autobiographical emotional narratives told by Israeli participants in Hebrew, which included both positive and negative emotions. These videos are part of a strictly-secured dataset, used for experiments on secure platforms and only with explicit permission. This approach ensures that the LLMs had no prior exposure to these specific stimuli (see Methods below). Moreover, the videos' language introduces an additional challenge for LLMs, as the LLMs evaluated were primarily trained on English-language data, heavily influenced by American and other Western cultural contexts <ref type="bibr" target="#b9">(Dey et al., 2024;</ref><ref type="bibr" target="#b51">Roumeliotis &amp; Tselikas, 2023)</ref>. Therefore, poor performance on this task would not necessarily reflect limitations in the LLMs' empathic accuracy capacities, but may instead reflect a cultural or linguistic gap between their training data and the current stimuli. Alternatively, such findings would support the proposition that semantic information is not enough for empathic accuracy. However, high performance-even on these culturally specific, Hebrew-language personal stories-would point to remarkably robust empathic accuracy abilities, achieved purely from semantic information. This would be especially compelling if the LLMs were to match or even surpass the performance of native Hebrew-speaking Israeli participants, who share the speakers' cultural background and have access to the full videos that include additional sensory information cues, such as tone of voice and facial expressions.</p><p>To address these questions, we conducted a study using stimuli from the Israeli Empathic Accuracy Stimuli Set <ref type="bibr" target="#b26">(Jospe et al., 2020)</ref>. In this dataset, each storyteller rated their own emotional states during the recording, allowing for an objective benchmark against which to compare the empathic accuracy of both humans and LLMs. In our design, we sampled two groups of human participants: One group read the transcripts, and the other watched the full videos, including all semantic, visual, and paralinguistic information. We then gathered ratings from LLMs based only on the textual transcripts of the stories, without any visual or paralinguistic information, and assessed their ability to infer emotions based solely on this semantic information. We then compared the empathic accuracy of LLMs to that of the human raters.</p><p>Because previous research has shown that LLMs can differ in their capacity for empathic responses <ref type="bibr" target="#b31">(Lee et al., 2024;</ref><ref type="bibr">Yongsatianchotet al., 2024)</ref>, we compared three LLMs alongside the human groups. We systematically examined whether LLMs might extract emotional cues from language more effectively than humans typically do, without a corresponding emotional experience and paralinguistic information.</p><p>Lastly, since humans are characterized by a negativity bias, meaning they tend to notice, interpret, and remember negative emotional information more readily than positive information <ref type="bibr" target="#b38">(Norris, 2021;</ref><ref type="bibr" target="#b52">Rozin &amp; Royzman, 2001;</ref><ref type="bibr" target="#b64">Vaish et al., 2008)</ref>, we further examine whether AI models, trained on human data, perform similar to (or differently from) humans when inferring negative versus positive emotions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Transparency and Openness</head><p>To protect the privacy of participants who shared autobiographical emotional experiences used as stimuli, the experimental stimuli are not publicly provided, but are available for academic use, and will be sent upon request from the corresponding authors. Data were analyzed using R, Version 4.3.2 (R Core Team, 2023) All studies were approved by the ethics committee of the social sciences faculty of the Hebrew University of Jerusalem. The study design and analysis were not pre-registered, as we had no clear hypotheses ahead of time. We report how we determined our sample size, all data exclusions, all manipulations, and all measures in the study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Participants</head><p>Based on a previously found effect size <ref type="bibr">(Hall &amp; Schmid Mast, 2007, r = .33)</ref>, we ran a power analysis using the 'pwr' R package to be able to detect a difference between the two human conditions, should one exist. Though this design is not identical to ours, it was the closest we could find, and differences between the LLMs themselves were not the main interest of our paper. We found that a sample of 60 participants in each group would be highly powered to detect an effect between the two human conditions (power = 0.9).</p><p>We recruited 128 Hebrew-speaking undergraduate students from the Hebrew University of Jerusalem through the university's participant recruitment platform. The students received either course credit or 60 NIS (~16 US dollars) in the video condition, or 30 NIS (~8 US dollars) in the text condition, as the latter required less time from the participants. We excluded one participant from the analysis who failed more than 3 attention checks, resulting in a final sample of 127 (ntext = 57, 63% female, Mage = 25.08 ± 4.15 (SD)).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Empathic Accuracy Stimuli</head><p>We selected 12 videos from the Israeli Empathic Accuracy Stimuli Set <ref type="bibr" target="#b26">(Jospe et al., 2020)</ref>. These videos featured 10 different storytellers (i.e. targets, 60% female Mage = 22.75 ± 1.98 (SD)) who shared personal emotional experiences in Hebrew. The videos were mixed in valence, with 4 videos depicting mostly positive emotions, 3 mostly negative emotions and 5 including mixed emotional content. The average duration of the videos was 146.92 seconds (SD = 42.03), with a minimum duration of 87 seconds and a maximum of 240 seconds. Once the targets finished narrating all stories, they watched the videos and continuously rated the valence of their emotions in each moment of the video. They were then asked to report on the intensity of eight specific emotions they had felt during their storytelling as a whole, using a scale from 1 ("not at all") to 9 ("very much"). The specific emotions included embarrassment, anger, sadness, happiness, disgust, pride, fear, and excitement. We converted the set of videos into written text in order to prompt the LLMs and present them to human participants in the text condition. All stimuli used in the study were not publicly available online, ensuring that LLMs had no prior exposure to them and no opportunity to learn them in advance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Procedure</head><p>After providing informed consent, participants first were shown the stimuli. In the video condition, participants came into the lab and viewed the videos in a random order, in two blocks of six videos each. A 10-minute break was offered between blocks.</p><p>While viewing each video, participants continuously assessed the emotional valence of the narrator, indicating the degree to which the emotions conveyed were positive or negative by moving a cursor along a dynamic scale ranging between 0 ("negative") and 100 ("positive") displayed beneath the video. This measurement is not relevant for evaluating text and so was not analyzed further in this research (it is part of a different, ongoing study in the lab, beyond the scope of the current work). At the end of each video, participants rated the intensity of the emotions they perceived the target felt.</p><p>These were the same specific emotions that the target had rated after the narration of their stories, using a nine-point scale (on a scale of 1 = not at all to 9 = very much).</p><p>Additionally, participants answered questions about their familiarity with the narrator and any technical disruptions during video playback. They were then asked one multiple-choice question regarding the content of the story. This was used as an attention check, and all trials where participants failed to answer correctly were removed. Participants who failed more than three of these questions were removed from the analysis. They then completed several other questionnaires, not examined in the current research.</p><p>In the text condition, participants took part in an online study in which they read the transcriptions of the same videos presented in the video condition. After each story, they rated the intensity of the emotions experienced by the target while telling the story and answered the same attention-check questions as in the video condition and the same subsequent questionnaires. Trials where participants failed to answer the attention check were removed .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">AI Models</head><p>Parallel to the human participants, we used three LLMs to gather similar empathic accuracy ratings from AI. These were GPT-4o-2024-08-06, Claude-3.5sonnet-20240620 and Gemini 1.5 Pro, which were state-of-the-art at the time we generated responses, between October and December 2024. These models were utilized to process the same series of 12 stories in a random order. Each model was tasked with analyzing the emotional content of the stories and providing ratings for the intensity of emotions, using the same scale as the human participants did. The AI models also processed the attention-check question concerning the content of each story. There were no instances where this question was answered incorrectly. The exact prompts are available in the supplementary section 1(translated into English). To make these iterations as parallel as possible to human participants, we added the full conversation history up until each story before the story itself, including the previous stories and ratings from that iteration. This was parallel to a human participant being asked to rate each story sequentially. We then treated each iteration of an LLM rating all 12 stories as a separate unique participant. It should be noted that this caused some noise, and it required an engineering process until we reached prompts that gave specific responses to each story, despite including the chat history.</p><p>In order to generate the ratings by each LLM, the prompts were delivered using an R script to each model through its respective API, which allows direct access to the model without specific third-party guidelines or restrictions. The code used the following packages: claudeR (Yamil Velez, 2024), openai (Iegor Rudnytskyi, 2023), gemini.R (Jinhwan <ref type="bibr" target="#b25">Kim, 2024)</ref>. All code and data can be found in our OSF project: <ref type="url" target="https://osf.io/qtmdr/?view_only=b7a208a91e4e4e14803ac7a1f3a4686b">https://osf.io/qtmdr/?view_only=b7a208a91e4e4e14803ac7a1f3a4686b</ref> Since there is no accepted benchmark for how many iterations to run on LLMs, we opted for matching the number of human samples and ran 60 iterations for each model. All runs were conducted using the same version of the models and identical parameters, specifying a temperature setting of 1 for all models, which is presumed to be a common setting for mainstream platforms using these LLMs at the time of study design. It should be noted that previous research shows temperature does not significantly impact performance for various tasks <ref type="bibr" target="#b41">(Patel et al., 2024;</ref><ref type="bibr" target="#b50">Renze, 2024;</ref><ref type="bibr" target="#b70">Windisch et al., 2024)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Measures:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Empathic accuracy</head><p>The empathic accuracy level of the perceiver was determined by calculating the absolute difference between the perceiver's rating and the storyteller's rating. This scale was then reversed, with 8 points for the highest accuracy and 0 points for the lowest.</p><p>The total of these reversed scores indicates the overall accuracy in recognizing emotions, with a scale that ranges from 0 to 64. To make it easier to understand, this scale was converted to a range of 0 to 100 (for similar calculation, see <ref type="bibr" target="#b23">Israelashvili et al., 2020)</ref>. We also calculated empathic accuracy separately for positive emotions (happiness, excitement, pride) and for negative emotions (embarrassment, sadness, disgust, anger, fear) in a similar manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Analysis:</head><p>All analyses were performed using R (R Core Team, 2023). Trials where participants or LLMs scored more than 2.5 standard deviations from the mean empathic accuracy score were excluded from the analysis, leading to the removal of 34 (4.16%) trials from the video condition, 34 (5.04%) trials from the text condition, 3 (.004% trials from GPT, 9 (.012%) trial from Claude, and 4 (.006%) trials from Gemini. No individual participants were removed.</p><p>First, we fitted a linear mixed model to predict empathic accuracy scores using the response source, which had five levels: GPT-4o, Claude-sonnet-3.5, Gemini pro 1.5, human participants in the video condition, and human participants in the text condition. The model maintained a random intercept for each participant/iteration and each story, using the lmer function from the lme4 package, with the model's contrasts dummy-coded, using the human participants' mean empathic accuracy in the video condition as the intercept. Thus, we compared all conditions to the most ecological human condition: human raters who received full audiovisual stimuli. We transformed the model effects to a type-III ANOVA to report here, with full model details available in supplementary section 2. We then analyzed specific post-hoc contrasts of interest, comparing the two human conditions to each other and to each AI model. These were conducted using the emmeans package, with Bonferroni corrections applied to adjust for multiple comparisons.</p><p>Second, we fitted a linear mixed-effect model that examined empathic accuracy from response source, the rated emotions' valence, and their interaction. Contrasts were dummy-coded, with the human participants' mean empathic accuracy in the video condition as an intercept for response source, and negative emotions as an intercept for the valence. The model maintained a random intercept for each participant/iteration and for each story. We again transformed the model to a type-III ANOVA for reporting purposes, with full details available in supplementary section 3. Post-hoc contrasts compared the two different human rating conditions to the AI-generated ratings and used Bonferroni corrections to adjust for multiple comparisons.</p><p>Third, we explored the distribution of AI-generated responses and compared their statistical characteristics to those of human participants, to see if they behave similarly and are as varied. Specifically, we looked at four characteristics: we used Shapiro-wilk's test to examine the normality of the distribution of each rating source's empathic accuracies; Levene's test to compare the variances of the AI models to human raters; we obtained the percentage of repeated responses by response source; and we subsetted the human and AI data to investigate the variance explained by the random effect of each iteration compared to that explained by the random effect of ratings from the same human rater.</p><p>In this examination of the distribution, we found that there was limited variance and a large number of repeated responses in the AI-generated ratings. Aiming to better represent AI ratings, we decided to generate a much larger number of AI responses, and to treat them as a population. To assess whether the larger population of AI-generated responses was more or less varied than the initial sample, we compared the proportion of duplicate responses in each dataset.</p><p>Lastly, we repeated our analyses on empathic accuracy. We compared the two different human samples to this larger AI population to examine our hypotheses again while representing as wide a range of AI responses to each story as possible (within reason). We compared the human ratings to the mu of this new population of AIgenerated ratings, for total EA, and specifically by valence. We also tested a linear model, predicting whether the differences between human ratings and the mode and mean of the AI ratings are significantly different from 0, while including a random effect for each specific story (Full details for all models are available in supplementary sections 4-7). We then also tested whether the mu of the new population is significantly different to human raters EA (generally and by valence) when averaging the EA of each individual participant across stimuli.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Data and code availability</head><p>All research materials including LLM instructions, anonymized data, and analyses file are available <ref type="url" target="https://osf.io/qtmdr/?view_only=b7a208a91e4e4e14803ac7a1f3a4686b">https://osf.io/qtmdr/?view_only=b7a208a91e4e4e14803ac7a1f3a4686b</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Cleaning</head><p>We removed all observations in which participants failed the attention check (n = 10 in the video condition, n = 10 in the text condition), with no individual participants removed. We also removed observations in the video condition where participants did not complete the continuous rating tasks (n = 5). One participant was removed entirely as they had more than 4 trials removed due to these reasons. We then removed observations in the video condition where participants recognized the target (n = 9), and observations where participants indicated technical difficulties (n = 4 in the video condition), leading to a total of 1491 observations from 127 human participants. There were no incorrect attention checks in the AI models' responses to the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Differences in Empathic Accuracy</head><p>The linear mixed model revealed a significant effect of response source on empathic accuracy (F)4, 264.63( = 38.02, p &lt; .001, η 2 = 0.36, 95% CI = [.29, 1.00]). Posthoc contrasts revealed that all LLMs showed significantly higher empathic accuracy than humans in either condition, but humans in the video condition were more accurate than those in the text condition (all ps &lt;.001, see Table <ref type="table" target="#tab_0">1</ref>). These results indicate that AI models are more empathically accurate than humans who read transcripts or viewed the full audiovisual stimuli, despite the fact the models received only Hebrew transcripts of the videos.   We then explored these differences for each valence of emotions. A linear mixed-effect model found a significant main effect of response source (F(4, 7126) = 21.56, p &lt; .001, η²ₚ = .01, 95% CI = [.01, 1.00]), with no significant effect of emotion valence (p = .53), and a significant interaction of response source and emotion valence (F(4, 7126)</p><p>= 24.32, p &lt; .001, η²ₚ = .01, 95% CI = [.01, 1.00]). Post-hoc contrasts revealed that in all cases AI models were either similar to human raters or significantly better than them, with Claude and Gemini being more accurate than human raters for negative emotions, and GPT and Gemini being more accurate than human raters for positive emotions.</p><p>Interestingly, human raters in the video condition were significantly more accurate than human raters in the text condition only for negative emotions, and not for positive emotions (see Table <ref type="table">2</ref>).</p><p>Table 2. Comparisons of empathic accuracy abilities between different LLMs and human participants' conditions for positive and negative emotions separately.</p><p>Table 2 shows the differences in empathic accuracy between every two response sources in the comparison in standard deviations. * = p &lt; .05, ** = p &lt; .01, *** = p &lt; .001. Valence Contrast Standardized mean difference SE df t p Negative Emotions GPT-4o -Human (Text) .15 .04 1174 3.28 .008 ** GPT-4o -Human (Video) -.04 .04 1143 -1.14 1.00 Claude -Human (Text) .43 .04 1176 9.85 &lt;.001 *** Claude -Human (Video) .24 .04 1145 5.83 &lt;.001 *** Gemini -Human (Text) .32 .04 1179 7.22 &lt;.001 *** Gemini -Human (Video) .13 .04 1149 3.05 .02 * Human (Text) -Human (Video) -.19 .04 1223 -4.45 &lt;.001 *** Positive Emotions GPT-4o -Human (Text) .22 .04 1142 5.53 &lt;.001 *** GPT-4o -Human (Video) .31 .04 1166 7.33 &lt;.001 *** Claude -Human (Text) -.02 .04 1148 -.37 1.00 Claude -Human (Video) .07 .04 1173 1.66 0.68 Gemini -Human (Text) .13 .04 1141 2.94 .02 * Gemini -Human (Video) .21 .04 1165 5.13 &lt;.001 *** Human (Text) -Human (Video) .08 .04 1207 2.00 0.32 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparing Human and AI-generated Data Characteristics</head><p>In examining the differences between human and AI-generated ratings, we found that all EA ratings were not in a normal distribution (see Table <ref type="table" target="#tab_3">3</ref>), and Levene's test revealed they significantly differed from each other in variance (F(4, 3549) = 19.82, p &lt; .001). We also documented two key differences between the AI-generated ratings and the human ones. First, we found that when subsetting the AI and the human data separately, a linear mixed model that predicts only the AI-generated ratings estimated the variance for the random effect of individual LLM iteration at 0 (τID = .00), showing no evidence for explaining any variance by assuming dependence within iterations. This was very different from the estimated variance for the random intercept of individual human participants when an identical model instead based its predictions on human ratings (τID = .11). We used an ANOVA to compare each subsetted model with the random intercept for specific ID or iteration, and without it. The comparison showed that the model predicting the AI data was not improved by the inclusion of the random intercept for iteration (χ²(1) = .00, p = 1.00). However, the model predicting human data was significantly improved (χ²(1) = 33.28, p &lt; .001). Second, the AI data included a large number of duplicates, with different iterations of AI ratings of each story being repeated more than once: 43.47% in Gemini, 21.34% in GPT, 63.84% in Claude. This was far more frequent than in ratings provided by different human participants (0.005% in the video condition, 0.007% in the text condition). This reveals, perhaps not surprisingly, that the variance in LLM responses is not similar to that of human raters, nor do AIgenerated empathic accuracy scores follow a normal distribution (see Figures <ref type="figure" target="#fig_1">1</ref><ref type="figure" target="#fig_2">2</ref>above). However, the large number of duplicate responses in the AI-generated ratings raises the possibility that our sample of AI responses captured only a subset of possible responses, with very different variability to that of the human raters, and thus our comparison may not be the best one. It is possible that a larger sample of responses, representing a population of AI-generated ratings would provide a better comparison to human ratings and a more detailed account of the differences (see below). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Dataset b: Validating a Population of AI Ratings</head><p>We then sought to address the possibility that our responses were not as varied as AI models could be, and that this variability is very different from that of human ratings, as seen by the large number of duplicate responses we observed. To respond to this potential limitation, we generated 10,000 more ratings using Gemini 1.5-pro for each story, to treat as a population, thus not requiring estimating the variability. Gemini was chosen because it showed the median level of variability with 43.47% identical ratings, with GPT having higher variability but worse performance, and Claude having lower variability but performing identically. We used each story in a prompt separately because, as mentioned above, we found no evidence for dependence between the models' answers in each iteration.</p><p>We first examined whether this new data was similar to our initial sample. To do this, we compared the percentage of identical ratings in the initial sample and new population. We found that contrary to our earlier expectation that this population would be more varied, there was instead lower variance in the new sample, which had an average of 99.85% repeated ratings, with the most common ratings being repeated between 36-99% of the time for each story. Generally speaking, LLMs generate very specific responses for each story, very close to providing a singularly unique rating of emotions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Differences in Empathic Accuracy between the Human Samples and Gemini</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rating Population</head><p>We next treated all 10,000 ratings of each story as a population, representing the LLM's empathic accuracy abilities, and compared our previous human sample to it.</p><p>Upon comparing human participants to the mu of this population, we found that the human participants showed lower empathic accuracy abilities than those of the LLM overall (t(1422) = -21.51, p &lt; .001, Cohen's d = .57, M = 82.33, 95% <ref type="bibr">CI [81.96,</ref><ref type="bibr">82.70</ref>],</p><p>compared to the μLLM = 86.40). To account for the dataset including different stimuli, we also calculated the difference between each human rating and the most common rating Gemini 1.5 Pro generated for each story. We then used a mixed-effect linear model to compare these differences to 0, with a random intercept for each story. We found that the overall difference was significantly lower than 0 (b = -4.95, SE = 1.17, t(11.78) = -4.24, p = .001). The same result held when examining the difference between the human rating and the mean empathic accuracy score for each story in the population, instead of the most common one (b = -4.83, SE = 1.03, t(12.06) = -4.68, p &lt; .001). These results show that when compared to the most common rating and to the average score, human raters were still less empathically accurate than the LLM ratings. We again examined the differences for positive and negative emotions separately. We found that human raters performed worse than Gemini  <ref type="bibr">= 83.38,</ref><ref type="bibr">95% CI [82.88,</ref><ref type="bibr">83.88</ref>], compared to the μLLM = 86.09). We found similar results using linear-mixed effect models testing whether the difference between all human ratings and the most common rating by Gemini is different from 0, while accounting for valence. The model showed an intercept that was significantly lower than 0 (b = -4.42, SE = 1.03, t(12.29) = -4.28, p = .001) with significantly greater differences for positive emotions compared to negative emotions (b = -0.92, SE = 0.37, t(2735.97) = -2.46, p = .014, Cohen's d = .07). The same results were significant when examining the average as opposed to the mode (b = -4.25, SE = 0.98, t(12.54) = -4.33, p = .001), with a similar effect of valence (b = -1.03, SE = 0.37, t(2751.88) = -2.79, p = .005, Cohen's d = .09). These results show that across all measures, human raters perform worse than Gemini in rating both positive and negative emotions, with greater differences in positive emotions. The mu of the gemini population for each valence is marked by the dashed red line.</p><p>The same results were replicated when we examined participants on an individual level, with Gemini scoring significantly higher than human raters (t(t(122) = -16.86, p &lt; .001, 95% CI [81.04, 82.17], M = 81.60, Cohen's d = 1.52), and higher than 95% of human raters. The same was true for both positive emotions (t(125) = -15.89, p &lt; .001, 95% <ref type="bibr">CI [79.89,</ref><ref type="bibr">81.45</ref>], M = 80.67, Cohen's d = 1.42), with Gemini scoring higher than 96% of participants, and for negative emotions (t(122) = -9.90, p &lt; .001, 95% <ref type="bibr">CI [81.39,</ref><ref type="bibr">82.96]</ref>, M = 82.17, Cohen's d = 0.89), with Gemini scoring higher than 78% of participants (see supplementary figure <ref type="figure" target="#fig_1">1</ref>).</p><p>To summarize, when using transcripts of spoken videos in Hebrew, and using stimuli that could not have been part of the models' training data, LLMs are already significantly more accurate at detecting human emotions than human raters are, both when humans receive the same text and when they have additional audio-visual channels available.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion</head><p>The results of this study provide compelling evidence that current LLMs can achieve levels of empathic accuracy that are either similar to or exceed those of human participants, for both positive and negative emotions, even when operating under more constrained conditions. All tested models were either not different from or significantly outperformed humans who read the same textual transcripts or viewed the full audiovisual recordings. Notably, these findings emerged despite the fact that the LLMs were provided with only the Hebrew text of the emotional narratives-without access to tone, facial expressions, or other contextual cues, and without experiencing any emotion themselves. Moreover, they performed similarly to or better than participants who were close in age, culture, and social norms to the targets. This finding shows that LLMs were able to infer emotional states from language alone with a precision that is equal to or surpasses human performance.</p><p>The LLMs' high empathic accuracy was true both when response generation included the full experiment, and when prompting the models with each story individually. The models showed higher accuracy with lower variability than humans.</p><p>In other words, the different distribution of LLM responses from that of human responses is a feature of LLMs, not a bug. These results shed light on mechanisms underlying empathic accuracy in both artificial and human agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Theoretical Implications</head><p>First, these results offer converging evidence that semantic information may be sufficient-at least for LLMs-to infer emotional states with high accuracy. LLMs not only matched but mostly outperformed humans in the same text-only condition, suggesting they may extract and weigh linguistic cues differently or more effectively than human readers do. Therefore, whereas LLMs are capable of inferring emotional states accurately through language, humans may do so through integrating additional processes. This is further evidenced by significant differences between the video and text conditions, with participants who received visual information being more accurate than those in the transcript condition, especially for negative emotions.</p><p>Second, by examining empathic accuracy in LLMs, our study uniquely isolates cognitive empathy (the ability to infer others' emotional states; <ref type="bibr" target="#b74">Zaki &amp; Ochsner, 2012)</ref> without the confounding effects of affective or motivational empathy. While in humans all three components of empathy typically co-occur <ref type="bibr" target="#b7">(Depow et al., 2021;</ref><ref type="bibr" target="#b65">van den Bedem et al., 2019)</ref>-our findings suggest that affective or motivational empathy is not a prerequisite for cognitive empathy, as seen with LLMs. This highlights how artificial models can be used to isolate and examine cognitive empathy in ways that are difficult to achieve in typical populations. Previously, such distinctions could only be studied indirectly through clinical populations, whereas LLMs now offer a complementary, non-clinical model for exploring these dynamics.</p><p>Moreover, it is possible that AI models are capable of higher levels of cognitive empathy precisely because they do not experience emotions like people do. Unlike humans, in estimating the targets' emotions, LLMs may rely on the common expressions of emotions, while humans may be influenced by their own emotional state, thus adding specific situational and personal biases to their estimations. This is not to say that AI is unbiased. It has been shown that AI systems' judgements display more bias than humans overall, and can even amplify these biases in humans following computer-human interactions <ref type="bibr">(Glickman &amp; Sharot, 2025)</ref>. If this amplification is also true in the affective domain, continuously using AI to estimate and validate one's own emotions, or to understand those of others, may result in exaggeration or over-amplification of the actual emotional states. Thus, this exaggeration could potentially lead to further inaccuracies and misunderstandings in human communication (see Genzer et al., under review for already existing amplification effects in humans).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Practical Implications</head><p>Apart from theoretical contributions, the demonstrated ability of LLMs to accurately infer emotional states from naturalistic stimuli, has relevance for a wide range of applications. In clinical and assistive contexts, AI could support emotional reflection, enhance communication <ref type="bibr" target="#b61">(Velagaleti, 2024;</ref><ref type="bibr" target="#b75">Zdravkova et al., 2022)</ref>, and assist in emotion recognition for individuals who struggle with perspective-taking and interpreting emotional nuance, such as those with autism spectrum disorder (ASD) (see for example <ref type="bibr" target="#b33">Levy et al., 2024)</ref>. Similarly, mental health professionals might use AI tools to track emotional patterns in therapy sessions, identify unspoken affect in written materials, or improve documentation of patient experiences <ref type="bibr" target="#b35">(Luxton, 2014;</ref><ref type="bibr" target="#b48">Rebelo et al., 2023)</ref>. However, such applications also raise important concerns because they may foster overreliance on AI systems, potentially leaving users at a disadvantage in settings where such tools are unavailable; and they pose significant ethical questions related to data privacy and the sensitive nature of emotional information.</p><p>In a world increasingly mediated by AI-through digital platforms, messaging systems, and virtual assistants-the capacity of AI to "read" emotions calls for a thoughtful examination of how it might transform interpersonal communication and relationships. AI may become an invisible intermediary, helping to translate, clarify, or even optimize emotional expression in human-human communication. This could, for instance, reduce misunderstandings in online exchanges, flag emotionally sensitive content before it causes harm, or assist individuals in expressing themselves more clearly in moments of distress (though see cautionary note on the risk of amplifying bias, above).</p><p>At the same time, such interventions risk altering the essence of human communication, which is often built on miscommunications, reinterpretations, and putting effort into better understanding those we care about <ref type="bibr" target="#b37">(Naaman, 2022;</ref><ref type="bibr" target="#b69">Wilson, 2023)</ref>. If AI systems routinely "smooth over" emotional misunderstandings, people may begin to rely on these systems to mediate their most intimate connections, which may affect learning, growth, and relationship deepening. In fact, research on AI-mediated communication has already shown that undisclosed AI involvement is considered unacceptable <ref type="bibr">(Purcell et al., 2023)</ref>. Moreover, any perceived AI involvement reduces the emotional meaning of communication between people <ref type="bibr" target="#b17">(Glikson &amp; Asscher, 2023;</ref><ref type="bibr" target="#b22">Hohenstein et al., 2023;</ref><ref type="bibr" target="#b54">Rubin et al., 2025)</ref>. As these technologies become increasingly integrated into our relationships, they may inadvertently diminish the quality of interpersonal connection and negatively impact social well-being.</p><p>In addition to these interpersonal concerns, the ability of AI to detect emotions-particularly subtle or unintended ones-raises serious ethical questions.</p><p>Emotion recognition may not always serve the user; it can also serve third parties, such as companies, governments, or platforms that collect, analyze, and act upon this emotional data (D. C. <ref type="bibr" target="#b39">Ong, 2021;</ref><ref type="bibr" target="#b56">Schaich Borg, 2021)</ref>. Emotions that individuals may not wish to express outwardly could be inferred through text or speech, potentially without the user's knowledge or consent. This opens the door to new forms of surveillance and manipulation, whether through targeted advertising, political messaging, or more coercive control. In sensitive contexts, such as healthcare, education, or law enforcement, the potential for misuse is especially concerning <ref type="bibr" target="#b24">(Jeyaraman et al., 2023;</ref><ref type="bibr" target="#b32">Leslie, 2019;</ref><ref type="bibr" target="#b67">Weber, 2020)</ref>. While users might become more emotionally legible to machines, they may simultaneously lose control over how, when, and to whom their emotions are revealed. Ensuring that emotional data is protected, consensually shared, and ethically used must become a central priority in the development and deployment of AI systems capable of empathic inference.</p><p>Lastly, it should be noted that empathic accuracy alone does not guarantee meaningful empathic engagement. In human relationships, the subjective feeling of being understood, feeling genuinely heard, seen or cared for, often matters more than objective accuracy <ref type="bibr" target="#b11">(Eyal et al., 2018;</ref><ref type="bibr" target="#b54">Rubin et al., 2025;</ref><ref type="bibr" target="#b72">Yin et al., 2024)</ref>. Thus, although LLMs demonstrate remarkable capabilities for cognitive empathy, they fundamentally lack the emotional resonance and motivation to care that underlie human connection. As such, they may serve as valuable tools, but not replacements, in domains where emotional depth and interpersonal nuance are essential <ref type="bibr" target="#b42">(Perry, 2023;</ref><ref type="bibr" target="#b53">Rubin et al., 2024)</ref>.</p><p>Moreover, empathic missteps, when acknowledged and repaired, can strengthen relationships and foster emotional growth <ref type="bibr">(Baldwin, 2014;</ref><ref type="bibr" target="#b18">Gordon &amp; Chen, 2016</ref>). An AI system that detects emotions perfectly but does not genuinely feel or care may fail to provide a sense of connection or comfort. In contrast, a human who slightly misjudges an emotion but responds with warmth, care, and effort may be perceived as </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Limitations and Future Directions</head><p>This study has several limitations. One is its reliance on Hebrew-language stimuli. On the one hand, this choice represents a methodological strength: Because Hebrew is underrepresented in the training data of most LLMs, the use of these narratives reduces the likelihood that the models had prior exposure to the specific content or similar linguistic patterns, thereby providing a more ecologically valid test of zero-shot empathic inference. On the other hand, this design choice limits the generalizability of our findings. It remains an open question whether LLMs would demonstrate similar levels of empathic accuracy in other underrepresented languages or cultural contexts.</p><p>Second, the study focused on empathic accuracy from video recordings and their transcribed text. Future studies should assess how accurate LLMs are at inferring emotions during live interactions (via text or video), rather than recorded ones.</p><p>Lastly, we focused on a specific set of emotional stimuli and a small group of widely used, closed-source commercial LLMs, using a predefined temperature and a specific number of iterations determined by the researchers. These parameters were selected in the absence of established research conventions for evaluating LLMs in comparison to human performance. It is important to note, though, that the primary aim of this study was not to identify the most accurate LLM or optimal temperature setting, nor to explain the internal mechanisms or architectures of these proprietary modelswhose exact algorithms, weights, and decision-making processes remain undisclosed, and change on a weekly basis. Rather, this was a proof of concept, designed to demonstrate the potential of LLMs as tools for addressing psychological questions and to explore their far-reaching implications for human relationships-both in terms of their promise and their potential for harm. Future research should extend this work by incorporating a broader range of autobiographical narratives, cultural contexts, and emotional content, as well as evaluating newer or more specialized models, including open-source LLMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Conclusions</head><p>This study demonstrates that LLMs are capable of remarkably high empathic accuracy, even when relying solely on text-based input and operating in a language and cultural context underrepresented in their training data. Their performance not only equaled or surpassed that of human participants in comparable conditions but also exceeded the empathic accuracy of humans with access to full audiovisual information.</p><p>These findings highlight the rich emotional information embedded in language, even if not fully exploited by humans, and add to the previous debate on the role of different informational cues in empathic accuracy. The ability of LLMs to exhibit high cognitive empathy in the absence of feeling or caring also underscores their potential as novel tools for studying cognitive empathy in isolation-offering a non-clinical complement to traditional research with special populations.</p><p>In a world increasingly mediated by AI, emotion-recognition technologies will undoubtedly reshape not only how we interact with machines, but also how we relate to one another-offering both opportunities for support and significant risks for emotional communication. Moreover, the ability to detect and interpret emotions at scale raises serious concerns about privacy, surveillance, and emotional autonomy.</p><p>Future research in social psychology will be essential for understanding how these technologies influence human connection, trust, and emotional expression-and for guiding their integration in ways that support, rather than disrupt, the fabric of social life.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Declaration of generative AI and AI-assisted technologies in the writing process</head><p>In writing this paper, the authors utilized ChatGPT-4o during editing to paraphrase sentences for clarity. After using this tool/service, the authors reviewed and edited the content as needed and takes full responsibility for the content of the published article.</p><p>There was no other use of generative AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Competing Interests Statement</head><p>The authors declare no competing interests.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>comparison in standard deviations. * = p &lt; .05, ** = p &lt; .01, *** = p &lt; .001.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Differences in empathic accuracy between sources. For each source, the box marks the IQR, with the X inside marking the mean empathic accuracy with a 95% CI for the mean around it. The whiskers mark the total range, and the histogram to the side shows the distribution.</figDesc><graphic coords="15,90.00,183.10,468.33,250.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Differences in empathic accuracy between sources for positive and negative emotions. For each source, the box marks the IQR, with the X inside marking the mean empathic accuracy with a 95% CI for the mean around it. The whiskers mark the total range, and the histogram to the side shows the distribution.</figDesc><graphic coords="17,90.00,72.00,415.25,511.07" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Differences in empathic accuracy between human raters and the mu of the population of gemini ratings. For each condition of human raters, the box marks the IQR, with the X inside marking the mean empathic with a 95% CI for the mean around it. The whiskers mark the total range, and the histogram to the side shows the distribution. The mu of the gemini population is marked by the dashed red line.</figDesc><graphic coords="20,90.00,204.19,415.20,233.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>for both positive emotions (t)1432( = -17.40, p &lt; .001, Cohen's d = .46, M = 82.06, 95% CI [81.51, 82.61], compared to the μLLM = 86.91) and negative emotions (t(1426) = -10.53, p &lt; .001, Cohen's d = .28, M</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Differences in empathic accuracy between human raters and the mu of the population of gemini ratings for positive (left) and negative (right) emotions separately. For each condition of human raters, the box marks the IQR, with the X inside marking the mean empathic accuracy with a 95% CI for the mean around it. The whiskers mark the total range, and the histogram to the side shows the distribution.</figDesc><graphic coords="21,90.00,183.49,415.20,233.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><figDesc>more genuinely empathic. Crucially, what makes an empathic response meaningful to the recipient and valued over time remains an open question that future research should explore more deeply.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparisons of empathic accuracy abilities between different LLMs and human participants.</figDesc><table><row><cell>Contrast</cell><cell>Standardized</cell><cell>SE</cell><cell>df</cell><cell>t</cell><cell>p</cell></row><row><cell></cell><cell>mean difference</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GPT-4o -Human (Text)</cell><cell>.34</cell><cell>.04</cell><cell>302</cell><cell>7.71</cell><cell>&lt;.001 ***</cell></row><row><cell>GPT-4o -Human (Video)</cell><cell>.19</cell><cell>.04</cell><cell>301</cell><cell>4.44</cell><cell>&lt;.001 ***</cell></row><row><cell>Claude -Human (Text)</cell><cell>.45</cell><cell>.04</cell><cell>304</cell><cell cols="2">10.16 &lt;.001 ***</cell></row><row><cell>Claude -Human (Video)</cell><cell>.30</cell><cell>.04</cell><cell>303</cell><cell>7.01</cell><cell>&lt;.001 ***</cell></row></table><note><p>*</p><p>Table1</p><p>shows the differences in empathic accuracy between every two response sources in the</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Results of Shapiro-Wilk tests for the normality of Empathic Accuracy scores by response source.</figDesc><table><row><cell>Model</cell><cell>W</cell><cell>p</cell></row><row><cell>GPT-4o</cell><cell>0.97</cell><cell>&lt;.001 ***</cell></row><row><cell>Claude</cell><cell>0.88</cell><cell>&lt;.001 ***</cell></row><row><cell>Gemini</cell><cell>0.98</cell><cell>&lt;.001 ***</cell></row><row><cell>Human (video)</cell><cell>0.98</cell><cell>&lt;.001 ***</cell></row><row><cell>Human (text)</cell><cell>0.99</cell><cell>&lt;.001 ***</cell></row></table><note><p>* = p &lt; .05, ** = p &lt; .01, *** = p &lt; .001.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7.">Acknowledgements</head><p>Funding: This work was supported by a grant from the <rs type="funder">Azrieli Israel Center for Addiction and Mental Health</rs> to A.P., and a fellowship from the <rs type="funder">Azrieli Israel Center for Addiction and Mental Health</rs> to M.R.</p><p>We would also like to thank <rs type="person">Dr. Noam Siegelman</rs>, for his extremely helpful consultation on the statistical analyses of this novel dataset.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">More than just a chat: a taxonomy of consumers&apos; relationships with conversational AI agents and their well-being implications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alabed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Javornik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gregory-Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Casey</surname></persName>
		</author>
		<idno type="DOI">10.1108/EJM-01-2023-0037</idno>
		<ptr target="https://doi.org/10.1108/EJM-01-2023-0037" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Marketing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="373" to="409" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The role of empathy in the formation and maintenance of social bonds</title>
		<author>
			<persName><forename type="first">C</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Keltner</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X02230010</idno>
		<ptr target="https://doi.org/10.1017/S0140525X02230010" />
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="22" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The essential difference: Male and female brains and the truth about autism</title>
		<author>
			<persName><forename type="first">S</forename><surname>Baron-Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<publisher>Basic Books</publisher>
		</imprint>
	</monogr>
	<note>1st pbk. ed</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Empathy-Altruism Hypothesis</title>
		<author>
			<persName><surname>Batson</surname></persName>
		</author>
		<idno type="DOI">10.1093/oxfordhb/9780195399813.013.023</idno>
		<ptr target="https://doi.org/10.1093/oxfordhb/9780195399813.013.023" />
	</analytic>
	<monogr>
		<title level="m">The Oxford Handbook of Prosocial Behavior</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Beyond physical sensations: investigating empathy and prosocial behavior in vicarious pain responders</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ben Adiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Genzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.1093/scan/nsae039</idno>
		<ptr target="https://doi.org/10.1093/scan/nsae039" />
	</analytic>
	<monogr>
		<title level="j">Social Cognitive and Affective Neuroscience</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Empathy is hard work: People choose to avoid empathy because of its cognitive costs</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Hutcherson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Scheffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Hadjiandreou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Inzlicht</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000595</idno>
		<ptr target="https://doi.org/10.1037/xge0000595" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="962" to="976" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Empathy, Compassion, and Social Relationships</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Davis</surname></persName>
		</author>
		<idno type="DOI">10.1093/oxfordhb/9780190464684.013</idno>
		<ptr target="https://doi.org/10.1093/oxfordhb/9780190464684.013" />
		<editor>E. M. Seppälä, E. Simon-Thomas, S. L. Brown, M. C. Worline, C. D. Cameron, &amp; J. R. Doty</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Oxford University Press</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Experience of Empathy in Everyday Life</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Depow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Inzlicht</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797621995202</idno>
		<ptr target="https://doi.org/10.1177/0956797621995202" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1198" to="1213" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Neural correlates of the core facets of empathy in schizophrenia</title>
		<author>
			<persName><forename type="first">B</forename><surname>Derntl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Finkelmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Voss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kellermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Habel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.schres.2011.12.018</idno>
		<ptr target="https://doi.org/10.1016/j.schres.2011.12.018" />
	</analytic>
	<monogr>
		<title level="j">Schizophrenia Research</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="70" to="81" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Better to Ask in English: Evaluation of Large Language Models on English, Low-resource and Cross-Lingual Settings</title>
		<author>
			<persName><forename type="first">K</forename><surname>Dey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Tarannum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Razzak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Naseem</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2410.13153" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Capacity of Generative AI to Interpret Human Emotions From Visual and Textual Data: Pilot Evaluation Study</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Elyoseph</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Refoua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Asraf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lvovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Shimoni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hadar-Shoval</surname></persName>
		</author>
		<idno type="DOI">10.2196/54369</idno>
		<ptr target="https://doi.org/10.2196/54369" />
	</analytic>
	<monogr>
		<title level="j">JMIR Mental Health</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Perspective mistaking: Accurately understanding the mind of another requires getting perspective, not taking perspective</title>
		<author>
			<persName><forename type="first">T</forename><surname>Eyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steffel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Epley</surname></persName>
		</author>
		<idno type="DOI">10.1037/pspa0000115</idno>
		<ptr target="https://doi.org/10.1037/pspa0000115" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="547" to="571" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Human-like Affective Cognition in Foundation Models</title>
		<author>
			<persName><forename type="first">K</forename><surname>Gandhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Fränken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wambu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gerstenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2409.11733" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Empathy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Genzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Ben Adiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.1017/9781009281072</idno>
		<ptr target="https://doi.org/10.1017/9781009281072" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mu rhythm suppression over sensorimotor regions is associated with greater empathic accuracy</title>
		<author>
			<persName><forename type="first">S</forename><surname>Genzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.1093/scan/nsac011</idno>
		<ptr target="https://doi.org/10.1093/scan/nsac011" />
	</analytic>
	<monogr>
		<title level="j">Social Cognitive and Affective Neuroscience</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="788" to="801" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The development of meaning contexts for empathic accuracy: Channel and sequence effects</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Gesn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ickes</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.77.4.746</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.77.4.746" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="746" to="761" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The Role of Empathic Accuracy in Adolescents&apos; Peer Relations and Adjustment</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Gleason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Jensen-Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ickes</surname></persName>
		</author>
		<idno type="DOI">10.1177/0146167209336605</idno>
		<ptr target="https://doi.org/10.1177/0146167209336605" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="997" to="1011" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">AI-mediated apology in a multilingual work context: Implications for perceived authenticity and willingness to forgive</title>
		<author>
			<persName><forename type="first">E</forename><surname>Glikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Asscher</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2022.107592</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2022.107592" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="page">107592</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Do you get where I&apos;m coming from?: Perceived understanding buffers against the negative impact of conflict on relationship satisfaction</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1037/pspi0000039</idno>
		<ptr target="https://doi.org/10.1037/pspi0000039" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="239" to="260" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">From the Lab to the Real World: Affect Recognition Using Multiple Cues and Modalities</title>
		<author>
			<persName><forename type="first">H</forename><surname>Gunes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Piccardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
		<idno type="DOI">10.5772/6180</idno>
		<ptr target="https://doi.org/10.5772/6180" />
	</analytic>
	<monogr>
		<title level="m">Affective Computing</title>
		<imprint>
			<publisher>I-Tech Education and Publishing</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">It Listens Better Than My Therapist</title>
		<author>
			<persName><forename type="first">A.-C</forename><surname>Haensch</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2504.12337" />
	</analytic>
	<monogr>
		<title level="m">Exploring Social Media Discourse on LLMs as Mental Health Tool</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sources of accuracy in the empathic accuracy paradigm</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmid Mast</surname></persName>
		</author>
		<idno type="DOI">10.1037/1528-3542.7.2.438</idno>
		<ptr target="https://doi.org/10.1037/1528-3542.7.2.438" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="438" to="446" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Publisher Correction: Artificial intelligence in communication impacts language and social relationships</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hohenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Kizilcec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Difranzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Aghajari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mieczkowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Jung</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-023-43601-0</idno>
		<ptr target="https://doi.org/10.1038/s41598-023-43601-0" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">16616</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Different faces of empathy: Feelings of similarity disrupt recognition of negative emotions</title>
		<author>
			<persName><forename type="first">Iegor</forename><surname>Rudnytskyi ; Israelashvili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sauter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.jesp.2019.103912</idno>
		<ptr target="https://doi.org/10.1016/j.jesp.2019.103912" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page">103912</biblScope>
			<date type="published" when="2020">2023. 2020</date>
		</imprint>
	</monogr>
	<note>Package &quot;openai&quot; Title R Wrapper for OpenAI API</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unraveling the Ethical Enigma: Artificial Intelligence in Healthcare</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jeyaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jeyaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yadav</surname></persName>
		</author>
		<idno type="DOI">10.7759/cureus.43262</idno>
		<ptr target="https://doi.org/10.7759/cureus.43262" />
	</analytic>
	<monogr>
		<title level="j">Cureus</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Title Interface for &quot;Google Gemini</title>
		<author>
			<persName><forename type="first">Jinhwan</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<publisher>API</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The contribution of linguistic and visual cues to physiological synchrony and empathic accuracy</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jospe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Genzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Klein Selle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2020.09.001</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2020.09.001" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">132</biblScope>
			<biblScope unit="page" from="296" to="308" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dissociating the ability and propensity for empathy</title>
		<author>
			<persName><forename type="first">C</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Gazzola</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2013.12.011</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2013.12.011" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="163" to="166" />
			<date type="published" when="2014">2014</date>
			<publisher>Elsevier Ltd</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Voice-only communication enhances empathic accuracy</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Kraus</surname></persName>
		</author>
		<idno type="DOI">10.1037/amp0000147</idno>
		<ptr target="https://doi.org/10.1037/amp0000147" />
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="644" to="654" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Empathic Accuracy Without Visual Cues</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Segal</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.2628240</idno>
		<ptr target="https://doi.org/10.2139/ssrn.2628240" />
	</analytic>
	<monogr>
		<title level="j">SSRN Electronic Journal</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Clinical Empathy as Emotional Labor in the Patient-Physician Relationship</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Larson</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.293.9.1100</idno>
		<ptr target="https://doi.org/10.1001/jama.293.9.1100" />
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">293</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">1100</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Large Language Models Produce Responses Perceived to be Empathic</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ong</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2403.18148" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Understanding artificial intelligence ethics and safety</title>
		<author>
			<persName><forename type="first">D</forename><surname>Leslie</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3240529</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3240529" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A real-time environmental translator for emotion recognition in autism spectrum disorder</title>
		<author>
			<persName><forename type="first">L</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ambaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ben-Itzchak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Holdengreber</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-024-83229-2</idno>
		<ptr target="https://doi.org/10.1038/s41598-024-83229-2" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">31527</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Finding love in algorithms: deciphering the emotional contexts of close encounters with AI chatbots</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1093/jcmc/zmae015</idno>
		<ptr target="https://doi.org/10.1093/jcmc/zmae015" />
	</analytic>
	<monogr>
		<title level="j">Journal of Computer-Mediated Communication</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Artificial intelligence in psychological practice: Current and future applications and implications</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Luxton</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0034559</idno>
		<ptr target="https://doi.org/10.1037/a0034559" />
	</analytic>
	<monogr>
		<title level="j">Professional Psychology: Research and Practice</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="332" to="339" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">New paradigms for assessing emotional intelligence: Theory and data</title>
		<author>
			<persName><forename type="first">C</forename><surname>Maccann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Roberts</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0012746</idno>
		<ptr target="https://doi.org/10.1037/a0012746" />
	</analytic>
	<monogr>
		<title level="j">Emotion</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="540" to="551" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">My AI must have been broken&quot;: How AI Stands to Reshape Human Communication</title>
		<author>
			<persName><forename type="first">M</forename><surname>Naaman</surname></persName>
		</author>
		<idno type="DOI">10.1145/3523227.3555724</idno>
		<ptr target="https://doi.org/10.1145/3523227.3555724" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th ACM Conference on Recommender Systems</title>
		<meeting>the 16th ACM Conference on Recommender Systems</meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="1" to="1" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The negativity bias, revisited: Evidence from neuroscience measures and an individual differences approach</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Norris</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470919.2019.1696225</idno>
		<ptr target="https://doi.org/10.1080/17470919.2019.1696225" />
	</analytic>
	<monogr>
		<title level="j">Social Neuroscience</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="68" to="82" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">An Ethical Framework for Guiding the Development of Affectively-Aware Artificial Intelligence</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ong</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACII52823.2021.9597441</idno>
		<ptr target="https://doi.org/10.1109/ACII52823.2021.9597441" />
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Affective Computing and Intelligent Interaction (ACII)</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Is Discourse Role Important for Emotion Recognition in Conversation?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Luu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narendranath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="www.aaai.org" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Exploring Temperature Effects on Large Language Models Across Various Clinical Tasks</title>
		<author>
			<persName><forename type="first">D</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Timsina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Raut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Levin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Nadkarni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Glicksberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Klang</surname></persName>
		</author>
		<idno type="DOI">10.1101/2024.07.22.24310824</idno>
		<ptr target="https://doi.org/10.1101/2024.07.22.24310824" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">AI will never convey the essence of human empathy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-023-01675-w</idno>
		<ptr target="https://doi.org/10.1038/s41562-023-01675-w" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1808" to="1809" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Nature Research</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Effects of prefrontal cortex damage on emotion understanding: EEG and behavioural evidence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stiso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dewar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lubell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Meling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Solbakk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Endestad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Knight</surname></persName>
		</author>
		<idno type="DOI">10.1093/brain/awx031</idno>
		<ptr target="https://doi.org/10.1093/brain/awx031" />
	</analytic>
	<monogr>
		<title level="j">Brain</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1086" to="1099" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">LRH: AI-Mediated Communication</title>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">A</forename><surname>Purcell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-M</forename><surname>Nussberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Köbis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">;</forename><surname>Jakesch</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">R: A language and environment for statistical computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Seeing bad does good: Relational benefits of accuracy regarding partners&apos; negative moods</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rafaeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gadassi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Howland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Boussi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lazarus</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11031-017-9614-x</idno>
		<ptr target="https://doi.org/10.1007/s11031-017-9614-x" />
	</analytic>
	<monogr>
		<title level="j">Motivation and Emotion</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="353" to="369" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Practitioner Empathy and the Duration of the Common Cold</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Rakel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Hoeft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Chewning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Craig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Niu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The impact of artificial intelligence on the tasks of mental healthcare workers: A scoping review</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Rebelo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Verboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>De Graaf</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chbah.2023.100008</idno>
		<ptr target="https://doi.org/10.1016/j.chbah.2023.100008" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior: Artificial Humans</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">100008</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">GENERATIVE AI: EXCELLENT EMOTION RECOGNITION ACROSS ETHNICS 1 Generative Artificial Intelligence Demonstrates Excellent Emotion Recognition Abilities Across Ethnical Boundaries</title>
		<author>
			<persName><forename type="first">E</forename><surname>Refoua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Meinlschmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Elyoseph</surname></persName>
		</author>
		<ptr target="https://ssrn.com/abstract=4901183" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The Effect of Sampling Temperature on Problem Solving in Large Language Models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Renze</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2024.findings-emnlp.432</idno>
		<ptr target="https://doi.org/10.18653/v1/2024.findings-emnlp.432" />
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2024</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="7346" to="7356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">ChatGPT and Open-AI Models: A Preliminary Review</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">I</forename><surname>Roumeliotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Tselikas</surname></persName>
		</author>
		<idno type="DOI">10.3390/fi15060192</idno>
		<ptr target="https://doi.org/10.3390/fi15060192" />
	</analytic>
	<monogr>
		<title level="j">Future Internet</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">192</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Negativity Bias, Negativity Dominance, and Contagion</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rozin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Royzman</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15327957PSPR0504_2</idno>
		<ptr target="https://doi.org/10.1207/S15327957PSPR0504_2" />
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Review</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="296" to="320" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Considering the Role of Human Empathy in AI-Driven Therapy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Arnon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Huppert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.2196/56529</idno>
		<ptr target="https://doi.org/10.2196/56529" />
	</analytic>
	<monogr>
		<title level="j">JMIR Mental Health</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2024">2024</date>
			<publisher>JMIR Publications Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Comparing the value of perceived human versus AI-generated empathy</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zimmerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-025-02247-w</idno>
		<ptr target="https://doi.org/10.1038/s41562-025-02247-w" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Empathic Accuracy in Clinical Populations</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyt.2020.00457</idno>
		<ptr target="https://doi.org/10.3389/fpsyt.2020.00457" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychiatry</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Frontiers Media S.A</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Four investment areas for ethical AI: Transdisciplinary opportunities to close the publication-to-practice gap</title>
		<author>
			<persName><forename type="first">Schaich</forename><surname>Borg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno type="DOI">10.1177/20539517211040197</idno>
		<ptr target="https://doi.org/10.1177/20539517211040197" />
	</analytic>
	<monogr>
		<title level="j">Big Data &amp; Society</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Large language models are proficient in solving and creating emotional intelligence tests</title>
		<author>
			<persName><forename type="first">K</forename><surname>Schlegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mortillaro</surname></persName>
		</author>
		<idno type="DOI">10.1038/s44271-025-00258-x</idno>
		<ptr target="https://doi.org/10.1038/s44271-025-00258-x" />
	</analytic>
	<monogr>
		<title level="j">Communications Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">The nomological network of emotion knowledge and emotion understanding in adults: Evidence from two new performance-based tests</title>
		<author>
			<persName><forename type="first">K</forename><surname>Schlegel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Scherer</surname></persName>
		</author>
		<idno type="DOI">10.1080/02699931.2017.1414687</idno>
		<ptr target="https://www.tandfonline.com/doi/full/10.1080/02699931.2017.1414687" />
	</analytic>
	<monogr>
		<title level="j">Cognition and Emotion</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Toward a hierarchical model of social cognition: A neuroimaging meta-analysis and integrative review of empathy and theory of mind</title>
		<author>
			<persName><forename type="first">M</forename><surname>Schurz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Radua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Tholen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maliske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Margulies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Mars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sallet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kanske</surname></persName>
		</author>
		<idno type="DOI">10.1037/bul0000303</idno>
		<ptr target="https://doi.org/10.1037/bul0000303" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="293" to="327" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Empathic accuracy and relationship satisfaction: A meta-analytic review</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sened</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lavidor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lazarus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Bar-Kalifa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rafaeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Ickes</surname></persName>
		</author>
		<idno type="DOI">10.1037/fam0000320</idno>
		<ptr target="https://doi.org/10.1037/fam0000320" />
	</analytic>
	<monogr>
		<title level="j">Journal of Family Psychology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="742" to="752" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Empathetic Algorithms: The Role of AI in Understanding and Enhancing Human Emotional Intelligence</title>
		<author>
			<persName><forename type="first">Sesha</forename><surname>Bhargavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Velagaleti</forename></persName>
		</author>
		<idno type="DOI">10.52783/jes.1806</idno>
		<ptr target="https://doi.org/10.52783/jes.1806" />
	</analytic>
	<monogr>
		<title level="j">Journal of Electrical Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3s</biblScope>
			<biblScope unit="page" from="2051" to="2060" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Impairment in cognitive and affective empathy in patients with brain lesions: Anatomical and cognitive correlates</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">G</forename><surname>Shamay-Tsoory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tomer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Goldsher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Aharon-Peretz</surname></persName>
		</author>
		<idno type="DOI">10.1080/13803390490515531</idno>
		<ptr target="https://doi.org/10.1080/13803390490515531" />
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical and Experimental Neuropsychology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1113" to="1127" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Empathy Impairment in Individuals With Autism Spectrum Conditions From a Multidimensional Perspective: A Meta-Analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2019.01902</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2019.01902" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2019">2019</date>
			<publisher>Frontiers Media S</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Not all emotions are created equal: The negativity bias in social-emotional development</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vaish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Grossmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Woodward</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.134.3.383</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.134.3.383" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="383" to="403" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Interrelation between empathy and friendship development during (pre)adolescence and the moderating effect of developmental language disorder: A longitudinal study</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Van Den Bedem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Willems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Dockrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Van Alphen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rieffe</surname></persName>
		</author>
		<idno type="DOI">10.1111/sode.12353</idno>
		<ptr target="https://doi.org/10.1111/sode.12353" />
	</analytic>
	<monogr>
		<title level="j">Social Development</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="599" to="619" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">On the Uses of Large Language Models to Design End-to-End Learning Semantic Communication</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1109/WCNC57260.2024.10570717</idno>
		<ptr target="https://doi.org/10.1109/WCNC57260.2024.10570717" />
	</analytic>
	<monogr>
		<title level="m">IEEE Wireless Communications and Networking Conference (WCNC)</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Weber</surname></persName>
		</author>
		<idno type="DOI">10.21125/inted.2020.1262</idno>
		<idno>IN EDUCATION. 4539-4544</idno>
		<ptr target="https://doi.org/10.21125/inted.2020.1262" />
	</analytic>
	<monogr>
		<title level="j">ETHICS CONCERNS IN ARTIFICIAL INTELLIGENCE USE</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Empathy-Building Interventions</title>
		<author>
			<persName><forename type="first">E</forename><surname>Weisz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zaki</surname></persName>
		</author>
		<idno type="DOI">10.1093/oxfordhb/9780190464684.013</idno>
		<ptr target="https://doi.org/10.1093/oxfordhb/9780190464684.013" />
		<editor>E. M. Seppälä, E. Simon-Thomas, S. L. Brown, M. C. Worline, C. D. Cameron, &amp; J. R. Doty</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>Oxford University Press</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Rethinking Communication in the Era of Artificial Intelligence: An HCR Special Issue</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="DOI">10.1177/27523543231188791</idno>
		<ptr target="https://doi.org/10.1177/27523543231188791" />
	</analytic>
	<monogr>
		<title level="j">Emerging Media</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="45" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The Impact of Temperature on Extracting Information From Clinical Trial Publications Using Large Language Models</title>
		<author>
			<persName><forename type="first">P</forename><surname>Windisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dennstädt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koechli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schröder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Aebersold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Förster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Zwahlen</surname></persName>
		</author>
		<idno type="DOI">10.7759/cureus.75748</idno>
		<ptr target="https://doi.org/10.7759/cureus.75748" />
	</analytic>
	<monogr>
		<title level="j">Cureus</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Yamil</forename><surname>Velez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024. 9000</date>
		</imprint>
	</monogr>
	<note>claudeR (version 0.0.0</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">AI can help people feel heard, but an AI label diminishes this impact</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Wakslak</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2319112121</idno>
		<ptr target="https://doi.org/10.1073/pnas.2319112121" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences of the United States of America</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">14</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Exploring Theory of Mind in Large Language Models through Multimodal Negotiation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yongsatianchot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Thejll-Madsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Marsella</surname></persName>
		</author>
		<idno type="DOI">10.1145/3652988.3673960</idno>
		<ptr target="https://doi.org/10.1145/3652988.3673960" />
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">The neuroscience of empathy: Progress, pitfalls and promise</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ochsner</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.3085</idno>
		<ptr target="https://doi.org/10.1038/nn.3085" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="675" to="680" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Cutting-edge communication and learning assistive technologies for disabled children: An artificial intelligence perspective</title>
		<author>
			<persName><forename type="first">K</forename><surname>Zdravkova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Krasniqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dalipi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ferati</surname></persName>
		</author>
		<idno type="DOI">10.3389/frai.2022.970430</idno>
		<ptr target="https://doi.org/10.3389/frai.2022.970430" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
