<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">INTERACTION PHONOLOGY -RHYTHMIC CO-ORDINATION AS SCAFFOLD FOR COMMUNICATIVE ALIGNMENT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Petra</forename><surname>Wagner</surname></persName>
							<email>petra.wagner@uni-bielefeld.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Bielefeld University</orgName>
								<address>
									<settlement>Bielefeld</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">INTERACTION PHONOLOGY -RHYTHMIC CO-ORDINATION AS SCAFFOLD FOR COMMUNICATIVE ALIGNMENT</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E70D70BA7638F403C049F5CDA4F2CEC5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Interaction Phonology <ref type="bibr" target="#b79">(Wagner et al., 2013)</ref> postulates a process of rhythmic co-ordination based on entrainment processes which provide the temporal scaffold for higher order adaptation among interlocutors in critical situations, and hence, improves communication. 10 years after the publication of our framework, the time is more than ripe for its first evaluation and a thorough re-assessment. To achieve this, I will first give an overview of the general assumptions and motivations underlying Interaction Phonology, and then describe its mechanism as a logistic, attention-guiding component in a model of speech processing in interaction. I will then derive a set of model predictions, and evaluate them based on a thorough review of more recent empirical studies. In a last step, I will slightly modify our original model of Interaction Phonology (cf. Figure <ref type="figure">1</ref>, for an overview of the original model; cf. Figure <ref type="figure" target="#fig_0">2</ref>, for the adapted version), and list desiderata for its further testing in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A SKETCH OF INTERACTION PHONOLOGY</head><p>When two or more people communicate, they agree on a shared language system, with the ultimate goal to enable a common understanding with the help of an interactionally grounded, shared symbolic representation. However, assumptions about the shared symbol inventory may differ. For instance, whether you refer to certain vegetables as 'potatoes', 'spuds', 'solanum tuberosum', or 'root vegetables', may depend on your individual assessment of the situation, individual preference, spoken variety or linguistic context. It is likely that speakers will therefore negotiate the conditions of usage of a particular term, to clarify reference, or to signal mutual cooperativeness and perspective taking in a process called grounding (Clarke and <ref type="bibr" target="#b13">Brennan, 1991)</ref>. During this process, it is not sufficient to agree on a shared inventory of symbols and grammatical constraints (e.g., "English"), because the way that abstract symbols are realized in the speech signal may differ, due to different speaking styles, varieties, registers, or external factors such as cognitive distraction or various types of 'noise'. For this reason, sub-symbolic phonetic convergence has been claimed to be closely linked to the phenomenon of symbolic alignment, i.e., the tendency of interlocutors to agree on a shared or similar inventory <ref type="bibr" target="#b58">(Pickering and Garrod, 2004)</ref>.</p><p>So, agreeing on speaking the same 'language' has something in common with two people agreeing on dancing a waltz. While the dance move sequences that qualify as 'symbolic' figures of a waltz may be clear to both dancers, the velocity, amplitude and detail of the pertaining movement trajectories need to be precisely negotiated, helped by an external pacemaker in the form of the rhythm of the accompanying music. In speech-based communication, it is likewise not sufficient to agree on an abstract set of phonemes, lexemes, and syntactic structures. Rather, speakers need to agree on a finegrained execution of the shared movement patterns within their individual motor systems, to achieve pronunciations that are mutually understood, e.g., similar to the relative timing of articulators as expressed within Articulatory Phonology <ref type="bibr" target="#b11">(Browman &amp; Goldstein, 1992)</ref>.</p><p>So far, researchers have accumulated plenty of evidence for sub-symbolic co-ordination processes taking place between interlocutors: Speakers align their pronunciation patterns, speech tempo and prosody <ref type="bibr" target="#b8">(Bosch et al., 2005;</ref><ref type="bibr" target="#b26">Gessinger et al., 2021;</ref><ref type="bibr" target="#b41">Levitan and Hirschberg, 2011;</ref><ref type="bibr" target="#b53">Pardo, 2006</ref><ref type="bibr">, Lewandowski, 2011, inter alia)</ref>, and occasionally even their conversational laughter <ref type="bibr" target="#b44">(Ludusan and Wagner, 2022)</ref>, but also on higher-order levels of linguistic organization such as lexical choice, syntactic structures, or referential gestures <ref type="bibr">(Brennan and Clarke, 1996;</ref><ref type="bibr">Bergmann and Kopp, 2012, inter alia)</ref>. However, most studies find a lot of individual variation both in rhythmic-prosodic entrainment and higher-level linguistic alignment. Still, a key assumption of mechanistic accounts of interpersonal alignment <ref type="bibr" target="#b58">(Pickering and Garrod, 2004;</ref><ref type="bibr" target="#b59">Pickering and Garrod, 2007)</ref> is that sub-symbolic, rhythmicprosodic entrainment fosters symbolic alignment and hence, comprehension, on higher levels of grammatic organization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FIGURE 1. AN OVERVIEW OF THE PROCESSES AND STRUCTURES INVOLVED IN INTERACTION PHONOLOGY</head><p>The diagram depicts the processes in a listener, who entrains to the rhythmic patterns of speech, based on the expectations inherent in their language competence. The level of rhythmic prosodic entrainment can be strengthened in difficult communicative situations. That way, the listeners' attention is guided to higher order linguistic aspects connected to the rhythmic structures thus enhanced. This attentional process may alter the way that rhythmic-prosodic structures are connected to higher order linguistic patterns, but also intensify the level of entrainment with an interlocutor. Taken together, these processes are expected to aid mutual understanding, particularly in 'difficult' situations. The model relies on a set of modules, some of which are part of the speaker's grammar. These encompass (1) an entrainment module, (2) an auditory analysis guided by it, which is also linked to (3) motor patterns, which automatically lead to convergence in speech production as an automatic bi-product of entrainment, a set of ( <ref type="formula">4</ref>) linguistic structures and expectations as part of a speaker's grammar, which are linked to the levels of entrainment via their corresponding levels of prosodic organization, and (5) a monitoring of communication relevance, which estimates the need for entrainment (informed by the auditory and linguistic analysis), and adjusts the level of entrainment by modulating the coupling strength.</p><p>To this day, speech processing architectures lack a unified account of whether and how any interaction between sub-symbolic and symbolic adaptation is actually achieved. In <ref type="bibr" target="#b79">Wagner et al. (2013)</ref>, we therefore argued for Interaction Phonology as a logistic, attention-guiding component that enables interlocutors to co-ordinate their articulatory movements on a low signal-level by a process of temporal entrainment. That way, listeners may guide their attention to crucial aspects of phonetic detail <ref type="bibr" target="#b27">(Ghitza and Greenberg, 2009;</ref><ref type="bibr" target="#b28">Ghitza, 2012;</ref><ref type="bibr">Giraud and Poeppel, 2012, Chapters 22 and 23, this volume)</ref> that will permit an easier access to higher-level linguistic information. As a consequence, symbolic alignment should be fostered by temporal co-ordination in an automatic, bottom-up fashion. We use the term entrainment in a narrow sense <ref type="bibr" target="#b51">(Obleser and Kayser, 2019)</ref>, where it describes a dynamic process of physically coupled oscillatory systems, which adapt their cycles both in period and phase, thereby ultimately achieving a fixed phase relationship. Humans are capable of interpersonal entrainment without an external, isochronous pacemaker, e.g., when spontaneously synchronizing their clapping behavior in enthusiastic applause by period doubling <ref type="bibr" target="#b50">(Néda et al., 2000)</ref>, or when speaking in synchrony <ref type="bibr" target="#b16">(Cummins, 2009)</ref>. Strikingly, humans have shown to synchronize their brain activities, strengthened by shared engagement and joint activity <ref type="bibr" target="#b18">(Dikker et al., 2021)</ref>.</p><p>In Interaction Phonology, the rhythmic properties of a language play a crucial role in this entrainment process. It has been noted that speech lacks the isochrony or regularity necessary for entrainment <ref type="bibr" target="#b17">(Cummins, 2012)</ref>. However, it may occasionally show fixed phase relationships or a high degree of regularity, at least in highly formalized speaking styles such as poetry <ref type="bibr">(Wagner, 2012)</ref>, which may lend itself to rhythmic entrainment, even though we do not yet understand the exact mechanism behind this. While absolute co-ordination cannot be meaningfully expected between interlocutors at all times, there is some evidence in favor of entrainment: Across several languages, overlapping speech shows a preference for speakers being in phase with the interlocutor's syllabic speech stream <ref type="bibr" target="#b84">(Włodarczak et al. 2012)</ref>. In line with entrainment models of attention <ref type="bibr" target="#b37">(Lakatos et al., 2008;</ref><ref type="bibr" target="#b39">Large and Jones, 1999)</ref>, Interaction Phonology postulates that this process helps listeners gain access to language-specific phonological and higher-level properties of the utterance spoken.</p><p>Furthermore, we argued that rhythmic entrainment is a necessary prerequisite for the automaticity and swiftness of representational alignment in human interaction. While not excluding the possibility of a reductionist account of the phenomena described, we do not think it necessary for now to subscribe to this idea. Still, we argued for an inter-speaker co-ordination mechanism as being fundamental not only for speech perception, but for communicative interaction, i.e., the permanent active attuning to one another. Interaction Phonology can be preliminarily defined as taking care of the co-ordinative interactive processes that are strongly built on rhythmic-phonological structures.</p><p>Interaction Phonology furthermore postulates that there are universal and language-specific structures, on which co-ordination takes place. In particular, it predicts that the rhythmic-prosodic organization of a language constrains the levels of temporal co-ordination between interlocutors. For a lack of better knowledge, these are assumed to be identical to the language-specific levels of prosodic organization (syllables, feet, prosodic phrases) and their internal metrical organization <ref type="bibr" target="#b34">(Jun, 2005)</ref>. In other words, according to Interaction Phonology, the temporal co-ordination between interlocutors who speak varieties with a similar rhythmic-prosodic organization should be comparatively easy. However, Interaction Phonology also postulates that the mechanisms of temporal co-ordination are to some degree universal, based on syllabic structures that are grouped into larger units such as phrases or similar. Even though their regularity, function and organization within the prosodic hierarchy may differ across languages, there is some space for rhythmic co-ordination even when interlocutors cannot rely on a large set of common temporal mechanisms that may serve as anchors to higher-level linguistic organization. An example would be an L2 listener's strategic reliance on prosodic universals as well as language-specific prosodic cues as indicators of lexical stress, which often is a useful approach to segment a speech stream into words <ref type="bibr" target="#b21">(Endress &amp; Hauser, 2010;</ref><ref type="bibr" target="#b76">Tyler &amp; Cutler, 2009;</ref><ref type="bibr" target="#b52">Ordin &amp; Nespor, 2013)</ref>. The idea of rhythmic entrainment as a universal co-ordinative process underlying linguistic organization has received further support by developmental studies that described movement synchronization between neonates and their caregivers <ref type="bibr" target="#b15">(Condon, 1974;</ref><ref type="bibr" target="#b33">Jaffe et al., 2001)</ref>, where a baby's acquisition may be helped by anchoring into the universal prosodic properties of speech, to pave the way for higher-order symbolic alignment <ref type="bibr">(Chapters 34,</ref><ref type="bibr">35,</ref><ref type="bibr">36,</ref><ref type="bibr">38,</ref><ref type="bibr">40,</ref><ref type="bibr">this volume)</ref>. In fact, neonates are born with an ability to use prosodic strategies independently of segmental properties to identify word boundaries in their early language acquisition process <ref type="bibr" target="#b23">(Fló et al., 2019</ref>). An early alignment to the rhythmic prosodic detail of a caregiver's movements may therefore be a generally useful strategy in language acquisition. However, as prosodic and phonetic alignment has shown to be to some degree voluntary, situation specific, and is less strong in populations with Autism Spectrum Disorder <ref type="bibr" target="#b70">(Schweitzer and Lewandowski, 2014;</ref><ref type="bibr" target="#b71">Schweitzer et al., 2017;</ref><ref type="bibr" target="#b85">Wynn et al., 2018)</ref>, Interaction Phonology allows for the modulation of underlying entrainment processes. That is, if conversational needs for mutual understanding and grounding are high, it predicts that entrainment can be willingly strengthened, thereby actively supporting mutual comprehension and conversational grounding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">THE MECHANISM OF INTERACTION PHONOLOGY</head><p>Interaction Phonology postulates that the incoming speech signal is subject to a process of rhythmicprosodic analysis that</p><p>• guides the listener's attention to the fine phonetic detail of the speech signal that may be of particular relevance for a given language, which coincide with crucial boundaries of higherlevel linguistic organization, and therefore facilitate their prompt identification. For now, we believe that the levels of entrainment are identical to the levels of organization in the prosodic hierarchies of the different languages. It is possible, that this language-specific co-ordination does not constitute an independent level of a language's grammar, but rather is a by-product of its morphosyntactic or phonological organization.</p><p>• is driven by a process of rhythmic entrainment, modulated according to communicative needs such as overall the level of 'noise', and informed by linguistic analyses of the ongoing interaction. Apart from objectively present external noise, this may also relate to the overall level of distraction, or the relevance of successful communication.</p><p>• is adaptive with respect to its level of entrainment, or coupling strength; these adaptations are strongly guided by the rhythmic-prosodic patterns of the language chosen to communicate, but may also be subject to long-term entrainment between interlocutors, if these (initially) speak different languages or varieties. • leads to an adaptation in speech production with respect to tempo and rhythmic modulation via perception-production coupling, and hence, an improved attention to detail on the listener's side and representational alignment in (adapted) speech production.</p><p>These analyses are organized within various model components, which are described in detail in Table <ref type="table" target="#tab_0">1</ref>, and are indicated by their respective numbers in Figure <ref type="figure">1</ref>. Model component Description 1 Entrainment module, guiding listener's attention to points in the incoming speech signal which are crucially linked to higher-order linguistic organization.</p><p>2 Entrained, or "guided" auditory analysis of incoming speech input, which interfaces with subsequent linguistic analysis of input 3 Motor patterns mapped to incoming acoustic analysis, automatically leading to adapted speech output 4 Set of linguistic structures and expectations as part of a speaker's grammar, which are linked to the levels of entrainment via their corresponding levels of prosodic organization, and which correspond to attractors in entrainment 5 A communication relevance monitor, which assesses the situation and ongoing communication (and with this, the need for entrainment), which may adapt the strength of necessary entrainment depending on present noise and the necessity of communicative success So far, Interaction Phonology has not yet a spelled out connection or interface with existing models of speech production and perception. However, most of these models miss a link between symbolic and sub-symbolic processing, and Interaction Phonology may help improving our understanding of this interface. Given its focus on communication, Interaction Phonology can only be meaningfully integrated with architectures that account for both perception and production.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">PREDICTIONS OF INTERACTION PHONOLOGY</head><p>Here, we spell out a set of testable predictions by Interaction Phonology. The predictions are chosen as they all test crucial aspects of the model. Interaction Phonology makes predictions beyond this list, especially with regards to prosodic universals and language-specific constraints. Also given its current lack of formality and underspecification, it should be clear that this list is currently incomplete and lacks formal rigor.</p><p>Prediction 1: Speech rate adaptation should improve speech perception in similar communication settings.</p><p>Prediction 2: Entrainment should be visible across the levels of the prosodic hierarchy, in a languagespecific fashion.</p><p>Prediction 3: The level of entrainment should be situation-specific, and vary within individuals across different situations.</p><p>Prediction 4: If rhythmic entrainment occurs, it should automatically result in symbolic alignment.</p><p>Prediction 1 falls out of the model, as the model postulates a positive effect of entrainment on speech perception by its guiding the listener's attention to relevant phonetic detail using the entrainment module (cf. Figure <ref type="figure">1</ref>: component 1). However, it needs to be taken into account that the model also predicts entrainment for those communicative situations in which perception may be impeded by various types of noise. Therefore, it is crucial for testing Prediction 1 that speech perception and entrainment are measured across similar settings, without added cognitive load or external noise. Speech rate is chosen mostly as a test (in favor of other potential features of rhythmic-prosodic entrainment) as there exist a considerable amount of empirical research on it. Prediction 2 falls out of the assumed link between levels of entrainment and language-specific structures (cf., Figure <ref type="figure">1</ref>: component 4). That is, Interaction Phonology expects a certain language-dependence with respect to the levels of entrainment that mirror the prosodic organization of the involved languages or varieties.</p><p>Going back to speech rate entrainment, depending on the rhythmic-prosodic structure of the language to be entrained to, speech rate adaptation may concentrate on morae, syllables, prosodic feet, prosodic words, or even phrasal structures. Prediction 3 is derived from the Interaction Phonology's assumption that entrainment is to some degree deliberate, and strategically chosen by interlocutors rather than a fully automatized process that will always be enabled (Figure <ref type="figure">1</ref>: component 5). In other words, Interaction Phonology predicts the level of entrainment to a certain speech rate to be stronger in challenging communicative situations. Prediction 4 falls out of the assumed automatic link between sub-symbolic co-ordination and symbolic alignment (cf., Figure <ref type="figure">1</ref>: connection between components 1 and 2). Here, the control mechanism that enables entrainment, automatically takes into account higher-level similarities. If these two fail to be coupled, this would be a challenge for our control mechanism, and would point to a strongly strategic symbolic alignment which is not necessarily coupled to sub-symbolic, motor-level processes of articulation. In other words, an entrainment to speech rate ought to be also visible in the usage of more similar words, or syntagmatic structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">EVALUATING INTERACTION PHONOLOGY</head><p>Next, it will be determined whether more recent empirical research is in line with the assumptions and predictions of Interaction Phonology, or falsifies (aspects of) it. Where no research results lend themselves to model evaluation, suggestions for future studies will be made, in order to better understand Interaction Phonology's flaws, limitations as well as strengths. The analysis will concentrate on the 4 main predictions of Interaction Phonology that has been spelled out above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">PREDICTION 1: SPEECH RATE ADAPTATION HELPS SPEECH PERCEPTION</head><p>In incremental, online speech perception, listeners need to simultaneously pay attention to several levels of linguistic organization. The ability to do this may be enhanced by the different time scales underlying the spell-out of these levels (phones, syllables, words, phrases), which can be entrained to cortical rhythms working on similar time scales <ref type="bibr" target="#b27">(Ghitza and Greenberg, 2009;</ref><ref type="bibr" target="#b28">Ghitza, 2012;</ref><ref type="bibr">Chapter 2, this volume)</ref>. Much work around rhythmic entrainment during perception has concentrated on attentional selection, which ought to focus on crucial parts of the speech signal, e.g., the initializations of syllables. There is converging evidence that some form of temporal entrainment indeed helps selectively attending to the incoming speech stream of a particular speaker among several concurrent speakers <ref type="bibr" target="#b51">(Obleser and Kayser, 2019)</ref>. Also, neural entrainment processes have shown to (somewhat) aid speech perception and sentence comprehension <ref type="bibr" target="#b38">(Lamekina and Meyer, 2022;</ref><ref type="bibr">Riecke et al., 2019;</ref><ref type="bibr" target="#b83">Wilsch et al., 2018;</ref><ref type="bibr" target="#b87">Zoefel et al., 2018)</ref>.</p><p>However, as speech tempos change dynamically in ongoing speech within the same speaker <ref type="bibr" target="#b62">(Quené, 2008)</ref>, and speech is not isochronous like music <ref type="bibr" target="#b17">(Cummins, 2012)</ref>, for entrainment to be a successful tool for enhancing speech perception, listeners need to be able to swiftly adapt to these speech tempo changes. Speech rate convergence in production is a phenomenon largely supported by empirical research, appearing in both in monological priming tasks <ref type="bibr" target="#b35">(Jungers and Hupp, 2009)</ref> and conversations <ref type="bibr" target="#b14">(Cohen-Priva et al., 2017;</ref><ref type="bibr" target="#b72">Schultz et al., 2016;</ref><ref type="bibr" target="#b25">Fuscone et al., 2021)</ref>. For perception, <ref type="bibr" target="#b19">Dilley and Pitt (2010)</ref> presented first evidence for listeners' indeed quickly adapting to the speech tempo of an incoming speech signal, leading them to perceptually insert additional syllables/words into a speech stream that was locally produced slowly, e.g., "leisure time" was perceived as "leisure or time". This effect, which they term LRE (lexical rate effect) is restricted to speech processing and does not generalize to tone perception <ref type="bibr" target="#b60">(Pitt et al., 2016)</ref>, but can be built up over longer stretches of time, thereby generating the expectations that drive selective attention <ref type="bibr">(Baese-Berk et al., 2014, chapter 23, this volume)</ref>. <ref type="bibr" target="#b9">Bosker (2017)</ref> showed in a series of experiments that it is the (isochronous) speech rate prior to a target that creates an anticipatory effect on perception. He interprets this as evidence for an underlying neural entrainment mechanism at play, which is not tied to the speech mode. What is not yet resolved is the question of whether entrainment is restricted to speech processing, or is a general monitoring and adaptation device. The studies reported here that have examined an impact of rhythmic entrainment on speech perception have done so in highly controlled laboratory settings. Thus, it can at least be said that in such contexts, an adaptation to speech tempo can be traced and appears to have a positive impact on speech perception. However, it still remains unclear how entrainment can actually be achieved given the intrinsic non-isochrony present in speech signals. Here, Bosker (2017), <ref type="bibr" target="#b51">Obleser and Kayser (2019)</ref> and <ref type="bibr" target="#b47">Meyer et al. (2020)</ref> claim that the -at best -pseudorhythmic acoustic properties of speech are sufficient to induce an entrainment mechanism which may lend itself to higher-order synchronicities in more abstract linguistic domains. For the moment, one can only speculate that highly adaptive (neural) oscillators with a fast reset should also be able to achieve a rapid entrainment to dynamically changing rhythms <ref type="bibr" target="#b31">(Inden et al., 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">PREDICTION 2: ENTRAINMENT SHOULD BE VISIBLE ACROSS LANGUAGE-SPECIFIC LEVELS OF THE PROSODIC HIERARCHY.</head><p>Building on the conspicuous similarities between the multi-timescales of cortical and speech rhythms <ref type="bibr" target="#b27">(Ghitza and Greenberg, 2009;</ref><ref type="bibr" target="#b28">Ghitza, 2012)</ref>, Interaction Phonology postulates that rhythmic entrainment should pertain to various time scales, and these time scales should reflect the rhythmic structure of the language(s) spoken. In particular, this should lead to language-specific rhythmic entrainment, as languages, language varieties or speaking styles differ with respect to their prosodic organization, and this should be reflected in the long-term abilities of entrainment. For example, languages may differ vastly with respect to the length and complexity of syllable-sized units <ref type="bibr" target="#b86">(Zec, 2007)</ref>. Interaction Phonology now predicts that speakers of languages with a higher degree of phonotactic complexity and variability are either more flexible in entraining to syllable streams, or maybe make less use of syllable-level entrainment, as it is more often doomed to fail. Also, languages differ with respect to their higher order prosodic organization, and may use different patterns of metrical organization <ref type="bibr" target="#b34">(Jun, 2005)</ref>. Such differences should also show in language-selective rhythmic entrainment.</p><p>Currently, empirical evidence indeed points towards rhythmic entrainment being active on different time scales: the LRE (see above) has been shown to also apply for syllable-level speaking rate as well as rhythm, indicating a certain degree of higher order entrainment on the foot or word level, where listeners modulate their perception based on whether they expect a stressed or unstressed syllable <ref type="bibr" target="#b49">(Morrill et al., 2014)</ref>. Furthermore, the effect has shown to be additive, and listeners are more attentive when several rhythmic boundaries co-occur. However, despite considerable work on entrainment to pulse and higher-order meter in music (cf. the overview in <ref type="bibr" target="#b22">Fitch, 2013)</ref>, and despite a long tradition in research to hypothesize about similar processing mechanisms being at play in music and speech processing and organization (e.g., <ref type="bibr">Lehrdahl and Jackendoff, 1983;</ref><ref type="bibr" target="#b77">Wagner, 2008;</ref><ref type="bibr">chapters 9, 31-33, this volume)</ref>, very little is actually known about language specific entrainment, and most evidence remains speculative. Some similarities between music and speech perception can be drawn from finger tapping studies, a sensorimotor synchronization paradigm that is well-established in music rhythm perception research <ref type="bibr" target="#b67">(Repp, 2005;</ref><ref type="bibr" target="#b68">Repp and Su, 2013)</ref>. Finger tapping to music rhythms has been shown to help improve music time perception, similar to the perceptual benefits of entraining to speech rhythm <ref type="bibr" target="#b45">(Manning and Schutz, 2013)</ref>. In speech perception tasks, finger tapping duration and intensity has likewise been shown to be sensitive to rhythmic structure linked to linguistic organization such as syllable onsets, lexical stress, sentence stress or accent <ref type="bibr" target="#b55">(Parrell et al., 2014</ref><ref type="bibr" target="#b64">, Rathcke et al., 2021)</ref>. Another paradigm called speech cycling investigated rhythmic entrainment of repetitive short phrases to external high and low tones, and found cross-linguistic similarities in patterning speech to these external tones for Japanese and English, despite their different syllable structures <ref type="bibr" target="#b75">(Tajima and Port, 2003)</ref>. While these studies point to a common sensorimotor entrainment mechanism, it should be noted that tapping in real-time to an incoming speech signal is extremely difficult to do, and listening to or reproducing repetitive single phrases resembles music rather than speech processing <ref type="bibr" target="#b2">(Anbari et al., 2013)</ref>. An alternative methodological paradigm, in which listeners tapped a perceived rhythmic structure directly after perceiving an utterance, revealed an ability of listeners to encode language-specific rhythmic-prosodic features in tapping patterns as well, and showed a stronger reliance on acoustic-prosodic features as compared to non-motor prosody perception tasks <ref type="bibr" target="#b80">(Wagner et al., 2019</ref><ref type="bibr">, Bruggemann et al., 2022)</ref>. However, it is yet unclear whether the results of tapping are indicative of sensorimotor entrainment proper, or simply fall out of a general analysis of linguistic structure, integrating linguistic, acoustic-phonetic and sensorimotor cues. Similar problems exist with studies on L2-acquisition which show that rhythmic priming has a beneficial effect on learning the target prosody in an L2, as they either rely on multimodal reproduction tasks, or use musical (rather than speech) rhythms as priming materials (e.g., <ref type="bibr" target="#b5">Baills and</ref><ref type="bibr">Prieto, 2021, Wang et al., 2016)</ref> -neither is conclusive as to whether it really is rhythmic entrainment to speech that leads to the positive effects on mastering an L2 prosody. Overall, we have some empirical evidence pointing into the direction that rhythmic entrainment has long-term consequences, leading to long-term rhythmic expectations which result in an improved rhythmic entrainment performance in an L1 as compared to an L2, and which may result in better abilities of learning an L2 prosody in speakers with a high degree in rhythmic training. However, clear-cut evidence for this prediction of Interaction Phonology is still lacking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">PREDICTION 3: THE LEVEL OF ENTRAINMENT SHOULD BE SITUATION-SPECIFIC, AND VARY WITHIN INDIVIDUALS ACROSS DIFFERENT SITUATIONS</head><p>Interaction Phonology postulates that interlocutors make a deliberate (though not necessarily conscious) choice in whether they employ prosodic entrainment, or not, and it is expected that entrainment should be selectively activated in challenging communicative situations, in which the benefits of attention can be exploited best. As the vast majority of studies have been performed in laboratory conditions, often relying on short, highly controlled utterances that show little resemblance with everyday interactions, this has not been investigated in ecologically valid conditions. However, some first approaches do exist:</p><p>In a study that looked at rate-dependent adaptive listening in quiet and noisy conditions, <ref type="bibr">Reinisch and Busker (2022)</ref> could show that listeners dynamically adapt at a low-level to challenging contexts, and can identify noisy target items more easily when these are preceded by coherently noisy signals. There is also increasing evidence that the selective attention to an individual speaker in a multi-party listening condition decreases entrainment to the ignored voices (e.g., <ref type="bibr" target="#b20">Ding and Simon, 2013;</ref><ref type="bibr" target="#b24">Fuglsang et al., 2017)</ref>. This points towards the level of entrainment being to some degree adjustable according to situation-specific needs.</p><p>Several studies investigated the impact of acoustic manipulation (vocoded speech) on the level of entrainment, hypothesizing that vocoding would be detrimental to speech quality and therefore trigger higher entrainment. <ref type="bibr">Peele et al. (2012</ref><ref type="bibr">Peele et al. ( , 2013) )</ref> find evidence for neural entrainment to speech being higher when it is vocoded (more difficult to comprehend). While this may point into a direction of selective entrainment in the case of speech that is difficult to process, <ref type="bibr" target="#b6">Baltzell et al. (2017)</ref> showed that vocoded speech preceded by natural speech primes also aided the comprehension of vocoded speech. This is in line with findings on synchronous speech, where synchronization is not influenced by intelligibility, but by rhythmic cues <ref type="bibr" target="#b16">(Cummins, 2009)</ref>.</p><p>Rather than manipulating the acoustics of their stimuli, <ref type="bibr" target="#b74">Song and Iverson (2018)</ref> and <ref type="bibr" target="#b32">Iverson et al. (2018)</ref> tested the influence of overall intelligibility on neural entrainment by comparing the performance of L1 and L2 listeners when hearing L1 or L2 speech. Their results point to patterns of stronger neural entrainment when listening to the less familiar (L1 for L2 listeners, L2 for L1 listeners), and hence, more challenging variety. However, the idea that any challenges to the ongoing communication success lead to an automatic increase in entrainment appears to be overly simplistic: a study by <ref type="bibr" target="#b30">Hjortkjaer et al. (2020)</ref> indicates that a higher working memory load actively decreases the level of neural entrainment, and also <ref type="bibr" target="#b1">Abel and Babel (2017)</ref> show lower phonetic convergence under high cognitive load. Interestingly, this effect was present both for a more difficult task as well as an increase in acoustic noise that had been tested for not being detrimental to speech intelligibility. These results indicate that entrainment needs cognitive resources by itself, possibly to uphold selective attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">PREDICTION 4: IF ENTRAINMENT OCCURS, IT SHOULD AUTOMATICALLY RESULT IN SYMBOLIC ALIGNMENT BETWEEN INTERLOCUTORS</head><p>By now, there is a long research tradition that has demonstrated adaptation between communication partners both on fine phonetic detail such as speech tempo, pause duration, intonation or segmental articulation as well as more abstract linguistic representations such as the lexicon, syntactic structures, or referential gestures (cf. 2). What is unclear is whether low-level co-ordination on fine phonetic details indeed quasi-automatically triggers an agreement on higher-order linguistic concepts, as predicted by Interaction Phonology, and in line with models of interpersonal adaptation that link production and perception <ref type="bibr" target="#b58">(Pickering and Garrod, 2004;</ref><ref type="bibr" target="#b86">2007)</ref>. However, clear-cut evidence for this idea appears to be difficult to come by, despite the undeniable benefit found for listening entrainment in speech perception (see above). <ref type="bibr">Krivokapic (2013)</ref> suggest that speech rate convergence between dialogue partners correlates with their alignment of variety-specific rhythmic patterns (Indian English and American English), indicating a certain automaticity in convergence across low-level and higherlevel rhythmic prosodic organization. Alternatively, this could be explained by falling out of interspeaker entrainment in speech rate, as duration indicates both speech rate as well as rhythmic organization. One of the few studies that found evidence for a communicative benefit (beyond intelligibility) of speech rate adaptation is <ref type="bibr" target="#b46">Manson et al. (2013)</ref>, who reported an increase in cooperation between interlocutors when they also aligned in speech rate. Similarly, Lubold and Pon-Barry ( <ref type="formula">2014</ref>) report an increase in perceived rapport. These results may point to a higher degree of conversational grounding in situations where rhythmic-prosodic entrainment is evident, and may indicate a mechanistic link between low-level speech rate adaptation to higher-order linguistic processing. However, other interpersonal factors such as mutual likeability were not affected by an increase in entrainment <ref type="bibr" target="#b46">(Manson et al., 2013)</ref>, which is further evidence that the underlying mechanism may be specialized to linguistic processing.</p><p>However, a clear-cut effect of entrainment on symbolic-linguistic alignment appears to be difficult to prove: Weise and Levitan (2017) fail to find evidence for a link between acoustic-prosodic and symbolic alignment, while <ref type="bibr" target="#b63">Rahimi et al. (2017)</ref> suggest that entrainment across different levels of linguistic organization can occur. Generally, most studies report a high degree of individual variation in entrainment, which seems to be at least to some degree driven by personal and interpersonal factors, e.g. mutual likability, perceived attractiveness, gender as well as the power dynamics between interlocutors <ref type="bibr" target="#b3">(Babel, 2012;</ref><ref type="bibr" target="#b54">Pardo, 2012;</ref><ref type="bibr" target="#b48">Michalsky and Schoormann, 2017;</ref><ref type="bibr" target="#b70">Schweitzer and Lewandowski, 2014;</ref><ref type="bibr" target="#b71">Schweitzer et al., 2017;</ref><ref type="bibr" target="#b65">Reichel et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION: AN ADAPTED SKETCH OF INTERACTION PHONOLOGY</head><p>For some key predictions of Interaction Phonology, empirical evidence is growing stronger. In particular, we see that rhythmic entrainment does take place in speech tempo adaptations, has a positive effect on intelligibility. While cross-linguistic studies on entrainment are very rare, there is evidence that it connects to the rhythmic-prosodic structure of individual languages, thereby probably also enhancing higher-level comprehension. Another key assumption of Interaction Phonology is that rhythmic-prosodic entrainment can be adjusted based on situative needs. Here, we indeed saw that listeners do adapt their entrainment to individual voices or increase entrainment in challenging listening situations. However, entrainment is not increased independently of the type of communicative challenge. Contrary to our prediction, working memory load seems to decrease entrainment, indicating that entrainment comes with a certain cognitive load of its own. Here, more research is necessary to better understand which type of situation triggers or decreases its effectiveness. Despite the positive effect entrainment has on intelligibility, when explicitly linking it to higher-level linguistic organization, there appears to be no automaticity in rhythmic-prosodic entrainment and higher-order symbolic alignment between interlocutors. At best, researchers find that this connection is not ruled out. In our account of Interaction Phonology, this connection is therefore removed for the time being, and the link between rhythmic prosodic entrainment and symbolic linguistic organization is limited it to grammatical aspects of sound structure (phonology).</p><p>From there, a connection to higher-order linguistic organization can made as part of listening comprehension, but the connection to further symbolic entrainment needs to be questioned. For now, the results leave a question mark as to the exact nature of the interface between sound-related and higher-order linguistic processing in Interaction Phonology. As to the auditory-motor mapping, which predicts automatic convergence of rhythmic-prosodic patterns in speech-based interaction, it is left as optional in the model, as most data shows high individual variation in speaker's level of converging prosodic patterns, even though it seems to be to some degree automatized for speech tempo. Here, further empirical work is needed to highlight the level of automaticity or deliberate control, and how it covaries with other speaker traits, their level of neurocognitive alignment, or situative factors.</p><p>Overall, it can be concluded that the model of Interaction Phonology can still be helpful to further inform psycholinguistic models of speech processing, to extend them to models of communicative interaction, and to improve and clarify the interface of symbolic and sub-symbolic processing in the models. Our adapted sketch of Interaction Phonology is illustrated in Figure <ref type="figure" target="#fig_0">2</ref>. or have been modified/extended in line with empirical findings. In particular, the language-specific structures and expectations for which we have evidence to guide rhythmic-prosodic entrainment and to be shaped by it currently are restricted to phonetic-phonological ones. It remains unclear, whether syntactic or lexical adaptations are connected with entrainment processes likewise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Summary</head><p>Interaction Phonology explains symbolic and sub-symbolic inter-speaker adaptations using the mechanism of rhythmic-prosodic entrainment. Many key assumptions (rhythmic entrainment as optional process that helps perception and is linked to grammar) are empirically supported. However, the original model was modified: auditory-motor mapping is optional, entrainment can also be actively decreased under high cognitive load, and the assumed automaticity between entrainment and symbolic alignment is questioned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implications</head><p>Interaction Phonology provides a testable theoretical framework for evaluating language-specific and language universal hypotheses related to rhythmic entrainment between interlocutors, and their relationship with higher-order alignment of abstract linguistic representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gains</head><p>Interaction Phonology provides a theoretical framework that provides the necessary scaffold for enabling an inter-speaker alignment of phonetic-phonological, and potentially also higher-order linguistic representations by a mechanism of rhythmic entrainment. Interaction Phonology extends existing speech processing models with an interface between symbolic and sub-symbolic processing, and integrating them into communication models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index terms</head><p>speech rhythm, entrainment, interaction, speech rate, intelligibility, synchronization, alignment</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 2 .</head><label>2</label><figDesc>FIGURE 2. AN ADAPTED SKETCH OF INTERACTION PHONOLOGYThose parts of Interaction Phonology that have received empirical support by are indicated by check marks. Other parts are either commented as optional (auditory-motor mapping and speech adaptation),</figDesc><graphic coords="11,71.49,298.21,453.60,417.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="2,71.49,354.54,453.60,391.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 . MAIN STRUCTURES AND PROCESSES OF INTERACTION PHONOLOGY.</head><label>1</label><figDesc></figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName><surname>References</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Cognitive load reduces perceived linguistic convergence between dyads</title>
		<author>
			<persName><forename type="first">J</forename><surname>Abel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Babel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Speech</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="479" to="502" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rhythmic constraints on read and rapped speech</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Anbari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Włodarczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th Rhythm Production and Perception Workshop</title>
		<meeting>the 14th Rhythm Production and Perception Workshop<address><addrLine>Birmingham</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Evidence for phonetic and social selectivity in spontaneous phonetic imitation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Babel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.wocn.2011.09.001</idno>
		<ptr target="https://doi.org/10.1016/j.wocn.2011.09.001" />
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="177" to="189" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Longterm temporal tracking of speech rate affects spoken-word recognition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Baese-Berk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Heffner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Dilley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Morrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mcauley</surname></persName>
		</author>
		<idno type="DOI">10.1177/095679761453370</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1546" to="1553" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Embodying rhythmic properties of a foreign language through handclapping helps children to better pronounce words</title>
		<author>
			<persName><forename type="first">F</forename><surname>Baills</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Prieto</surname></persName>
		</author>
		<idno type="DOI">10.1177/1362168820986716</idno>
	</analytic>
	<monogr>
		<title level="j">Language Teaching Research</title>
		<imprint>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page">0</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The effect of prior knowledge and intelligibility on the cortical entrainment response to speech</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Baltzell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Richards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3144" to="3151" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Gestural alignment in natural dialogue</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kopp</surname></persName>
		</author>
		<ptr target="https://escholarship.org/uc/cognitivesciencesociety/34/34" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On temporal aspects of turn taking in conversational dialogues</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Oostdijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Boves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="80" to="86" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Accounting for rate-dependent category boundary shifts in speech perception</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Bosker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="333" to="343" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Conceptual pacts and lexical choice in conversation</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.22.6.1482</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.22.6.1482" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1482" to="1493" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Articulatory phonology: An overview</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Browman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phonetica</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="155" to="180" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Beware of the individual: Evaluating prominence perception in spontaneous speech</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bruggeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schade</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Włodarczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wagner</surname></persName>
		</author>
		<idno type="DOI">10.21437/SpeechProsody.2022-55</idno>
	</analytic>
	<monogr>
		<title level="j">Speech Prosody</title>
		<imprint>
			<biblScope unit="volume">2022</biblScope>
			<biblScope unit="page" from="268" to="272" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Grounding in communication</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Brennan</surname></persName>
		</author>
		<idno type="DOI">10.1037/10096-006</idno>
	</analytic>
	<monogr>
		<title level="m">Perspectives on socially shared cognition</title>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Resnick</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Levine</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Teasley</surname></persName>
		</editor>
		<imprint>
			<publisher>American Psychological Association</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="127" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Converging to the baseline: Corpus evidence for convergence in speech rate to interlocutor&apos;s baseline</title>
		<author>
			<persName><forename type="first">U</forename><surname>Cohen Priva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Edelist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gleason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2989" to="2996" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Neonate movement is synchronized with adult speech: Interactional participation and language acquisition</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Condon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="99" to="101" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rhythm as entrainment: The case of synchronous speech</title>
		<author>
			<persName><forename type="first">F</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="28" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Oscillators and syllables: a cautionary note</title>
		<author>
			<persName><forename type="first">F</forename><surname>Cummins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">364</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Crowdsourcing neuroscience: inter-brain coupling during face-to-face interactions outside the laboratory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dikker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Michalareas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Oostrik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Serafimaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Kahraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Struiksma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poeppel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">227</biblScope>
			<biblScope unit="page">117436</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Altering context speech rate can cause words to appear or disappear</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Dilley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1664" to="1670" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Adaptive temporal encoding leads to a background-insensitive cortical representation of speech</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Simon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5728" to="5735" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Word segmentation with universal prosodic cues</title>
		<author>
			<persName><forename type="first">A</forename><surname>Endress</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="177" to="199" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Rhythmic cognition in humans and animals: distinguishing meter and pulse perception</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Fitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Systems Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">68</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Newborns are sensitive to multiple cues for word segmentation in continuous speech</title>
		<author>
			<persName><forename type="first">A</forename><surname>Fló</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brusini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Macagno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nespor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mehler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Ferry</surname></persName>
		</author>
		<idno type="DOI">10.1111/desc.12802</idno>
	</analytic>
	<monogr>
		<title level="j">Developmental Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">12802</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Noise-robust cortical tracking of attended speech in realworld acoustic scenes</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Fuglsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hjortkjaer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page" from="435" to="444" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Reproducibility in speech rate convergence experiments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fuscone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Favre</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Prevot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="817" to="832" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Phonetic accommodation to natural and synthetic voices: Behavior of groups and individuals in speech shadowing</title>
		<author>
			<persName><forename type="first">I</forename><surname>Gessinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Raveh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Möbius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="43" to="63" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the possible role of brain rhythms in speech perception: intelligibility of time-compressed speech with periodic and aperiodic insertions of silence</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ghitza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phonetica</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="113" to="126" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On the role of theta-driven syllabic parsing in decoding speech: intelligibility of speech with a manipulated modulation spectrum</title>
		<author>
			<persName><forename type="first">O</forename><surname>Ghitza</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2012.00238</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cortical oscillations and speech processing: emerging computational principles and operations</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Giraud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Poeppel</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.3063</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="511" to="517" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Cortical oscillations and entrainment in speech processing during working memory load</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hjortkjaer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Märcher-Rørsted</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Fuglsang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1279" to="1289" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Rapid entrainment to spontaneous speech: A comparison of oscillator models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Inden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Malisz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wachsmuth</surname></persName>
		</author>
		<ptr target="https://escholarship.org/uc/item/0c905908" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th Annual Conference of the Cognitive Science Society Austin</title>
		<meeting>the 34th Annual Conference of the Cognitive Science Society Austin</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cortical entrainment to speech under competing-talker conditions: Effects of cognitive load due to presentation rate and task difficulty</title>
		<author>
			<persName><forename type="first">P</forename><surname>Iverson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bradley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1921" to="1921" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Jaffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Beebe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Crown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Jasnow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rochat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Stern</surname></persName>
		</author>
		<title level="m">Rhythms of dialogue in infancy: Coordinated timing in development. Monographs of the society for research in child development</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">149</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Prosodic typology: The phonology of intonation and phrasing</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Jun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>OUP</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Speech priming: Evidence for rate persistence in unscripted speech</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jungers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hupp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Cognitive Processes</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="611" to="624" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rhythm and convergence between speakers of American and Indian English</title>
		<author>
			<persName><forename type="first">Jelena</forename><surname>Krivokapić</surname></persName>
		</author>
		<idno type="DOI">10.1515/lp-2013-0003</idno>
	</analytic>
	<monogr>
		<title level="j">Laboratory Phonology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="65" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Entrainment of neuronal oscillations as a mechanism of attentional selection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Lakatos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Karmos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Ulbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="page" from="110" to="113" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Entrainment to speech prosody influences subsequent sentence comprehension</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Lamekina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Meyer</surname></persName>
		</author>
		<idno type="DOI">10.1080/23273798.2022.2107689</idno>
	</analytic>
	<monogr>
		<title level="j">Language, Cognition and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="263" to="276" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The dynamics of attending: How people track time-varying events</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Large</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="159" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An overview of hierarchical structure in music</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lerdahl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jackendoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Music Perception: An Interdisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="229" to="252" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Measuring acoustic-prosodic entrainment with respect to multiple levels and dimensions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Levitan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hirschberg</surname></persName>
		</author>
		<idno type="DOI">10.21437/Interspeech.2011-771</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH 2011</title>
		<meeting>INTERSPEECH 2011</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="3081" to="3084" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Phonetic convergence, language talent, personality and attention</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lewandowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jilka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Communication</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Acoustic-prosodic entrainment and rapport in collaborative learning dialogues</title>
		<author>
			<persName><forename type="first">N</forename><surname>Lubold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pon-Barry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2014 ACM workshop on Multimodal Learning Analytics Workshop and Grand Challenge</title>
		<meeting>the 2014 ACM workshop on Multimodal Learning Analytics Workshop and Grand Challenge</meeting>
		<imprint>
			<date type="published" when="2014-11">2014, November</date>
			<biblScope unit="page" from="5" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Laughter entrainment in dyadic interactions: temporal distribution and form</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ludusan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="page" from="42" to="52" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Moving to the beat&quot; improves timing perception</title>
		<author>
			<persName><forename type="first">F</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schutz</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-013-0439-7</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin and Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1133" to="1139" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Convergence of speech rate in conversation predicts cooperation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Manson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Gervais</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Kline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolution and Human Behavior</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="419" to="426" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Synchronous, but not entrained: exogenous and endogenous cortical rhythms of speech and language processing</title>
		<author>
			<persName><forename type="first">L</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language, Cognition and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1089" to="1099" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Pitch Convergence as an Effect of Perceived Attractiveness and Likability</title>
		<author>
			<persName><forename type="first">J</forename><surname>Michalsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Schoormann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2253" to="2256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Distal rhythm influences whether or not listeners hear a word in continuous speech: Support for a perceptual grouping hypothesis</title>
		<author>
			<persName><forename type="first">T</forename><surname>Morrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dilley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pitt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2013.12.006</idno>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="69" to="74" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Physics of the rhythmic applause</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Néda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ravasz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Vicsek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Brechet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Barabási</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review E</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">6987</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Neural entrainment and attentional selection in the listening brain</title>
		<author>
			<persName><forename type="first">J</forename><surname>Obleser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kayser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="913" to="926" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Transition Probabilities and Different Levels of Prominence in Segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ordin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nespor</surname></persName>
		</author>
		<idno type="DOI">10.1111/lang.12024</idno>
	</analytic>
	<monogr>
		<title level="j">Language Learning</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="800" to="834" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">On phonetic convergence during conversational interaction</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="2382" to="2393" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Reflections on phonetic convergence: Speech perception does not mirror speech production</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Linguistics Compass</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="753" to="767" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Spatiotemporal coupling between speech and manual motor actions</title>
		<author>
			<persName><forename type="first">B</forename><surname>Parrell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Byrd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Phase-locked responses to speech in human auditory cortex are enhanced during comprehension</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davis</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhs118</idno>
	</analytic>
	<monogr>
		<title level="j">Cereb Cortex</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1378" to="1387" />
			<date type="published" when="2012">2013. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Neural oscillations carry speech rhythm through to comprehension</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peelle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Davis</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2012.00320</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Towards a mechanistic psychology of dialogue</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garrod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioural and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="169" to="226" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Do people use language production to make predictions during comprehension?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Pickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Garrod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="105" to="110" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Rate dependent speech processing can be speech-specific: Evidence from the perceptual disappearance of words under changes in context speech rate</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szostak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Dilley</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-015-0981-7</idno>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="334" to="345" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Meter and speech</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Port</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="599" to="611" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Multilevel modeling of between-speaker and within-speaker variation in spontaneous speech tempo</title>
		<author>
			<persName><forename type="first">H</forename><surname>Quené</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1104" to="1113" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paletz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<title level="m">Entrainment in Multi-Party Spoken Dialogues at Multiple Linguistic Levels. Proceedings of INTERSPEECH</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1696" to="1700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Tapping into linguistic rhythm</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rathcke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Bella</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Laboratory Phonology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Entrainment profiles: Comparison by gender, role, and feature set</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">D</forename><surname>Reichel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Š</forename><surname>Beňuš</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mády</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="46" to="57" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Encoding speech rate in challenging listening conditions: White noise and reverberation. Attention</title>
		<author>
			<persName><forename type="first">E</forename><surname>Reinisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Bosker</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-022-02554-8</idno>
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="2303" to="2318" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Sensorimotor synchronization: a review of the tapping literature</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Repp</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03206433</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="969" to="992" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Sensorimotor synchronization: a review of recent research</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Repp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Su</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-012-0371-2</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="403" to="452" />
			<date type="published" when="2006">2013. 2006-2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<author>
			<persName><forename type="first">L</forename><surname>Riecke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Formisano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sorger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Başkent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gaudrain</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2017.11.033</idno>
	</analytic>
	<monogr>
		<title level="m">Neural Entrainment to Speech Modulates Speech Intelligibility</title>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="161" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Social factors in convergence of F1 and F2 in spontaneous speech</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lewandowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Seminar on Speech Production</title>
		<meeting>the 10th International Seminar on Speech Production<address><addrLine>Cologne</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="391" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Social Attractiveness in Dialogs</title>
		<author>
			<persName><forename type="first">A</forename><surname>Schweitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lewandowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Duran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2243" to="2247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Speech rates converge in scripted turn-taking conversations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Philipps</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcfarland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Titone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Palmer</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0142716415000545</idno>
	</analytic>
	<monogr>
		<title level="j">Applied Psycholinguistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1201" to="1220" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">The mathematical theory of communication</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weaver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949">1949</date>
			<pubPlace>Urbana</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Illinois</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Listening effort during speech perception enhances auditory and lexical processing for non-native listeners and accents</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Iverson</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2018.06.001</idno>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="163" to="170" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Speech rhythm in English and Japanese</title>
		<author>
			<persName><forename type="first">K</forename><surname>Tajima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Port</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Phonetic Interpretation: Papers in Laboratory Phonology VI</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Local</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Ogden</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Temple</surname></persName>
		</editor>
		<imprint>
			<publisher>CUP</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="317" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Cross-language differences in cue use for speech segmentation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Tyler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cutler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page" from="367" to="376" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">The rhythm of language and speech: Constraints, models, metrics and applications. Online manuscript</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wagner</surname></persName>
		</author>
		<idno>URN: urn:nbn:de:0070-pub-19168457</idno>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Meter specific timing and prominence in German poetry and prose</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wagner</surname></persName>
		</author>
		<idno type="DOI">10.1515/9783110301465.219</idno>
	</analytic>
	<monogr>
		<title level="m">Understanding Prosody: The Role of Context, Function and Communication</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Niebuhr</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Boston</addrLine></address></meeting>
		<imprint>
			<publisher>De Gruyter</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="219" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Interaction phonology -a temporal coordination component enabling representational alignment within a model of communication</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Malisz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Inden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Wachsmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Alignment in Communication: Towards a New Theory of Communication</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Wachsmuth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>De Ruiter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Jaecks</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Kopp</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, Philadelphia</addrLine></address></meeting>
		<imprint>
			<publisher>John Benjamins</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="109" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Exploiting the speech-gesture link to capture finegrained prosodic prominence impressions and listening strategies</title>
		<author>
			<persName><forename type="first">P</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ćwiek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Samlowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page">100911</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Capitalizing on musical rhythm for prosodic training in computeraided language learning</title>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech and Language</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="67" to="81" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Looking for structure in lexical and acoustic-prosodic entrainment behaviors</title>
		<author>
			<persName><forename type="first">A</forename><surname>Weise</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Levitan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter</title>
		<meeting>the 2018 Conference of the North American Chapter</meeting>
		<imprint>
			<publisher>Human Language Technologies</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="297" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Transcranial alternating current stimulation with speech envelopes modulates speech comprehension</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wilsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Neuling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Obleser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Herrmann</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2018.01.038</idno>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="766" to="774" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Temporal entrainment in overlapped speech: Crosslinguistic study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Włodarczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Šimko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="615" to="618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Speech rate entrainment in children and adults with and without autism spectrum disorder</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Wynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Borrie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P</forename><surname>Sellers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Journal of Speech-Language Pathology</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">965</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">The Cambridge Handbook of Phonology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zec</surname></persName>
		</author>
		<editor>P. de Lacy</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="161" to="194" />
			<pubPlace>Cambridge CUP</pubPlace>
		</imprint>
	</monogr>
	<note>The syllable</note>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Phase Entrainment of Brain Oscillations Causally Modulates Neural Responses to Intelligible Speech</title>
		<author>
			<persName><forename type="first">B</forename><surname>Zoefel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Archer-Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Davis</surname></persName>
		</author>
		<idno type="DOI">org/10.1016/j.cub.2017.11.071</idno>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="401" to="408" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
