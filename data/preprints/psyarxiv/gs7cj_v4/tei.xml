<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Understanding the origin of omitted moments in memories of real-world events</title>
				<funder>
					<orgName type="full">ULiège</orgName>
				</funder>
				<funder>
					<orgName type="full">Belgium</orgName>
				</funder>
				<funder ref="#_fDpJMJ9">
					<orgName type="full">Wallonia-Brussels Federation -Concerted Research Actions</orgName>
				</funder>
				<funder>
					<orgName type="full">S.-FNRS)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Bastien</forename><surname>Durocher</surname></persName>
							<email>bdurocher@uliege.be</email>
							<affiliation key="aff0">
								<orgName type="department">Psychology and Neuroscience Research Unit</orgName>
								<orgName type="laboratory">Psychology and Neuroscience of Cognition Research Unit</orgName>
								<orgName type="institution">University of Liège</orgName>
								<address>
									<settlement>Liège</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Liège</orgName>
								<address>
									<addrLine>Place des Orateurs 1</addrLine>
									<postCode>4000</postCode>
									<settlement>Liège</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nathan</forename><surname>Leroy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Psychology and Neuroscience Research Unit</orgName>
								<orgName type="laboratory">Psychology and Neuroscience of Cognition Research Unit</orgName>
								<orgName type="institution">University of Liège</orgName>
								<address>
									<settlement>Liège</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">William</forename><surname>Warnier</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Psychology and Neuroscience Research Unit</orgName>
								<orgName type="laboratory">Psychology and Neuroscience of Cognition Research Unit</orgName>
								<orgName type="institution">University of Liège</orgName>
								<address>
									<settlement>Liège</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Arnaud</forename><surname>D'argembeau</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Psychology and Neuroscience Research Unit</orgName>
								<orgName type="laboratory">Psychology and Neuroscience of Cognition Research Unit</orgName>
								<orgName type="institution">University of Liège</orgName>
								<address>
									<settlement>Liège</settlement>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Understanding the origin of omitted moments in memories of real-world events</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BCFFB282E884EC2AC788122E99898757</idno>
					<note type="submission">Preprint submitted for publication. Version: September 30, 2025</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-22T14:44+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Episodic memory</term>
					<term>temporal compression</term>
					<term>event segmentation</term>
					<term>recognition memory</term>
					<term>naturalistic events</term>
					<term>wearable eye-tracking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>When recalling real-world events, people typically remember a sequence of key moments rather than a continuous stream, often omitting portions of their previous experience. It remains unclear whether such omissions reflect gaps in memory encoding or whether the corresponding moments are available in memory but not accessed during retrieval. To investigate this, the present study assessed recognition memory for recalled versus omitted segments. Participants walked around their university campus while wearing eye-tracking glasses that recorded their experience.</p><p>Twenty-four hours later, they freely recalled the events and completed a recognition task, discriminating between 5-s video clips from their own walk and those from other participants.</p><p>Recognition accuracy was lower for unrecalled than for recalled moments, but nevertheless above chance. A second experiment replicated these results and tested whether overlaying participants' original eye movements on the clips during recognition would enhance performance-it did not.</p><p>These results suggest that omissions in the recall of events result from both encoding and retrieval processes: while some moments may not be stored, others are available but not accessed during recall. We discuss how the dynamics of event perception and memory reconstruction contribute to the selective recall of real-world experiences.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>participant's past experience and including specific details such as the location, people, objects, and actions involved <ref type="bibr" target="#b25">(Jeunehomme et al., 2018)</ref>. Importantly, however, these experience units that composed memories were separated by temporal discontinuities-segments that participants did not represent when mentally replaying events. To quantify these discontinuities, participants were asked to identify the event segments corresponding to each recalled unit, based on the video footage recorded by the wearable camera. This showed that recalled experience units were separated by temporal gaps of dozens of seconds in terms of the actual event duration (53s on average), resulting in an event being recalled much faster than its actual duration <ref type="bibr" target="#b25">(Jeunehomme et al., 2018;</ref><ref type="bibr" target="#b22">Jeunehomme &amp; D'Argembeau, 2019)</ref>. Importantly, however, the density of recalled moments, and thus the number of discontinuities in memory representations, varied substantially across events. Notably, events that involved goal-directed interactions with the environment (e.g., an action such as buying a magazine) were recalled with a much finer temporal resolution than moments of spatial displacement from one point to another.</p><p>The temporal structure of memories for the unfolding of events depends, in part, on the way people parse the stream of experience into meaningful units <ref type="bibr" target="#b7">(Brunec et al., 2018;</ref><ref type="bibr" target="#b23">Jeunehomme &amp; D'Argembeau, 2020)</ref>. According to event segmentation theory, the continuous flow of perceptual information is divided into segments marked by significant changes (e.g., in location, people, actions, and so on), which give rise to the perception of event boundaries <ref type="bibr" target="#b42">(Radvansky &amp; Zacks, 2014;</ref><ref type="bibr" target="#b55">Zacks et al., 2007)</ref>. Research has shown that these event boundaries are more likely to be remembered than details occurring between them <ref type="bibr" target="#b39">(Pettijohn et al., 2016;</ref><ref type="bibr" target="#b47">Swallow et al., 2009)</ref>. Because actions are segmented more finely than moments of navigation <ref type="bibr" target="#b51">(Tversky et al., 2004)</ref>, they contain more event boundaries and are therefore less compressed in memory <ref type="bibr" target="#b23">(Jeunehomme &amp; D'Argembeau, 2020)</ref>. While this suggests that the temporal compression of experience in memory depends on the segmental structure of events, an important question remains: when does this compression mechanism occur? On the one hand, event segmentation processes during perception could contribute to the formation of temporal gaps inbetween encoded experience units <ref type="bibr" target="#b32">(Leroy et al., 2024)</ref>, leading to lossy event representations in memory. On the other hand, temporal gaps could be a consequence of retrieval processes: event structure provides easy access points for retrieving complex and continuous memories, which may lead to the "skipping" of available but less relevant information <ref type="bibr" target="#b36">(Michelmann et al., 2023)</ref>.</p><p>Therefore, it remains unclear whether the segments people omit when mentally replaying events are due to selective encoding or selective retrieval, or both. In other words, do temporal gaps in event recall result from a lack of accessibility or availability <ref type="bibr" target="#b50">(Tulving &amp; Pearlstone, 1966)</ref> of information in memory?</p><p>One approach to addressing this question is to assess recognition memory for moments corresponding to the segments that are omitted during event recall. If these unrecalled moments were not encoded in the first place, recognition memory performance for these moments should be near chance level. On the other hand, if these moments are available in memory but not accessed during retrieval, people should still be able to identify them reliably in a recognition memory task. A third possibility is that both encoding and retrieval processes contribute to the observed memory gaps, in which case recognition memory performance should be weaker for unrecalled than recalled moments, but nevertheless better than chance.</p><p>To test these hypotheses, we conducted two experiments using a paradigm that assessed memory for real-world events using methods adapted from <ref type="bibr">Jeunehomme and colleagues (2018</ref><ref type="bibr">Jeunehomme and colleagues ( , 2019</ref><ref type="bibr">Jeunehomme and colleagues ( , 2020))</ref>. In Experiment 1, participants experienced a series of events during a short walk around a university campus, while equipped with a wearable camera and eye-tracking device <ref type="bibr" target="#b1">(Baumann &amp; Dierkes, 2023)</ref>. The day after their walk, participants were asked to recall the events in as much detail as possible. Recognition memory performance was then evaluated for both recalled and unrecalled moments, allowing us to examine whether temporal gaps in recall result from the unavailability or differences in accessibility of information in memory. To foreshadow the results, we found that recognition memory was lower for previously unrecalled than recalled moments, but still much better than chance. Experiment 2 then aimed to replicate these results and to investigate whether recognition memory performance could be further improved when cues about gaze allocation is provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>The aims of Experiment 1 were twofold: (i) to replicate the previously observed difference in the density of recalled experience units between actions and spatial displacements <ref type="bibr" target="#b25">(Jeunehomme et al., 2018;</ref><ref type="bibr" target="#b22">Jeunehomme &amp; D'Argembeau, 2019</ref><ref type="bibr">, 2020)</ref>, and (ii) to investigate whether event segments omitted during recall are nevertheless available in memory. Participants first went on a short walk on the university campus, equipped with eyeglasses that recorded events from their own perspective. The next day, participants' memory was assessed, first, with a free recall task, and then with an old/new recognition memory task constructed using the footage from the video recordings of the events. Like <ref type="bibr" target="#b25">Jeunehomme et al. (2018)</ref>, we computed the density of recalled experience units (i.e., the amount of experience units recalled per minute of the actual event) for segments of the tour involving actions and segments involving navigation. In addition, we analyzed whether unrecalled moments could nevertheless be recognized, and how recognition performance compared to that obtained for recalled moments.</p><p>In line with previous studies, we predicted that the density of recalled experience units would be higher for action segments than for navigation segments. Then, the recognition memory data allowed us to consider three possibilities regarding the status of unrecalled moments. If temporal compression during event recall is due to a lossy encoding process (i.e., the omitted moments are not available in memory), recognition performance for unrecalled moments should be close to chance. By contrast, if temporal compression during event recall occurs because of retrieval rather than encoding processes, recognition performance should be good and similar for recalled and unrecalled moments. Finally, if both encoding and retrieval affect temporal compression in recall, then recognition memory performance for unrecalled moments should be better than chance, but not as good as performance for recalled moments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Participants were first-year psychology students at the University of Liège who were recruited through the department's participant pool system and took part in the study in exchange for course credits. Our target sample size was 20 participants, determined a priori using G*Power <ref type="bibr">(Faul et al. 2007</ref>), as it provided more than 95% statistical power (for a paired t-test) to replicate the difference between actions and spatial displacements (d = 1.51 for the 24-h delay group) 1 in the density of recalled experience units reported by <ref type="bibr" target="#b25">Jeunehomme et al. (2018)</ref>. Furthermore, a sensitivity power analysis indicated that this sample size provided sufficient power (80%) to detect a medium effect size (d = 0.58; with an alpha = 0.05, one tailed) 2 . In total, 28 participants were recruited to account for possible exclusions. Seven participants were indeed excluded for the following reasons: three participants deviated from the itinerary in major ways, which made the recognition memory task unapplicable; two participants obtained remarkably high scores on the recognition memory test (area under the ROC curve above 0.95) and reported, for many trials, 1 The effect size d reported here and in later t-tests is Cohen's dz <ref type="bibr" target="#b31">(Lakens, 2013)</ref>. 2 In the present study, we used one-sided tests, as recommended by <ref type="bibr" target="#b44">Rubin (2022)</ref>, since our aim was to test directional hypotheses (e.g., recognition memory is better for recalled than unrecalled segments). that they used non-mnemonic inferences rather than memory for event detail to make their judgment (see below),<ref type="foot" target="#foot_0">foot_0</ref> and two participants because their free recall production was either very poor or extremely detailed (i.e., three standard deviations below or above the group mean), leading to an insufficient number of trials available to compare recognition memory for recalled and unrecalled moments. The resulting 21 participants (15 women, 6 men) were aged between 18 and 23 years old (mean = 18.61 years, SD = 1.51). All participants provided written informed consent, and the study was approved by the local ethics committee <ref type="bibr">(ref. 11146-5769)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and procedure</head><p>The procedure was adapted from <ref type="bibr" target="#b25">Jeunehomme et al. (2018)</ref> and consisted of two sessions.</p><p>In the first session, participants were equipped with the filming device and went for a 10-15-min walk around the campus (see Figure <ref type="figure">1</ref>). In the second session, conducted 24 hours later, participants completed a series of memory tasks related to their walk from the previous day, including a free recall task and a recognition memory task (see Figure <ref type="figure">2</ref>). We used a 24-hour delay to have sufficient time to extract video segments from the recorded walk and to select appropriate lures for the recognition task. This interval is comparable to the delay employed in a prior investigation of recognition memory for video segments extracted from real-life events <ref type="bibr" target="#b38">(Misra et al., 2018)</ref>. Note also that <ref type="bibr" target="#b25">Jeunehomme et al. (2018)</ref> did not observe significant differences in recall performance between immediate testing and testing after a one-day delay, thereby suggesting that such an interval does not substantially affect recall outcomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Walk on campus.</head><p>On the first day, participants were invited to take a walk on the campus while wearing the Neon device, a pair of eyeglasses equipped with cameras and eye-tracking technology produced by Pupil Labs <ref type="bibr" target="#b1">(Baumann &amp; Dierkes, 2023)</ref>. As these glasses are comfortable to wear and resemble normal eyewear, they enable naturalistic recording of events from a participant's point of view, as well as gaze data (although gaze data were recorded, they are not reported here).</p><p>The walk was designed to last 10 to 15 min and was interspersed with three actions that the participants had to perform (tear a tag off a flyer, check a bus timetable, buy a pack of chewing gum) before looping back to the experiment room (see Figure <ref type="figure">1</ref>, for a detailed description). Participants were given an aerial view of the walk (Figure <ref type="figure">1</ref>) and had all the time they needed to study it before starting the experiment. The experimenter provided a verbal description of the walk in chronological order, without indicating that it was divided into "action" and "navigation" segments. Care was taken not to emphasize any particular part. To avoid disproportionally directing attention to specific actions, we provided a similar amount of information for action and navigation segments, including useful landmarks and important turns to aid navigation, as well as instructions for the three actions. Participants were then equipped with the Neon eyeglasses, as well as an overcoat and a pair of black latex gloves. The purpose of this attire was to conceal the participant's hands and personal clothes from the camera field while they perform actions, to avoid the presence of visual clues to their appearance during the recognition task (see below).</p><p>As our objective was to study naturalistic episodic memory formation, participants were not informed that their memory for the walk would be subsequently tested. The real goal of the experiment was therefore hidden by a cover story: participants believed that we sought to test the quality of the eye-tracking data collection in a naturalistic setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1</head><p>Map of the University Campus Given to the Participants Before Their Walk.</p><p>Note. Participants started the walk at point B. They had to exit the building and cross a paved area to enter the next building and tear a tag off a flyer (1). They then exited the building and walked alongside the road until they arrived at a bus stop, where they checked a specific bus schedule (2).</p><p>Next, they proceeded down a path that led to the university cafeteria, in which they had to buy chewing gum (3; they were given a 2€ coin to buy the chewing gum). Finally, they left the cafeteria and walked back to the first building. The paths taken are highlighted in red. Map data: Google © 2025 Maxar Technologies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall task.</head><p>The following day, participants first received a free recall task in which they were asked to mentally replay their tour, in as much detail as possible, and to verbally describe everything that came to mind as they recalled the events. Emphasis was placed on the need to report any remembered event or detail, no matter how small or seemingly unimportant-for example, people or vehicles encountered, objects looked at, places passed through, or actions performed (e.g., opening a door or waiting for a car to pass). To illustrate this, participants were told: "Even if some details seem obvious or trivial, such as opening a door or looking at a tree, make sure to mention them." An audio recording of the verbal descriptions of their memories was made (Figure <ref type="figure">2A</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recognition task.</head><p>After the free recall task, participants performed a recognition memory task for all the events that made up their tour. For each participant, the video recording captured by the eyeglasses during their tour was segmented into a series of 5-s extracts. During the recognition task, all these 5-s segments from the participant's original video were presented in random order, mixed with an equal number of 5-s foil extracts, resulting in about 250 to 350 trials in total (depending on the duration of the participant's tour). Foils were drawn from the videos of previous participants and members of the research team and were matched with targets of each individual participant for weather conditions and season. If no suitable lures were available that matched a participant's specific conditions (e.g., weather, time of day), we filmed additional lures during the 24-hour delay.</p><p>For each 5-s clip, participants judged whether it came from their own walk or another participant's, using a 6-point confidence scale (1 = "absolutely certain this video is not mine" to 6 = "absolutely certain this video is mine"; see Figure <ref type="figure">2B</ref>). While making recognition judgments, participants were asked to verbalize everything that came to their mind. These verbal reports allowed us to exclude trials in which responses relied on non-mnemonic inferences rather than episodic memory. Such cases involved deductive judgments based on incidental features-like seeing one's own reflection or distinctive clothing-that could, in principle, be used to correctly judge a clip as old or new by someone who had not experienced the original event. In addition, we also excluded video clips that lacked distinctive elements for discriminating targets from lures. For example, when both target and lure clips depicted an empty hallway, participants explicitly reported having no basis for discrimination and thus responded at chance. After exclusions, an average of 281.14 trials per participant remained (SD = 51.63), down from 300.56 <ref type="bibr">(SD = 27.22)</ref>. Unbeknownst to the participants, these trials were either part of the action category (M = 50.92, SD = 12.60 trials per participant) or the navigation category (M = 230.19, SD = 45.18 trials per participant), depending on the part of the walk they depicted (see Figure <ref type="figure">1</ref>).</p><p>In the retained trials, participants generally referred to specific features of the episode when making their recognition judgment. Commonly mentioned cues included bystanders, vehicles, the state of objects (e.g., whether the door had been left open), and participants' own behavior during the walk (e.g., keeping or pocketing collected items, hesitating when locating a target object, or making a distinctive head movement to look at something). These reports confirmed that recognition judgments were generally based on the retrieval of event-specific details rather than on deductions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>Representation of the Memory Tasks. Note. A. Free recall task. Participants freely recalled all the events they experienced during their tour, in as much detail as possible, while the verbal descriptions of their memories were recorded.</p><p>B. Recognition memory task. On each trial of the recognition memory task, participants were presented with a 5-s video extract taken from their own or another person's tour and made their recognition judgment using a 6-point confidence scale. C. Experience unit identification task.</p><p>Participants were asked to match each experience unit they had recalled to the corresponding moment in the video recording of their walk.</p><p>In addition to assessing the density of recalled experience units, the identification of experience units also enabled us to separate trials of the recognition memory task according to whether they corresponded to recalled or unrecalled moments. Target trials were thus categorized as recalled or unrecalled based on whether or not they contained an experience unit identified by the participant. For lures, we had no direct way of separating trials into these two categories.</p><p>However, as all participants walked the same route and performed the same actions, we were able to mark lure trials as "recalled" if they happened at the same point along the walk or during the same action as a recalled trial, and as "unrecalled" otherwise. Participants had an average of 49.95 recalled trials (SD = 17.91) and 231 unrecalled trials (SD = 54.29).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall task</head><p>Participants recalled an average of 27.62 experience units in total (95% CI <ref type="bibr">[23.04; 32.20]</ref>), corresponding to 2.30 experience units per minute of the actual event (95% CI [1.84; 2.75]). First, we sought to replicate previous studies showing that people recall a higher density of experience units for events involving actions than events involving spatial navigation. Action moments corresponded to parts of the walk where the spatial location of the participants remained stable, while they engaged in planned interactions with their environment. Action segments were located in the first building they entered (ripping a tag from a flyer), at the bus stop, and in the small shop in which they bought chewing gum (see Figure <ref type="figure">1</ref>). During all the remaining segments of the tour, participants were simply walking from one location to the other, and these segments were marked as spatial navigation. In line with previous studies, a one-tailed paired-samples t-test indicated that the density of recalled experience units (i.e., the number of experience units per minute of the actual event) was significantly higher for action segments (M = 4.94, 95% <ref type="bibr">CI [3.90;</ref><ref type="bibr">5.97]</ref>) than for navigation segments (M =1.84, 95% CI [1.44; 2.25]), t(20) = 8.19, p &lt; .001, d = 1.79 (95% CI [1.08; 2.47]) (see Figure <ref type="figure">3</ref>). Raincloud Plots showing the Density of Experience Units recalled for action and navigation segments in Experiment 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recognition task</head><p>Recognition memory performance was assessed using receiver operating characteristic (ROC) curves, which examine the relationship between the hit rate and the false alarm rate across levels of confidence <ref type="bibr" target="#b53">(Yonelinas &amp; Parks, 2007)</ref>. For example, in our case, the first (leftmost) point of the curves represents hit rate and false alarm rate for the items that elicited the strongest "old" response (here, "6"), the next point plots hit rate and false alarm rate for the items that elicited either a "6" or a "5" response, the next point is for the items that were answered with a "6", "5", or "4" response, and so on (by convention, the last point is not plotted as it is necessarily located in the (1,1) corner of the graph). As demonstrated by <ref type="bibr" target="#b4">Brady et al. (2023)</ref>, calculating the area under the curve (AUC) for the ROC of an old/new task that uses confidence scales is one of the most precise and reliable ways to assess recognition memory performance.</p><p>An AUC of 0.5 would represent a random classification between old and new items, while an AUC of 1 represents a perfect performance. We computed the individual ROCs and their AUCs with the ROC Toolbox v1.1.3 for MATLAB <ref type="bibr" target="#b29">(Koen et al., 2017)</ref> and then calculated a general average AUC at the group level, as well as average AUCs in our different conditions. Aggregated ROC curves were plotted using the weighted average of the hit and false alarm rates for all participants at each threshold value.</p><p>The average AUC was 0.88 (95% CI [0.85; 0.90]), indicating very good overall recognition performance. Our first goal was to compare recognition performance for trials corresponding to moments that had been previously recalled by participants and trials corresponding to unrecalled moments. The ROC curves and AUCs for these two types of trials are shown on Figure <ref type="figure" target="#fig_2">4A</ref>. A one-tailed paired-sample t-test showed that the AUCs were significantly higher for recalled segments (M = 0.92, 95% CI [0.89; 0.95]) than for unrecalled segments (M = 0.84, 95% CI [0.81; 0.87]), t(20) = 5.17, p &lt; .001, d = 1.13 (95% CI [0.57; 1.67]).</p><p>Recognition performance was well above chance, even for unrecalled segments. Visual inspection of the ROCs indicates that hits were more frequently associated with low confidence judgements in the unrecalled condition than in the recalled condition. Almost 50% of the hits in the recalled condition were associated with confidence level 6. action segments (M = 0.93, 95% CI [0.91; 0.95]) than for navigation segments (M = 0.84, 95% CI [0.81; 0.87]), t(20) = 8.52, p &lt; .001, d = 1.86 (95% CI [1.14; 2.56]). Visual inspection of the ROCs indicates that hits were associated with higher confidence judgements in the action condition than in the navigation condition. Aggregated ROC Curves and raincloud plots of their AUCs as a function of recall performance </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The results of the recall task replicate those of <ref type="bibr" target="#b25">Jeunehomme et al. (2018)</ref>, showing that the density of recalled experience units was greater for action than spatial navigation segments. Our main goal was then to investigate the availability of unrecalled moments in memory, using the recognition task. The results showed that, overall, participants were able to discriminate most of their tour segments from those of other participants with a high degree of accuracy. As expected, recognition memory performance for recalled moments was excellent, although not perfect.</p><p>Performance for unrecalled moments was significantly worse than for recalled moments, indicating a reduced availability of unrecalled moments in memory. However, recognition performance was still good and far above chance level, indicating that many moments that were omitted during recall were available in memory, although not in a directly accessible form. Thus, some event segments omitted during recall were available in memory, while other segments were not. These results suggest that the presence of temporal discontinuities during the mental replay of real-world events results from two mechanisms: the selective encoding of certain event segments (so that other segments are not available in memory), and retrieval strategies that favor access to some segments at the expense of others (even though the latter are available in memory).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>In Experiment 2, we sought to replicate the results of Experiment 1 and to explore whether additional cueing could further improve participants' recognition memory performance.</p><p>More specifically, we investigated whether presenting cues about gaze allocation would increase recognition performance. This was partly motivated by the fact that some participants in Experiment 1 expressed that, when viewing the old/new test stimuli, they wished they could have seen where the person was looking to make a more informed recognition judgment. Information about patterns of fixation could indeed help participants differentiate between visually similar stimuli by remembering where they were looking in the visual scene. Additionally, there is evidence that eye movements during retrieval help participants reinstate the spatiotemporal context of their memories <ref type="bibr">(Wynn et al., 2019)</ref>. <ref type="bibr" target="#b15">Foulsham and Kingstone (2013)</ref> found that participants were sometimes able to recognize their own fixation pattern on an image, compared to that of other people, although the effect was moderate. However, they used static images as stimuli, which have been shown to elicit different fixation patterns than scenes experienced firsthand in natural environments <ref type="bibr" target="#b16">(Foulsham et al., 2011)</ref>. Therefore, in Experiment 2, we examined whether providing information about gaze dynamics would help participants make better recognition judgements. The availability of gaze information during the recognition memory task was manipulated by presenting the original fixation pattern on the video stimuli for half of the trials, whereas the other half of the trials were identical to that of Experiment 1. If gaze patterns help reinstate the content of an event, participants should be better able to distinguish between targets and lures, and recognition performance should therefore be higher, when gaze information is provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Participants were recruited using the same procedure as in Experiment 1. In total, 36 participants were tested but 7 of them were excluded for the following reasons: one participant guessed that their memory would be tested, three participants deviated from the intended path in major ways, two participants because of technical difficulties during the presentation of the recognition memory task, and one was using attention-impacting medication. The remaining sample included 29 participants (26 women; mean age = 19 years old, SD = 2.18). This sample size provided more than 95% power to replicate the difference in recognition memory performance between recalled and unrecalled segments observed in Experiment 1. We did not perform an a priori power analysis for the gaze cueing effect, but a sensitivity analysis indicated that our sample size provided 80% power to detect a medium effect (d = 0.47), which is smaller than the effect reported by <ref type="bibr">Foulsham and Kingston (2013;</ref><ref type="bibr">d = 0.57)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and procedure</head><p>The procedure was identical to that of Experiment 1, with the following exception: in the recognition memory task, for half of the trials, the stimuli included the position of the eyeglasses wearer's gaze dynamically overlaid on top of the video, in the form of a moving red circle (see Figure <ref type="figure" target="#fig_3">5</ref>). The stimuli were created using the tools available on the Pupil Cloud (v7.5), an online workspace provided by Pupil Labs for processing video recordings and gaze data collected with their equipment <ref type="bibr">(Pupil Labs, 2025)</ref>. As in Experiment 1, the stimuli were created by dividing each participant's full video recording into 5-s segments. Next, the segments were assigned to the cued and uncued gaze conditions in an alternating order: the first segment was assigned to the cued condition, the second to the uncued condition, the third to the cued condition, and so on. A similar procedure was used to create lures with cued and uncued gaze information. Target and lure trials with and without gaze information were presented in random order.</p><p>Trials of the recognition memory task were excluded following the same criteria as in Experiment 1. In Experiment 2, participants contributed an average of 251.34 trials (SD = 28.53), including 74.14 recalled (SD = 24.20) and 177.21 unrecalled trials (SD = 29.28), as well as 40.03 action (SD = 9.73) and 211.31 navigation trials (SD = 25.07). Screenshot from a Stimulus Video Showing a Red Circle Indicating what the Participant Fixated in the Environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recall Task</head><p>Participants recalled an average of 30.28 experience units in total (95% <ref type="bibr">CI [26.16;</ref><ref type="bibr">34.36]</ref>), corresponding to 2.36 experience units per minute of the actual event (95% CI [2.03; 2.70]). As in Experiment 1, a one-tailed paired-samples t-test indicated that the density of recalled experience units was significantly higher for action segments (M = 5.52, 95% CI [4.62; 6.41]) than for spatial navigation segments (M = 1.85, 95% CI [1.53; 2.17]), t(28) = 8.77, p &lt; .001, d = 1.63 (95% CI [1.06; 2.18]) (see Figure <ref type="figure">6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Raincloud Plots of the Density of Experience Units recalled for action and navigation Segments in Experiment 2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recognition task</head><p>As in Experiment 1, we aimed to investigate recognition memory performance for segments that had been recalled or omitted when participants mentally replayed the events. Furthermore, we sought to investigate whether gaze cueing improves recognition performance.</p><p>The ROC curves for the corresponding types of trials are shown in Figure <ref type="figure">7</ref>. We conducted a 2way repeated measures ANOVA with recall status (recalled, unrecalled) and gaze cueing (cued, uncued) as within-subject factors on AUCs. As expected, recalled moments (M = 0.90, 95% CI [0.87; 0.92]) were better recognized than unrecalled moments (M = 0.84, 95% CI [0.81; 0.87]), = 0.85, 95% CI [0.82; 0.88]) did not differ from that of uncued gaze trials (M = 0.85, 95% CI [0.82; 0.88]), F(1,28) = 0.01, p = .92, η 2 p.&lt; 0.001. There was no significant interaction effect, F(1,28) = 0.17, p = .68, η 2 p.= 0.01.</p><p>As in Experiment 1, we also compared recognition performance for action and spatial navigation segments (see Figure <ref type="figure">7C</ref>). The AUCs were significantly higher for action trials (M = 0.91, 95% CI [0.89; 0.94]) than navigation trials (M = 0.83, 95% CI [0.81; 0.86]), t(28) = 6.00, p &lt;.001, d = 1.11 (95% CI [0.64; 1.57]).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 7</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aggregated ROC Curves and raincloud plots of their AUCs as a function of recall performance (A), gaze cueing (B), and type of segments (C) in Experiment 2</head><p>obtained by computing hit and false alarm rates at each confidence threshold for all participants and averaging these rates across participants. Right: Raincloud plots of the AUCs of the individual ROC curves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Disentangling effects of recall status and event type on recognition memory</head><p>The results of both Experiments 1 and 2 showed that recognition performance was better for recalled than for unrecalled segments. However, the analyses collapsed action and navigation trials, raising the possibility that the observed differences might simply reflect participants' tendency to recall more action events. To address this issue, we conducted additional analyses that simultaneously considered event type (action vs. navigation), recall status (recalled vs. unrecalled), and their interaction. Because the low number of trials in some conditions would have led to unreliable ROC curves, we assessed recognition performance using d', which was calculated by collapsing 1-3 confidence ratings into "new" responses and 4-6 into "old" responses. Participants with fewer than 3 lures and 3 targets in each condition were excluded (10 participants in total: 3 from Experiment 1 and 7 from Experiment 2). We calculated a d' score per condition for each participant using the psycho package in R <ref type="bibr" target="#b35">(Makowski, 2018)</ref> Recognition performance (d') was analyzed using a two-way repeated measures ANOVA with event type (action vs. navigation) and recall status (recalled vs. unrecalled) as within-subject factors. The pattern of results was consistent with our previous analyses. There was a significant main effect of event type, showing that action segments (M = 2.22, 95% CI [1.98; 2.45]) were recognized better than navigation segments (M = 1.51, 95% <ref type="bibr">CI [1.36;</ref><ref type="bibr">1.66]</ref>), F(1,39) = 25.74, p &lt; .001, η 2 p = 0.4. The main effect of recall status was also significant, indicating that recalled moments (M = 1.99, 95% CI [1.83; 2.14]) were better recognized than unrecalled moments (M = 1.55, 95% CI [1.39; 1.70]), F(1,39) = 16.46, p &lt; .001, η 2 p = 0.3. There was no significant interaction between event type and recall status, F(1,39) = 0.13, p = .72, η 2 p = 0.003. These results thus show that differences in recognition performance between recalled and unrecalled segments were not confounded by event type (see Figure <ref type="figure">8</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 8</head><p>Raincloud plot of d' as a function of recall status and type of segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The results of Experiment 2 replicate those of Experiment 1 regarding the availability of unrecalled moments in memory: recognition memory performance was higher for recalled than unrecalled segments but was still very good in the latter case. Providing additional cues regarding gaze allocation did not improve recognition performance. The ROC curves for cued and uncued trials not only had the same AUC but also remarkably similar shapes, indicating that neither the hit rate nor the false alarm rate were affected by gaze cueing. Finally, additional analyses of recognition data from both Experiments 1 and 2 confirmed that the recognition advantage for recalled over unrecalled segments was robust across event types and not driven by differences between action and navigation segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General discussion</head><p>Recalling an event typically takes less time than experiencing it. This temporal compression arises because remembering does not involve reinstating the full temporal structure of the event; instead, individuals recall a sequence of discontinuous "slices" that capture the most informative or salient moments <ref type="bibr" target="#b11">(D'Argembeau et al., 2022)</ref>. Between these recalled segments lie portions of the original experience that are not explicitly represented when mentally replaying an event. The present study investigated whether these omitted segments are still available in memory. To this end, we compared recognition memory performance for moments that were recalled versus those that were omitted during the mental replay of real-world events. Across two experiments, we found that recognition performance was significantly lower for unrecalled moments than for recalled ones, but nevertheless above chance level. Furthermore, both recall and recognition performance were significantly better for segments involving specific actions compared to those involving spatial navigation.</p><p>The primary contribution of this study is to clarify the origin of omitted moments in memories of real-world events by comparing recognition memory performance for recalled versus unrecalled moments. Unsurprisingly, recognition accuracy for recalled moments was nearly perfect. The examination of recognition performance for unrecalled moments then allowed us to test three competing hypotheses: (a) that unrecalled moments are lost due to selective encoding processes; (b) that unrecalled moments are available in memory but inaccessible during recall; and (c) that both encoding and retrieval processes contribute to the discontinuities observed during event recall. Results from both experiments support the third hypothesis: recognition performance for unrecalled moments was well above chance, yet significantly lower than for recalled moments. These results suggest that the temporal compression observed in the recall of real-world events arises from the combined effects of selective encoding and retrieval mechanisms.</p><p>The fact that some moments from prior experiences were neither recalled nor recognized suggests that these moments were unavailable in memory. One likely explanation is that these moments were not encoded into long-term memory, or at least not in a form that supports episodic recollection. Research on event cognition has shown that attention is unevenly distributed across the ongoing flow of daily experiences: people allocate more attention to moments marked by significant changes, such as shifts in location or activity <ref type="bibr" target="#b20">(Hard et al., 2011)</ref>.</p><p>In contrast, portions of events that are less informative, highly predictable, or redundant seem less likely to be encoded <ref type="bibr" target="#b13">(Faber &amp; Gennari, 2015;</ref><ref type="bibr" target="#b24">Jeunehomme &amp; D'Argembeau, 2023;</ref><ref type="bibr" target="#b30">Kosie &amp; Baldwin, 2019)</ref>. Encoding into long-term memory is also contingent upon the capacity of working memory, which maintains a dynamic model of the current situation to guide prediction and behavior <ref type="bibr" target="#b17">(Franklin et al., 2020;</ref><ref type="bibr" target="#b43">Richmond &amp; Zacks, 2017;</ref><ref type="bibr" target="#b54">Zacks, 2020)</ref>. Event segmentation theory holds that upon perceiving an event boundary, the current event model is updated and transferred to long-term memory <ref type="bibr" target="#b2">(Bird, 2020;</ref><ref type="bibr" target="#b34">Lu et al., 2022;</ref><ref type="bibr" target="#b43">Richmond &amp; Zacks, 2017)</ref>.</p><p>However, recent studies suggest that when the information accumulated in an event model exceeds working memory capacity, the resulting event representation may be truncated-some parts of the continuous stream of experience fail to be encoded <ref type="bibr" target="#b32">(Leroy et al., 2024</ref><ref type="bibr" target="#b33">(Leroy et al., , 2025))</ref>. Thus, the idea that working event models selectively encode relevant information may explain why some (less informative) segments of experience are unavailable in memory.</p><p>Even when experiences are successfully encoded, not all of them are readily accessible during retrieval. Indeed, the good overall recognition performance for unrecalled segments indicates that some information available in long-term memory is not accessed during free recall.</p><p>This could be due to a reduced strength of the corresponding memory traces and/or the pragmatics of event recall. First, it is likely that segments accessed during event recall differ from those that are recognized but not recalled in terms of memory strength and level of integration. Functional magnetic resonance imaging (fMRI) studies have examined encoding-related brain activity for items that were subsequently recalled versus those that were recognized but not recalled <ref type="bibr" target="#b5">(Brassen et al., 2006;</ref><ref type="bibr" target="#b19">Habib &amp; Nyberg, 2008;</ref><ref type="bibr" target="#b46">Staresina &amp; Davachi, 2006)</ref>. It was found that recognized-but-unrecalled items elicited lower medial temporal lobe activation during encoding compared to recalled items. <ref type="bibr" target="#b19">Habib and</ref><ref type="bibr">Nyberg (2008, p. 1720)</ref> suggest that "failure to access information that is available in memory may reflect weaker memory representations". This interpretation aligns with the present result that recognition of unrecalled segments was associated with lower confidence than recognition of recalled segments, suggesting reduced memory strength <ref type="bibr" target="#b45">(Squire et al., 2007)</ref>. However, some unrecalled segments (about 30%) were recognized with high confidence, suggesting that reduced trace strength may not fully account for the omission of certain moments during event recall. A possible explanation is that these highstrength omitted moments are less well integrated into event models. The aforementioned fMRI studies also found additional prefrontal activation during the encoding of subsequently recalled items, interpreted as reflecting successful contextual binding in working memory <ref type="bibr" target="#b5">(Brassen et al., 2006;</ref><ref type="bibr" target="#b46">Staresina &amp; Davachi, 2006)</ref>. This is consistent with the view that successful recall depends on the integration of information into a coherent event model during encoding, allowing it to be stored as part of an event memory. Consequently, memory traces that were not contextually integrated as part of the event may be missed by the memory search process initiated during event recall, even if encoded with high strength.</p><p>This skipping of certain segments during event recall can be understood in two different ways. First, although free recall has been shown to reinstate the chronological order of real-life events <ref type="bibr" target="#b12">(Diamond &amp; Levine, 2020)</ref>, studies using complex narratives have shown that participants prioritize causal coherence over temporal continuity when the two are in conflict <ref type="bibr" target="#b0">(Antony et al., 2024;</ref><ref type="bibr" target="#b6">Brownstein &amp; Read, 2007;</ref><ref type="bibr">see Chen &amp; Bornstein, 2024, for a review)</ref>. In these studies, participants tended to recall causally related events together, even when they were not chronologically contiguous. This mode of recalling narratives naturally resulted in temporally discontinuous accounts, although this was not necessarily due to information loss during encoding. As <ref type="bibr" target="#b26">Keven (2016</ref><ref type="bibr" target="#b28">Keven ( , 2022) )</ref> argues, this selection process during recall is a necessary byproduct of integrating simple, snapshot-like memories from different times and places into cohesive, retrievable, and temporally and causally organized episodic memories. <ref type="bibr">Keven (2018, p. 30)</ref> gives the example of remembering a "missing-the-bus" episode, in which "[we] don't remember all of the minute details involved in the actual experience; [we] remember only the causally and teleologically relevant ones in the right temporal order." This retrieval pattern closely mirrors the way our participants recalled events, progressing from one causally significant point (e.g.: "I opened the door and left the building") to the next (e.g.: "when I arrived at the bus stop, there was someone standing in front of the schedule"), while omitting certain segments that occurred in between, even if they were perceptually distinctive (e.g., seeing a worker unloading equipment from a truck parked on the side of the road). However, such segments would be easily recognizable with high confidence in the recognition memory task. This account provides an explanation of the omission of some memory traces during recall, through a retrieval process that favors the creation of informative and meaningful representations over the reinstatement of a continuous stream of events.</p><p>An alternative theoretical framing of our results conceptualizes recall as a process of scanning through, and bypassing, elements within a continuous stream of experience.</p><p>In a recent study, <ref type="bibr" target="#b36">Michelmann et al. (2023)</ref> presented participants with a film excerpt and instructed them to mentally replay portions of it. The duration of these mental simulations was found to reflect the number of intervening event boundaries more than the absolute temporal distance between the beginning and end of the sequence. The authors concluded that participants scanned their memory event-by-event, occasionally skipping ahead to the next event boundary instead of simulating every event exhaustively. This pattern supports an account of the retrieval of naturalistic events as a structured scanning process leveraging event boundaries as access points into continuous memories. In our experiments, moments omitted during recall but subsequently recognized may correspond to those skipped during this scanning process. Overall, a combination of selective processes and cognitive limitations operating at both encoding and retrieval can help explain why the recall of real-world events is characteristically sparse.</p><p>Previous research has demonstrated that humans possess remarkable recognition memory capacities for visual information. After briefly viewing hundreds of pictures of objects or scenes, people can accurately identify which specific pictures they saw previously (e.g., <ref type="bibr">Brady et al., 2008)</ref>, and often remember contextual details such as where and when the images were seen <ref type="bibr">(Trinkl &amp; Wolfe, 2024)</ref>. The present results extend this body of work by showing that recognition memory for dynamic, real-world event segments is also highly accurate. However, the good recognition performance observed in our study stands in contrast to the findings of <ref type="bibr" target="#b38">Misra et al. (2018)</ref>, who reported near-chance recognition accuracy. In their study, participants also walked along a route while wearing a camera and, 24 hours later, were asked to discriminate between video stimuli from their own recordings and those of others. A key methodological difference between the two studies lies in the duration of the video clips used during the recognition task: Misra et al. used 1-s segments, whereas we used 5-s segments. The shorter segments likely contained less distinctive information, making recognition judgments more difficult. In preliminary piloting for the current study, we found that clips shorter than 5 seconds often lacked sufficient unique features-such as the presence of a person or vehicle-to reliably distinguish targets from lures, given that they involved the same environments. In addition to clip duration, other factors such as participants' familiarity with the environment and the overall length of the recorded events may also have contributed to the differences in recognition performance observed across studies.</p><p>Experiment 2 showed that providing cues about gaze allocation did not improve recognition performance. This finding may appear to contrast with the results of <ref type="bibr" target="#b15">Foulsham and Kingstone (2013)</ref>, who reported that participants were able to discriminate their own fixations from those of others. However, their study indicated that such discrimination was limited, and more recent research has shown that participants are often unable to distinguish between their own and another individual's fixation patterns <ref type="bibr" target="#b9">(Clarke et al., 2017;</ref><ref type="bibr" target="#b52">Võ et al., 2016)</ref>. Therefore, gaze behavior may not be distinctive enough to function as an effective memory cue. Moreover, gaze allocation in naturalistic, real-world contexts tends to be more centrally concentrated than in laboratory settings <ref type="bibr" target="#b16">(Foulsham et al., 2011)</ref>, a factor that may have further reduced the effectiveness of gaze-based cues in the present study. An additional, and potentially critical, difference between our study and that of <ref type="bibr" target="#b15">Foulsham and Kingstone (2013)</ref> concerns the characteristics of target and lure stimuli. In their study, lure and target images were identical, differing only in the fixation patterns overlaid on them. By contrast, in our study, lure and target stimuli were dynamic and, although they corresponded to the same walk segment, they could nonetheless differ in content (e.g., the presence of different persons in the scene). Such content differences may have overridden any potential benefit of gaze information for recognition performance.</p><p>The present results replicate those of <ref type="bibr" target="#b25">Jeunehomme et al. (2018)</ref> regarding the density of recalled experience units in naturalistic event memory, both overall and within distinct segments of action versus navigation. In both experiments, we observed experience unit densities comparable to those reported in their study, and moments involving actions were recalled with finer granularity than moments involving navigation. Interestingly, a similar pattern emerged in our recognition memory task, in which action segments were better recognized than navigation segments. Action segments were thus both more accessible during retrieval and more available in memory overall. These results align with the mechanisms of memory compression discussed above: navigation segments typically consisted of extended stretches in which participants walked in a straight line through slowly changing spatial environments-conditions that, according to the view described above, makes them highly compressible in memory. In contrast, actions introduced frequent breakpoints and shifts in goal processing <ref type="bibr" target="#b20">(Hard et al., 2011;</ref><ref type="bibr" target="#b51">Tversky et al., 2004)</ref>, increasing their likelihood of being encoded and subsequently recalled <ref type="bibr" target="#b23">(Jeunehomme &amp; D'Argembeau, 2020)</ref>. Taken together, these findings suggest that episodic memory is biased toward encoding goal-relevant activity, consistent with the proposal that it functions as "a record of short-term goal processing" <ref type="bibr" target="#b10">(Conway, 2009</ref><ref type="bibr">(Conway, , p. 2310))</ref>.</p><p>While the present findings help delineate the contributions of encoding and retrieval processes to the temporal compression of events in episodic memory, further research is needed to more precisely characterize the types of information that each process preferentially retains. In addition, the present study did not address the potential role of memory consolidation in shaping the temporal structure of event representations. Consolidation processes acting on encoded traces may contribute to the stabilization and restructuring of memory representations over time <ref type="bibr" target="#b18">(Gilboa &amp; Moscovitch, 2021)</ref>. It is plausible that consolidation selectively preserves certain elementssuch as salient actions or goal-directed behaviors-while allowing less informative or redundant details to decay or become inaccessible. One way to investigate this possibility is to manipulate the delay between encoding and retrieval (for review, see <ref type="bibr" target="#b41">Radvansky et al., 2022)</ref>. In their original study, <ref type="bibr" target="#b25">Jeunehomme et al. (2018)</ref> found that the density of recalled experience units was comparable at immediate recall, after 24 h and after one week-suggesting that the accessible representation of the event remained relatively stable over these delays-but significantly decreased after one month. However, this finding pertains only to the segments that were successfully recalled. What about unrecalled segments? How long do such segments remain available in memory? Assessing recognition memory for unrecalled segments after different delays could help to elucidate the role consolidation processes in the temporal structure and selective retention of episodic experiences.</p><p>Finally, several limitations of the present study should be acknowledged. First, the video clips used in the recognition task were constrained by the field of view of the Neon eye tracking glasses. Although the frontal camera's field of view (V: 103°, H: 77°) covers most of the human binocular field of view, it remains possible that some environmental elements attended to by participants were not captured (e.g., if participants looked at something outside the frame due to gaze aversion), which could have affected recognition performance. Second, our recognition task focused exclusively on the visual modality, as it is the predominant modality in episodic memory representations for most people <ref type="bibr" target="#b10">(Conway, 2009)</ref>. However, it is possible that providing additional audio cues would further increase the accessibility of unrecalled segments. Third, participants were given instructions regarding the walk, which might have directed their attention towards specific environmental features. We took care not to emphasize any part of the walk, providing equivalent information for navigation and action segments. Thus, although an effect of instructions on memory cannot be entirely excluded, we consider it unlikely that the observed differences in memory for action versus navigation segments were driven by the instructions. 5</p><p>Finally, although participants were encouraged to report everything that came to mind during recall, it remains possible that some information was accessed but not verbalized, whether intentionally or unintentionally. For example, participants may have judged certain moments too trivial or self-evident to mention. While this possibility cannot be entirely excluded, we believe our instructions helped to reduce-though perhaps not eliminate-this potential bias.</p><p>In conclusion, episodic memory represents past experiences in a temporally compressed format-we remember events in much less time than it took to experience them. Prior research has linked this compression to the presence of temporal discontinuities in memories, whereby event recall consists of a series of discrete moments separated by substantial gaps. The present study aimed to investigate the origin of these omissions-specifically, whether the omitted segments remain available in memory but are not accessed during recall, or whether they are 5 Another reason why we do not believe that recall differences between actions and spatial displacements were due to task instructions is another recent (unpublished) study in our lab. Participants viewed video clips depicting either actions or spatial displacements and later recalled them, without receiving prior information about the clips' content. Even under these conditions, actions were recalled better-were less compressed-than spatial navigation events. simply unavailable. Using a recognition memory task informed by a preceding free recall task, we found that omitted segments were usually recognized by participants, though not as well as the segments that had been recalled. These findings suggest that the temporal structure of episodic memories is shaped by both encoding and retrieval processes, which jointly influence which aspects of experience are retained and accessed. Together, these mechanisms may support the formation of adaptive event memories, allowing individuals to retain information that is most relevant for guiding behavior and future decision-making.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>4 Figure 3</head><label>43</label><figDesc>Figure 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>Figure4B. A one-tailed paired-sample t-test showed that the AUCs were significantly higher for</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5</head><label>5</label><figDesc>Figure 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>, which implements Hautus (1995)'s correction for extreme values. We then pooled participants from both experiments (n = 40) to increase statistical power. On average, included participants contributed 21.48 recalled action trials (SD = 7.52), 42.5 recalled navigation trials (SD = 20.89), 23.14 unrecalled action trials (SD = 11.21) and 176.74 unrecalled navigation trials (SD = 41.83).</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0"><p>Note that the exclusion of these two participants did not change the pattern of results.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1"><p>For all statistical analyses, when the assumptions of classical parametric tests were violated, we verified that the pattern of results was similar using robust statistical methods (i.e., based on 20% trimmed means and bootstrapping), which do not assume normality and homoscedasticity<ref type="bibr" target="#b14">(Field &amp; Wilcox, 2017)</ref>. As the results were similar, we only report results based on classical (nonrobust) inferential methods.</p></note>
		</body>
		<back>

			<div type="funding">
<div><head>Funding:</head><p>This work was supported by <rs type="funder">ULiège</rs> with a grant from the <rs type="funder">Wallonia-Brussels Federation -Concerted Research Actions</rs> (<rs type="grantNumber">ARC 23/27-05 -COMPRESS</rs>). <rs type="person">Arnaud D'Argembeau</rs> is a Research Director at the <rs type="institution">Fonds de la Recherche Scientifique (F.R.</rs><rs type="funder">S.-FNRS)</rs>, <rs type="funder">Belgium</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_fDpJMJ9">
					<idno type="grant-number">ARC 23/27-05 -COMPRESS</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability of data and materials:</head><p>The datasets analyzed in the current study are available in the following OSF repository:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code availability</head><p>The statistical analyses were conducted using jamovi (v2.6, The jamovi project, 2024), the corresponding files are available on the OSF repository at <ref type="url" target="https://osf.io/ze3hj/">https://osf.io/ze3hj/</ref> . ROC analyses were performed with the ROC toolbox by <ref type="bibr" target="#b29">Koen et al. (2017)</ref>. It is available at <ref type="url" target="https://github.com/jdkoen/roc_toolbox">https://github.com/jdkoen/roc_toolbox</ref>. The files used are available on the OSF repository.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statements</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of interest:</head><p>The authors have no relevant financial or non-financial interests to disclose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics approval:</head><p>The study was approved by the ethics committee of the Faculty of Psychology of the University of <ref type="bibr">Liège (ref. 11146-5769)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent to participate and for publication:</head><p>All participants provided written informed consent for the collection and the usage of their data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Authors' contribution:</head><p>Bastien Durocher: conceptualization, methodology, formal analysis, investigation, data curation, writing -original draft. Nathan Leroy: conceptualization, methodology, writing -review &amp; editing. William Warnier: investigation, data curation. Arnaud D'Argembeau: conceptualization, methodology, writing -review &amp; editing, supervision, funding acquisition.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Causal and Chronological Relationships Predict Memory Organization for Nonlinear Narratives</title>
		<author>
			<persName><forename type="first">J</forename><surname>Antony</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dhoat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bennion</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_02216</idno>
		<ptr target="https://doi.org/10.1162/jocn_a_02216" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2368" to="2385" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Neon Accuracy Test Report</title>
		<author>
			<persName><forename type="first">C</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dierkes</surname></persName>
		</author>
		<idno type="DOI">10.5281/ZENODO.10420388</idno>
		<ptr target="https://doi.org/10.5281/ZENODO.10420388" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">Pupil Labs</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">How do we remember events?</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bird</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cobeha.2020.01.020</idno>
		<ptr target="https://doi.org/10.1016/j.cobeha.2020.01.020" />
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="120" to="125" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Memory and navigation: Compression of space varies with route length and turns</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bonasia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Blommesteyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moscovitch</surname></persName>
		</author>
		<idno type="DOI">10.1002/hipo.22539</idno>
		<ptr target="https://doi.org/10.1002/hipo.22539" />
	</analytic>
	<monogr>
		<title level="j">Hippocampus</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="12" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Measuring memory is harder than you think: How to avoid problematic measurement practices in memory research</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wixted</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-022-02179-w</idno>
		<ptr target="https://doi.org/10.3758/s13423-022-02179-w" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="421" to="449" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Hippocampal-prefrontal encoding activation predicts whether words can be successfully recalled or only recognized</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brassen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weber-Fahr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sommer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Lehmbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Braus</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bbr.2006.04.002</idno>
		<ptr target="https://doi.org/10.1016/j.bbr.2006.04.002" />
	</analytic>
	<monogr>
		<title level="j">Behavioural Brain Research</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="271" to="278" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Situation models and memory: The effects of temporal and causal information on recall sequence</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Brownstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Read</surname></persName>
		</author>
		<idno type="DOI">10.1080/09658210701539596</idno>
		<ptr target="https://doi.org/10.1080/09658210701539596" />
	</analytic>
	<monogr>
		<title level="j">Memory</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="730" to="745" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Boundaries Shape Cognitive Representations of Spaces and Events</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">K</forename><surname>Brunec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moscovitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Barense</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2018.03.013</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2018.03.013" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="637" to="650" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The causal structure and computational value of narratives</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Bornstein</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2024.04.003</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2024.04.003" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="769" to="781" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">People Are Unable to Recognize or Report on Their Own Eye Movements</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D F</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mahon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Irvine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Hunt</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470218.2016.1231208</idno>
		<ptr target="https://doi.org/10.1080/17470218.2016.1231208" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2251" to="2270" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Episodic memories</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Conway</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuropsychologia.2009.02.003</idno>
		<ptr target="https://doi.org/10.1016/j.neuropsychologia.2009.02.003" />
	</analytic>
	<monogr>
		<title level="j">Neuropsychologia</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2305" to="2313" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Slices of the past: How events are temporally compressed in episodic memory</title>
		<author>
			<persName><forename type="first">A</forename><surname>D'argembeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Jeunehomme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stawarczyk</surname></persName>
		</author>
		<idno type="DOI">10.1080/09658211.2021.1896737</idno>
		<ptr target="https://doi.org/10.1080/09658211.2021.1896737" />
	</analytic>
	<monogr>
		<title level="j">Memory</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="48" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Linking Detail to Temporal Structure in Naturalistic-Event Recall</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Diamond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Levine</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797620958651</idno>
		<ptr target="https://doi.org/10.1177/0956797620958651" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1557" to="1572" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">In search of lost time: Reconstructing the unfolding of events from memory</title>
		<author>
			<persName><forename type="first">M</forename><surname>Faber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Gennari</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2015.06.014</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2015.06.014" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Robust statistical methods: A primer for clinical psychology and experimental psychopathology researchers</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Field</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Wilcox</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.brat.2017.05.013</idno>
		<ptr target="https://doi.org/10.1016/j.brat.2017.05.013" />
	</analytic>
	<monogr>
		<title level="j">Behaviour Research and Therapy</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="19" to="38" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Where Have Eye Been? Observers Can Recognise Their Own Fixations</title>
		<author>
			<persName><forename type="first">T</forename><surname>Foulsham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kingstone</surname></persName>
		</author>
		<idno type="DOI">10.1068/p7562</idno>
		<ptr target="https://doi.org/10.1068/p7562" />
	</analytic>
	<monogr>
		<title level="j">Perception</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1085" to="1089" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The where, what and when of gaze allocation in the lab and the natural environment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Foulsham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kingstone</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2011.07.002</idno>
		<ptr target="https://doi.org/10.1016/j.visres.2011.07.002" />
	</analytic>
	<monogr>
		<title level="j">Vision Research</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="1920" to="1931" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Structured Event Memory: A neuro-symbolic model of event cognition</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Franklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000177</idno>
		<ptr target="https://doi.org/10.1037/rev0000177" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="327" to="361" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">No consolidation without representation: Correspondence between neural and psychological representations in recent and remote memory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gilboa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moscovitch</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2021.04.025</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2021.04.025" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="2239" to="2255" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural correlates of availability and accessibility in memory</title>
		<author>
			<persName><forename type="first">R</forename><surname>Habib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Nyberg</surname></persName>
		</author>
		<idno type="DOI">10.1093/cercor/bhm201</idno>
		<ptr target="https://doi.org/10.1093/cercor/bhm201" />
	</analytic>
	<monogr>
		<title level="j">Cerebral Cortex</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1720" to="1726" />
			<date type="published" when="1991">2008. 1991</date>
			<pubPlace>New York, N.Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The shape of action</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Hard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Recchia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0024310</idno>
		<ptr target="https://doi.org/10.1037/a0024310" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="586" to="604" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Corrections for extreme proportions and their biasing effects on estimated values ofd′</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Hautus</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03203619</idno>
		<ptr target="https://doi.org/10.3758/BF03203619" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods, Instruments, &amp; Computers</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="51" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The time to remember: Temporal compression and duration judgements in memory for real-life events</title>
		<author>
			<persName><forename type="first">O</forename><surname>Jeunehomme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>&amp; D'argembeau</surname></persName>
		</author>
		<idno type="DOI">10.1177/1747021818773082</idno>
		<ptr target="https://doi.org/10.1177/1747021818773082" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="930" to="942" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Event segmentation and the temporal compression of experience in episodic memory</title>
		<author>
			<persName><forename type="first">O</forename><surname>Jeunehomme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>&amp; D'argembeau</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00426-018-1047-y</idno>
		<ptr target="https://doi.org/10.1007/s00426-018-1047-y" />
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="481" to="490" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Memory editing: The role of temporal discontinuities in the compression of events in episodic memory editing</title>
		<author>
			<persName><forename type="first">O</forename><surname>Jeunehomme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>&amp; D'argembeau</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0001141</idno>
		<ptr target="https://doi.org/10.1037/xlm0001141" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="766" to="775" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Temporal compression in episodic memory for real-life events</title>
		<author>
			<persName><forename type="first">O</forename><surname>Jeunehomme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Folville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stawarczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Van Der Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>&amp; D'argembeau</surname></persName>
		</author>
		<idno type="DOI">10.1080/09658211.2017.1406120</idno>
		<ptr target="https://doi.org/10.1080/09658211.2017.1406120" />
	</analytic>
	<monogr>
		<title level="j">Memory</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="759" to="770" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Events, narratives and memory</title>
		<author>
			<persName><forename type="first">N</forename><surname>Keven</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11229-015-0862-6</idno>
		<ptr target="https://doi.org/10.1007/s11229-015-0862-6" />
	</analytic>
	<monogr>
		<title level="j">Synthese</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2497" to="2517" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Carving event and episodic memory at their joints</title>
		<author>
			<persName><forename type="first">N</forename><surname>Keven</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X17001406</idno>
		<ptr target="https://doi.org/10.1017/S0140525X17001406" />
	</analytic>
	<monogr>
		<title level="j">The Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">What does it take to remember episodically? In Current Controversies in Philosophy of Memory</title>
		<author>
			<persName><forename type="first">N</forename><surname>Keven</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022">2022</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The ROC Toolbox: A toolbox for analyzing receiver-operating characteristics derived from confidence ratings</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Koen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Harlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Yonelinas</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-016-0796-z</idno>
		<ptr target="https://doi.org/10.3758/s13428-016-0796-z" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1399" to="1406" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Attentional profiles linked to event segmentation are robust to missing information</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Kosie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Baldwin</surname></persName>
		</author>
		<idno type="DOI">10.1186/s41235-019-0157-4</idno>
		<ptr target="https://doi.org/10.1186/s41235-019-0157-4" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Research: Principles and Implications</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Article 1</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and ANOVAs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lakens</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2013.00863</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2013.00863" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">863</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Working memory capacity for continuous events: The root of temporal compression in episodic memory?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Majerus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>&amp; D'argembeau</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2024.105789</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2024.105789" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">247</biblScope>
			<biblScope unit="page">105789</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The role of working memory in encoding the temporal structure of events in episodic memory : Evidence from a dual-task paradigm</title>
		<author>
			<persName><forename type="first">N</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Majerus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>&amp; D'argembeau</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13421-025-01798-7</idno>
		<ptr target="https://doi.org/10.3758/s13421-025-01798-7" />
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A neural network model of when to retrieve and encode episodic memories</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.74445</idno>
		<ptr target="https://doi.org/10.7554/eLife.74445" />
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">74445</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The psycho Package: An Efficient and Publishing-Oriented Workflow for Psychological Science</title>
		<author>
			<persName><forename type="first">D</forename><surname>Makowski</surname></persName>
		</author>
		<idno type="DOI">10.21105/joss.00470</idno>
		<ptr target="https://doi.org/10.21105/joss.00470" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page">470</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Evidence That Event Boundaries Are Access Points for Memory Retrieval</title>
		<author>
			<persName><forename type="first">S</forename><surname>Michelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Norman</surname></persName>
		</author>
		<idno type="DOI">10.1177/09567976221128206</idno>
		<ptr target="https://doi.org/10.1177/09567976221128206" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="326" to="344" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Speed of timecompressed forward replay flexibly changes in human episodic memory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Michelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Staresina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hanslmayr</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-018-0491-4</idno>
		<ptr target="https://doi.org/10.1038/s41562-018-0491-4" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="143" to="154" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Minimal memory for details in real life events</title>
		<author>
			<persName><forename type="first">P</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Kreiman</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-018-33792-2</idno>
		<ptr target="https://doi.org/10.1038/s41598-018-33792-2" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">16701</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Event boundaries and memory improvement</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Pettijohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Tamplin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Krawietz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Radvansky</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2015.12.013</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2015.12.013" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="136" to="144" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<ptr target="https://cran.r-project.org" />
		<title level="m">R: A Language and environment for statistical computing</title>
		<imprint>
			<publisher>Pupil Labs</publisher>
			<date type="published" when="2024">2025. 2024</date>
		</imprint>
	</monogr>
	<note>Computer software Pupil Cloud (Version 7.5) Version 4.4) [Computer software</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A new look at memory retention and forgetting</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Radvansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Doolen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Pettijohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ritchey</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0001110</idno>
		<ptr target="https://doi.org/10.1037/xlm0001110" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1698" to="1723" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Radvansky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<title level="m">Event cognition</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Constructing Experience: Event Models from Perception to Action</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Richmond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2017.08.005</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2017.08.005" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="962" to="980" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">That&apos;s Not a Two-Sided Test! It&apos;s Two One-Sided Tests! Significance</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rubin</surname></persName>
		</author>
		<idno type="DOI">10.1111/1740-9713.01619</idno>
		<ptr target="https://doi.org/10.1111/1740-9713.01619" />
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="50" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Recognition memory and the medial temporal lobe: A new perspective</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Wixted</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Clark</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn2154</idno>
		<ptr target="https://doi.org/10.1038/nrn2154" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews. Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="872" to="883" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Differential encoding mechanisms for subsequent associative recognition and free recall</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Staresina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Davachi</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.2877-06.2006</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.2877-06.2006" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">36</biblScope>
			<biblScope unit="page" from="9162" to="9172" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Event boundaries in perception affect memory encoding and updating</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Swallow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Abrams</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0015631</idno>
		<ptr target="https://www.jamovi.org" />
	</analytic>
	<monogr>
		<title level="j">Journal of Psychology: General</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="236" to="257" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>Version 2.6 Computer Software</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Image memorability influences memory for where the item was seen but not when</title>
		<author>
			<persName><forename type="first">N</forename><surname>Trinkl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13421-024-01635-3</idno>
		<ptr target="https://doi.org/10.3758/s13421-024-01635-3" />
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1112" to="1123" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Memory and consciousness</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tulving</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0080017</idno>
		<ptr target="https://doi.org/10.1037/h0080017" />
	</analytic>
	<monogr>
		<title level="j">Canadian Psychology/Psychologie Canadienne</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Availability versus accessibility of information in memory for words</title>
		<author>
			<persName><forename type="first">E</forename><surname>Tulving</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Pearlstone</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0022-5371(66)80048-8</idno>
		<ptr target="https://doi.org/10.1016/S0022-5371(66)80048-8" />
	</analytic>
	<monogr>
		<title level="j">Journal of Verbal Learning and Verbal Behavior</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="381" to="391" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Events by Hands and Feet</title>
		<author>
			<persName><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15427633scc0401_2</idno>
		<ptr target="https://doi.org/10.1207/s15427633scc0401_2" />
	</analytic>
	<monogr>
		<title level="m">Spatial Cognition and Computation</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">You think you know where you looked? You better look again</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Võ</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-H</forename><surname>Aizenman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename></persName>
		</author>
		<idno type="DOI">10.1037/xhp0000264</idno>
		<ptr target="https://doi.org/10.3390/vision3020021" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1477" to="1481" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Receiver operating characteristics (ROCs) in recognition memory: A review</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Yonelinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Parks</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.133.5.800</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.133.5.800" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="800" to="832" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Event Perception and Memory</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-010419-051101</idno>
		<ptr target="https://doi.org/10.1146/annurev-psych-010419-051101" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="165" to="191" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Event Perception: A Mind/Brain Perspective</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Zacks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">K</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Swallow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Braver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Reynolds</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.133.2.273</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.133.2.273" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="273" to="293" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
