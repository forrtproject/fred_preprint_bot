<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Use of adjectives in prediction during spoken language comprehension in older adults: Evidence from anticipatory eyemovements</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Anurag</forename><surname>Anurag</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centre of Behavioural and Cognitive Sciences</orgName>
								<orgName type="institution">University of Allahabad</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Niharika</forename><surname>Singh</surname></persName>
							<email>niharika@cbcs.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Centre of Behavioural and Cognitive Sciences</orgName>
								<orgName type="institution">University of Allahabad</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Centre of Behavioural and Cognitive Sciences</orgName>
								<orgName type="institution">University of Allahabad</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Use of adjectives in prediction during spoken language comprehension in older adults: Evidence from anticipatory eyemovements</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6FC71F326D985245E5CD2F9CFE18210E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Aging</term>
					<term>Anticipation</term>
					<term>Language comprehension</term>
					<term>anticipatory eye movements</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Previous research suggests that while cognitive abilities decline with age, semantic and verbal knowledge remain stable or may even improve with age. The present study investigated how aging impacts anticipation during comprehension, considering that both language experience and cognitive factors modulates prediction during comprehension. We investigated whether older adults can utilize gender-marked adjectives to predict the target noun during Hindi sentence comprehension. Two visual world paradigm studies (Experiment 1 &amp; 2) were conducted, where young and older adults listened to sentences containing a target word while looking a visual display containing the target object along with three distractors. The sentences consisted of adjectives which were highly associated with the target object. We measured anticipatory gaze towards the target object before it was mentioned in the sentence indexing prediction using adjective. The results from both experiments showed that older adults exhibited anticipatory gaze towards the target noun soon after hearing adjective, which did not differ from that of young adults. The findings provide robust evidence that older adults can effectively use semantic, syntactic or associative information from the adjective to predict the target noun, similar to young adults. The present findings show that older adults can generate prediction using their world knowledge and accumulated language experience throughout their lives.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The process of aging is marked by a gradual decline in cognitive abilities, which include, diminished executive control, processing speed, and overall reduction in memory capacity <ref type="bibr" target="#b9">(Huettig &amp; Janse, 2016;</ref><ref type="bibr">Braver &amp; West, 2008;</ref><ref type="bibr">Raz, 2000;</ref><ref type="bibr">West, 1996)</ref>. Despite marked decline in various cognitive components, semantic knowledge and vocabulary (i.e. crystallized intelligence) remain resilient or may even be enhanced with aging. This has led to a great deal of research on understanding how aging impacts anticipation during language comprehension, as both language experience and cognitive factors, contribute to anticipation. Previous studies present conflicting evidence regarding prediction in older adults during comprehension <ref type="bibr">(Federmeier et, al.,2010;</ref><ref type="bibr">Dave et. al., 2021;</ref><ref type="bibr">Stine-Morrow, Miller, &amp; Hertzog, 2006;</ref><ref type="bibr">Payne &amp; Stine-Morrow, 2012)</ref>. There are studies that show a decline in anticipation in older population, however, contrary to this, there are some studies which have found that older adults can generate prediction comparable to younger adults by relying on the rich context and semantic knowledge <ref type="bibr">(Milburn et al., 2023;</ref><ref type="bibr">Payne &amp; Silcox, 2019;</ref><ref type="bibr" target="#b17">Pichora-Fuller, 2008;</ref><ref type="bibr">Stine-Morrow et al., 2006;</ref><ref type="bibr">Lash et al., 2013;</ref><ref type="bibr">Choi et al., 2017)</ref>. In the present study, we examined whether older adults can use gender-marked adjectives during comprehension of spoken Hindi sentences to predict the target noun in real time using visual world paradigm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language experience and anticipation</head><p>Anticipation during language comprehension refers to the generation of predictions regarding future elements in a sentence, including words, phrases, or even broader discourse structures. Readers or listeners constantly generate expectations about the likely course of a sentence, drawing from various cues, such as such as thematic roles <ref type="bibr">(Altmann,1999;</ref><ref type="bibr" target="#b1">Altmann &amp; Kamide, 1999)</ref>, syntactic frames <ref type="bibr">(Chen, Gibson, &amp; Wolf, 2005;</ref><ref type="bibr">Staub &amp; Clifton, 2006)</ref>, morpho-syntactic structures <ref type="bibr" target="#b16">(Kamide, Scheepers, &amp; Altmann, 2003;</ref><ref type="bibr">Huettig &amp; Brouwer,2015)</ref>, prosody <ref type="bibr">(Weber, Grice, &amp; Crocker, 2006)</ref>, linguistic knowledge <ref type="bibr" target="#b12">(Mishra et al. 2012;</ref><ref type="bibr">Mani &amp; Hueittig, 2012)</ref>, pragmatics, or world knowledge <ref type="bibr">(Kamide, Altman &amp; Scheepers, 2003;</ref><ref type="bibr">Warren &amp; Dickey, 2021;</ref><ref type="bibr">McRae &amp; Matsuki, 2009)</ref>. As language experience increases, the use of these cues becomes efficient leading to more refined and accurate predictions <ref type="bibr" target="#b12">(Mishra et al. 2012;</ref><ref type="bibr">Cheimariou, Farmer, &amp; Gordon, 2021)</ref>. Language proficiency, vocabulary size, grammar, and efficient language processing contribute to a person's ability to accurately predict during language comprehension. Previous studies have shown that individuals with better vocabulary knowledge <ref type="bibr">(Fernaldd, Perfors, &amp; Marchman, 2006;</ref><ref type="bibr">Tokildsen et al., 2008)</ref> or greater exposure to print, process words more automatically <ref type="bibr">(Cheimariou, Farmer, &amp; Gordon. (2021;</ref><ref type="bibr">)</ref>. <ref type="bibr">Mani &amp; Hueittig (2012)</ref> found that children with higher vocabulary size launched more anticipatory gaze towards the target object when they heard sentences with constraining verb than sentences with non-constraining verbs. Similar findings were replicated with 8 year old children using visual world paradigm, where skilled readers displayed more anticipatory gaze towards the target before spoken onset of the noun in a semantically constraining condition, thus showing language fluency and efficiency contributes to prediction <ref type="bibr" target="#b10">(Mani &amp; Huettig, 2016)</ref>. <ref type="bibr" target="#b12">Mishra et al. (2012)</ref> showed that prediction during comprehension in adults is modulated by different levels of literacy. It was found that individuals with lower literacy were less effective at utilizing adjectives as a cue to predict upcoming spoken linguistic input compared to those with high literacy. The participants were shown a visual arrangement of objects and simultaneously heard sentences with adjectives which were highly constraining towards one of the objects in the display. High literates quickly shifted their gaze towards the object compatible with the adjective before it was mentioned in the sentence, while low literates only did so after hearing the name of the object in the sentence. Likewise, evidence from the visual world paradigm has demonstrated use of different sources of knowledge as a cue for prediction during sentence comprehension <ref type="bibr" target="#b1">(Altmann &amp; Kamide, 1999;</ref><ref type="bibr" target="#b7">Boland, 2005;</ref><ref type="bibr" target="#b8">Borovsky et al., 2012;</ref><ref type="bibr" target="#b16">Kamide et al., 2003;</ref><ref type="bibr">Mack et al., 2013;</ref><ref type="bibr">Milburn et al., 2016)</ref>. It has been found that people use world knowledge to predict verb argument. Altman and colleagues (1999) investigated how selectional restriction of verb is used in online prediction of likely theme (object) of a verb using visual world paradigm. Altaman and <ref type="bibr" target="#b1">Kamide (1999)</ref> demonstrated that individuals utilize the selectional restriction of verbs (e.g., eat vs. move) to predict the verb-argument. Participants were more likely to launch anticipatory eye movements towards a picture of a cake upon hearing a sentence with constraining (For example, "The boy will eat the….") compared to when they heard sentences with non constraining verb (For example, "The boy will move the…."). This shows people use selectional restriction of verb to narrow down the set of plausible objects to follow. <ref type="bibr" target="#b16">Kamide et al., (2003)</ref> showed that world knowledge can further refine the generation of prediction of verb argument. Their findings showed that participants combined world knowledge about the agent (girl vs. man) with the restrictions of the verb to drive predictions about the verb argument. For example, participants gazed more towards the picture of a carousel in the display upon hearing, "The girl will ride the… ", whereas looked more towards the picture of a motor cycle when they heard, "The man will ride the…..". This shows the participants used a blend of world knowledge and verb selectional restriction for generating predictions. In sum, the evidence suggests that prediction during comprehension is influenced by language experience and world knowledge <ref type="bibr">(Milburn, 2016;</ref><ref type="bibr" target="#b19">Kukona et al., 2016;</ref><ref type="bibr">Magnuson,2019;</ref><ref type="bibr">See Kamide, 2008</ref> for more details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anticipation and Aging:</head><p>Previous research presents mixed evidence on how anticipation during sentence comprehension is impacted by aging. There are some studies which have shown that older adults have difficulty in generating expectations about upcoming words, thus indicating towards reduced prediction abilities with aging. These findings are consistent with the broader cognitive changes associated with aging, including declines in working memory capacity, processing speed, and inhibitory control, which have a negative impact <ref type="bibr">(Federmeier &amp; Kutas, 2005;</ref><ref type="bibr"></ref> Janse &amp; Jesse 2014) on various aspects of cognition, including memory and language processing. For example, working memory plays a crucial part in sentence comprehension and anticipation. High working memory capacity enables individuals to predict better and also helps in resolving prediction errors during sentence processing <ref type="bibr">(Häuser et al., 2017)</ref>. Working memory serves as an interface for interaction of long term memory, linguistic information and visual attention during language comprehension in a visual context <ref type="bibr">(Huettig, Oliver &amp; Hartsuikar, 2011)</ref>. <ref type="bibr">Huettig and Jense (2016)</ref> did a study using a visual world paradigm where the participants received spoken instructions while viewing four objects, and the articles employed in the sentence were gender-marked in a way that ensured agreement in gender solely with the target. The study used multiple regression analyses to show that both verbal and spatial working memory influence language-mediated anticipatory eye movements. The finding suggested that enhanced working memory abilities and faster processing speed predicted anticipatory eye movements. In sentence reading, working memory can influence regression probability, and processing speed influences the go-past time in the eye-tracking task. These factors appeared to significantly impact general language processing and prediction in particular <ref type="bibr">(Cheimariou. S, 2016)</ref>. So any deficit in cognitive factors could hinder the cognitive resources necessary for generating and maintaining predictions. In a sentence reading study by <ref type="bibr" target="#b18">Kliegl et al. (2004)</ref> indicate that both, young and older adults were influenced by predictability by the context, but the way it affected them differed. Younger adults tended to skip words that were highly predictable, whereas older adults did not exhibit the same predictability-related effect in skipping rates. Instead, older adults made more fixations on unpredictable words and fewer fixations on highly predictable ones. Consequently, both age groups read highly predictable words more swiftly than less predictable ones, but the advantage in reading for predictable words was manifested differently depending on age. In some contexts, older adults are able to use the cue to process the upcoming input, but when cognitive load is increased, they fail to perform sentence processing like younger adults <ref type="bibr">(Hauser et al, 2017)</ref>. In a recent research by <ref type="bibr">Fernandez et al., (2020)</ref>, they tested the impact of speech rate on anticipatory eye movement of young and old adults during spoken sentence comprehension. They varied speech rates (3.5, 4.5, 5.5 and 6.0 syllables per second) of the presented sentences. The results showed that older adults exhibit anticipatory behaviour akin to that of younger adults and even display anticipatory gaze towards the target at a slower speech rate of 3.5 to 4.5 syllables per second but not with rapid speech rates of 5.5 and 6.0 syllables per seconds. Further, evidence form ERP studies have shown that older adults exhibited a smaller and delayed N400 as compared to young adults when processing highly constraining sentences with unexpected endings. This reduced N400 in older adults indicate failure of prediction of the upcoming target word <ref type="bibr">(Federmeier et al., 2007;</ref><ref type="bibr">Wlotko et al. (2010;</ref><ref type="bibr">DeLong et al., 2012;</ref><ref type="bibr">Federmeier &amp; Kutas, 2005;</ref><ref type="bibr">Federmeier et al., 2010)</ref>. In contrast, alternative research proposes that while older adults experience age-related cognitive decline, their ability to generate predictions remains intact. Older adults can rely on well-established world knowledge, simpler syntactic cues, or broader lexical heuristics to formulate predictions that differ in nature from those of younger adults <ref type="bibr">(Cheimariou. S, 2016</ref><ref type="bibr">, Milburn, 2021)</ref>. It is argued that crystallized knowledge, including world knowledge remains well preserved in older adults despite cognitive decline <ref type="bibr">(Horn &amp; Cattell, 1967)</ref>. Previous studies have shown that older adults compensate for the effects of cognitive decline by relying on their well preserved world knowledge for prediction during comprehension <ref type="bibr">(Milburn et. al., 2023;</ref><ref type="bibr" target="#b17">Pichora-Fuller, 2008;</ref><ref type="bibr">Stine-Morrow et al., 2006</ref><ref type="bibr">). Milburn et. al., (2023)</ref>, findings provide clear evidence that older adults are able to exploit the world knowledge to activate upcoming verb arguments, particularly when that world knowledge is cued by semantically-rich verb + argument combinations (e.g., <ref type="bibr" target="#b8">Borovsky et al., 2012;</ref><ref type="bibr" target="#b16">Kamide et al.,2003)</ref>. The older participants showed more pronounced prediction as compared to young adults when they heard sentences with agent + constraining verb( The dog will drink…) than when they predicted solely on the basis of constraining verb( Someone will drink…). Stronger prediction in older adults in the agent + verb condition shows that older adults were able to take advantage of semantic/world knowledge better than younger adults which resulted in more anticipatory gaze towards the target for the older adults. This is similar to visual-world findings reported by <ref type="bibr" target="#b3">Baltaretu and Chambers (2018)</ref> which found that older adults exhibited anticipatory fixations to an upcoming spoken input as quickly as young adults' did. This aligns with the idea that older adults can effectively exploit semantic context while language comprehension <ref type="bibr" target="#b17">(Pichora-Fuller, 2008;</ref><ref type="bibr">Stine-Morrow et al., 2006)</ref>, demonstrating comparable performance to younger adults when rich semantic context is available <ref type="bibr">(Lash et al., 2013;</ref><ref type="bibr">Payne &amp; Silcox, 2019)</ref>. It is quite possible that lifelong linguistic experience in older adults makes them more skilled language users, enabling them to predict upcoming information better than young adults.</p><p>Nevertheless, this advantage is counterbalanced by age-related cognitive declines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Present Study</head><p>Previous studies on prediction in older adults primarily focused on anticipation using rich semantic context or verb-argument structures. However, it requires further investigation whether older adults can rely upon their world knowledge to predict target word utilizing adjectives and grammatical gender information as cues for prediction. Use of gender-marked adjective for prediction requires knowledge of morphosyntactic rules, as well as semantic/world knowledge about the noun and adjective associations. The frequent co-occurrence of certain adjectives and nouns in everyday language (for example: soft fur; green leaves) contributes to our semantic and world knowledge <ref type="bibr">(Fyshe et al., 2019)</ref>. Previous investigations with young adults indicate use of gender-marked adjectives to anticipate subsequent noun referent. <ref type="bibr">Gussow et al. (2019)</ref> explored the role of gender-marked adjectives in adjusting lexical predictions during Spanish sentence comprehension. It was found that participants gaze was constrained by the gender marked adjectives such that participants looked towards the gender marked noun that matched with the gender marked adjectives. Similarly, in Hindi language, adjectives are gender marked (e.g. chota (small(masculine) and choti(small, feminine)) matching with the modified noun's gender. Using a visual world paradigm <ref type="bibr" target="#b12">Mishra et al.(2012)</ref> presented spoken Hindi sentences, with gender-marked adjectives followed by the particle "wala/wali" and a noun (e.g., "Abhi aap ek unvha wala darwaza dekhengey" (Right now, you are going to see a tall door). It was found that young literates launched more anticipatory gaze towards the noun matching with the gender marked adjective. Notably, the study found that adjectives were the sole predictor for the noun, as the sentences themselves were contextually neutral. Taken together, these findings illustrate the use of gender marked adjectives for anticipation.</p><p>In current study, we conducted two experiments to investigate the use of gender-marked adjectives as a cue for anticipation during spoken sentence comprehension in Hindi, comparing young and older adults using visual world paradigm. In both the experiments, we used the same sentences from the study by <ref type="bibr" target="#b12">Mishra et al. (2012)</ref>, which consisted of gender-marked adjective as a cue to predict the target noun. The visual display was consisted of a target object along with three distarctor objects. The spoken sentences offered no other semantic cues to predict the noun except for the adjective ( Abhi aap ek nukili waali sui dekhengey/Now you will see a sharp needle), which was highly associated with the target noun. The two experiments conducted only differed in the duration of the display preview time. It was hypothesized that if older adults can use adjectives as a cue to predict upcoming target noun, both young and older adults would demonstrate comparable anticipatory looks to the noun. Conversely, if older adults cannot utilize adjectives to predict the target noun, they will exhibit fewer or no anticipatory eye movements towards the noun upon hearing the adjective compared to young adults.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods Participants</head><p>Twenty-nine young adults (20 to 30 years, mean=22.62, SD=2.22) and twenty-four older adults (55 to 75 years, mean=63.08, SD=5.51) participated in the study. All participants had normal or corrected-tonormal vision and no history of speech-language, hearing, or neuropsychological disorders. Participants self-identified as native Hindi speakers and had at least 15 years of formal education. To exclude the presence of unreported memory or any other cognitive disorders, participants were given the Mini-Mental State Exam (MMSE: <ref type="bibr">Folstein, Folstein &amp; McHugh, 1975)</ref>. All participants achieved a score of 28 or higher on the MMSE, indicating cognitive health (young adult's mean=29.03, SD= 0.86; old adult's mean=29.12, SD=0.90). These scores are above the lower-quartile cutoff scores for healthy older adults <ref type="bibr" target="#b6">(Bleecker et al., 1988)</ref>. The ethics committee of University of Allahabad approved the study, and informed consent was obtained from all participants. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Stimulus Presentation</head><p>The experiment consisted of presentation of 58 visual displays (28 experimental and 30 fillers), each consisting of four visual objects (one target and three distractors) paired with a spoken sentence. Each experimental sentence consisted of a lead-in phrase ("abhi aap ek"/Now you will) followed by an adjective (e.g., 'nukili', sharp), then the particle ('wala'/'wali') and a noun (e.g., 'Sui', needle)(e.g. "Abhi aap ek nukili waali sui dekhengey"/Now you will see a sharp needle). The adjective (e.g., 'nukili' sharp) was associated with only one object in the display.</p><p>Similarly, the grammatical gender of the adjective agreed only with the target object, not with the distractor objects in the same display. The filler sentences were without adjectives (eg. "Abhi aap ek kitab dekhege"/ Now you see a book). A rating study was conducted for sentences and pictures to select the most suitable stimuli for the experiment. For sentence rating, 20 young Hindi-speaking adults from the University of Allahabad participated; none participated in the main study. Eighty sentences were provided for the rating, 40 sentences with adjectives and 40 filler sentences. For sentences with adjectives, participants rated them based on adjectivenoun association and understandability of the sentences on a 7-point Likert scale. Twenty-eight experimental sentences and 30 filler sentences with an average rating of more than 6 were selected for the main study.</p><p>All the sentences were recorded by a female native Hindi speaker. Visual displays used in the experiment (Figure <ref type="figure" target="#fig_0">1</ref>) consisted of line drawings of the target object (e.g., sui) and three unrelated distractors. All visual stimuli were frequent and common objects known to both young and old participant groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants were seated at a comfortable distance from a 24-inch monitor. A central fixation point appeared on the screen for 750 ms, followed by a blank screen for 500 ms. then four pictures appeared on the screen. The positions of the pictures were randomized across four fixed positions of a (virtual) grid on every trial. The auditory sentence was presented 1500 ms from the display onset. Participants have to perform a 'look and listen' task <ref type="bibr" target="#b1">(Altmann &amp; Kamide, 1999)</ref>.Participants' eyes were tracked using an Eyelink 1000 tracker (SR Research Ltd., Toronto, Ontario, Canada) with a sampling rate of 1000Hz. The study utilized the Experiment Builder software (SR Research Ltd., Toronto, Ontario, Canada) to design and administer the experiment. Participants observed stimuli with both eyes on a monitor situated around 60 cm from them, and head movements were restricted by using forehead and chin rests. Following an explanation of the experiment's structure, the eye tracker was calibrated using a 9-point fixation stimulus to ensure precise and accurate tracking of the eyes across the entire display screen </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data coding procedure</head><p>The information from the right eye of each participant was examined and categorized based on fixations, saccades, and blinks. The temporal aspects of fixations were determined in relation to the commencement of the adjective in the spoken utterance. Fixations were classified according to whether they focused on the target picture or unrelated distractor pictures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Figure <ref type="figure" target="#fig_2">3</ref> displays a time-course graph illustrating the fixation proportion to the target object or averaged distractors for young and old Adults. The curves on the graph are synchronized with the acoustic onset of the spoken adjective, and the average noun onset was 1240ms (approx.). The x-axis represents time in milliseconds from the acoustic onset of spoken adjectives. Each data point on the graph represents the proportion of trials with a fixation at that specific time point <ref type="bibr">(Huettig &amp; Altmann, 2005)</ref>. As we can see in Figure <ref type="figure" target="#fig_2">3</ref>, participants start to shift their eye gaze towards the target (noun) well before acoustic onset. This is because they can extract information about the upcoming input from the adjective (e.g., 'nukili wali') and use that information to generate predictions about the upcoming noun ('sui'), which helps them shift their eye gaze towards the target. Proportions of fixation were calculated for each trial, taking into account the specific starting (for example, at the onset of the noun) and ending points (for example, at the offset of the noun) for that particular trial. To compare proportion of looks for the target and distractor images for each time-window we calculated the ratio between the proportion of fixations to the target image and the sum of the proportions of fixations towards the target and the distractor images together:</p><p>target-to-distractor ratio= (looks to target)/(looks to target+looks to distractor)</p><p>To calculate ratios without encountering undefined expressions due to instances where neither the target nor the distractors received any looks, a tiny constant of 0.00000001 was added to each observation (the number of glances at an image per subject for each item in every time window). If the ratio exceeds 0.5, it signifies that the expected image garnered more than half of the total looks directed at both the expected and alternative images combined (refer to <ref type="bibr">Dahan &amp; Tanenhaus, 2005;</ref><ref type="bibr" target="#b11">Huettig &amp; McQueen, 2007;</ref><ref type="bibr">McQueen &amp; Huettig, 2012)</ref>.</p><p>For statistical analysis, the ratios were subjected to a logit transformation, ensuring that a ratio of 0.5, which indicates equal probabilities of fixating on the expected versus the alternative image, was mapped to a value of 0 in the transformed dataset. Linear mixedeffects models were estimated utilizing the lme4 package <ref type="bibr">(Bates, Maechler, &amp; Dai, 2009)</ref> in the R programming environment (R Core Team, 2023). The model with a formula: fixation ~ time_window * group + (1 | Participants) + (1 | trial) was used .This implies that fixation is modeled as a function of the effects of time window, group, and their interaction, with random intercepts for participants and trial.</p><p>The results showed comparable anticipation effect for both the age groups on the target-to-distractor ratio, as model showed that the young group's fixation did not significantly differ from the older group at the reference level (B=-1.402, SE=1. This result suggests there was no statistical difference between both the groups, as both young and old adults were able to use the information extracted at adjectives to guide their anticipatory eye gaze towards the target image well before the unfolding of the target(noun) word <ref type="bibr">(Cheimariou. S, 2016</ref><ref type="bibr">, Milburn et. al., 2023</ref><ref type="bibr" target="#b3">, Baltaretu and Chambers (2018)</ref>.</p><p>Overall, the results indicate that both young and older adults were able to use the adjective to predict the upcoming noun; further older adults did not differ in launching their anticipatory gaze towards the object depicting the noun in the sentence. This shows that older adults could use the predictive cues as efficiently and robustly as the young participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2:</head><p>Huettig and Guerra (2019), using visual world paradigm showed that reducing the display preview time makes prediction challenging. Experiment 2 was designed to investigate how both groups would perform when the time is given to process the visual information is reduced. In the visual world paradigm, when participants see the visual display, they activate visual, phonological, and semantic representations of the objects in the display, which are maintained in their working memory <ref type="bibr">(Heuttig, Mishra, &amp; Olivers, 2012;</ref><ref type="bibr" target="#b11">Huettig &amp; McQueen, 2007)</ref>.</p><p>During comprehension of spoken sentences, the match between the predicted target item and its representations in working memory drives participants' gaze towards the visual object corresponding to the predicted target. However, reducing display time can hamper the activation of these representations, making prediction difficult. Experiment 2 was same as experiment 1 except for the visual preview duration. In experiment 1, participants had a preview display of 1500 ms before the acoustic onset of the sentence, whereas in the Experiment 2, it was reduced to 500ms. It was hypothesized that short preview duration would hamper anticipation for both the groups, but older would be affected the most.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Twenty-four young adults (20 to 30 years, mean=22.41, SD=2.35) participated in the experiment. All the participants were current residents of Prayagraj (UP, India) and native Hindi speakers, and collegegoing students. All the participants had normal vision, and none had any known hearing problems. Twenty-four old adults (55 to 75 years, mean=62.79, SD=5.57) from Prayagraj, with self-reported normal or corrected-to-normal vision and without a history of speech-language, hearing, or neuropsychological disorders participated in the experiment. Participants self-identified as native Hindi speakers and had at least 15 years of formal education. In order to exclude the presence of unreported memory or other cognitive disorders, participants were given the Mini-Mental State Exam (MMSE: <ref type="bibr">Folstein, Folstein &amp; McHugh, 1975)</ref>. All participants scored 28 or better on the MMSE (young adult's mean=29.04, SD= 0.90; old adult's mean=28.95, SD=0.85), which is above the lower-quartile cutoff scores for healthy older adults <ref type="bibr" target="#b6">(Bleecker et al., 1988)</ref>. The ethics committee of University of Allahabad approved the study, and informed consent was obtained from all participants. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants were seated at a comfortable distance from a 24-inch monitor. A central fixation point appeared on the screen for 750 ms, followed by a blank screen for 500 ms. then four pictures appeared on the screen. The positions of the pictures were randomized across four fixed positions of a (virtual) grid on every trial. The auditory sentence was presented 500 ms from the display onset. Participants have to perform a 'look and listen' task <ref type="bibr" target="#b1">(Altmann &amp; Kamide, 1999)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Result</head><p>The outcomes are displayed in a manner consistent with the approach used in experiment 1. Figure <ref type="figure">5</ref> shows a time-course graph illustrating the fixation proportion to the target object and averaged distractors for young and old adults. The curves on the graph are synchronized with the acoustic onset of the spoken adjective. The x-axis represents time in milliseconds from the acoustic onset of spoken adjectives. As we can see in Figure <ref type="figure">5</ref>, like Experiment 1, participants in Experiment 2 also start shifting their eye gaze towards the target (noun) well before acoustic onset.</p><p>Figure <ref type="figure">5</ref>: Changes in fixation proportions on the target objects and</p><p>(averaged) unrelated distractor objects for young and old adults A comparable anticipation effect was found for both groups on the targetto-distractor ratio, as model showed that the young group's fixation ratio did not differ significantly from the older group at the reference level that the data did not provide evidence of differences between groups in the specified time intervals.</p><p>The results of the Experiment 2 replicate the pattern obtained in the Experiment 1, thus providing evidence of comparable prediction abilities in the older adults compared to the young adults. Further, it shows that both groups can predict even with shorter preview duration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion:</head><p>The main aim of the study was to investigate whether older adults can generate prediction during spoken sentence comprehension using gender-marked adjectives in Hindi. To examine this, two experiments were conducted where young and older adults were presented with sentences consisting of gender-marked adjectives related to the upcoming noun in the spoken sentence. Participants' anticipatory eye movements were tracked towards an array of images depicting the target (suii fem (needle)) that matched with gender-marked adjective (nukili waali) along with other three unrelated distractors (all feminie) while they listened to the spoken sentences.</p><p>The results indicate that soon after the onset of the adjective followed by the particle waala/waali, both young and older adults launched more anticipatory gaze towards the target object consistent with the adjective, compared to the distractors. This was well evident through a higher target-to-distractor ratio in both the Baseline offset-Adjective offset and the Adjective offset-Noun onset time-windows for both the age groups. A marked rise in the target-to-distractor ratio for the Adjective offset-Noun onset window compared to the Baseline and Baseline offset-Adjective offset windows for both the groups indicates more anticipatory fixations towards the target object. This suggests that both age groups, soon after hearing the adjective, were able to preactivate the noun compatible with adjective, thus providing clear evidence that both young and older adults effectively used gendermarked adjectives to predict the upcoming noun. This is consistent with other studies showing use of grammatical cues (Altman &amp; <ref type="bibr" target="#b2">Kamide, 2007)</ref>, grammatical gender (Gussow, Kapnoula, &amp; Molinaro, 2019), adjectives <ref type="bibr" target="#b12">(Mishra et al, 2012</ref><ref type="bibr">, Gussow et al., 2019)</ref> for prediction previously found with young adults. The present study extends these findings with older adults suggesting older adults too can use adjectives to make accurate and rapid predictions.</p><p>The between group comparisons showed the target-to distractor ratio for the Baseline offset-Adjective offset and the Adjective offset to Noun onset time-windows for the older adults were comparable to the target-to-distractor ratio for the young adults; showing older adults did not differ from young adults in their anticipatory gaze to a target object. This suggests that older adults robustly predicted the upcoming noun based on the gender-marked adjective. Participants fixating the target before the mention of noun were observed in both longer (Experiment 1) and shorter (Experiment 2) display preview durations, thus confirming our hypothesis. The current findings provide clear evidence that prediction during comprehension is not hampered with aging. This aligns with previous studies using visual-world findings indicating that older adults can anticipate likely upcoming target as quickly and effectively as young adults <ref type="bibr" target="#b3">(Baltaretu and Chambers, 2018;</ref><ref type="bibr">Milburn et. al 2021</ref><ref type="bibr">, Huetting &amp; Janse, 2015)</ref>. The present findings shows that older adults relied on their world knowledge about the association between adjectives and noun to predict the target noun.</p><p>Our findings is line with previous findings indicating crystallized intelligence, including lexical semantic knowledge remains quite stable with advancing age. Previous studies have shown that older adults, like their younger counterparts matched for verbal abilities, tend to generate similar word associates and category exemplars <ref type="bibr">(Burke &amp; Peters, 1986;</ref><ref type="bibr">Howard, 1980)</ref>.The gender-marked adjectives used in our study were highly associated with the target nouns. For example, the adjective "nukili"(sharp (feminie)) was highly associated with the target noun 'suii'(needle(feminie)), but not associated with the three unrelated distracters ( eg. Topi, billi, angoothi ). Older adults relied on either associative or/and syntactic information <ref type="bibr" target="#b4">(Bar, 2007)</ref> for prediction as the adjectives were highly constraining towards the target noun. This shows that older adults can use world knowledge about the association between adjective and noun as well as syntactic knowledge such as gender and case agreement between adjective and noun for anticipation. This provides evidence that older adults can engage in prediction relying upon their resilient crystallized intelligence and semantic knowledge <ref type="bibr">(Horn &amp; cattell, 1967;</ref><ref type="bibr">Milburn et al., 2016;</ref><ref type="bibr">2023)</ref>.</p><p>According to the language experience driven account of anticipation in language, it is expected that prediction abilities increase with linguistic experiences <ref type="bibr" target="#b12">(Mishra et. al., 2012)</ref>. Following this theory, one would predict higher prediction skills in older adults compared to young adults. However, our study revealed comparable prediction abilities in both young and old adults. It is plausible that semantic, grammatical knowledge and conceptual associations strengthen with age due to years of language experience, enhancing prediction skills in older adults. However, cognitive decline associated with aging may hamper this enhancement. Consequently, the expected increase in prediction skill may not be evident in anticipatory eye movements.</p><p>Previous studies investigating anticipation in older adults have shown that older adults can predict when provided with rich semantic context <ref type="bibr" target="#b16">(Kamide et al., 2003;</ref><ref type="bibr">Milburn et al., 2016</ref><ref type="bibr">, Lash et al., 2013;</ref><ref type="bibr">Payne &amp; Silcox, 2019;</ref><ref type="bibr" target="#b17">Pichora-Fuller, 2008;</ref><ref type="bibr">Stine-Morrow et al., 2006;</ref><ref type="bibr">Wingfield &amp; Stine-Morrow, 2000)</ref>. <ref type="bibr">Milburn et. al (2021)</ref> found that older adults can effectively take advantage of their preserved crystallized intelligence and world knowledge in prediction during sentence comprehension. They found that the older participants showed more pronounced anticipatory fixations to the target than younger adults when presented with semantically rich-verb + argument combinations (e.g., "The dog will drink…".) compared to when only a verb argument was used to predict( e.g., "Someone will drink the milk….") the target. While their study strongly supported preserved prediction in older adults, it also revealed the critical role of semantically rich context in generating robust predictions during sentence comprehension in older adults <ref type="bibr">(Payne &amp; Silcox, 2019;</ref><ref type="bibr" target="#b17">Pichora-Fuller, 2008;</ref><ref type="bibr">Stine-Morrow et al., 2006;</ref><ref type="bibr">Wingfield &amp; Stine-Morrow, 2000)</ref>. However, in our study, adjective was the sole predictor of the noun, as the sentence itself was contextually and semantically neutral (e.g., "Abhi aap ek nulili (adjective) waali suii(target)dekengey"/ Now you will see a sharp needle). <ref type="bibr">Unlike Milburn et. al's(2021)</ref> study, where prediction is built up over the course of sentence, making use of agent + verb to predict the noun(e.g., object argument), the cue for prediction in our study was relatively local or adjacent to the target noun. It seems that both the age groups strategically exploited the only predictive cue available in the sentence for prediction, as only one object in the display matched the adjective. This indicates that older adults can predict upcoming nouns based on gender-marked adjectives in Hindi, marking a departure from previous studies focusing on global, discourse, or rich semantic contexts for prediction in older adults. This study showcases anticipation using local, lexical context in the older population by relying upon the adjective and its grammatical gender. This is consistent with the <ref type="bibr">Huettig &amp; Janse (2015)</ref> findings showing use of local article gender as a cue for prediction of noun, which remains unchanged with age.</p><p>The present findings contradicts accounts proposing languagespecific decline in predictive processing in healthy cognitive aging <ref type="bibr">(DeLong et al., 2012;</ref><ref type="bibr">Wlotko et al., 2010)</ref> and other studies where negative effect of aging on prediction in older adults was found <ref type="bibr">(Federmeier &amp; Kutas, 2005;</ref><ref type="bibr" target="#b14">Janse &amp; Jesse 2014)</ref>. This discrepancy in the results could be attributed to several differences in our study and others. Firstly, the age range for the older group in our study was 55-75 years, with a mean of 63.08 years, which is less than the age ranges used in other studies. Most of the older participants (N=18) fell within the 55-65 age range, while only 6 older participants were between 66-75 age range. It is quite possible that recruitment of relatively less old population in our study may have influenced the findings of our study, and including older adults over 70 years could yield different results.</p><p>Secondly, the sentences used in study were quite simple. Use of contextual information for prediction is linked with working memory capacity <ref type="bibr">( Federmeier et al., 2005)</ref>.While longer sentences can offer multiple progressive cues which aids prediction, they also impose processing cost. Use of simple sentences in our study, with a cue adjacent to the target noun, imposed minimal load on the working memory during meaning integration, leaving capacity relatively free to engage in prediction. In the present study, the older adults' mean WM score (out of 30) was 17.8 while for younger adults it was 20.5. It is quite possible that older adults despite have low WM scores could do engage into prediction as the sentences were quite simple.</p><p>In the Experiment 2, we examined whether prediction in older adults is dependent upon extended preview duration of visual display presentations. We hypothesized that longer preview duration is necessary for activation of potential target object, and reducing this duration may hinder prediction. The preview duration was reduced to 500ms, and it was expected that it would result in either no or reduced prediction, particularly affecting the older group. The results from the Experiment 2 showed slightly smaller anticipatory eye movements towards the target object following adjective in the older participants compared to the young adults, however, this difference was not significant for any of the time-windows. Surprisingly, the results from the Experiment 2 contradicted our hypothesis, suggesting that both the groups could activate the target object despite shorter visual display duration. <ref type="bibr">Huettig and Guerra (2019)</ref> found that reducing preview duration affected prediction only in the normal speech rate condition, not for slow speech rate condition. In our study the sentences were presented at slower pace, just like any other visual world paradigm study, which were slightly longer than natural speech, may have contributed to the prediction observed in both the groups. The average duration of the sentences used in our was 4416.6 ms(SD= 251.35) which is bit longer than the normal pace at which such short sentences are spoken in a naturalistic settings. While we did not explicitly examined prediction using sentences with normal speech rate, it is plausible that employing one could have resulted in a smaller prediction effect, especially for the older adults. Even if the prediction happened because of the slower speech rate in our study, it still indicates that older adults demonstrate prediction comparable to the young adults, even with shorter preview duration. The present study clearly shows that older adults are capable of activating the representations which is utilized for prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>The current study provides a robust evidence that older adults can generate prediction using gender marked adjectives, which indicates towards utilization of their world knowledge and morpho-syntactic knowledge during language comprehension <ref type="bibr">(Milburn et al.,2021;</ref><ref type="bibr">Lash et al., 2013;</ref><ref type="bibr">Payne &amp; Silcox, 2019</ref>. The present findings show positive influence of life long experience with language on prediction which was evidenced by the comparable anticipatory gaze towards the target object in young and older adults .Further, it shows that utilization of their world knowledge in older adults doesn't remain restricted to generation of verb-argument predictions but it also extends to prediction of nouns using adjective noun agreement knowledge. This further strengthens previous findings that language experience, exposure, and world knowledge influence prediction during comprehension <ref type="bibr" target="#b12">(Mishra et al.,2012;</ref><ref type="bibr">Milburn et al.,2021;</ref><ref type="bibr">Fernaldd, Perfors, &amp; Marchman, 2006;</ref><ref type="bibr">Tokildsen et al., 2008)</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements:</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig 1 :</head><label>1</label><figDesc>Fig 1: Example display, where the auditory sentence was "abhi aap ek nukili wali sui dekhege".</figDesc><graphic coords="10,72.00,71.95,451.30,330.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig 2 :</head><label>2</label><figDesc>Fig 2: Trial structure for Experiment 1.</figDesc><graphic coords="11,72.00,352.25,427.20,251.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Changes in fixation proportions on the target objects and (averaged) unrelated distractor objects for young and old adults for experiment 1.</figDesc><graphic coords="12,72.00,385.95,451.30,247.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig 4 :</head><label>4</label><figDesc>Fig 4: Trial structure for Experiment 2</figDesc><graphic coords="16,72.05,483.25,451.25,246.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>patients for the clinician. Journal of psychiatric research, 12(3),189-198.   Fyshe, A., Sudre, G., Wehbe, L., Rafidi, N., &amp; Mitchell, T. M. (2019).The lexical semantics of adjective-noun phrases in the human brain. Human brain mapping, 40(15), 4457-4469. Gunter TC,Jackson JL, Mulder G.(1995). Language, memory, and aging: A electrophysiological exploration of the N400 during reading of memory-demanding sentences. Psychophysiology. 1995;32(3):215-229.  Gussow, A. E., Kapnoula, E. C., &amp; Molinaro, N. (2019). Any leftovers from a discarded prediction? Evidence from eye-movements during sentence comprehension. Language, Cognition and Neuroscience, 34(8), 1041-1058.  Häuser, K., Demberg, V., &amp; Kray, J. (2017). Age differences in language comprehension during driving: Recovery from prediction errors is more effortful for older adults. In CogSci.  Horn, J. L., &amp; Cattell, R. B. (1967). Age differences in fluid and crystallized intelligence. Acta psychologica, 26, 107-129  Howard DV. Category norms: A comparison of the Battig and Montague (1969) norms with the responses of adults between the ages of 20 and 80. Journals of Gerontology. 1980; 35(2):225-231. [PubMed: 7410780]  Huettig, F. (2015). Four central questions about prediction in language processing. Brain research, 1626, 118-135.  Huettig, F., &amp; Altmann, G. T. (2005). Word meaning and the control of eye fixation: Semantic competitor effects and the visual world paradigm. Cognition, 96(1), B23-B32.  Huettig, F., &amp; Brouwer, S. (2015). Delayed anticipatory spoken language processing in adults with dyslexia-evidence from eyetracking. Dyslexia, 21(2), 97-122.  Huettig, F., &amp; Guerra, E. (2019). Effects of speech rate, preview time of visual context, and participant instructions reveal strong  Posit team (2023). RStudio: Integrated Development Environment for R. Posit Software, PBC, Boston, MA. URL  Raz, N., Craik, F. I. M., &amp; Salthouse, T. A. (2000). The handbook of aging and cognition. Unter Mitarbeit von Craik, FIM and Salthous, TA.  Staub, A., &amp; Clifton Jr, C. (2006). Syntactic prediction in language comprehension: evidence from either... or. Journal of experimental psychology: Learning, memory, and cognition, 32(2), 425. Stine-Morrow, E. A., Miller, L. M. S., &amp; Hertzog, C. (2006). Aging and self-regulated language processing. Psychological bulletin, 132(4), 582.  Stine-Morrow, E. A., Miller, L. M. S., &amp; Hertzog, C. (2006). Aging and self-regulated language processing. Psychological bulletin, 132(4), 582.  Stine-Morrow, E. A., Shake, M. C., Miles, J. R., &amp; Noh, S. R. (2006). Adult age differences in the effects of goals on self-regulated sentence processing. Psychology and aging, 21(4), 790.  Torkildsen, J. V. K., Svangstu, J. M., Hansen, H. F., Smith, L., Simonsen, H. G., Moen, I., &amp; Lindgren, M. (2008). Productive vocabulary size predicts event-related potential correlates of fast mapping in 20-month-olds. Journal of cognitive neuroscience, 20(7), 1266-1282.  Warren, T., &amp; Dickey, M. W. (2021). The use of linguistic and world knowledge in language processing. Language and Linguistics Compass, 15(4), e12411.  Weber, A., Grice, M., &amp; Crocker, M. W. (2006). The role of prosody in the interpretation of structural ambiguities: A study of anticipatory eye movements. Cognition, 99(2), B63-B72.  West, R. L. (1996). An application of prefrontal cortex function theory to cognitive aging. Psychological bulletin, 120(2), 272.  Wingfield, A., &amp; Stine-Morrow, E. A. (2000). Language and speech.  Wlotko, E. W., Lee, C. L., &amp; Federmeier, K. D. (2010). Language of the aging brain: Event-related potential studies of comprehension in older adults. Language and linguistics compass, 4(8), 623-638.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="17,72.00,273.25,451.30,219.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table ( 1</head><label>(</label><figDesc>): Participants data for Experiment 1</figDesc><table><row><cell></cell><cell cols="2">AGE</cell><cell cols="2">MMSE</cell><cell cols="2">Raven's Progressive Matrices</cell><cell cols="2">Digit span</cell><cell cols="2">Hindi Proficiency</cell><cell cols="2">Hindi Exposure</cell></row><row><cell></cell><cell>old</cell><cell>youn g</cell><cell>old</cell><cell>youn g</cell><cell>old</cell><cell>youn g</cell><cell>old</cell><cell>youn g</cell><cell>old</cell><cell>young</cell><cell>old</cell><cell>youn g</cell></row><row><cell>No. of participants</cell><cell>24</cell><cell>29</cell><cell>24</cell><cell>29</cell><cell>24</cell><cell>29</cell><cell>24</cell><cell>29</cell><cell>24</cell><cell>29</cell><cell>24</cell><cell>29</cell></row><row><cell>Mean</cell><cell>63.08 3</cell><cell>22.62 1</cell><cell>29.12 5</cell><cell>29.03 4</cell><cell>44.83 3</cell><cell>51.27 6</cell><cell>17.83 3</cell><cell>20.75 9</cell><cell cols="3">9.530 8.793 74.343</cell><cell>51.09 9</cell></row><row><cell cols="5">Std. Deviation 5.516 2.227 0.900 0.865</cell><cell>10.23 1</cell><cell cols="6">4.543 3.784 2.760 0.468 0.906 19.766</cell><cell>16.53 7</cell></row><row><cell>Minimum</cell><cell>55.00 0</cell><cell>20.00 0</cell><cell>28.00 0</cell><cell>28.00 0</cell><cell>25.00 0</cell><cell>42.00 0</cell><cell>12.00 0</cell><cell>14.00 0</cell><cell cols="3">8.571 6.286 36.923</cell><cell>26.15 4</cell></row><row><cell>Maximum</cell><cell>75.00 0</cell><cell>29.00 0</cell><cell>30.00 0</cell><cell>30.00 0</cell><cell>59.00 0</cell><cell>58.00 0</cell><cell>30.00 0</cell><cell>26.00 0</cell><cell cols="2">10.000 10.000</cell><cell>100.00 0</cell><cell>91.53 8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table (</head><label>(</label><figDesc></figDesc><table><row><cell cols="7">Table (2): Participants data for Experiment 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">AGE</cell><cell cols="2">MMSE</cell><cell cols="2">Raven's Progressive Matrices</cell><cell cols="2">Digit span</cell><cell cols="2">Hindi Proficiency</cell><cell cols="2">Hindi Exposure</cell></row><row><cell></cell><cell>old</cell><cell>youn g</cell><cell>old</cell><cell>youn g</cell><cell>old</cell><cell>young</cell><cell>old</cell><cell>youn g</cell><cell cols="3">old young old</cell><cell>youn g</cell></row><row><cell>Mean</cell><cell>62.7 92</cell><cell>22.4 17</cell><cell>28.9 58</cell><cell>29.0 42</cell><cell>46.333</cell><cell>50.917</cell><cell>18.1 25</cell><cell>20.5 42</cell><cell cols="2">9.482 8.804</cell><cell>75.51 5</cell><cell>51.36 5</cell></row><row><cell>Std. Deviation</cell><cell>5.57 2</cell><cell>2.35 8</cell><cell>0.85 9</cell><cell>0.90 8</cell><cell>8.218</cell><cell>4.781</cell><cell>3.76 8</cell><cell>2.88 9</cell><cell cols="2">0.461 0.973</cell><cell>16.72 1</cell><cell>17.23 5</cell></row><row><cell>Minimum</cell><cell>54.0 00</cell><cell>20.0 00</cell><cell>28.0 00</cell><cell>28.0 00</cell><cell>28.000</cell><cell>42.000</cell><cell>12.0 00</cell><cell>14.0 00</cell><cell cols="2">8.571 6.286</cell><cell>36.92 3</cell><cell>26.15 4</cell></row><row><cell>Maximum</cell><cell>73.0 00</cell><cell>29.0 00</cell><cell>30.0 00</cell><cell>30.0 00</cell><cell>59.000</cell><cell>58.000</cell><cell>30.0 00</cell><cell>26.0 00</cell><cell>10.00 0</cell><cell>10.00 0</cell><cell>98.75 0</cell><cell>91.53 8</cell></row><row><cell cols="7">2): Participants data for Experiment 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">AGE</cell><cell cols="2">MMSE</cell><cell cols="2">Raven's Progressive Matrices</cell><cell cols="2">Digit span</cell><cell cols="2">Hindi Proficiency</cell><cell cols="2">Hindi Exposure</cell></row><row><cell></cell><cell>old</cell><cell>youn g</cell><cell>old</cell><cell>youn g</cell><cell>old</cell><cell>young</cell><cell>old</cell><cell>youn g</cell><cell cols="3">old young old</cell><cell>youn g</cell></row><row><cell>No. of Participants</cell><cell>24</cell><cell>24</cell><cell>24</cell><cell>24</cell><cell>24</cell><cell>24</cell><cell>24</cell><cell>24</cell><cell>24</cell><cell>24</cell><cell>24</cell><cell>24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>This work was supported by a Cognitive Science Research Initiative grant to Niharika Singh and FIST (Fund for Improvement of S&amp;T Infrastructure) grant to the Centre by the Department of Science and Technology, India.  Braver, T. S., &amp; West, R. (2008). Working memory, executive control, and aging. In F. I. M. Craik &amp; T. A. Salthouse (Eds.), The handbook of aging and cognition (3rd ed., pp. 311-372). Psychology Press  Burke, D. M., &amp; Peters, L. (1986). Word associations in old age: evidence for consistency in semantic encoding during adulthood. Fernald, A., Perfors, A., &amp; Marchman, V. A. (2006). Picking up speed in understanding: Speech processing efficiency and vocabulary growth across the 2nd year. Developmental psychology, 42(1), 98.  Fernandez, L. B., Engelhardt, P. E., Patarroyo, A. G., &amp; Allen, S. E. (2020). Effects of speech rate on anticipatory eye movements in the visual world paradigm: Evidence from aging, native, and non-native language processing. Quarterly Journal of Experimental Psychology, 73(12), 2348-2361.  Folstein, M. F., Folstein, S. E., &amp; P. R. (1975). "Minimental state": a practical method for grading the cognitive state of</figDesc><table><row><cell>Psychology and aging, 1(4), 283.</cell></row><row><cell> Cheimariou, S. (2016). Prediction in aging language processing.</cell></row><row><cell>The University of Iowa.</cell></row><row><cell> Cheimariou, S., Farmer, T. A., &amp; Gordon, J. K. (2021). The effects of</cell></row><row><cell>age and verbal ability on word predictability in reading. Psychology</cell></row><row><cell>and aging, 36(4), 531.</cell></row><row><cell> Chen, E., Gibson, E., &amp; Wolf, F. (2005). Online syntactic storage</cell></row><row><cell>costs in sentence comprehension. Journal of Memory and</cell></row><row><cell>Language, 52(1), 144-169.</cell></row><row><cell> Choi, W., Lowder, M. W., Ferreira, F., Swaab, T. Y., &amp; Henderson, J.</cell></row><row><cell>M. (2017). Effects of word predictability and preview lexicality on</cell></row><row><cell>eye movements during reading: A comparison between young and</cell></row><row><cell>older adults. Psychology and Aging, 32(3), 232.</cell></row><row><cell> Dahan, D., &amp; Tanenhaus, M. K. (2005). Looking at the rope when</cell></row><row><cell>looking for the snake: Conceptually mediated eye movements</cell></row><row><cell>during spoken-word recognition. Psychonomic bulletin &amp;</cell></row><row><cell>review, 12(3), 453-459.</cell></row><row><cell> Dave, S., Brothers, T., Hoversten, L. J., Traxler, M. J., &amp; Swaab, T. Y.</cell></row><row><cell>(2021). Cognitive control mediates age-related changes in flexible</cell></row><row><cell>anticipatory processing during listening comprehension. Brain</cell></row><row><cell>Research, 1768, 147573.</cell></row><row><cell> DeLong, K. A., Groppe, D. M., Urbach, T. P., &amp; Kutas, M. (2012).</cell></row><row><cell>Thinking ahead or not? Natural aging and anticipation during</cell></row><row><cell>reading. Brain and language, 121(3), 226-239.</cell></row><row><cell> Federmeier, K. D., &amp; Kutas, M. (2005). Aging in context: age-</cell></row><row><cell>related changes in context use during language</cell></row><row><cell>comprehension. Psychophysiology, 42(2), 133-141.</cell></row><row><cell> Federmeier, K. D., Kutas, M., &amp; Schul, R. (2010). Age-related and</cell></row><row><cell>individual differences in the use of prediction during language</cell></row><row><cell>comprehension. Brain and language, 115(3), 149-161.</cell></row><row><cell> Federmeier, K. D., Kutas, M., &amp; Schul, R. (2010). Age-related and</cell></row><row><cell>individual differences in the use of prediction during language</cell></row><row><cell>comprehension. Brain and language, 115(3), 149-161.</cell></row><row><cell> Federmeier, K. D., Wlotko, E. W., De Ochoa-Dewald, E., &amp; Kutas, M.</cell></row><row><cell>(2007). Multiple effects of sentential constraint on word</cell></row><row><cell>processing. Brain research, 1146, 75-84.</cell></row></table><note><p></p></note></figure>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data availability statement:</head><p>The data supporting the findings of this study is available in "Figshare". The data can be accessed through the given link, http://doi.org/10.6084/m9.figshare.26186534</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflict of Interest</head><p>The authors declare there is no conflict of interest.</p><p> Lash, A., Rogers, C. S., <ref type="bibr">Zoller, A., &amp; Wingfield, A. (2013)</ref>.</p><p>Expectation and entropy in spoken word recognition: Effects of age and hearing acuity. Experimental Aging Research, 39(3), 235-253.</p><p> Mack, J. E., <ref type="bibr">Ji, W., &amp; Thompson, C. K. (2013)</ref>. Effects of verb meaning on lexical integration in agrammatic aphasia: Evidence from eyetracking. Journal of neurolinguistics, 26(6), 619-636.</p><p> Mani, N., <ref type="bibr" target="#b12">&amp; Huettig, F. (2012)</ref>. Prediction during language processing is a piece of cake-But only for skilled </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Thematic role assignment in context</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Altmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="124" to="145" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Incremental interpretation at verbs: Restricting the domain of subsequent reference</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Altmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kamide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="247" to="264" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The real-time mediation of visual attention by language and world knowledge: Linking anticipatory (and other) eye movements to linguistic processing</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Altmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kamide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of memory and language</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="502" to="518" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">When criminals blow up... balloons. Associative and combinatorial information in the generation of on-line predictions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Baltaretu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Chambers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th Annual Meeting of the Cognitive Science Society</title>
		<meeting>the 40th Annual Meeting of the Cognitive Science Society<address><addrLine>Austin, TX</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="124" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The proactive brain: using analogies and associations to generate predictions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="280" to="289" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maechler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H B</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Singmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Package &apos;lme4&apos;. convergence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Age-specific norms for the mini-mental state exam</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Bleecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bolla-Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kawas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Agnew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1565" to="1565" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Visual arguments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Boland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="237" to="274" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Knowing a lot for one&apos;s age: Vocabulary skill and not age is associated with anticipatory incremental sentence interpretation in children and adults</title>
		<author>
			<persName><forename type="first">A</forename><surname>Borovsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Elman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fernald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental child psychology</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="196" to="208" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Brain Research</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Individual differences in working memory and processing speed predict anticipatory spoken language processing in the visual world</title>
		<author>
			<persName><forename type="first">F</forename><surname>Huettig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Janse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language, Cognition and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="80" to="93" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Is prediction necessary to understand language? Probably not. Language</title>
		<author>
			<persName><forename type="first">F</forename><surname>Huettig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Mani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition and Neuroscience</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="31" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The tug of war between phonological, semantic and shape information in languagemediated visual search</title>
		<author>
			<persName><forename type="first">F</forename><surname>Huettig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of memory and language</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="460" to="482" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Mechanisms and representations of language-mediated visual attention</title>
		<author>
			<persName><forename type="first">F</forename><surname>Huettig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">K</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Olivers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in psychology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">394</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Looking, language, and memory: bridging research from the visual world and visual search paradigms</title>
		<author>
			<persName><forename type="first">F</forename><surname>Huettig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">N</forename><surname>Olivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Hartsuiker</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.actpsy.2010.07.013</idno>
		<ptr target="https://doi.org/10.1016/j.actpsy.2010.07.013" />
	</analytic>
	<monogr>
		<title level="j">Acta psychologica</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="138" to="150" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Working memory affects older adults&apos; use of context in spoken-word recognition</title>
		<author>
			<persName><forename type="first">E</forename><surname>Janse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jesse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1842" to="1862" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Anticipatory processes in sentence processing</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kamide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Linguistics Compass</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="647" to="670" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Integration of syntactic and semantic information in predictive processing: Crosslinguistic evidence from German and English</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Kamide</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Scheepers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Altmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of psycholinguistic research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="37" to="55" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Use of supportive context by younger and older adult listeners: Balancing bottom-up and topdown information processing</title>
		<author>
			<persName><forename type="first">Kathleen</forename><surname>Pichora-Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of audiology</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">sup2</biblScope>
			<biblScope unit="page" from="72" to="S82" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Length, frequency, and predictability effects of words on eye movements in reading</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kliegl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Grabner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rolfs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Engbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European journal of cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="262" to="284" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The real-time prediction and inhibition of linguistic outcomes: Effects of language and literacy skill</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kukona</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Braze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Johns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Mencl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Dyke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Magnuson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Tabor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="page" from="72" to="84" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
