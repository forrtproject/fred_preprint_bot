<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Comparing job applicant deception in asynchronous vs synchronous video interviews, with and without AI-assisted assessments</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Emerald</publisher>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-12-13">2023-12-13</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hung-Yue</forename><surname>Suen</surname></persName>
							<idno type="ORCID">0000-0002-6796-2031</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Technology Application and Human Resource Development</orgName>
								<orgName type="institution">National Taiwan Normal University</orgName>
								<address>
									<postCode>106</postCode>
									<settlement>Taipei City</settlement>
									<country>Taiwan. R</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kuo-En</forename><surname>Hung</surname></persName>
							<idno type="ORCID">0000-0003-2091-2747</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Technology Application and Human Resource Development</orgName>
								<orgName type="institution">National Taiwan Normal University</orgName>
								<address>
									<postCode>106</postCode>
									<settlement>Taipei City</settlement>
									<country>Taiwan. R</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Comparing job applicant deception in asynchronous vs synchronous video interviews, with and without AI-assisted assessments</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Information Technology &amp; People</title>
						<title level="j" type="abbrev">ITP</title>
						<idno type="ISSN">0959-3845</idno>
						<imprint>
							<publisher>Emerald</publisher>
							<biblScope unit="volume">38</biblScope>
							<biblScope unit="issue">2</biblScope>
							<biblScope unit="page" from="963" to="983"/>
							<date type="published" when="2023-12-13" />
						</imprint>
					</monogr>
					<idno type="MD5">959869EE03AEDD66E891CE9626750F3C</idno>
					<idno type="DOI">10.1108/itp-02-2023-0189</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-22T20:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Automated video interviews</term>
					<term>digital interview</term>
					<term>faking behaviors</term>
					<term>human-AI interaction (HAII)</term>
					<term>hiring algorithms</term>
					<term>video conferencing</term>
					<term>recording interviews</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Asynchronous Video Interviews (AVIs) incorporating Artificial Intelligence (AI)-assisted assessment has become popular as a pre-employment screening method. The extent to which applicants engage in deceptive impression management (IM) behaviors during these interviews remains uncertain. Furthermore, the accuracy of human detection in identifying such deceptive IM behaviors is limited. This study seeks to explore differences in deceptive IM behaviors by applicants across video interview modes (AVIs versus Synchronous Video Interviews (SVIs))</p><p>and the use of AI-assisted assessment (AI versus non-AI). The study also investigates if video interview modes affect human interviewers' ability to detect deceptive IM behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design/methodology/approach</head><p>We conducted a field study with four conditions based on two critical factors: the synchrony of video interviews (AVI vs. SVI) and the presence of AI-assisted assessment (AI vs. Non-AI):</p><p>Non-AI-assisted AVIs, AI-assisted AVIs, Non-AI-assisted SVIs, and AI-assisted SVIs. The study involved 144 pairs of interviewees and interviewers/assessors. To assess applicants' deceptive IM behaviors, we employed a combination of interviewee self-reports and interviewer perceptions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Previous research on AI-assisted video interviews has primarily focused on technical methodology <ref type="bibr" target="#b48">(Su et al., 2021)</ref>, their impact on applicants' perceptions <ref type="bibr">(Kim and Heo, 2022;</ref><ref type="bibr">Langer et al., 2019ab;</ref><ref type="bibr" target="#b62">Zhang and Yencha 2022)</ref>, trust in the technology <ref type="bibr" target="#b49">(Suen and Hung, 2023)</ref>, and interview ratings <ref type="bibr">(Suen et al., 2019a)</ref>. However, our current understanding of how job interviewees interact with AI-assisted video interviews and whether they display different behaviors compared to traditional interviews is inadequate <ref type="bibr" target="#b7">(Baker et al., 2020)</ref>, particularly in the context of deceptive impression management (IM) or faking <ref type="bibr">(Langer et al., 2020)</ref>. During job interviews, it is common for job applicants to overstate their qualifications in order to improve their chances of securing employment <ref type="bibr" target="#b55">(Swider et al., 2016)</ref>. Additionally, a substantial number of job applicants have acknowledged employing deceptive IM during the interview process <ref type="bibr" target="#b21">(Donovan et al., 2003)</ref>. While honest IM may improve predictive validity for task performance, deceptive IM may introduce bias into hiring decisions <ref type="bibr" target="#b14">(Bourdage et al., 2018)</ref>. Prior studies have shown that even experienced interviewers struggle to detect or identify interviewees' IM, which can distort or inflate the interview evaluation <ref type="bibr" target="#b45">(Roulin et al., 2015)</ref>. This effect is present even in highly structured interviews <ref type="bibr" target="#b5">(Amaral et al., 2019)</ref>, which are commonly used in AI-assisted video interviews <ref type="bibr" target="#b48">(Su et al., 2021)</ref>.</p><p>However, it remains unclear whether interviewees' deceptive behaviors vary between synchrony modes of video interviews (AVIs vs. SVIs) and if they exhibit different faking tendencies during video interviews with AI-assisted assessment. Additionally, it's unknown whether human interviewers' or assessors' ability to detect deception differs between SVIs and AVIs. Therefore, researchers such as <ref type="bibr" target="#b9">Basch et al. (2021)</ref> and <ref type="bibr">Lukacik et al.(2022)</ref> have called for more studies to explore whether job applicants exhibit deceptive IM differently in AI-assisted video interviews compared to interviews without AI assistance, as candidates' faking could <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2025)</ref>. Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information <ref type="bibr">Technology &amp; People,</ref><ref type="bibr">38(2)</ref>, 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 6 significantly impact hiring decisions through biases <ref type="bibr">(Langer et al., 2019a;</ref><ref type="bibr">Liem et al., 2018)</ref>. In <ref type="bibr">Lukacik et al.'s (2022)</ref> review of relevant studies, they discovered there is no empirical evidence regarding the use of actual IM by job applicants in AVIs. Similarly, <ref type="bibr">Baker and colleagues (2020)</ref> suggest conducting a comparative study to examine the differences in interviewee behaviors between AVIs and SVIs.</p><p>The purpose of this study is threefold: 1) to investigate whether job applicants exhibit different tendencies to fake in between asynchronous modes (AVIs) and synchronous modes (SVIs) of video interviews; 2) to examine whether job candidates' propensity to fake differs between AI-assisted assessment and non-AI-assisted assessment; and 3) to determine whether the mode of video interview synchrony (AVI vs. SVI) impacts the accuracy of human assessors or interviewers in detecting job candidates' faking behaviors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and hypotheses</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Applicant Faking in Employment Interviews</head><p>Interviewing is a widely utilized method for candidates to highlight their suitability and for interviewers to foster a positive employer image. It serves as a tool for IM, often prioritizing a positive image over complete truthfulness <ref type="bibr">(Peck and Levashina, 2017;</ref><ref type="bibr" target="#b58">Wilhelmy et al., 2017)</ref>.</p><p>Interviewees' attempts to control their ideal self-image to affect interviewers' ratings are instances of IM <ref type="bibr" target="#b55">(Swider et al., 2016)</ref>. IM plays a central role in selection interviews, and job candidates can use different types of IM to present themselves in the best possible way while being honest or deceptive (faking) <ref type="bibr" target="#b14">(Bourdage et al., 2018)</ref>. For example, job candidates can use honest IM to promote their accomplishments related to job requirements, or they can use deceptive IM to fake answers to interview questions and state nonexistent achievements to obtain <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2025)</ref>. Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information <ref type="bibr">Technology &amp; People,</ref><ref type="bibr">38(2)</ref>, 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 7 a job offer <ref type="bibr">(Marcus, 2009)</ref>. <ref type="bibr" target="#b33">Ho et al. (2021)</ref> also found that some interviewees may effectively use deceptive IM to enhance their prospects of being hired. Although it is debatable whether honest IM is an issue in personnel selection, deceptive IM has been found to significantly boost interviewer ratings, potentially leading to biases in hiring decisions <ref type="bibr" target="#b41">(Roth et al., 2021)</ref>.</p><p>According to "the model of faking likelihood in employment interviews" <ref type="bibr">(Levashina and Campion, 2006)</ref>, job applicants engage in deceptive behaviors during job interviews when they have a higher capability, willingness, and opportunity to fake. Additionally, more than 90% of job applicants admit to engaging in deception at least once during an employment interview using tactics such as slight image creation, extensive image creation, image protection, and ingratiation <ref type="bibr">(Levashina and Campion, 2007)</ref>. Slight image creation involves presenting the image of being a good candidate for the job that is close to the truth. Extensive image creation involves inventing the image of being a good candidate for a job that includes false information.</p><p>Image protection involves defending the image of being a good candidate for the job which involves omitting negative information. Ingratiation involves gaining favor with the interviewer to improve the appearance of being a good candidate for the job by attempting to please the interviewer regardless of the selection criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Applicant faking in AVIs vs. SVIs</head><p>The main difference between AVIs and SVIs is the real-time interaction. In an SVI mode, interviewees sit face-to-face with a real human interviewer(s) from the comfort of the interviewee's own device and location, whereas interviewees do not have the opportunity to interact or build rapport with the interviewer(s) in an AVI setting because there is no live interviewer in attendance <ref type="bibr" target="#b16">(Brenner et al., 2016)</ref>. <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2025)</ref>. Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information <ref type="bibr">Technology &amp; People,</ref><ref type="bibr">38(2)</ref>, 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 8</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Media Richness in AVI vs. SVI</head><p>Media richness theory <ref type="bibr" target="#b18">(Daft and Lengel, 1986)</ref> highlights that various media offer different levels of information richness, significantly shaping communication dynamics and outcomes. This theory elucidates why individuals tailor their communication strategies to different media.</p><p>The richness of a medium is assessed using several criteria, including immediate feedback capacity, cues transmission, personalized information, and complexity of language usage. These criteria collectively influence communication dynamics and outcomes across diverse media <ref type="bibr" target="#b6">(Apers &amp; Derous, 2017)</ref>.</p><p>In the context of employment video interviews, it implies that interviewees participating in AVIs may face challenges such as limited immediate feedback, diminished conveyance of non-verbal cues, fewer chances for personalized communication, and heightened difficulty in understanding complex or ambiguous messages compared to their counterparts in SVIs <ref type="bibr">(Suen et al., 2019a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Faking Likelihood in AVI vs. SVI</head><p>In line with media richness theory and the model of faking likelihood in employment interviews, regarding feedback capacity, an interviewee may believe that he or she has less capacity to immediately explain or mask his or her weaknesses to the interviewer(s) (image protection) in AVIs than in SVIs because no interviewer appears in AVIs. Regarding the transmission of cues, an interviewee has no interaction with an interviewer in AVIs and thus cannot detect any cues expressed by the interviewer (e.g., nodding and smiling) that can be used to adjust an answer to enhance (slight image creation) or invent (extensive image creation) an interviewee image to present person-job fit or to appear similar to the interviewer (ingratiation), unlike in SVIs.</p><p>Regarding the personalized communication style, an interviewee has no information about the interviewer(s) who may evaluate his or her interview video; thus, interviewees have less opportunity to tailor their communication style to conform to the interviewers' values or attitudes (ingratiation), which the interviewer's nonverbal signals may express in SVIs. With respect to understanding and deciphering ambiguous or complex messages, an interviewee has no chance to determine the preferences of an interviewer based on facial expressions or other nonverbal cues that may be meaningful for the job, the organization, or the hiring decision-makers personal values in AVIs, in contrast to SVIs <ref type="bibr" target="#b47">(Shin et al., 2017)</ref>. Therefore, the interviewee may have more difficulty utilizing cues to modify (slight image creation) or create better (extensive image creation) answers to fit job expectations, to omit information that may be negative for the job opportunity (image protection), or to praise or compliment the assessor (ingratiation). (see <ref type="bibr">Lukacik et al., 2022)</ref> Drawing on the rationale put forth by <ref type="bibr" target="#b9">Basch et al. (2021)</ref>, job candidates perceived it more difficult to engage in IM during mediated, lower media richness SVIs compared to face-toface interviews. SVIs provide more information richness compared to AVIs, which lack immediate feedback, interaction, and opportunities to tailor communication styles to counterparts. Additionally, interviewees may struggle to comprehend ambiguous or complex messages conveyed by interviewers in AVIs <ref type="bibr" target="#b31">(Hassell et al., 2017)</ref>. Consequently, the limited opportunities for faking in AVIs relative to SVIs can be inferred. Based on these considerations, we propose the following:</p><p>Hypothesis 1: Interviewees tend to fake more in SVIs than in AVIs. <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2025)</ref>. Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information <ref type="bibr">Technology &amp; People,</ref><ref type="bibr">38(2)</ref>, 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 10 Some AVI and SVI service providers install an embedded AI algorithm to automatically infer interviewees' personality traits <ref type="bibr">(Suen et al., 2019b)</ref>, interview performance (called interviewability) <ref type="bibr">(Naim et al., 2018)</ref>, or interpersonal communication skills <ref type="bibr" target="#b39">(Rao et al., 2017)</ref> according to interviewees' audio-visual expressions on video <ref type="bibr" target="#b17">(Çeliktutan and Gunes, 2017)</ref>. AI can also make hiring recommendations in actual employment interviews by extracting verbal or nonverbal cues from both the interviewee and the interviewer <ref type="bibr">(Nguyen et al., 2014)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Applicant faking with AI vs. non-AI-assisted assessment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">The Role of AI in Video Interviews</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">The Impact of AI on Applicant Faking Likelihood</head><p>Whether actual candidates exhibit varying faking tendencies in AI-assisted AVIs or SVIs remains unexplored <ref type="bibr" target="#b9">(Basch et al., 2021;</ref><ref type="bibr">Lukacik et al., 2022)</ref>. We can deduce the probability of this based on job applicants' capacity, willingness, and opportunity to fake during interviews, as outlined in the Model of Faking Likelihood <ref type="bibr">(Levashina and Campion, 2006)</ref>. If a candidate understands the criteria used by human interviewers, they are more likely to fake to align with these standards. However, when a candidate is uncertain about how AI assesses their interview performance, faking behavior may decrease because the candidate lacks knowledge about AIassisted assessment criteria <ref type="bibr">(Langer et al., 2020)</ref>. Currently, job candidates can easily access interview questions and human selection criteria from target companies through platforms like Glassdoor <ref type="bibr" target="#b54">(Suen et al., 2020b)</ref>. However, they may struggle to comprehend AI assessment criteria due to limited explanations <ref type="bibr">(Jaser et al., 2022)</ref>.</p><p>In addition, in light of the model of volitional rating behavior (Kane, 1994) and expectancy theory <ref type="bibr" target="#b57">(Vroom, 1964)</ref>, a job candidate's willingness to fake in interviews depends on the perceived probability of being caught. When job applicants expect more risk of being caught faking, they are less likely to engage in the behaviors <ref type="bibr">(Levashina and Campion, 2006)</ref>. Because AI is perceived as a "smart" interviewer <ref type="bibr">(Langer et al., 2019b)</ref>, interviewees may be afraid that <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2025)</ref>. Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information <ref type="bibr">Technology &amp; People,</ref><ref type="bibr">38(2)</ref>, 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 11 their faking behaviors will be detected by the AI interviewer more easily than by human interviewers <ref type="bibr">(Langer et al., 2020)</ref>; therefore, they may have less willingness to engage in creating a slight or extensive image beyond a reasonable description of the truth or to enact ingratiation to gain a job opportunity <ref type="bibr">(Levashina and Campion, 2007)</ref>. The second hypothesis is proposed as follows:</p><p>Hypothesis 2: Interviewees tend to fake less in AI-assisted video interviews than in non-AI-assisted video interviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Human detection of applicant faking in AVIs vs. SVIs</head><p>Although applicant faking may threaten the validity of personnel interviews <ref type="bibr" target="#b42">(Roulin and Powell, 2018)</ref>, human interviewers have limited capacity to identify faking behaviors <ref type="bibr" target="#b43">(Roulin et al., 2014)</ref>, and only 12-19% of faking behaviors could be accurately detected across multiple studies <ref type="bibr" target="#b45">(Roulin et al., 2015)</ref>. <ref type="bibr" target="#b42">Roulin and Powell (2018)</ref> argued that human interviewers could not identify applicants faking because they extensively use invalid nonverbal cues conveyed by interviewees to assess the interviewees' deception. For example, many human interviewers perceive that an interviewee is faking when the interviewee appears anxious. However, interviewees who fake more in the context of selection interviews attempt to control their expressions and demonstrate less anxiety <ref type="bibr" target="#b46">(Schneider et al., 2015)</ref>. <ref type="bibr" target="#b42">Roulin and Powell (2018)</ref> proposed that a better method to detect faking behaviors for human interviewers or assessor(s) should focus on the content of interviewees' answers, and this method can be implemented better in behavioral-based structured interviews.</p><p>In line with media richness theory, SVIs have more information richness than AVIs <ref type="bibr">(Köchling et al., 2022)</ref>. Therefore, an interviewee has more opportunity to express nonverbal cues in SVIs than in AVIs, and human interviewers or assessors may perceive richer nonverbal cues that are invalid for detecting faking behaviors in SVIs than in AVIs. Moreover, the presence of a picture-in-picture window during SVIs where an interviewer can observe his or her presentation in a mirror increases self-focused attention, which may cause cognitive loading and distract the interviewer's attention when evaluating the interviewee's answers <ref type="bibr">(Horn and Behrend, 2017)</ref>. We anticipate that interviewers can focus more on the content of interviewees' answers in AVIs than in SVIs because AVIs offer fewer nonverbal cues and no picture-in-picture window. Accordingly, interviewers/assessors have a higher probability of accurately detecting interviewees who are faking in AVIs than in SVIs and therefore have more opportunity to adjust the interviewee's score or evaluation based on their perceptions of faking behaviors. We propose our last hypothesis as follows:</p><p>Hypothesis 3: Interviewers/assessors can detect an interviewee's faking more accurately in AVIs than in SVIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Materials and methods</head><p>To address the aforementioned research questions, we carried out a field study involving actual job interviewers/assessors and job applicants in the context of employment interviews. The credibility of our study is particularly strong as the interviewers were experienced recruiters, and the interviewees were actual job applicants applying for an internship position. Through this field study, our research aims to provide insights into how AVI and AI influence the responses of job applicants and interviewers with regard to faking behaviors in AI video interviews. <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2025)</ref>. Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information <ref type="bibr">Technology &amp; People,</ref><ref type="bibr">38(2)</ref>, 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 13 This field study aimed to investigate the faking behaviors of job applicants and the accuracy of interviewer detection in four different experimental selection interview conditions based on two settings: the asynchrony of video interview modes (AVI vs. SVI) and the use of AI-assisted assessment (AI vs. Non-AI). These four conditions include Non-AI-assisted AVIs (Non-AI-AVI), AI-assisted AVIs (AI-AVI), Non-AI-assisted SVIs (Non-AI-SVI), and AIassisted SVIs (AI-SVI). The video interview modes were manipulated using different platforms, LINE (2022) for SVI and HRDA (2022) for AVI. The authors are co-developers of HRDA. The AI manipulation was done by instructing the interviewees that "My interview performance will be evaluated by an AI algorithm ( in both AVI-AI and SVI-AI groups) / a human assessor/interviewer (in both AVI and SVI groups)."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Procedure and design</head><p>In both AVI and SVI modes, each interviewee was assigned randomly to an interviewer/assessor and underwent an evaluation of their communication skills through a series of five behavioral-based structured interview questions used by a professional employer organization (PEO) that provides staffing services to employers for various job functions, including internships. An example of a sample question is "Can you describe a time when you had to resolve a conflict in a work environment? How did you go about it?" The interview process lasted approximately 18-25 minutes per candidate. Interviewees had three minutes to answer each question, preceded by one minute to think about or generate a response before the recording began for each question. The use of structured interviews in this study aimed to mitigate interference from interviewers' IM (e.g. rapport building, rapport building, selling, or smooth-talking) on applicants' behavior in the SVI context <ref type="bibr" target="#b58">(Wilhelmy et al., 2017)</ref>. A more reliable comparison was ensured by controlling this confounding factor during the comparison <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2025)</ref>. Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information <ref type="bibr">Technology &amp; People,</ref><ref type="bibr">38(2)</ref>, 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 14 with AVI. Furthermore, structured interviews helped prevent hasty evaluations by interviewers/assessors due to IM used by job applicants <ref type="bibr" target="#b25">(Frieder et al., 2016)</ref>.</p><p>In the SVI mode, interviews were conducted on video conferencing software, and interviewees were informed that their entire video interviews, including verbal and nonverbal messages, would be reviewed and assessed by an interviewer. The interviewers did not receive the resumes of the interviewees in advance to prevent any bias. In the AVI setting, interviews were conducted on a recorded video interview platform, and interviewees had access to a live recording preview window on their smartphone screen, similar to the SVI setting. Each question was presented on a separate screen, and interviewees were not allowed to request a re-record or review of their responses before moving on to the next question, just like in the SVI setting.</p><p>In the AI setting, interviewees were informed that their interview performances would be evaluated not only by a human interviewer/assessor but also with the assistance of AI algorithms, with the specific criteria used by each kept undisclosed. In the non-AI setting, interviewees were informed that their interview performances would be evaluated by a human, without disclosing the specific criteria used. To ensure the validity of this manipulation, we followed the approach of Langer et al. ( <ref type="formula">2020</ref>) and asked all interviewees in the AI groups to confirm that they did not receive any information about how their interview performance would be evaluated. In both AI and non-AI settings, interviewees were allowed to complete their responses before moving on to the next question without interruption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Participants</head><p>We recruited paired interviewers/assessors and interviewees through a PEO based on an academic-industry cooperation agreement. The interviewers/assessors were the PEO's actual recruiters with an average of 8 years of interview experience who were invited to participate in the experiment and were offered a gift card worth approximately 30 USD as compensation. The interviewees were interested in pursuing intern job vacancies and were promised entrance to a second round of face-to-face interviews if their performance was satisfactory to the interviewers/assessors.</p><p>To reach the minimum required sample size for testing H1 and H2, we employed G*Power <ref type="bibr" target="#b22">(Faul et al., 2009)</ref> to estimate the necessary sample size for an Independent Samples T-Test (one-tail) with a moderate effect size (d) of 0.5, an alpha level of 0.05, a power of 0.9, and two groups with an allocation ratio of 1. Given these criteria, our goal was to enlist at least 140 interviewer/assessor-interviewee pairs. Ultimately, our study involved 144 job interviewers and 144 job applicants, who were randomly divided into four groups: 70 pairs for the AVI group, 74 pairs for the SVI group, 72 pairs for the AI group, and 72 pairs for the non-AI group in the final analysis.</p><p>We also ensured that the total number of paired data points was sufficient for Pearson's correlation analysis (one-tails) by recruiting more participants than the required sample size of 88, based on the assumption of a moderate effect size of .30, alpha = 0.05, and power = 0.9.</p><p>During the recruitment process, we discarded participants who failed to complete (5) or withdraw from (10) the survey or failed the manipulation check (1) for the AI treatment, leaving us with a final dataset for analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Interviewees</head><p>A total of 144 graduate students and recent graduates seeking internship opportunities participated in the study, with 65 (45%) males and 79 (55%) females. The interviewees' ages ranged from 20 to 28 years (Mean = 23.56, Standard Deviation, SD = 0.93). Among them, 36%</p><p>Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> </p><p>16 held a Master's degree, while 64% had a bachelor's degree. Additionally, 28% had more than a year of full-time work experience, and 72% had part-time work experience. 13% had prior video interview experience.</p><p>To ensure voluntary participation and address concerns about self-reported faking, we implemented <ref type="bibr" target="#b38">Powell et al.'s (2021)</ref> safeguard protocol. This involved sending an email invitation with a digital consent form to participants, assuring them of response confidentiality, and emphasizing the voluntary nature of participation. A post hoc check was conducted to gauge participants' confidence in response confidentiality, resulting in a mean value of 4.52 with an SD of 0.67. This aligns with <ref type="bibr" target="#b38">Powell et al.'s (2021)</ref> findings, indicating the effectiveness of our safeguard procedure in reducing potential biases in participant responses, particularly regarding self-reported faking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Interviewers/assessors</head><p>The study invited a total of 144 recruiters from the PEO to participate, of whom 98 (68%) were female and 46 (32%) were male HR professionals. The participating recruiters had an average of 8 years of employment interview experience. The interviewees were randomly assigned to one of four experimental settings and each interview was conducted in a one-on-one mode as per Fifić and Gigerenzer's (2014) method, which ensured that each interviewer/assessor was matched with only one interviewee. To ensure that the interviewers/assessors were familiar with the experimental procedures and knew how to operate the video interview platforms, they underwent a one-hour training session, during which they received assistance from the PEO's administrators. It should be noted that the interviewers/assessors had already used the SVI and AVI platforms to screen their job candidates before the study, as reported by <ref type="bibr">Suen et al. (2019a)</ref>.</p><p>Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 17</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Measures</head><p>After the interviews, both interviewees and interviewers/assessors completed a brief deceptive IM scale comprising 16 items to evaluate applicants' deceptive behaviors. This scale, adapted from <ref type="bibr" target="#b14">Bourdage et al. (2018)</ref>, consisted of four subscales: slight image creation (Cronbach's α = 0.82-0.85), extensive image creation (α = 0.80-0.83), image protection (α = 0.86-0.88), and ingratiation (α = 0.88-0.89). Scores were collected from both applicants' self-reports and interviewers'/assessors' perceptions. To compute overall faking scores for self-reported and interviewer/assessor perception, we averaged the scores across the four subscales, following the approach of <ref type="bibr" target="#b38">Powell et al. (2021)</ref>. Participants, including interviewers and assessors, as well as interviewees, were randomly assigned to one of four conditions, and paired data were collected, aligning scores from interviewers/assessors with self-reported scores from interviewees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Linear Relationships Between Variables</head><p>Before testing the hypotheses, we conducted a chi-square analysis and (Analysis of Variance, ANOVA) to investigate whether the interviewees' demographic characteristics such as age, sex, education, work experience, and video interview experience (Langer et al., 2016) had any impact on the group differences and dependent variables (i.e., applicant faking) in this study <ref type="bibr" target="#b15">(Brandã o et al., 2019)</ref>. However, these analyses did not find any statistically significant factors (p&lt;.05) that might have influenced the differences between the AVI and SVI modes or between the AI and non-AI settings. Therefore, we did not include these demographic data in the subsequent analyses.</p><p>Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref>  The matrix reveals that interviewees reported engaging in more faking behaviors (r = .284 to .469, p &lt; .01) during SVIs compared to AVIs. Furthermore, interviewees indicated that they engaged in less extensive faking when AI was involved compared to non-AI interview settings (r = -.169 to -254, p &lt; .05), except for image protection and ingratiation. Furthermore, interviewers/assessors noted a higher frequency of faking behaviors in interviewees during SVIs compared to AVIs (r = .346 to .554, p &lt; .01). However, they did not perceive significant differences in faking behaviors when considering the presence or absence of AI-assisted assessment (p &gt; .05). It's important to note that there was only a modest alignment in the perception of overall faking (r = .263, p &lt; .01) and extensive image creation (r = .198, p &lt; .05) 19 between interviewers/assessors and interviewees. There were no significant correlations found for the other three faking behaviors (p &gt; .05).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Impact of AVI vs. SVI and AI vs. Non-AI on Faking</head><p>To evaluate H1 and H2, we conducted a series of independent samples T-tests to investigate the impact of synchrony of video interviews (AVI vs. SVI) and the use of AI-assisted assessment (AI vs. non-AI) on interviewees' overall faking scores and specific faking scores.</p><p>Before examining the main effects of the two independent variables, it was determined that the interaction effects between the variables did not significantly impact the dependent variables.</p><p>Figure <ref type="figure">1</ref> presents the mean scores of interviewees' self-reported and interviewers'/assessors' perceived faking behaviors of interviewees across different video interview modes and AI settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Applicant Faking Reported by Interviewees and Interviewers/Assessors</head><p>The T-test results, as shown in Table <ref type="table" target="#tab_5">2</ref>, revealed that the self-reported overall faking score in the AVI Group was significantly lower than in the SVI Group, with a substantial negative effect size (Cohen's d = -0.738), thereby supporting H1 based on the applicants' self-</p><p>Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 20 reported data. Furthermore, self-reported faking scores for slight image creation, extensive image creation, and ingratiation in the AVI Group were also significantly lower than in the SVI Group,</p><p>showing small to moderate negative effect sizes (Cohen's d = -0.164 to -0.622). However, no significant difference was found in self-protection between the AVI and SVI groups From the perspective of interviewers and assessors, no statistically significant (p &gt;.05) differences were found in either overall or specific faking scores between the AI and non-AI groups. As a result, H2 was not supported based on evaluations by interviewers and assessors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluating Faking Detection in AVI vs. SVI</head><p>To evaluate the accuracy of identifying applicant faking behaviors, we followed the approach of <ref type="bibr" target="#b43">Roulin et al. (2014)</ref> by examining the correlation between interviewers'/assessors' perceptions of faking scores and the self-reported faking scores of interviewees. Simple linear regression was conducted to test H3, comparing the correlations between interviewees' selfreported faking scores and interviewers'/assessors' perceptions in both AVI and SVI settings. Table <ref type="table" target="#tab_6">3</ref> presents the correlations between interviewees' self-reported faking scores and the perceptions of both interviewers and assessors. The results indicate that these correlations were generally higher in the AVI mode than in the SVI mode. To compare the correlation coefficients between SVI and AVI across different faking types, a Steiger's Z-test was employed with a significance level of α=0.05. The analysis results, as shown in Table <ref type="table" target="#tab_6">3</ref>, revealed that for extensive image creation, the correlation coefficients between SVI and AVI were significantly negatively different. However, for other specific faking behaviors and overall faking, the differences in correlation coefficients were not statistically significant. These findings suggest that the AVI mode allowed assessors to more accurately identify interviewees' fabricated responses compared to interviewers using the SVI mode. Consequently, our results provide partial support for H3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Media Richness Impact on AVI and SVI Perceptions</head><p>To examine the impact of media richness on the distinct perceptions of AVI and SVI among interviewees and interviewers, a supplementary exploratory investigation was conducted.</p><p>We recruited 60 new job candidates, who were not part of the original 144 participants from the main study, to gain experience with digital interviews. They followed the same procedure and were randomly assigned to either AVI or SVI conditions. Additionally, we invited 30 interviewers and 30 assessors from the original group of 144 participants to take part in a postsurvey specifically designed for either AVI or SVI.</p><p>Consequently, a total of 30 interviewees and interviewers participated in the post-survey for SVI, while another 30 interviewees and 30 assessors engaged in the post-survey for AVI. As the PEO conducted the survey in an anonymous manner, access to respondents' demographic</p><p>Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 23</p><p>data was not possible. This investigation encompassed both the 60 interviewers/assessors and the 60 interviewees who rated or completed the video interviews using AVI and SVI.</p><p>We employed a 13-item, five-point scale developed by <ref type="bibr" target="#b23">Ferry et al. (2001)</ref> to investigate the perceived differences in media richness, specifically examining multiple channels, immediacy of feedback, and personalness. Multiple channels involve utilizing various senses for communication, whereas multiple cues refer to alternative ways of conveying information within a specific channel. Immediacy of feedback refers to the medium's ability to facilitate feedback and the speed at which feedback can be provided. Personalness relates to the extent to which a message conveyed through a specific medium is perceived as having a personal nature (see <ref type="bibr" target="#b23">Ferry et al., 2001)</ref>.</p><p>We conducted confirmatory factor analyses and reliability analyses to examine the threefactor scale. The survey results from interviewers/assessors and interviewees revealed a</p><p>Comparative Fit Index (CFI) of 0.93 and 0.86, respectively, which can be considered an adequate level of fit. The three sub-dimensions of media richness, as well as Cronbach's α for the overall scale, ranged from 0.90 to 0.97 and 0.85 to 0.97, respectively, indicating a high level of internal consistency reliability.</p><p>A series of independent t-tests were conducted to examine the differences in media richness measures between AVI and SVI. For interviewers/assessors, the analysis revealed a significant difference in media richness measures between the two groups (t(58) = 12.422 -16.232, p &lt; .001). The effect sizes (Cohen's d) ranged from 3.207 to 4.191, indicating a large effect. These results suggest that SVI is perceived to have significantly higher levels of media richness compared to AVI by the interviewers/assessors. Similarly, for interviewees, a significant difference in media richness measures between the two groups was observed (t(58) = 11.623 -14.135, p &lt; .001). The effect sizes (Cohen's d) ranged from 3.001 to 4.137, also indicating a large effect. The findings indicate that interviewees perceive SVI to possess significantly higher levels of media richness compared to AVI. Consequently, the analysis reveals notable differences in media richness between SVI and AVI, as perceived by both interviewers/assessors and interviewees. These differences have subsequent effects on their behaviors during the digital interviews conducted in this study. Figure <ref type="figure" target="#fig_0">2</ref> below presents the means of media richness for AVI and SVI as perceived by the 60 interviewers/assessors and interviewees. 5 Discussion Although AI-assisted video interviews are gaining popularity, future research should be conducted to investigate job candidates' actual IM in various video interview modes, as  <ref type="bibr">Liem et al., 2018;</ref><ref type="bibr">Melchers et al., 2022;</ref><ref type="bibr" target="#b59">Woods et al., 2020)</ref>.</p><p>Our findings suggest that the intensity of faking behaviors among interviewees varies depending on the video interview mode (AVI versus SVI), as perceived by both interviewees and interviewers/assessors. SVIs, which provide more nonverbal cues for social signal processing, may result in a higher occurrence of faking behaviors compared to AVIs. SVIs didn't result in more information omission (image protection) compared to AVIs according to interviewees' selfreported data. This might be because the interview questions did not extensively cover past failure-related experiences of applicants, and the structured interview format lacked follow-up questions. As a result, interviewees felt less need for image protection, as reflected by the mean score of 2.53.</p><p>The study revealed that AI reduced the self-reported slight and extensive image creation of interviewees. However, based on the observations of interviewers/assessors, there were no significant differences in faking behaviors between AI-assisted assessment and non-AI-assisted assessment AVI or SVI modes. The finding is consistent with previous research, suggesting that the presence of AI in SVIs does not impact job candidates' faking intentions <ref type="bibr">(Bill and Melchers, 2022)</ref>.</p><p>The interviewers/assessors were unable to perceive any discernible differences in applicants' deceptions in the presence or absence of AI. One possible explanation is that the AI interface used in the study lacked visible interfaces or transparency (see <ref type="bibr" target="#b49">Suen and Hung, 2023)</ref>,</p><p>Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 26 which may have failed to alert interviewees that their deceptions would be detected. The findings support previous research indicating that the use of AI assessment in video interviews does not negatively affect candidates' self-presentation (Köchling et al., 2022). The structured interview format employed in this study may have influenced the effects of AI on different aspects of faking behaviors. Without follow-up questions, interviewees may have avoided discussing past failures (image protection) and adhered to expected norms (ingratiation) to pass faking detection. However, they may have believed that AI could more easily detect slight or extensive image creation, leading to a reduction in those behaviors during interactions with AI. While our findings support H2 based on self-reported overall faking scores, it is crucial to consider other factors that could have influenced the results. Our research reinforces previous findings that indicate the limited ability of experienced interviewers to detect subtle forms of applicant faking, regardless of the inclusion of AI. However, our results demonstrate that interviewers exhibited greater proficiency in identifying interviewees' self-reported extensive image creation in AVIs compared to SVIs. This finding suggests that SVIs have a higher media richness level compared to AVIs, which can cause interviewers to become easily distracted and observe too many invalid cues, leading to misjudgments of interviewees' exaggerations. In other words, using AVIs instead of SVIs can enhance assessors' detection accuracy for extensive image creation.</p><p>The paper provides multiple significant academic contributions. Firstly, it enhances our comprehension of the likely social impacts of utilizing various video interview modes <ref type="bibr" target="#b7">(Baker et al., 2020;</ref><ref type="bibr">Lukacik et al., 2022)</ref> and AI algorithms in the hiring process <ref type="bibr" target="#b62">(Zhang and Yencha, 2022)</ref>, and more broadly, of AI application and human responses in the workplace <ref type="bibr" target="#b61">(Yu et al., 2023)</ref>. Moreover, our study refines the theoretical model of interviewee performance (Huffcutt et</p><p>Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 27 al., 2011) by examining the effect of AI-assisted AVIs (Hickman et al., 2022). To our knowledge, this study may be one of the first to investigate how AVIs and AI influence interviewees' deceptive IM and interviewers' ability to detect deception. Secondly, the current study extends and refines the model of faking likelihood in employment interviews (Levashina and Campion, 2006) in line with media richness theory and the model of volitional rating behavior based on expectancy theory in the context of both AVI and SVI with and without AI interacting with interviewees and interviewers. By understanding the role of media richness of the video interview mode in applicant faking behaviors, this research can help predict deceptive IM behaviors used by job interviewees in video interviews. Lastly, the media richness of the video interview mode may affect the accuracy of faking detection by interviewers, particularly for extensive image creation. The roles of the faking likelihood model, volitional rating behavior, and expectancy offer insights into interactive computing regarding how AI video interviews impact interviewees' willingness to misrepresent their work experience or accomplishments. This study has important practical implications for practitioners designing AI video interview systems for employers. One key recommendation is for employers to use AVIs with AI to auto-screen job applicants in the pre-selection phase, which can reduce the likelihood of deceptive IM when using AVI. In AVIs, there is no human interviewer to flatter or provide feedback, which can discourage applicants from engaging in deception. When AI is integrated into AVIs, it does not appear to influence assessors' evaluations of candidates' performance due to the use of deceptive IM tactics by the candidates. Furthermore, employers should be aware that human interviewers have limited ability to detect faking behavior. Although AVIs can improve human detection accuracy, the improvement Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 28 is not substantial. Employers could consider incorporating AI as a copilot to complement the assessor's selection training in order to enhance the evaluation of candidates' interview performance. This approach can improve the accuracy and validity of faking detection in video interviews by reducing reliance on human observation and attribution of nonverbal cues (Monaro et al., 2022).</p><p>There are several notable limitations of this study that can guide future research. First, the results were generated under specific conditions, including the use of particular video interview tools, the absence of resumes, the omission of a warm-up phase, the use of single questions about past behavioral incidents without follow-up questions, and the presentation of intern roles as job openings. These conditions may limit the generalizability of the findings (see <ref type="bibr">Lukacik et al., 2022)</ref>. Future studies should re-examine faking behaviors in other contexts while controlling for all possible variables.</p><p>Second, the participants in this study had limited work and interview experience, and they lived in a society without restrictions on the use of AI video interviews in hiring, such as the Illinois Artificial Intelligence Video Interview Act. Therefore, future research should include more diverse and experienced participants from different states or countries to test the research model.</p><p>Third, while the interviewees in AI-assisted assessment groups knew that their interview performance would be evaluated, they may have been less cautious about how the AI evaluated their performance, as is the case in many real AI-assisted video interviews <ref type="bibr">(Jaser et al., 2022)</ref>.</p><p>Therefore, future studies should design AI systems that transparently explain how they work in advance <ref type="bibr" target="#b61">(Yu et al., 2023)</ref>.</p><p>Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. <ref type="url" target="https://doi.org/10.1108/ITP-02-2023-0189">https://doi.org/10.1108/ITP-02-2023-0189</ref> 29</p><p>Fourth, the AI in this study did not have any visible interfaces, which might have decreased the interviewees' awareness of the AI's presence during the interview process <ref type="bibr" target="#b49">(Suen and Hung, 2023)</ref>. Future studies could characterize AI as a tangible avatar or immediate chatbot <ref type="bibr">(Gkinko and Elbanna, 2022;</ref><ref type="bibr">Pillai et al., 2023a;</ref><ref type="bibr" target="#b37">Pillai et al., 2023b)</ref> and examine its effects on applicant faking.</p><p>Fifth, although self-reported scores are commonly regarded as a reliable criterion for assessing applicant faking <ref type="bibr" target="#b38">(Powell et al., 2021)</ref>, they are also susceptible to response bias <ref type="bibr" target="#b10">(Bauhoff, 2014)</ref>. Future research should consider adopting or developing machine learning models to assess interview deception in high-stakes contexts (cf. <ref type="bibr">Monaro et al., 2022)</ref>.</p><p>Finally, despite our supplementary study confirming differences in media richness, it's essential to acknowledge that SVIs and AVIs may not be completely equivalent aside from the richness of the media. Future research endeavors could explore alternative explanations for the observed effects, such as Media Synchronicity Theory <ref type="bibr" target="#b20">(Dennis et al., 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>To conclude, our study aligns with the recommendation for AI video interview research to focus on human-AI interaction in AVIs, rather than conventional human-computer interactions in SVIs with non-AI systems. By examining the impact of video interview mode and AI on the interview process, our findings indicate that the use of AVIs can decrease interviewee deception, while the utilization of AI can reduce their tendency to create a highly crafted image. These results provide insight into the potential for AI-assisted video interviews to enhance selection validity in terms of applicant faking. Furthermore, our study provides valuable guidance for future research to examine the broader implications of AVIs and AI on workplace practices and theories.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Perceptions of AVI and SVI Among Interviewers and Interviewees</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. https://doi.org/10.1108/ITP-02-2023-0189 18 To understand the patterns and linear relationships between the variables in this study, we conducted a Pearson correlation analysis, as shown in Table 1. Mean, SD, and Correlation matrix.</figDesc><table><row><cell>Varaibles</cell><cell>Mean SD</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell></row><row><cell>1. Slight image creation (Self-reported)</cell><cell>3.16 0.75</cell><cell>--</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">2. Extensive image creation (Self-reported) 3.01 0.92 .788 ***</cell><cell>--</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3. Image protection (Self-reported)</cell><cell cols="3">2.53 0.59 .434 *** .429 ***</cell><cell>--</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4. Ingratiation (Self-reported)</cell><cell cols="4">3.03 0.74 .744 *** .766 *** .335 ***</cell><cell>--</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5. Overall Faking (Self-reported)</cell><cell cols="5">2.94 0.63 .770 *** .921 *** .616 *** .869 ***</cell><cell>--</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>6. Slight image creation (Interviewers/Assessors)</cell><cell cols="6">3.41 0.73 .116 .231 ** .053 .293 *** .216 **</cell><cell>--</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>7. Extensive image creation (Interviewers/Assessors)</cell><cell cols="7">3.31 0.68 .126 .198 * .182 * .288 *** .237 ** .492 ***</cell><cell>--</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>8. Image protection (Interviewers/Assessors)</cell><cell cols="8">3.25 0.60 .277 *** .312 *** .141 .273 *** .308 *** .628 *** .378 ***</cell><cell>--</cell><cell></cell><cell></cell><cell></cell></row><row><cell>9. Ingratiation (Interviewers/Assessors)</cell><cell cols="9">3.30 0.74 .063 .073 .119 .162 .121 .555 *** .782 *** .501 ***</cell><cell>--</cell><cell></cell><cell></cell></row><row><cell>10. Overall Faking (Interviewers/Assessors)</cell><cell cols="2">3.32 0.56 .170</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>* .242 ** .148 .308 *** .263 ** .822 *** .818 *** .748 *** .877 *** --11. Video interview mode (SVI=2; AVI=1) 1.51 0.50 .299 *** .284 *** .082 .469 *** .348 *** .554 *** .392 *** .346 *** .429 *** .530 *** --12. AI setting (AI=2; Non-AI=1) 1.50 0.50 -.254 ** -.169 * -.041 -.089 -.172 * -.102 -.136 -.072 -.028 -.020 .028 *p &lt; .05, ** p &lt; .01, *** p &lt; .001</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 .</head><label>2</label><figDesc>Independent Samples T-Test Results , H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. Information Technology &amp; People, 38(2), 963-983. https://doi.org/10.1108/ITP-02-2023-0189 21In examining the influence of AI on applicant faking, T-tests revealed that interviewees' self-reported overall faking score in the AI group was lower than that in the non-AI groups. This</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>95% CI for</cell></row><row><cell>Independent Samples T-Test</cell><cell>Faking Behaviors</cell><cell>Source</cell><cell>t</cell><cell>p</cell><cell>Mean Difference</cell><cell cols="2">Mean Difference Cohen's d</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Lower Upper</cell></row><row><cell></cell><cell>Slight image creation</cell><cell></cell><cell cols="3">-3.728 &lt; .001 -0.447</cell><cell>-0.684 -0.210</cell><cell>-0.622</cell></row><row><cell></cell><cell>Extensive image creation</cell><cell></cell><cell cols="3">-3.525 &lt; .001 -0.519</cell><cell>-0.81 -0.228</cell><cell>-0.588</cell></row><row><cell>AVI vs. SVI</cell><cell>Image protection</cell><cell></cell><cell cols="3">-0.984 0.327 -0.097</cell><cell>-0.292 0.098</cell><cell>-0.164</cell></row><row><cell></cell><cell>Ingratiation</cell><cell></cell><cell cols="3">-6.335 &lt; .001 -0.688</cell><cell>-0.903 -0.473</cell><cell>-1.056</cell></row><row><cell></cell><cell>Overall faking</cell><cell>Self-report</cell><cell cols="3">-4.427 &lt; .001 -0.439</cell><cell>-0.634 -0.243</cell><cell>-0.738</cell></row><row><cell></cell><cell>Slight image creation</cell><cell></cell><cell cols="3">-3.134 0.002 -0.381</cell><cell>-0.621 -0.141</cell><cell>-0.522</cell></row><row><cell></cell><cell>Extensive image creation</cell><cell></cell><cell cols="3">-2.038 0.043 -0.308</cell><cell>-0.607 -0.009</cell><cell>-0.340</cell></row><row><cell>AI vs. Non-AI</cell><cell>Image protection</cell><cell></cell><cell cols="3">-0.492 0.623 -0.049</cell><cell>-0.244 0.147</cell><cell>-0.082</cell></row><row><cell></cell><cell>Ingratiation</cell><cell></cell><cell cols="3">-1.066 0.288 -0.131</cell><cell>-0.373 0.111</cell><cell>-0.178</cell></row><row><cell></cell><cell>Overall faking</cell><cell></cell><cell cols="3">-2.086 0.039 -0.217</cell><cell>-0.423 -0.011</cell><cell>-0.348</cell></row><row><cell></cell><cell>Slight image creation</cell><cell></cell><cell cols="3">-7.928 &lt; .001 -0.807</cell><cell>-1.009 -0.606</cell><cell>-1.322</cell></row><row><cell></cell><cell>Extensive image creation</cell><cell></cell><cell cols="3">-5.071 &lt; .001 -0.532</cell><cell>-0.739 -0.325</cell><cell>-0.846</cell></row><row><cell>AVI vs. SVI</cell><cell>Image protection</cell><cell></cell><cell cols="3">-4.39 &lt; .001 -0.414</cell><cell>-0.601 -0.228</cell><cell>-0.732</cell></row><row><cell></cell><cell>Ingratiation</cell><cell></cell><cell cols="3">-5.656 &lt; .001 -0.631</cell><cell>-0.851 -0.410</cell><cell>-0.943</cell></row><row><cell></cell><cell>Overall faking</cell><cell>Interviewers /</cell><cell cols="3">-7.454 &lt; .001 -0.596</cell><cell>-0.754 -0.438</cell><cell>-1.243</cell></row><row><cell></cell><cell>Slight image creation</cell><cell>Assessors</cell><cell cols="3">-1.222 0.224 -0.149</cell><cell>-0.389 0.092</cell><cell>-0.204</cell></row><row><cell></cell><cell>Extensive image creation</cell><cell></cell><cell cols="3">1.637 0.104 0.185</cell><cell>-0.038 0.408</cell><cell>0.273</cell></row><row><cell>AI vs. Non-AI</cell><cell>Image protection</cell><cell></cell><cell cols="3">-0.859 0.392 -0.086</cell><cell>-0.284 0.112</cell><cell>-0.143</cell></row><row><cell></cell><cell>Ingratiation</cell><cell></cell><cell cols="3">-0.338 0.736 -0.042</cell><cell>-0.286 0.202</cell><cell>-0.056</cell></row><row><cell></cell><cell>Overall faking</cell><cell></cell><cell cols="3">-0.243 0.808 -0.023</cell><cell>0.094 0.163</cell><cell>-0.041</cell></row><row><cell cols="8">In terms of interviewers/assessors' perceptions, T-tests indicated that interviewees' overall</cell></row><row><cell cols="8">and specific faking scores in the AVI groups were significantly lower than in the SVI group,</cell></row></table><note><p>accompanied by substantial negative effect sizes (Cohen's d = -0.732 to -1.322), thereby strongly supporting H1 from the interviewers' and assessors' perspective. Suen</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 .</head><label>3</label><figDesc>Correlation: Interviewee Self-Reports vs. Interviewer Perceptions</figDesc><table><row><cell></cell><cell cols="5">Slight image creation Extensive image creation image protection Ingratiation Overall faking</cell></row><row><cell>SVI</cell><cell>.067</cell><cell>.032</cell><cell>.013</cell><cell>.006</cell><cell>.076</cell></row><row><cell>AVI</cell><cell>.148</cell><cell>.280*</cell><cell>.055</cell><cell>.109</cell><cell>.103</cell></row><row><cell>Steiger's Z-Value</cell><cell>-.974</cell><cell>-3.306**</cell><cell>-.516</cell><cell>-1.270</cell><cell>-.334</cell></row><row><cell>n = 144</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>**p &lt; .01; *p &lt; .05</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p>Suen, H. Y., &amp; Hung, K. E. (2025). Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments. InformationTechnology &amp; People, 38(2), 963-983. https://doi.org/10.1108/ITP-02-2023-0189</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189References" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Why does impression management positively influence interview ratings? The mediating role of competence and warmth</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Amaral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ho</surname></persName>
		</author>
		<idno type="DOI">10.1111/ijsa.12260</idno>
		<ptr target="https://doi.org/10.1111/ijsa.12260" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Selection and Assessment</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="315" to="327" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Are They Accurate? Recruiters&apos; Personality Judgments in Paper versus Video Resumes</title>
		<author>
			<persName><forename type="first">C</forename><surname>Apers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Derous</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2017.02.063</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2017.02.063" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="9" to="19" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Just sit back and watch: large disparities between video and face-to-face interview observers in applicant ratings</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Kueny</surname></persName>
		</author>
		<idno type="DOI">10.1080/10447318.2020.1805874</idno>
		<ptr target="https://doi.org/10.1080/10447318.2020.1805874" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="1968" to="1979" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Technology in the employment interview: A meta-analysis and future research agenda</title>
		<author>
			<persName><forename type="first">N</forename><surname>Blacksmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Wilford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Behrend</surname></persName>
		</author>
		<idno type="DOI">10.25035/pad.2016.002</idno>
		<ptr target="https://doi.org/110.25035/pad.2016.002" />
	</analytic>
	<monogr>
		<title level="j">Personnel Assessment and Decisions</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="20" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">It takes more than a good camera: Which factors contribute to differences between face-to-face interviews and videoconference interviews regarding performance ratings and interviewee perceptions?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Basch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Melchers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kurz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10869-020-09714-3</idno>
		<ptr target="https://doi.org/10.1007/s10869-020-09714-3" />
	</analytic>
	<monogr>
		<title level="j">Journal of Business and Psychology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="921" to="940" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Self-report bias in estimating cross-sectional and treatment effects</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bauhoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Encyclopedia of Quality of Life and Well-Being Research</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Michalos</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="5798" to="5800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Thou Shalt not Lie! Exploring and testing countermeasures against faking intentions and faking in selection interviews</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Melchers</surname></persName>
		</author>
		<idno type="DOI">10.1111/ijsa.12402</idno>
		<ptr target="https://doi.org/10.1111/ijsa.12402" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Selection and Assessment</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="22" to="44" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Thou Shalt not Lie! Exploring and testing countermeasures against faking intentions and faking in selection interviews</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Melchers</surname></persName>
		</author>
		<idno type="DOI">10.1111/ijsa.12402</idno>
		<ptr target="https://doi.org/10.1111/ijsa.12402" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Selection and Assessment</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="22" to="44" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">I (might be) just that good&quot;: honest and deceptive impression management in employment interviews</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Bourdage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tarraf</surname></persName>
		</author>
		<idno type="DOI">10.1111/peps.12285</idno>
		<ptr target="https://doi.org/10.1111/peps.12285" />
	</analytic>
	<monogr>
		<title level="j">Personnel Psychology</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="597" to="632" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Online recruitment in Portugal: Theories and candidate profiles</title>
		<author>
			<persName><forename type="first">C</forename><surname>Brandã O</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">V</forename><surname>Santos</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbusres.2018.04.011</idno>
		<ptr target="https://doi.org/10.1016/j.jbusres.2018.04.011" />
	</analytic>
	<monogr>
		<title level="j">Journal of Business Research</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="273" to="279" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Asynchronous Video Interviewing as a New Technology in Personnel Selection: The Applicant&apos;s Point of View</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Brenner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Ortner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fay</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2016.00863</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2016.00863" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">863</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Automatic prediction of impressions in time and across varying context: Personality, attractiveness and likeability</title>
		<author>
			<persName><forename type="first">O</forename><surname>Çeliktutan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gunes</surname></persName>
		</author>
		<idno type="DOI">10.1109/TAFFC.2015.2513401</idno>
		<ptr target="https://doi.org/10.1109/TAFFC.2015.2513401" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="29" to="42" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Organizational Information Requirements, Media Richness and Structural Design</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Daft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Lengel</surname></persName>
		</author>
		<idno type="DOI">10.1287/mnsc.32.5.554</idno>
		<ptr target="https://doi.org/10.1287/mnsc.32.5.554" />
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="554" to="571" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Media, tasks, and communication processes: A theory of media synchronicity</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Valacich</surname></persName>
		</author>
		<idno type="DOI">10.2307/25148660</idno>
		<ptr target="https://doi.org/10.2307/25148660" />
	</analytic>
	<monogr>
		<title level="j">MIS Quarterly</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="575" to="600" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An Assessment of the Prevalence, Severity, and Verifiability of Entry-Level Applicant Faking Using the Randomized Response Technique</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Donovan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Dwight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Hurtz</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15327043HUP1601_4</idno>
		<ptr target="https://doi.org/10.1207/S15327043HUP1601_4" />
	</analytic>
	<monogr>
		<title level="j">Human Performance</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="106" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Statistical power analyses using G*Power 3.1: Tests for correlation and regression analyses</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Lang</surname></persName>
		</author>
		<idno type="DOI">10.3758/brm.41.4.1149</idno>
		<ptr target="https://doi.org/10.3758/brm.41.4.1149" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1149" to="1160" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Measuring Facts of Media Richness</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Ferry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Kydd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Sawyer</surname></persName>
		</author>
		<idno type="DOI">10.1080/08874417.2001.11647026</idno>
		<ptr target="https://doi.org/10.1080/08874417.2001.11647026" />
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Information Systems</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="69" to="78" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Are two interviewers better than one?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fifić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbusres.2014.03.003</idno>
		<ptr target="https://doi.org/10.1016/j.jbusres.2014.03.003" />
	</analytic>
	<monogr>
		<title level="j">Journal of Business Research</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1771" to="1779" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">How quickly do interviewers reach decisions? An examination of interviewers&apos; decision-making time across applicants</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Frieder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Van Iddekinge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Raymark</surname></persName>
		</author>
		<idno type="DOI">10.1111/joop.12118</idno>
		<ptr target="https://doi.org/10.1111/joop.12118" />
	</analytic>
	<monogr>
		<title level="j">Journal of Occupational and Organizational Psychology</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="223" to="248" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hope, tolerance and empathy: employees&apos; emotions when using an AI-enabled chatbot in a digitalised workplace</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gkinko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elbanna</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-04-2021-0328</idno>
		<ptr target="https://doi.org/10.1108/ITP-04-2021-0328" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1714" to="1743" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hope, tolerance and empathy: employees&apos; emotions when using an AI-enabled chatbot in a digitalised workplace</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gkinko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elbanna</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-04-2021-0328</idno>
		<ptr target="https://doi.org/10.1108/ITP-04-2021-0328" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1714" to="1743" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Video interviewing: A potential selection tool for hospitality managers-a study to understand applicant perspective</title>
		<author>
			<persName><forename type="first">P</forename><surname>Guchait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ruetzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Toldi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijhm.2013.08.004</idno>
		<ptr target="https://doi.org/10.1016/j.ijhm.2013.08.004" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Hospitality Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="90" to="100" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Personality traits associated with various forms of lying</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lemon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Curtis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Griffith</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12646-020-00563-x</idno>
		<ptr target="https://doi.org/10.1007/s12646-020-00563-x" />
	</analytic>
	<monogr>
		<title level="j">Psychological Studies</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="239" to="246" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Some things are better left unseen: Toward more effective communication and team performance in video-mediated interactions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Hassell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Cotton</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2017.03.039</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2017.03.039" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="200" to="208" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Automated video interview personality assessments: reliability, validity, and generalizability investigations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Saef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Woo</surname></persName>
		</author>
		<idno type="DOI">10.1037/apl0000695</idno>
		<ptr target="https://doi.org/10.1037/apl0000695" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Psychology</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1323" to="1351" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The relation between deceptive impression management and employment interview ratings: A meta-analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Stanley</surname></persName>
		</author>
		<idno type="DOI">10.1037/cbs0000223</idno>
		<ptr target="https://doi.org/10.1037/cbs0000223" />
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Behavioural Science</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="164" to="174" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-018939" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<idno type="DOI">10.1108/ITP-04-2022-0287</idno>
		<ptr target="https://doi.org/10.1108/ITP-04-2022-0287" />
		<imprint>
			<publisher>Technology &amp; People</publisher>
		</imprint>
	</monogr>
	<note>ahead-of-print ahead-of-print</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Students&apos; adoption of AI-based teacher-bots (T-bots) for learning in higher education</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Sivathanu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Metri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kaushik</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2021-0152</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2021-0152" />
	</analytic>
	<monogr>
		<title level="s">Information Technology &amp; People</title>
		<imprint>
			<date type="published" when="2023">2023b</date>
		</imprint>
	</monogr>
	<note>ahead-of-print ahead-of-print</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Shake and fake: The role of interview anxiety in deceptive impression management</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Bourdage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bonaccio</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10869-020-09708-1</idno>
		<ptr target="https://doi.org/10.1007/s10869-020-09708-1" />
	</analytic>
	<monogr>
		<title level="j">Journal of Business Psychology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="829" to="840" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Automatic assessment of communication skill in non-conventional interview settings: A comparative study</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S B</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rasipuram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Jayagopi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m">Proceedings of the 19th ACM International Conference on Multimodal Interaction</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Lank</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Vinciarelli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">H S</forename><surname>Subramanian</surname></persName>
		</editor>
		<meeting>the 19th ACM International Conference on Multimodal Interaction</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="221" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Liar, Liar, Pants on Fire: How Verbal Deception Cues Signal Deceptive Versus Honest Impression Management and Influence Interview Ratings</title>
		<author>
			<persName><forename type="first">L</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">C</forename><surname>Klehe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Willhardt</surname></persName>
		</author>
		<idno type="DOI">10.25035/pad.2021.01.007</idno>
		<ptr target="https://doi.org/10.25035/pad.2021.01.007" />
	</analytic>
	<monogr>
		<title level="j">Personnel Assessment and Decisions</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Identifying applicant faking in job interviews: Examining the role of criterion-based content analysis and storytelling</title>
		<author>
			<persName><forename type="first">N</forename><surname>Roulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Powell</surname></persName>
		</author>
		<idno type="DOI">10.1027/1866-5888/a000207</idno>
		<ptr target="https://doi.org/10.1027/1866-5888/a000207" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality Psychology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="143" to="154" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Interviewers&apos; perceptions of impression management in employment interviews</title>
		<author>
			<persName><forename type="first">N</forename><surname>Roulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bangerter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Levashina</surname></persName>
		</author>
		<idno type="DOI">10.1108/JMP-10-2012-0295</idno>
		<ptr target="https://doi.org/10.1108/JMP-10-2012-0295" />
	</analytic>
	<monogr>
		<title level="j">Journal of Management Psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="141" to="163" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Honest and deceptive impression management in the employment interview: can it be detected and how does it impact evaluations?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Roulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bangerter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Levashina</surname></persName>
		</author>
		<idno type="DOI">10.1111/peps.12079</idno>
		<ptr target="https://doi.org/10.1111/peps.12079" />
	</analytic>
	<monogr>
		<title level="j">Personnel Psychology</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="395" to="444" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Cues to deception in the employment interview</title>
		<author>
			<persName><forename type="first">L</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Roulin</surname></persName>
		</author>
		<idno type="DOI">10.1111/ijsa.12106</idno>
		<ptr target="https://doi.org/10.1111/ijsa.12106" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Selection and Assessment</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="190" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The Benefits of Distance and Mediation: How People React to Conflicts in Video Chat vs. FtF</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bente</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2017.03.022</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2017.03.022" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Predicting behavioral competencies automatically from facial expressions in real-time video-recorded interviews</title>
		<author>
			<persName><forename type="first">Y.-S</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11554-021-01071-5</idno>
		<ptr target="https://doi.org/10.1007/s11554-021-01071-5" />
	</analytic>
	<monogr>
		<title level="j">Journal of Real-Time Image Processing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1011" to="1021" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Building Trust in Automatic Video Interviews using Various AI Interfaces: Tangibility, Immediacy, and Transparency</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Does the use of synchrony and artificial intelligence in video interviews affect interview ratings and applicant attitudes?</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2019.04.012</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2019.04.012" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="93" to="101" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1108/ITP-02-2023-0189" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="963" to="983" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">TensorFlow-based automatic personality recognition used in asynchronous video interviews</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-E</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2019.2902863</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2019.2902863" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="61018" to="61023" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Intelligent video interview agent used to predict communication skill and perceived personality traits</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-E</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13673-020-0208-3</idno>
		<ptr target="https://doi.org/10.1186/s13673-020-0208-3" />
	</analytic>
	<monogr>
		<title level="j">Human-centric Computing and Information Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Employer Ratings through Crowdsourcing on Social Media: An Examination of U.S. Fortune 500 Companies</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-E</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-H</forename><surname>Tseng</surname></persName>
		</author>
		<idno type="DOI">10.3390/su12166308</idno>
		<idno>6308</idno>
		<ptr target="https://doi.org/10.3390/su12166308" />
	</analytic>
	<monogr>
		<title level="j">Sustainability</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">16</biblScope>
			<date type="published" when="2020">2020b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Initial impressions: what they are, what they are not, and how they influence structured interview outcomes</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Swider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Barrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">B</forename><surname>Harris</surname></persName>
		</author>
		<idno type="DOI">10.1037/apl0000077</idno>
		<ptr target="https://doi.org/10.1037/apl0000077" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Psychology</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="625" to="638" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Marketing AI recruitment: the next phase in job application and selection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Esch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferolie</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2018.09.009</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2018.09.009" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="215" to="222" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Work and motivation</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H</forename><surname>Vroom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964">1964</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Selling and Smooth-Talking: Effects of Interviewer Impression Management from a Signaling Perspective</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wilhelmy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kleinmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Melchers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Götz</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2017.00740</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2017.00740" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">740</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Personnel selection in the digital age: a review of validity and applicant reactions, and future</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nikolaou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Comparing job applicant deception in asynchronous vs. synchronous video interviews, with and without AI-assisted assessments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-02-2023-0189</idno>
		<ptr target="https://doi.org/10.1080/1359432X.2019.1681401" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Work and Organizational Psychology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="64" to="77" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
	<note>Information Technology &amp; People</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Antecedents and outcomes of artificial intelligence adoption and application in the workplace: the socio-technical system theory perspective</title>
		<author>
			<persName><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ashton</surname></persName>
		</author>
		<idno type="DOI">10.1108/ITP-04-2021-0254</idno>
		<ptr target="https://doi.org/10.1108/ITP-04-2021-0254" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="454" to="474" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Examining perceptions towards hiring algorithms</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Yencha</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.techsoc.2021.101848</idno>
		<ptr target="https://doi.org/10.1016/j.techsoc.2021.101848" />
	</analytic>
	<monogr>
		<title level="j">Technology in Society</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page">101848</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
