<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Third-party evaluators perceive AI as more compassionate than expert humans</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Springer Science and Business Media LLC</publisher>
				<availability status="unknown"><p>Copyright Springer Science and Business Media LLC</p>
				</availability>
				<date type="published" when="2025-01-10">2025-01-10</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dariya</forename><surname>Ovsyannikova</surname></persName>
							<idno type="ORCID">0009-0004-8360-0921</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Victoria</forename><forename type="middle">Oldemburgo</forename><surname>De Mello</surname></persName>
							<idno type="ORCID">0000-0003-2867-8529</idno>
						</author>
						<author role="corresp">
							<persName><forename type="first">Michael</forename><surname>Inzlicht</surname></persName>
							<email>michael.inzlicht@utoronto.ca</email>
							<idno type="ORCID">0000-0001-9297-6497</idno>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Rotman School of Management</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychology 1265 Military Trail Toronto</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<postCode>M1C 1A4</postCode>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Third-party evaluators perceive AI as more compassionate than expert humans</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Communications Psychology</title>
						<title level="j" type="abbrev">Commun Psychol</title>
						<idno type="eISSN">2731-9121</idno>
						<imprint>
							<publisher>Springer Science and Business Media LLC</publisher>
							<biblScope unit="volume">3</biblScope>
							<biblScope unit="issue">1</biblScope>
							<date type="published" when="2025-01-10" />
						</imprint>
					</monogr>
					<idno type="MD5">A3ADE8E446F058EDCA231A32C7C3EC87</idno>
					<idno type="DOI">10.1038/s44271-024-00182-6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Empathy connects us but strains under demanding settings. This study explored how third parties evaluated AI-generated empathetic responses versus human responses in terms of compassion, responsiveness, and overall preference across four preregistered experiments. Participants (N = 556) read empathy prompts describing valenced personal experiences and compared the AI responses to select non-expert or expert humans. Results revealed that AI responses were preferred and rated as more compassionate compared to select human responders (Study 1). This pattern of results remained when author identity was made transparent (Study 2), when AI was compared to expert crisis responders (Study 3), and when author identity was disclosed to all participants (Study 4). Third parties perceived AI as being more responsive-conveying understanding, validation, and care-which partially explained AI's higher compassion ratings in Study 4. These findings suggest that AI has robust utility in contexts requiring empathetic interaction, with the potential to address the increasing need for empathy in supportive communication contexts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Empathy is crucial for fostering societal unity and effective communication. It allows individuals to balance their own interests with the wellbeing of others through shared experiences and emotions. It can promote cooperation, altruism, and helping behaviors, thereby strengthening social bonds <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref> . Psychologically, empathy also has a nourishing effect on its recipients, such that people feel validated, understood, and connected when others empathize with them <ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5</ref> . Despite the positive impact of empathy on its recipients, the effort required to express empathy can be costly and burdensome to the empathizer <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7</ref> , making them less likely to respond empathically, a phenomenon known as empathy avoidance and compassion fatigue <ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9</ref> . This seems to be particularly apparent in clinical settings, where healthcare professionals may sacrifice some of their ability to empathize in order to avoid burnout <ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8</ref> , to manage personal distress <ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11</ref> , or to balance their emotional engagement with the need to effectively allocate resources to each client, particularly individuals with complex cases <ref type="bibr" target="#b11">12</ref> .</p><p>One consequence of these challenges is that empathy is in short supply, especially as the mental health sector struggles with accessible service and workforce shortages <ref type="bibr" target="#b12">13</ref> amid the increasing incidence of mental health disorders <ref type="bibr" target="#b13">14</ref> . Such shortages make the maintenance of compassionate care even more difficult for the currently employed mental health professionals, for whom it serves as one of several key responsibilities <ref type="bibr" target="#b7">8</ref> . While empathy is often understood as a dynamic process that originates from the experience of the empathizer <ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4</ref> , less is known about its effects on the perceivers of empathic support. Considering this and the challenges of meeting societal needs for empathy, here, we compare the quality of written empathic responses generated by Artificial Intelligence (AI) to select and expert humans. We ask if AI can match or even exceed the quality of responses made by human empathizers and examine the conditions under which people are more likely to prefer an empathetic response from an AI over a human.</p><p>In response to the gap between the supply and demand of empathy, scientists have asked if AI could provide consistent and quality supportive care. Despite arguments that AI cannot experience empathy or feel emotions <ref type="bibr" target="#b14">15</ref> , it can express empathy by generating responses or behaviors that appear to reflect empathic concern <ref type="bibr" target="#b15">16</ref> or the intention to alleviate distress <ref type="bibr" target="#b7">8</ref> . As such, scientists have begun exploring the effectiveness of AI powered by large language models in providing empathic support <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref> . These investigations, through methods ranging from third-party evaluations <ref type="bibr" target="#b16">17</ref> to direct recipient feedback <ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20</ref> , reveal that AI can be rated as comparable to, if not superior in, expressing empathetic support. For example, in a recent study <ref type="bibr" target="#b16">17</ref> , researchers compared the perceived quality and level of empathy in ChatGPT's responses to public questions generated on a Reddit forum (r/AskDocs) to responses made by verified human physicians through third party ratings made by healthcare professionals. It was found that chatbot responses were rated significantly more empathic and of higher quality than physician responses <ref type="bibr" target="#b16">17</ref> .</p><p>Interestingly, chatbot responses were also significantly longer than physician responses, perhaps reflecting the difficulties for humans to convey empathy through written text, particularly when these responses are made by healthcare professionals, who may experience competing demands and time constraints <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref> .</p><p>Several lines of evidence illustrate the potential benefits of interacting with an empathic AI. The fact that AI interactions are anonymous and that they involve machines and not humans can facilitate greater disclosure of personal information <ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25</ref> , perhaps because chatbots are not inherently judgmental and thus do not evoke a fear of feeling criticized <ref type="bibr" target="#b18">19</ref> . The latter effect is particularly important, as both the act and degree of self-disclosure have been experimentally demonstrated to increase and deepen subsequent disclosures, increase perceived intimacy and enjoyment of the interaction, as well as increase feelings of trust <ref type="bibr" target="#b23">24</ref> . Together, these elements and associated outcomes of AI interactions might explain why interacting with artificial agents might provide some social benefits to people <ref type="bibr" target="#b17">18</ref> .</p><p>Yet, the receptiveness to AI-generated empathic responses could be influenced by the recipient's awareness of and preconceived attitudes towards receiving support from non-human entities. For instance, people's perception of empathy expressions from AI could be rooted in an awareness that AI, unlike humans, lacks genuine emotional experience <ref type="bibr" target="#b14">15</ref> and thus cannot actually care; being unmoved by empathic AI statements might then reflect warranted skepticism about its capabilities regardless of its actual effectiveness <ref type="bibr" target="#b19">20</ref> . Simultaneously, general attitudes towards AI, related to factors such as personality, conspiracy mindset <ref type="bibr" target="#b25">26</ref> , and religiosity <ref type="bibr" target="#b26">27</ref> , among others, may play a critical role in the evaluation and acceptance of AI.</p><p>One recent study investigated differences in people's perceptions of feeling heard after receiving human or AI-generated responses that were or were not transparently labeled <ref type="bibr" target="#b19">20</ref> . AI responses were generally evaluated as more emotionally supportive and responsive than human responses. However, the AI advantage disappeared when participants believed that they were responded to by AI, such that their ratings of feeling heard and understood were higher when they believed that the responses came from a human. Critically, when AI and human responses were accurately labeled, participants reported equivalent perceptions of feeling heard and understood by either agent <ref type="bibr" target="#b19">20</ref> , suggesting that the benefits reaped from empathic AI interactions can occur even after accounting for the drop in perceived response quality, when people are made aware that they are not interacting with another human. Further research found that the mere act of emotional disclosure over a 25-minute conversation carried numerous emotional, psychological, and relational benefits, irrespective of whether participants believed they were conversing with an AI or human agent <ref type="bibr" target="#b18">19</ref> . Collectively, while these findings highlight the nuances of human reactions to AI-generated content, they challenge the notion that human interaction is irreplaceable in empathic exchanges and further suggest that attitudes towards empathyexpressing AI can improve with increasing familiarity and time.</p><p>Despite preliminary evidence that AI responses are rated as being greater or equal in empathy to human responses, there are a few limitations to this initial work. First, given the ethical requirements of consent and transparency in the use of AI <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b27">28</ref> , studies need to compare responses from humans versus AI, both when participants are blind to the source and fully aware of it. Doing so allows for the generalizability of empathic AI preference to ethical and legal contexts and allows for the investigation of the effects of AI aversion <ref type="bibr" target="#b28">29</ref> . Second, the present literature is limited in using laypersons to generate empathic responses that are then compared with AI responses <ref type="bibr" target="#b19">20</ref> . In other words, these participants do not receive formal training in providing empathic support and/or do not assume professional roles in providing empathic care.</p><p>At present, there are no known studies that compare empathic AI to trained "experts" of empathy or even samples selected for being particularly empathic, especially individuals working in the mental healthcare sector.</p><p>Here, in a series of four preregistered studies, we investigate whether there are significant differences in the way that third-party persons evaluate empathic responses by AI or human agents. We ask: do third-party evaluators rate responses made by AI as more compassionate than responses made by fellow humans selected for being good empathizers? (Study 1); will these differential evaluations hold when the identities of the two sources are made transparent? (Study 2); will they hold when empathic AI is compared to real-life experts of empathic support? (Study 3); and why is transparently labeled AI so good at generating empathic statements? (Study 4). To address the final question, we examine the mediating role of perceived responsiveness in driving judgments of compassion.</p><p>We hypothesized that participants would rate the responses generated by AI as more compassionate than those of select and expert human responders. We further hypothesized that participants would rate responses generated by AI as significantly better quality and prefer AI responses to responses generated by select and expert humans in a binary forced-choice scenario.</p><p>Finally, with respect to Study 4, we further hypothesized that participants would rate the AIgenerated responses as more responsive than human-generated responses in terms of communicating care, understanding, and validation <ref type="bibr" target="#b29">30</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>Our goal was to assess which agent was better at generating empathic statements: humans or AI. To evaluate this, we compared human-generated or GPT-generated written responses to empathic prompts across four experiments. We first created 10 empathy prompts (first-person descriptions of both positive (5) and negative (5) experiences). In studies 1-3, participants read all 10 empathy prompts describing personal experiences. In study 4, only 6 of the 10 prompts were presented to participants. For each empathy prompt, participants read a pair of potential empathic responses: one human-generated response and one GPT-generated response. Examples of vignettes and responses can be seen in Fig. <ref type="figure" target="#fig_3">1</ref>.</p><p>To generate the select human responses used in studies 1 and 2, we first piloted a study on our university participant pool and then formally ran the study on Prolific Academic <ref type="bibr" target="#b30">31</ref> . Ten participants were instructed to read the 10 empathy prompts and generate a compassionate written response to the author of the prompt. Out of the 100 overall responses generated (10 per participant), we asked 3 graduate students and 4 research assistants to rank order the top 5 responders based on how overall compassionate their responses were in terms of quality, emotional salience, relatability, and level of detail. The 5 responders who were ranked in the top 5 most often had their responses selected for use in the studies. Thus, we consider this a select group of empathic responders, as they were first screened and selected based on their overall empathic quality.</p><p>In studies 3 and 4, the human response stimuli were obtained from a sample of hotline crisis responders-volunteers trained to respond to psychological crises through telephone calls-whom we considered expert empathizers. These participants were recruited via emails that were internally distributed to all responders within the Distress Centres of Greater Toronto, a multi-helpline organization that offers emotional support to Canadian callers across general and national helplines. Five responders provided written empathic responses to the same 10 empathy prompts as the Prolific Academic sample. All responses were inspected for quality and used in the study, such that each participant only saw one randomly selected option of these 5 responses per vignette.</p><p>The AI-generated responses across all studies were created by prompting ChatGPT (model gpt-4-0125-preview) with the 10 vignettes describing the emotional experience (one at a time) and asking it to generate an appropriate empathetic response. Given the stochastic nature of ChatGPT, we generated 5 separate responses per vignette. All responses generated by ChatGPT were used in the study. These responses were randomized in the study, such that participants only saw one of these 5 responses per vignette. For a detailed report of how the empathy prompts and responses were generated, see section 1 in the Supplementary Information file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EMPATHIC AI 9</head><p>After reading the empathy prompt and each pair of responses, participants first reported the level of compassion in each response and then selected the one they considered the best at addressing the prompt (response preference). To measure perceived compassion, participants were asked how much each response: a) reflected the emotional state in the prompt, b) was compassionate, and c) was impersonal (reverse-coded). All responses were recorded on a 5-point Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree) and averaged per empathic response. Response preference was measured by asking participants which one of the two responses was better at addressing the personal experience in the empathy prompt through a binary forced-choice question, where human responses were coded as 0 and AI responses were coded as 1. We aggregated the ratings for all 10 (or 6) vignette responses to create average scores for compassion and preference for both AI responses and human responses.</p><p>In study 4, we measured participants' perceived level of responsiveness for all responses.</p><p>Participants evaluated the responsiveness of human and AI responses using a 5-point Likert scale, based on facets of understanding (paraphrasing the reported experience, further inquiring about the experience, expressing understanding), validation (agreeing with the individual, validating their feelings/emotions, using exclamations and judgments), and caring (expressing empathy or emotions, offering support, concern, or comfort, and emphasizing the outcome sharing of the individual's scenario and/or circumstances) <ref type="bibr" target="#b29">30</ref> . Each facet was measured with three items, and responses were recorded using a 5-point Likert scale ranging from 1 (Strongly Disagree) to 5 (Strongly Agree). Responsiveness scores were averaged across these facets.</p><p>Detailed item measures and figures can be found in sections 1 and 2 of the Supplementary Information file, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EMPATHIC AI 10</head><p>In experiment 1, all participants were left blind to whether each response was generated by a human or AI. In experiments 2 and 3, participants were randomly assigned to either transparent or blind conditions in a between-subject design; in the transparent condition, they were told whether each response was generated by AI or humans; in the blind condition, participants did not see the label for each response, so they could not immediately know which response was generated by a human or AI. Experiment 4 only had the transparent condition, so participants could see the author labels for both empathy sources.</p><p>In addition to the response ratings, we also measured (but did not fully analyze) participants' trait level empathy using the Interpersonal Reactivity Index <ref type="bibr" target="#b31">32</ref> . This was done to explore whether participants' compassion ratings of AI and human-generated responses were moderated by their reported level of trait empathy. More details on this measure can be found in the Supplementary Methods section of the Supplementary Information file, under the Measures subsection. Participants were paid £5.25, £4.50, £4.50, and £3.75 (GBP) for their participation in studies 1-4, respectively. All aspects of the present study were approved and undertaken in compliance with the ethical regulations surrounding human research participants set by the Research Ethics Board at the University of Toronto. Informed consent was obtained from all participants, who were all debriefed and compensated following study completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sampling Strategy</head><p>In studies 1 and 4, which had a completely within-subject design, we aimed for a sample of 54 participants, given that a power analysis suggests we'd achieve at least 80% power to detect the average effect size in social psychology of d = .4 <ref type="bibr" target="#b32">33</ref> . For studies 2 and 3, where we had a mixed design with one between-subject and one within-subject variable, we aimed to run 400 participants, giving us 80% power to detect an interaction as small as f = 0.15 even after dropping the expected number of inattentive participants. A sample of English-speaking participants was recruited on Prolific Academic <ref type="bibr" target="#b30">31</ref> . Study data was collected between September 2023 and May 2024. After excluding participants that failed one or both attention checks, the distinct sample size for each study consisted of n = 54 and n = 58 participants in studies 1 and 4, respectively, and n = 99 (vs. 98 blind) and n = 121 (vs. 126 blind) participants per condition in studies 2 and 3, respectively. These individuals had an average age of 42.0 years (SD = 13.7) in study 1, 36.2 years (SD = 13.4) in study 2, 37.2 years (SD = 13.6) in study 3, and 37.0 years (SD = 12.3) in study 4. The demographic distribution of our samples in terms of age, gender, and race, with responses to all variables provided by participants alongside study data on Prolific Academic <ref type="bibr" target="#b30">31</ref> , is reported in Table <ref type="table" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Analyses</head><p>In studies 1 and 4, we ran dependent samples t-tests to evaluate whether the GPTgenerated or the human-generated responses were more compassionate. To evaluate response preference, we ran one-sample t-tests where the mean preference (ranging from 0 for human to 1 for AI) was compared against chance (0.5).</p><p>In studies 2 and 3, due to the mixed method design, we ran mixed models (using the afex package in R) to determine the interaction between compassion judgments for GPT versus human-generated responses and blind versus transparent conditions. For the mediation model in study 4, we used within-person mediation with the lme4 package, after which we bootstrapped using 1000 samples.</p><p>To further explore the results, we divided our vignettes into positive-valenced or negative-valenced-vignettes reporting positive or negative experiences. We used interaction mixed regression models to evaluate whether the vignette valence moderated the relationship between response author (human or AI) and perceived compassion or preference. All analyses were performed on R 4.0.3 <ref type="bibr" target="#b33">34</ref> . Additional information regarding exploratory analyses is reported in Supplementary Note 1 and 2 of the Supplementary Information File.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preregistration</head><p>We preregistered studies 1-4 at aspredicted.org. The links for all the studies (preregistration dates included) are provided as follows: study 1 (https://aspredicted.org/ha2av.pdf), study 2 (https://aspredicted.org/c3y4s.pdf), study 3 (https://aspredicted.org/v62tg.pdf), and study 4 (https://aspredicted.org/q5hq9.pdf). All preregistration documents are available at the repository https://osf.io/wjx48/. We originally planned to conduct repeated measures ANOVA in Studies 2, 3, and 4. However, we deviated from this approach and used multilevel models instead, as our data violated Mauchly's test of sphericity, a key assumption of ANOVA. As a robustness check, we also ran ANOVAs, which are reported in Supplementary Note 3 of the Supplementary Information File. The ANOVA results were consistent in direction and significance with those from the multilevel models. Additionally, we mistakenly described response preference as a continuous variable, when it was actually a binary forced-choice variable. Given this, the most appropriate analysis was a one-sample t-test against 0.5, rather than the dependent samples t-test originally preregistered. Finally, while we preregistered exploring whether participants' reported trait empathy moderated their compassion ratings for AI or human-authored responses, we found no credible evidence of trait empathy affecting compassion ratings for either response source.</p><p>We nevertheless report this finding for study 1 in Supplementary Note 3 of the Supplementary Information File. Across all studies, data distribution was assumed to be normal, but this was not formally tested. However, given our use of multi-level models, which are robust to non-normal data, this assumption was not critical.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We initially hypothesized that participants would rate the AI-generated responses as more compassionate than the human-generated responses. We also hypothesized that the AI responses would be preferred over the human responses. The two preregistered hypotheses were confirmed across all four experiments. The results for the compassion hypothesis are summarized for all four studies in Fig. <ref type="figure" target="#fig_4">2</ref>. The findings for response preferences across studies 1-4 are summarized in Fig. <ref type="figure" target="#fig_5">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>The AI-generated responses (M = 4.08, SD = .59) were rated as significantly more compassionate than the select human-generated responses (M = 3.50, SD = .524), t( <ref type="formula">53</ref> When exploring the moderating effect of vignette valence, we found a significant interaction, F(1, 159) = 12.89, p &lt; .001, partial η² = .08, 95% CI = [0.02, 1.00], such that the AI responses were rated as especially more compassionate than human responses when the empathy prompts contained a negative experience (B = .85, SE = .104, p &lt; .001) than when they contained a positive experience (B = .32, SE = .10, p = .002). The summarized findings for the effect of vignette valence for the latter and subsequent studies can be found in Fig. <ref type="figure" target="#fig_6">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>Experiment 2 replicated the main findings of experiment 1. We found a main effect for empathy source, F(1, 195) = 63.18, p &lt; .001, partial η² = .24, 95% CI = [0.16, 1.00], such that the GPT-generated responses (M = 4.06, SD = .65) were rated as more compassionate than the select human-generated responses (M = 3.60, SD = .63). However, we also found an interaction between empathy source and the transparency condition, F(1, 195) = 10.84, p &lt; .001, η² = .05, 95% CI = [0.01, 1.00], indicating that AI's empathy advantage was larger when participants were blind to the empathy source (B = .65, SE = .08, p &lt; .001). Despite this interaction, participants still rated AI as more compassionate even when AI was transparently labeled (B = .27, SE = .08, p &lt; .001). AI responses, in other words, were clearly rated as more compassionate than humans' even when participants knew the response was generated by AI.</p><p>We also examined whether response valence moderated the interaction between author and condition. Although we did not find a significant 2x2x2 interaction, F(1, 585) = .39, p = .53, we did find an interaction between author and valence, F(1, 585) = 30.70 p &lt; .001, partial η²= .05, 95% CI = [0.02, 1.00], such that the difference between AI and human responses was greater for the negative scenarios (B = .67, SE = .05, p &lt; .001) than for the positive scenarios (B = .24, SE = .05, p &lt; .001). This suggests that AI had a greater advantage over humans when addressing vignettes describing negative experiences, and this was the case whether the empathic responses were transparently labeled or not.</p><p>Finally, we also examined response preference. We found that the AI responses were judged as better at addressing the prompt than the select human responses, t(196) = 7.04, p &lt; .001, d = .50, 95% CI = [0.35, 0.65]. We further found significant differences in participants' response preferences by transparency condition, such that the preference for AI-generated responses was greater when participants were blind (M = 0.68, SD = 0.22) rather than transparently exposed (M = 0.57, SD = 0.25) to the response author labels, t(195) = 3.34, p = .001, d = 0.48, 95% CI = [0.19, 0.76].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>Experiment 3 had a design like experiment 2, except the human responses were created by trained hotline crisis responders. Again, we found a main effect of author, F(1, 245) = 154.36, p &lt; .001, partial η² = 0.39, 95% CI = [0.31, 1.00] such that AI responses (M = 4.08, SD = .63) were rated as more compassionate than human responses (M = 3.47, SD = .60). As with Experiment 2, however, this main effect was subsumed under a significant interaction between response source and the transparency condition, F(1, 245) = 20.81, p &lt; .001, partial η² = .08, 95% CI = [0.03, 1.00], suggesting that AI's compassion advantage over expert humans was stronger when participants were blind to author source. Nonetheless, simple effects analyses indicate that AI's responses were rated as more compassionate than humans in both the blind (B = .83, SE = .07, p &lt; .001) and transparent (B = .38, SE = .07, p &lt; .001) conditions.</p><p>In experiment 3, we again did not find a 2x2x2 interaction between response author, condition, and valence, F(1, 735) = .53, p = .47, but we replicated the author by valence interaction from study 2, F(1, 735) = 8.37, p = 0.004, partial η² = .01, 95% CI = [0.00, 1.00], such that perceived compassion was even greater for AI than expert humans when it addressed negative prompts (B = .71, SE = .05, p &lt; .001) than when it addressed positive prompts (B = .51, SE = .05, p &lt; .001).</p><p>Response preference also followed the pattern of the two previous studies, such that AI responses were considered better at addressing the prompt than expert humans, t(246) = 11.38, p &lt; .001, d = .72, 95% CI = [0.58, 0.86]. We once again found significant differences in participants' response preferences by transparency condition, such that the preference for AIgenerated responses was greater when participants were blind (M = 0.74, SD = 0.23) rather than transparently exposed (M = 0.62, SD = 0.25) to the response author labels, t(245) = 4.06, p &lt; .001, d = 0.52, 95% CI = [0.26, 0.77]. In examining the extent of participants' preferences for compassionate statements generated by AI v. human experts separately across blind and transparent conditions against a test value of 0.5, we confirmed that AI responses were judged as better at addressing the prompt than the expert human responses to a greater extent in the blind, t(125) = 11.5, p &lt; .001, d = 1.02, 95% CI = [0.81, 1.24], rather than transparent condition, t(120) = 5.18, p &lt; .001, d = 0.47, 95% CI = [0.28, 0.66].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 4</head><p>Experiment 4 used some of the same human expert and AI responses as Experiment 3, but all the responses were transparently labeled. In addition, participants rated how understanding, validating, and caring each response was. Regarding responsiveness, we hypothesized that AI responses would be rated as expressing greater responsiveness than empathic responses generated by expert humans (crisis line workers). Specifically, we hypothesized that AI responses would be rated as more understanding, validating, and caring. We further replicated the interaction effect between author and valence, F(1, 171) = 4.00, p = .04, partial η²= .02, 95% CI = [0.00, 1.00], with simple effects analyses suggesting that compassion ratings for AI were greater when it addressed negative prompts (B = .64, SE = .10, p &lt; .001) than when it addressed positive prompts (B = .36, SE = .10, p = .002). These findings highlight that AI is not only perceived as broadly responsive but also surpasses human experts in demonstrating understanding, validation, and care.</p><p>After further examining responsiveness, we found a significant author by interaction, F (1, 171) = 4.00, p = .047, partial η²= .02, 95% CI = [0.00, 1.00]. Post-hoc comparisons suggested that responsiveness ratings for AI were greater when it addressed negative circumstances, (B = .64, SE = .10, p &lt; .001) than positive circumstances (B = .36, SE = .10, p = .006).</p><p>Finally, to explore whether responsiveness ratings mediated the effect of author on compassion, we conducted a within-subjects mediation analysis. The indirect effect of empathy source on compassion ratings through responsiveness was significant, as the bootstrap confidence interval based on 1,000 samples did not include zero, 95% CI = [0.1823, 0.3923], p &lt; .001. Furthermore, analysis of the direct effect revealed that response author still significantly predicted compassion ratings even after accounting for responsiveness, F(1, 113) = 18.04, p &lt; .001, indicating partial mediation. Responsiveness itself was a strong predictor of compassion ratings, F(1, 113) = 108.12, p &lt; .001. These results suggest that while part of why AI responses are rated as more compassionate is that they are perceived as more responsive, perceived responsiveness cannot explain all the variance in compassion ratings for AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Empathy has numerous benefits on its recipients, but the toll associated with its expression, with competing pressures <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref> , can facilitate avoidance and a reduction in prosocial behaviors <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref> .</p><p>The gap between empathic supply and demand leaves recipients with unfulfilled needs for supportive care and contributes to heightened reports of social isolation, loneliness, and mental health concerns <ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36</ref> , which have intensified since the COVID-19 pandemic, particularly among youth <ref type="bibr" target="#b34">35</ref> . Given these challenges, researchers have examined whether Artificial Intelligence (AI) would be perceived as comparably effective to humans in providing empathic support <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref> .</p><p>Recent research suggests that AI can indeed be effective in promoting healthy social behaviors <ref type="bibr" target="#b36">37</ref> like self-disclosure <ref type="bibr" target="#b18">19</ref> , trust, enjoyment, intimacy <ref type="bibr" target="#b23">24</ref> , and improved mood <ref type="bibr" target="#b17">18</ref> .</p><p>In the present study, we asked if third party evaluators would rate responses made by AI as more compassionate than responses made by select and expert humans. Across four preregistered experiments, the results robustly supported our initial hypotheses: AI-generated responses were consistently rated as more compassionate and were preferred over humangenerated responses. Though AI may not express authentic empathy or share others' suffering <ref type="bibr" target="#b14">15</ref> , it can express a form of compassion through its facilitation of active support <ref type="bibr" target="#b7">8</ref> . In fact, it is so effective that third-party evaluators perceive it as being better than skilled humans. While AI does not experience empathy in the psychological sense, it is important to note that empathy is an interaction between two entities, rather than solely an internal experience of the empathizer.</p><p>From this perspective, the interacting partner could still derive the benefits of empathic engagement, even when it originates from an artificial system. In the present study, the perception of AI's empathic responses might bring about effects in its recipients that could be similar to (or even better than) the effects of empathy expressed by humans-at least through the eyes of third-party evaluators.</p><p>In experiments 2 and 3, we randomly assigned participants to blind and transparent conditions, where they were ignorant and aware of the response author identity, respectively. In an aim to assess the AI advantage against the influence of source transparency, we confirmed that the AI advantage decreased when people knew the response authors' identities. However, participants continued to rate AI responses as more compassionate than human responses even when they knew that the response was AI-authored. This pattern of findings is consistent with the existing literature surrounding the impact of source disclosure on people's perceptions of AIgenerated content, where the effectiveness of AI-generated content is lower when source identity is disclosed, even when its quality is evaluated as largely comparable to human responses <ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39</ref> .</p><p>In short, people seem to prefer AI content more when they are unaware that it was made by AI. One partial explanation for these findings is offered by the literature surrounding algorithm aversion (or rather, human favoritism) <ref type="bibr" target="#b28">29</ref> . Literature surrounding algorithm aversion posits that knowing that a piece of content is AI-generated biases its reception, though reactions vary with AI's contextual application <ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b39">40</ref> . Alternatively, the devaluation of AI-generated content may come from legitimate skepticism about AI's capabilities in the context of empathy, given its inability to embody genuine feeling or care <ref type="bibr" target="#b14">15</ref> . While AI aversion is common <ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41</ref> , it can be partly overcome with experience <ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43</ref> , successful use <ref type="bibr" target="#b28">29</ref> , and framing that emphasizes AI's supportive motives <ref type="bibr" target="#b43">44</ref> . Taken together, these observations suggest that negative initial impressions of AI effectiveness can improve as individuals gain more experience and positive outcomes with AI.</p><p>Following these findings, one potential future direction lies in asking whether this is true for all people or only a subset. People's expectations of AI largely depend on their perception of it-shaped by numerous attitudinal, social, and cognitive variables-which can impact the perceived value and experience of AI-generated support <ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b43">44</ref> . Thus, it is crucial to examine the heterogeneity of these findings.</p><p>Notably, we established that AI responses maintained their compassion advantage even when compared to those from a subset of crisis line responders, trained experts in delivering empathic support to a diverse Canadian population. This advantage persisted across both blind and transparent source identity conditions, including when all participants were aware of the authors' identities for each empathic response (Study 4). These findings are particularly significant since responders in this organization undergo extensive training before selection <ref type="bibr" target="#b44">45</ref> and may work concurrently in health fields that tend to centralize empathic communication with clients <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b45">46</ref> . Despite their training, these individuals report constraints like time pressures, highseverity cases <ref type="bibr" target="#b21">22</ref> , and competing demands, which can contribute to compassion fatigue, staff shortages, and diminished client care and trust <ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23</ref> . Given these factors, a sample of regular individuals selected for their empathic abilities could perform as well as, or even surpass, crisis line workers in delivering empathic responses.</p><p>Further support for the notion that external constraints on professional human empathizers may limit the quality of their empathic communication was offered by a supplemental comparison of expert to non-expert (select) Prolific responders, whose carefully selected responses reflected high quality of content, emotional salience, and relatability to each scenario in the vignette. A detailed report of this evaluation can be found in Supplementary Note 2 of the Supplementary Information file, which revealed that our select responses were rated as no less compassionate than experts' by third-party raters, and neither authored response was preferred over the other. In sum, despite the high quality of empathic responses from both samples of human responders, AI's consistent performance in providing superior empathetic responses highlights its utility in compassionate care through complementing, or potentially enhancing, human communication <ref type="bibr" target="#b7">8</ref> and preparedness, particularly in brief, written contexts. This utility is underscored by recent findings demonstrating that support workers can successfully use AI collaboratively to guide their empathic responses <ref type="bibr" target="#b45">46</ref> .</p><p>The overall observation that AI-generated responses were rated as more effective than those produced by trained empathic professionals challenges conventional assumptions regarding human expertise and highlights the difficulty in overcoming the costs and constraints associated with the expression of empathy <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b46">47</ref> . In contrast, AI consistently provides empathic support without showing a decline in empathy quality <ref type="bibr" target="#b15">16</ref> or context-appropriate responding <ref type="bibr" target="#b43">44</ref> . This advantage may contribute to AI's sustained high ratings for responsiveness <ref type="bibr" target="#b29">30</ref> in the present study, which partially explains its greater perceived compassion relative to both expert and non-expert human responders. Specifically, AI responses were rated as more understanding than human responses, as they actively solicited more details, summarized, and expressed understanding. AI responses were also rated as expressing more validation through their greater acknowledgment of the individual's feelings and use of expressive language. In terms of caring, AI responses were evaluated to significantly outperform humans' by more effectively expressing empathy and support and engaging more deeply with the hypothetical individuals' experiences <ref type="bibr" target="#b29">30</ref> .</p><p>Our results further indicate that AI had an advantage over humans when responding to negative prompts, such as in vignettes that depicted suffering and sadness. Interestingly, while AI was also perceived to be better than select and expert humans at responding to positive prompts depicting joy, this advantage was not as apparent. Why might that be? One rationale may be that familiarity with one's social partner is particularly important for the expression of empathic support under positive rather than negative circumstances and is expressed more readily to close others than strangers <ref type="bibr" target="#b47">48</ref> . An additional explanation for the observed differences is that expressed compassion (empathic concern), distinctively aimed at alleviating distress <ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b48">49</ref> , may have heightened the salience of AI's responses to typical negative prompts, as people generally associate empathy with responses to pain or suffering.</p><p>Cumulatively, these findings highlight the communicative skill and value of generative AI systems like ChatGPT and have profound implications for further integration of AI in domains requiring expressed empathy. Public perception of AI and its involvement in empathic support is complex, influenced by diverse individual and perceptual factors <ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27</ref> .</p><p>Nevertheless, the consistent preference for AI-generated responses in the present study, even when compared to trained professionals and varied transparency conditions, suggests a significant shift in how AI's role in communication might be perceived and potentially managed in the future, particularly in areas demanding consistent, high-quality exchanges.</p><p>In addition to the strengths of empathic AI, it is nevertheless important to note the prospective risks of its empathic expressions for both the recipients and human providers of empathy <ref type="bibr" target="#b15">16</ref> . In particular, there are highlighted ethical concerns surrounding non-transparent AI use in empathy delivery, emphasizing the need for informed recipient choices regarding the source from which they obtain supportive care <ref type="bibr" target="#b15">16</ref> . Moreover, an overreliance on empathic AI may increase the demands for personalized and unconditional support from recipients, which could undermine existing human effort, reinforce problematic behavior, and contribute to a counterproductive increase in mental health concerns <ref type="bibr" target="#b15">16</ref> . Thus, a balanced approach that leverages both AI and human communicative strengths is essential, ensuring that the integration of empathic AI fosters positive change while respecting ethical standards and supplementing, rather than replacing, human-based care.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>While the results across the present four studies are promising, several limitations should be noted. First, given that the AI and human-generated responses were rated by third-party evaluators, the patterns of findings may not generalize to interactions in which the evaluators are direct recipients of empathy. Future research could assess whether AI's advantage in providing empathic support relative to fellow humans maintains and informs participant preferences through direct recipient feedback <ref type="bibr" target="#b19">20</ref> . Additionally, the present study did not examine whether familiarity with and use of AI technology may have differentially influenced evaluations of AI and human-generated responses across blind and transparent conditions. Familiarity and proficiency with AI, among other personality and social variables, play an important role in shaping attitudes towards AI <ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27</ref> . Given that the present study and related efforts to assess empathic AI relative to humans have done so through brief interactions <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref> , future studies need to examine more long-term interactions with empathic AI to establish whether people's preferences and attitudes towards AI change as a function of time and assess the role of empathic AI in supporting experienced users' mental health <ref type="bibr" target="#b49">50</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>In sum, our study demonstrates the strengths of AI in communication contexts that require empathic expressions, albeit from a third-party lens. Participants consistently rated AIgenerated responses as more compassionate, understanding, validating, and caring; they knowingly preferred AI responses to human-generated responses when author identity was made explicit and even when the human comparison was comprised of trained empathy first responders. Ultimately, AI's ability to consistently deliver compassionate communication positions it as a strategic asset in support scenarios where human resources are stretched thin.     </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>) = 5.36, p &lt; .001, d = .73, 95% CI = [0.43, 1.03]. Participants also preferred the AI response over the select human response, t(53) = 5.03, p &lt; .001, d = .68, 95% CI = [0.38, 0.98].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>As with the earlier three studies, AI-generated responses were rated as significantly more compassionate (M = 3.91, SD = .47) than the expert human-generated responses (M = 3.41, SD = .51), F(1, 57) = 32.69, p &lt; .001, partial η² = .36, 95% CI = [0.20, 1.00]. Similarly, AI responses were preferred to expert human responses with respect to being better at addressing the prompt, t(57) = 5.41, p &lt; .001, d = .71, 95% CI = [0.42, 1.00].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Finally</head><label></label><figDesc>, AI-generated responses (M = 3.24, SD = .47) were rated as significantly more responsive than the expert human-generated responses (M = 2.97, SD = .51), t(57) = 4.57, p &lt; .001, d = .60, 95% CI = [-0.88, -0.32]. Specifically, AI responses outperformed human experts across all three facets of partner responsiveness: AI responses were evaluated as significantly more understanding (M = 3.23, SD = .48 vs. M = 2.99, SD = 0.53), t(57) = 3.86, p &lt; .001, d = .51, 95% CI = [0.23, 0.78]; validating (M = 3.54, SD = .45 vs. M = 3.24, SD = 0.52), t(57) = 4.49, p &lt; .001, d = .59, 95% CI = [0.31, 0.87]; and caring than expert human responses (M = 3.24, SD = .52 vs. M = 2.69, SD = 0.68), t(57) = 7.78, p &lt; .001, d = 1.02, 95% CI = [0.70, 1.34].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Example responses to negative and positive prompts from human and AI sources. Human and ChatGPT-4 generated responses to negative and positive prompts. Each response demonstrates the differing emphases placed on emotional support by humans and AI.</figDesc><graphic coords="31,72.00,72.00,450.00,287.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Comparison of compassion ratings by response author across studies 1-4. Distributions of compassion ratings for responses authored by humans (red) and AI (blue) in four separate studies. Panels represent Studies 1 through 4, with each study split into conditions where the response author label was concealed or transparent to evaluators. Error bars represent the standard error of the mean. The sample sizes are n = 54 for Study 1, n = 197 for Study 2 (n = 98 blind, n = 99 transparent), n = 247 for Study 3 (n = 126 blind, n = 121 transparent), and n = 58 for Study 4.</figDesc><graphic coords="33,115.50,72.00,380.80,380.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: Preference ratings for AI versus human-authored responses across studies under different transparency conditions. Violin plots illustrate preference distributions where 0 denotes a preference for human-authored responses and 1 denotes a preference for AI-authored responses, across four separate studies. Panels represent Study 1 through 4, segmented into conditions where the response author labels were concealed or transparent to evaluators. The dotted red line at 0.5 indicates no preference for human or AI responses. Error bars denote 95% confidence intervals. The sample sizes are n = 54 for Study 1, n = 197 for Study 2 (n = 98 blind, n = 99 transparent), n = 247 for Study 3 (n = 126 blind, n = 121 transparent), and n = 58 for Study 4.</figDesc><graphic coords="34,121.50,72.00,368.30,368.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 4 :</head><label>4</label><figDesc>Fig. 4: Compassion ratings by valence and transparency condition across four studies. Violin plots display compassion ratings for AI versus human-authored responses, split by positive (left column) and negative (right column) vignette valence across four studies. Error bars denote 95% confidence intervals. The sample sizes are n = 54 for Study 1, n = 197 for Study 2 (n = 98 blind, n = 99 transparent), n = 247 for Study 3 (n = 126 blind, n = 121 transparent), and n = 58 for Study 4.</figDesc><graphic coords="35,128.25,72.00,355.20,532.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Demographic Distributions of Participants in Studies 1-4.</head><label>1</label><figDesc>This table displays the demographic distributions for participants across four distinct studies, detailing age, sex, race, and country of residence. Each study's demographic profile is presented with mean and standard deviation for age, along with the count and percentage breakdown for sex, race, and country of residence. Sample sizes are specified for each study.</figDesc><table><row><cell></cell><cell cols="2">42.0±13.7</cell><cell cols="2">36.2±13.4</cell><cell cols="2">37.2±13.6</cell><cell cols="2">37.0±12.3</cell></row><row><cell>Median</cell><cell></cell><cell>40</cell><cell></cell><cell>32</cell><cell></cell><cell>33</cell><cell></cell><cell>35</cell></row><row><cell>Minimum -Maximum</cell><cell cols="2">21 -76</cell><cell cols="2">18 -77</cell><cell cols="2">18 -104</cell><cell cols="2">19 -64</cell></row><row><cell>Sex</cell><cell>Count</cell><cell>%</cell><cell>Count</cell><cell>%</cell><cell>Count</cell><cell>%</cell><cell>Count</cell><cell>%</cell></row><row><cell>Female</cell><cell>25</cell><cell>46.3 %</cell><cell>87</cell><cell>44.2 %</cell><cell>141</cell><cell>57.1 %</cell><cell>37</cell><cell>64.9 %</cell></row><row><cell>Male</cell><cell>28</cell><cell>51.9 %</cell><cell>107</cell><cell>54.3 %</cell><cell>105</cell><cell>42.5 %</cell><cell>20</cell><cell>35.1 %</cell></row><row><cell>Prefer not to say</cell><cell>0</cell><cell>0.0 %</cell><cell>1</cell><cell>0.5 %</cell><cell>1</cell><cell>0.4 %</cell><cell>0</cell><cell>0.0 %</cell></row><row><cell>N/A</cell><cell>1</cell><cell>1.9 %</cell><cell>2</cell><cell>1.0 %</cell><cell>0</cell><cell>0.0 %</cell><cell>0</cell><cell>0.0 %</cell></row><row><cell>Race</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Asian</cell><cell>6</cell><cell>11.1 %</cell><cell>32</cell><cell>16.2 %</cell><cell>45</cell><cell>18.2 %</cell><cell>9</cell><cell>15.8 %</cell></row><row><cell>Black</cell><cell>13</cell><cell>24.1 %</cell><cell>27</cell><cell>13.7 %</cell><cell>23</cell><cell>9.3 %</cell><cell>4</cell><cell>7.0 %</cell></row><row><cell>Mixed</cell><cell>3</cell><cell>5.6 %</cell><cell>15</cell><cell>7.6 %</cell><cell>10</cell><cell>4.0 %</cell><cell>6</cell><cell>10.5 %</cell></row><row><cell>White</cell><cell>31</cell><cell>57.4 %</cell><cell>101</cell><cell>51.3 %</cell><cell>158</cell><cell>64.0 %</cell><cell>35</cell><cell>61.4 %</cell></row><row><cell>Other</cell><cell>0</cell><cell>0.0 %</cell><cell>15</cell><cell>7.6 %</cell><cell>9</cell><cell>3.6 %</cell><cell>3</cell><cell>5.3 %</cell></row><row><cell>N/A</cell><cell>1</cell><cell>1.9 %</cell><cell>7</cell><cell>3.6 %</cell><cell>2</cell><cell>0.8 %</cell><cell>0</cell><cell>0.0 %</cell></row><row><cell>Country of Residence</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Canada</cell><cell>24</cell><cell>44.4 %</cell><cell>67</cell><cell>34.0 %</cell><cell>187</cell><cell>75.7 %</cell><cell>33</cell><cell>57.9 %</cell></row><row><cell>United States</cell><cell>30</cell><cell>55.6 %</cell><cell>130</cell><cell>66.0 %</cell><cell>60</cell><cell>24.3 %</cell><cell>24</cell><cell>42.1 %</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">Gregory Depow</rs>, <rs type="person">Leif Anderson</rs>, <rs type="person">Katy Tam</rs>, <rs type="person">Dasha Sandra</rs>, <rs type="person">Yiyi Wang</rs>, and all other members of the <rs type="institution">Work and Play Lab</rs> for their support in material validation and insights along the way.</p></div>
			</div>
			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Availability</head><p>All datasets and materials are available at the repository https://osf.io/wjx48/</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code Availability</head><p>Code is available at the repository https://osf.io/wjx48/ EMPATHIC AI 25</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare no competing interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional Information</head><p>Supplementary information is available for this paper at https://osf.io/wjx48/.</p><p>Correspondence and requests for materials should be addressed to Michael Inzlicht.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Empathic Concern: What It Is and Why It&apos;s Important</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Batson</surname></persName>
		</author>
		<idno type="DOI">10.1093/oso/9780197610923.001.0001</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
			<pubPlace>Oxford University PressNew York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The complex relation between morality and empathy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Decety</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Cowell</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2014.04.008</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2014.04.008" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="337" to="339" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Its ultimate and proximate bases</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Preston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">B M</forename><surname>De Waal</surname></persName>
		</author>
		<author>
			<persName><surname>Empathy</surname></persName>
		</author>
		<idno type="DOI">10.1017/s0140525x02000018</idno>
		<ptr target="https://doi.org/10.1017/s0140525x02000018" />
	</analytic>
	<monogr>
		<title level="j">Behav Brain Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Experience of Empathy in Everyday Life</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Depow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Inzlicht</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797621995202</idno>
		<ptr target="https://doi.org/10.1177/0956797621995202" />
	</analytic>
	<monogr>
		<title level="j">Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1198" to="1213" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Digital clinical empathy in a live chat: multiple findings from a formative qualitative study and usability tests</title>
		<author>
			<persName><forename type="first">H</forename><surname>Luetke Lanfer</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12913-024-10785-8</idno>
		<ptr target="https://doi.org/10.1186/s12913-024-10785-8" />
	</analytic>
	<monogr>
		<title level="j">BMC Health Serv Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Empathy is hard work: People choose to avoid empathy because of its cognitive costs</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Cameron</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000595</idno>
		<ptr target="https://doi.org/10.1037/xge0000595" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="962" to="976" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Caring is costly: People avoid the cognitive work of compassion</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Scheffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Inzlicht</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0001073</idno>
		<ptr target="https://doi.org/10.1037/xge0001073" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page" from="172" to="196" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Artificial intelligence technologies and compassion in healthcare: A systematic scoping review</title>
		<author>
			<persName><forename type="first">E</forename><surname>Morrow</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2022.971044</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2022.971044" />
	</analytic>
	<monogr>
		<title level="j">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="2023">971044. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Predictors of compassion fatigue in mental health professionals: A narrative review</title>
		<author>
			<persName><forename type="first">D</forename><surname>Turgoose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Maddox</surname></persName>
		</author>
		<idno type="DOI">10.1037/trm0000116</idno>
		<ptr target="https://doi.org/10.1037/trm0000116" />
	</analytic>
	<monogr>
		<title level="j">Traumatology</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="172" to="185" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Can Clinical Empathy Survive? Distress, Burnout, and Malignant Duty in the Age of Covid-19</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anzaldua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Halpern</surname></persName>
		</author>
		<idno type="DOI">10.1002/hast.1216</idno>
		<ptr target="https://doi.org/10.1002/hast.1216" />
	</analytic>
	<monogr>
		<title level="j">Hastings Center Report</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="22" to="27" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Impact of the COVID-19 Pandemic on Burnout, Compassion Fatigue, and Compassion Satisfaction in Healthcare Personnel: A Systematic Review of the Literature Published during the First Year of the Pandemic</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lluch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Galiana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Doménech</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Sansó</surname></persName>
		</author>
		<idno type="DOI">10.3390/healthcare10020364</idno>
		<ptr target="https://doi.org/10.3390/healthcare10020364" />
	</analytic>
	<monogr>
		<title level="j">Healthcare</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Compassion: a scoping review of the healthcare literature</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sinclair</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12904-016-0080-0</idno>
		<ptr target="https://doi.org/10.1186/s12904-016-0080-0" />
	</analytic>
	<monogr>
		<title level="j">BMC Palliative Care</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Challenges and Opportunities in Global Mental Health: a Research-to-Practice Perspective</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Wainberg</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11920-017-0780-z</idno>
		<ptr target="https://doi.org/10.1007/s11920-017-0780-z" />
	</analytic>
	<monogr>
		<title level="j">Curr Psychiatry Rep</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Global, regional, and national burden of 12 mental disorders in 204 countries and territories, 1990-2019: a systematic analysis for the Global Burden of Disease Study</title>
		<idno type="DOI">10.1016/S2215-0366(21)00395-3</idno>
		<ptr target="https://doi.org/10.1016/S2215-0366(21)00395-3" />
	</analytic>
	<monogr>
		<title level="j">The Lancet Psychiatry</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="137" to="150" />
			<date type="published" when="2019">2019. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">AI will never convey the essence of human empathy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Perry</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-023-01675-w</idno>
		<ptr target="https://doi.org/10.1038/s41562-023-01675-w" />
	</analytic>
	<monogr>
		<title level="j">Nat Hum Behav</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1808" to="1809" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">In praise of empathic AI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Inzlicht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>D'cruz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bloom</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2023.12.003</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2023.12.003" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="89" to="91" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparing Physician and Artificial Intelligence Chatbot Responses to Patient Questions Posted to a Public Social Media Forum</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Ayers</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamainternmed.2023.1838</idno>
		<ptr target="https://doi.org/10.1001/jamainternmed.2023.1838" />
	</analytic>
	<monogr>
		<title level="j">JAMA Intern Med</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Effectiveness of an Empathic Chatbot in Combating Adverse Effects of Social Exclusion on Mood</title>
		<author>
			<persName><forename type="first">M</forename><surname>De Gennaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Krumhuber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lucas</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2019.03061</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2019.03061" />
	</analytic>
	<monogr>
		<title level="j">Front. Psychol</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Psychological, Relational, and Emotional Effects of Self-Disclosure After Conversations With a Chatbot</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hancock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Miner</surname></persName>
		</author>
		<idno type="DOI">10.1093/joc/jqy026</idno>
		<ptr target="https://doi.org/10.1093/joc/jqy026" />
	</analytic>
	<monogr>
		<title level="j">Journal of Communication</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="712" to="733" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">AI can help people feel heard, but an AI label diminishes this impact</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Wakslak</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2319112121</idno>
		<ptr target="https://doi.org/10.1073/pnas.2319112121" />
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci. U.S.A</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<date type="published" when="2024">2319112121. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">How are compassion fatigue, burnout, and compassion satisfaction affected by quality of working life? Findings from a survey of mental health staff in Italy</title>
		<author>
			<persName><forename type="first">G</forename><surname>Cetrano</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12913-017-2726-x</idno>
		<ptr target="https://doi.org/10.1186/s12913-017-2726-x" />
	</analytic>
	<monogr>
		<title level="j">BMC Health Services Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">How Demanding Is Volunteer Work at a Crisis Line? An Assessment of Work-and Organization-Related Demands and the Relation With Distress and Intention to Leave</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C W J</forename><surname>Willems</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H C</forename><surname>Drossaert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Miedema</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bohlmeijer</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpubh.2021.699116</idno>
		<ptr target="https://doi.org/10.3389/fpubh.2021.699116" />
	</analytic>
	<monogr>
		<title level="j">Front. Public Health</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Predicting compassion fatigue among psychological hotline counselors using machine learning techniques</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12144-021-01776-7</idno>
		<ptr target="https://doi.org/10.1007/s12144-021-01776-7" />
	</analytic>
	<monogr>
		<title level="j">Curr Psychol</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="4169" to="4180" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">I Hear You, I Feel You&apos;: Encouraging Deep Self-disclosure through a Chatbot</title>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Yamashita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Fu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3313831.3376175</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems 1-12</title>
		<meeting>the 2020 CHI Conference on Human Factors in Computing Systems 1-12<address><addrLine>Honolulu HI USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A Therapeutic Relational Agent for Reducing Problematic Substance Use (Woebot): Development and Usability Study</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Prochaska</surname></persName>
		</author>
		<idno type="DOI">10.2196/24850</idno>
		<ptr target="https://doi.org/10.2196/24850" />
	</analytic>
	<monogr>
		<title level="j">J Med Internet Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="2021">24850. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Attitudes towards AI: measurement and associations with personality</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Messingschlager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gnambs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hutmacher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Appel</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-024-53335-2</idno>
		<ptr target="https://doi.org/10.1038/s41598-024-53335-2" />
	</analytic>
	<monogr>
		<title level="j">Sci Rep</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<date type="published" when="2024">2909. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The Relationship between Religiosity Level and Emotional Responses to Artificial Intelligence in University Students</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kozak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Fel</surname></persName>
		</author>
		<idno type="DOI">10.3390/rel15030331</idno>
		<ptr target="https://doi.org/10.3390/rel15030331" />
	</analytic>
	<monogr>
		<title level="j">Religions</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Does it matter if empathic AI has no empathy?</title>
		<author>
			<persName><forename type="first">G</forename><surname>Shteynberg</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-024-00841-7</idno>
		<ptr target="https://doi.org/10.1038/s42256-024-00841-7" />
	</analytic>
	<monogr>
		<title level="j">Nat Mach Intell</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="496" to="497" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">People&apos;s Perceptions (and Bias) Toward Creative Content Generated by Ai (ChatGPT-4), Human Experts, and Human-AI Collaboration</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gosline</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.4453958</idno>
	</analytic>
	<monogr>
		<title level="j">SSRN Journal</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Responsive behaviors in good times and in bad</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Maisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Gable</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Strachman</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1475-6811.2008.00201.x</idno>
		<ptr target="https://doi.org/10.1111/j.1475-6811.2008.00201.x" />
	</analytic>
	<monogr>
		<title level="j">Personal Relationships</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="317" to="338" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Prolific.ac-A subject pool for online experiments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Palan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schitter</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbef.2017.12.004</idno>
		<ptr target="https://doi.org/10.1016/j.jbef.2017.12.004" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral and Experimental Finance</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="22" to="27" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Interpersonal Reactivity Index (IRI): (Davis, 1980)</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Keaton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Worthington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Bodie</surname></persName>
		</author>
		<idno type="DOI">10.1002/9781119102991.ch34</idno>
	</analytic>
	<monogr>
		<title level="m">The Sourcebook of Listening Research</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="340" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">One Hundred Years of Social Psychology Quantitatively Described</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Bond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Stokes-Zoota</surname></persName>
		</author>
		<idno type="DOI">10.1037/1089-2680.7.4.331</idno>
		<ptr target="https://doi.org/10.1037/1089-2680.7.4.331" />
	</analytic>
	<monogr>
		<title level="j">Review of General Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="331" to="363" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<ptr target="https://www.r-project.org/" />
		<title level="m">R: The R Project for Statistical Computing</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The burden of loneliness: Implications of the social determinants of health during COVID-19</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Mcquaid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ogunlana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jaworska</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.psychres.2020.113648</idno>
		<ptr target="https://doi.org/10.1016/j.psychres.2020.113648" />
	</analytic>
	<monogr>
		<title level="j">Psychiatry Research</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<date type="published" when="2021">113648. 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The growing problem of loneliness</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Cacioppo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cacioppo</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0140-6736(18)30142-9</idno>
		<ptr target="https://doi.org/10.1016/S0140-6736(18)30142-9" />
	</analytic>
	<monogr>
		<title level="j">The Lancet</title>
		<imprint>
			<biblScope unit="volume">391</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Perceptions and Opinions of Patients About Mental Health Chatbots: Scoping Review</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Abd-Alrazaq</surname></persName>
		</author>
		<idno type="DOI">10.2196/17828</idno>
	</analytic>
	<monogr>
		<title level="j">J Med Internet Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Revealing the source: How awareness alters perceptions of AI and human-generated mental health responses</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pareek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Carlbring</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.invent.2024.100745</idno>
		<ptr target="https://doi.org/10.1016/j.invent.2024.100745" />
	</analytic>
	<monogr>
		<title level="j">Internet Interventions</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2024">100745. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The effect of source disclosure on evaluation of AI-generated messages</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schmälzle</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chbah.2024.100058</idno>
		<ptr target="https://doi.org/10.1016/j.chbah.2024.100058" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior: Artificial Humans</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<date type="published" when="2024">100058. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">What influences algorithmic decision-making? A systematic literature review on algorithm aversion</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mahmud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K M N</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smolander</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.techfore.2021.121390</idno>
		<ptr target="https://doi.org/10.1016/j.techfore.2021.121390" />
	</analytic>
	<monogr>
		<title level="j">Technological Forecasting and Social Change</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<date type="published" when="2022">121390. 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Algorithm aversion: People erroneously avoid algorithms after seeing them err</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Massey</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000033</idno>
		<ptr target="https://doi.org/10.1037/xge0000033" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="114" to="126" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">People devalue generative AI&apos;s competence but not its advice in addressing societal and personal challenges</title>
		<author>
			<persName><forename type="first">R</forename><surname>Böhm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jörling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fuchs</surname></persName>
		</author>
		<idno type="DOI">10.1038/s44271-023-00032-x</idno>
		<ptr target="https://doi.org/10.1038/s44271-023-00032-x" />
	</analytic>
	<monogr>
		<title level="j">Commun Psychol</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Decoding algorithm appreciation: Unveiling the impact of familiarity with algorithms, tasks, and algorithm performance</title>
		<author>
			<persName><forename type="first">H</forename><surname>Mahmud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K M N</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><forename type="middle">(</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Robert) &amp; Mikalef</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dss.2024.114168</idno>
		<ptr target="https://doi.org/10.1016/j.dss.2024.114168" />
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">179</biblScope>
			<date type="published" when="2024">114168. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Influencing human-AI interaction by priming beliefs about AI can increase perceived trustworthiness, empathy and effectiveness</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pataranutaporn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-023-00720-7</idno>
		<ptr target="https://doi.org/10.1038/s42256-023-00720-7" />
	</analytic>
	<monogr>
		<title level="j">Nat Mach Intell</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1076" to="1086" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<author>
			<persName><forename type="first">Helpline</forename><surname>Volunteer</surname></persName>
		</author>
		<ptr target="https://www.dcogt.com/helpline-volunteer/" />
		<title level="m">Distress Centres Of Greater Toronto</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Human-AI collaboration enables more empathic conversations in text-based peer-to-peer mental health support</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Miner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Atkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Althoff</surname></persName>
		</author>
		<idno type="DOI">10.1038/s42256-022-00593-2</idno>
		<ptr target="https://doi.org/10.1038/s42256-022-00593-2" />
	</analytic>
	<monogr>
		<title level="j">Nat Mach Intell</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="46" to="57" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Against Empathy: The Case for Rational Compassion. (Ecco, an imprint of HarperCollins Publishers</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bloom</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Interaction between valence of empathy and familiarity: is it difficult to empathize with the positive events of a stranger?</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Motomura</surname></persName>
		</author>
		<idno type="DOI">10.1186/s40101-015-0049-3</idno>
		<ptr target="https://doi.org/10.1186/s40101-015-0049-3" />
	</analytic>
	<monogr>
		<title level="j">J Physiol Anthropol</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Empathizing With Others&apos; Pain Versus Empathizing With Others&apos; Joy: Examining the Separability of Positive and Negative Empathy and Their Relation to Different Types of Social Behaviors and Social Emotions</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Andreychik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Migliaccio</surname></persName>
		</author>
		<idno type="DOI">10.1080/01973533.2015.1071256</idno>
		<ptr target="https://doi.org/10.1080/01973533.2015.1071256" />
	</analytic>
	<monogr>
		<title level="j">Basic and Applied Social Psychology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="274" to="291" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Loneliness and suicide mitigation for students using GPT3-enabled chatbots</title>
		<author>
			<persName><forename type="first">B</forename><surname>Maples</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cerit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pea</surname></persName>
		</author>
		<idno type="DOI">10.1038/s44184-023-00047-6</idno>
		<ptr target="https://doi.org/10.1038/s44184-023-00047-6" />
	</analytic>
	<monogr>
		<title level="j">Mental Health Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
