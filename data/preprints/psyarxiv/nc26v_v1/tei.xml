<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ordinal response scales: Psychometric grounding for design and analysis</title>
				<funder ref="#_jP5n7Fm">
					<orgName type="full">German Research Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Lukas</forename><surname>Sönning</surname></persName>
						</author>
						<title level="a" type="main">Ordinal response scales: Psychometric grounding for design and analysis</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C818056CFE17E54B49A6B23670508C0F</idno>
					<note type="submission">This is an Accepted Manuscript of an article accepted for publication in Research Methods in Applied Linguistics</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T02:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Ordinal data</term>
					<term>rating scales</term>
					<term>acceptability judgments</term>
					<term>Likert scale</term>
					<term>judgment task</term>
					<term>measurement</term>
					<term>psychological scaling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Ordinal response scales are commonly used in applied linguistics. To summarize the distribution of ratings or judgments provided by informants, these are usually converted into numbers and then averaged or analyzed with ordinary regression models. This approach has been criticized in the literature; one caveat (among others) is the assumption that distances between categories are known. The present paper illustrates how empirical insights into the perception of response labels may inform the design and analysis stage of a study. We start with a review of how ordinal scales are used in linguistic research. Our survey offers insights into typical scale layouts and analysis strategies, and it allows us to identify three commonly used rating dimensions (agreement, intensity, and frequency). We take stock of the experimental literature on the perception of relevant scale point labels and then demonstrate how psychometric insights may direct scale design and data analysis. This includes a careful consideration of measurement-theoretic and statistical issues surrounding the numeric-conversion approach to ordinal data. We focus on the consequences of these drawbacks for the interpretation of empirical findings, which will enable researchers to make informed decisions and avoid drawing false conclusions from their data. We present a case study on yous(e) in two varieties of English, which shows that reliance on psychometric scale values can alter statistical conclusions, while also giving due consideration to the key limitations of the numeric-conversion approach to ordinal data analysis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Ordinal response scales are commonly used across different branches of linguistics to elicit some kind of judgment, perception, or opinion. In experimental syntax, for instance, participants may rate the acceptability of a sentence on a 7-point scale ranging from "not at all acceptable" to "fully acceptable". When analyzing data obtained in this way, researchers routinely assign numbers to the categories (in this case, say, running from 1 to 7). Following <ref type="bibr" target="#b25">Labovitz (1967)</ref>, we will use the term scoring system to refer to the numeric translation of an ordinal scale. The data are then usually treated as though they had been measured on a continuous (or interval) scale, to calculate averages or use ordinary (mixed-effects) regression. This practice, which is widespread across empirical disciplines (see, e.g., <ref type="bibr" target="#b15">Harwell &amp; Gatti, 2001;</ref><ref type="bibr" target="#b29">Liddell &amp; Kruschke, 2018)</ref> including linguistics (see <ref type="bibr" target="#b49">Sönning et al., 2024)</ref>, has sparked heated methodological debates (see, e.g., <ref type="bibr" target="#b14">Harpe, 2015;</ref><ref type="bibr" target="#b18">Jamieson, 2004;</ref><ref type="bibr" target="#b20">Knapp, 1990;</ref><ref type="bibr" target="#b37">Norman, 2010;</ref><ref type="bibr"></ref> for linguistic data, see <ref type="bibr">Endresen &amp; Janda, 2017)</ref>. The widely accepted belief that an interval-level analysis of ordinal data is inappropriate goes back to an influential paper by <ref type="bibr" target="#b50">Stevens (1946)</ref>, who proposed a taxonomy of scale types (nominal, ordinal, interval, and ratio) along with "appropriate" statistics for each. Among the caveats of the numericconversion approach is the fact that it requires information on the spacing between consecutive categories. Even though these distances are usually unknown, the statistical analysis proceeds as though they had been measured.</p><p>A survey of the use of ordinal response scales in language research shows that two broad types may be distinguished (see Section 2; also <ref type="bibr">Krosnick &amp; Fabrigar, 1997, p. 149</ref>): (i) fully verbalized sequences with labels for all categories; and (ii) scales that consist of a number of boxes with descriptors only at the endpoints. If only the extremes are labeled and the intermediate options are evenly spaced (on the page or screen), the equidistance assumption may be tenable. When all scale points are verbalized, however, the perceived distance between categories will mainly depend on how informants interpret the labels; to encourage an equally-apportioned interpretation, however, numbers may be add to the scale point labels. To the advantage of empirical researchers, experimental studies have produced insights into the perception of quantificational expressions linked to a number of dimensions that are frequently used to build graded scales. Psycholinguistic research on intensifiers, for instance, has shown that English native speakers recognize similar increments in intensity between hardly-slightly and considerably-highly <ref type="bibr" target="#b42">(Rohrmann, 2007)</ref>. The aim of the present paper is to illustrate how such insights into the perception of response labels may inform study design and data analysis. We therefore build on earlier methodological work, which has mainly focused on scale construction (i.e., the selection of approximately equal-interval sequences; e.g., <ref type="bibr" target="#b5">Beckstead, 2014;</ref><ref type="bibr" target="#b10">Friedman &amp; Amoo, 1999;</ref><ref type="bibr" target="#b42">Rohrmann, 2007)</ref>. The present study goes further, however, and considers how psychometric scale values can suggest more suitable scoring systems for data analysis -that is, a set of numeric scores that gives a better approximation to the perception of verbal labels. As our literature survey shows, custom scale values are very rarely used in current research, and only few methodological studies acknowledge this possibility <ref type="bibr">(Labovitz, 1967, p. 155;</ref><ref type="bibr">Worcester &amp; Burns, 1975, p. 191</ref>; see also <ref type="bibr">Tukey, 1961, p. 246)</ref>.</p><p>The paper starts out with a review of work published in a broad range of linguistic journals to examine the use of ordinal response scales in language research. The focus is on their structure (number of scale points and how they are verbalized), the underlying dimension that makes the categories ordinal (e.g., intensity, frequency), and how the data are analyzed statistically. Our survey points to three commonly used dimensions: agreement, intensity, and frequency. Section 3 reviews psychometric work on these dimensions, to map the metric properties of related scale point labels. The utility of these insights for the construction and evaluation of response scales is exemplified in Section 4. Section 5 then discusses the use of psychometrically grounded scoring systems for an interval-scale analysis of ordinal data. This dive into the heated and enduring controversy over "appropriate" statistics for ordinal data will carefully consider competing positions, both from a measurement-theoretic and a statistical viewpoint. The data-analytic perspective that emerges from this exercise emphasizes that the question of appropriateness concerns the interpretation of results rather than the statistical operations by which they have been arrived -a viewpoint that has in fact been expressed by a number of prominent (applied) statisticians (e.g., <ref type="bibr">Anderson, 1961, p. 315;</ref><ref type="bibr">Mosteller, 1958, p. 288;</ref><ref type="bibr">Tukey, 1961, p. 246;</ref><ref type="bibr">Vellemann &amp; Wilkinson, 1993)</ref>. Section 6 presents a case study, where insights into the perception of quantifiers (no-one, few, some, many, most, everyone) are used to analyze data from a survey on morpho-syntactic language variation. Section 7 then closes with a summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Ordered response scales in language research</head><p>Let us start by examining the use of ordinal scales in the linguistic research literature. We included into our survey all articles published between 2012 and 2022 in 17 linguistic journals (4,441 publications in total), which range broadly across subfields and methodologies. For an overview, please refer to Web appendix 1 (https://osf.io/qfmh8). The search terms "rating scale", "rating task", "judg(e)ment task", "ordinal", "Likert", and "semantic differential" were used to extract potentially relevant documents (n = 909). We then manually identified those articles that employed an ordinal response scale (n = 405), where informants indicate some kind of assessment by choosing from an ordered set of categories. If a study relied on different scale formats 1 , each layout entered our survey, yielding a greater number of response scales (n = 473) than articles in our database. A tabular record with our coded data and background information on scale and study features forms part of the TROLLing post associated with this article <ref type="bibr">(Sönning, 2024a)</ref>.</p><p>As for their role in the research design, the ordinal scales in our survey were predominantly used to measure outcome (dependent) variables (n = 276; 58%), but also correlational (n = 44; 9%) and predictor (independent) variables (n = 65; 14%). Other purposes included sample description (n = 44; 9%) and stimulus validation (n = 44; 9%).</p><p>Table <ref type="table" target="#tab_0">1</ref> gives an overview of the structure of graded scales and cross-tabulates (i) number of response categories, ranging from 3 to 11; and (ii) the way in which (verbal) information is incorporated into the scale, e.g., whether only the endpoints are labeled or whether the scale is fully verbalized. The figures in boldface give the overall distribution of these attributes. We note that it is quite typical to have 5 (37%) or 7 (27%) response categories. Excluding 64 scales whose layout could not be ascertained, we observe that in most cases (49%) only the endpoints of the scale are labeled. Our focus in the present study is on fully labeled sequences, where descriptors are given for all categories. In our survey, 173 instruments (42%) have this format. In  This category includes numbers-only (n = 20, 5%), endpoints-plus-midpoint (n = 15, 4%), midpoint-only (n = 1) and stars (n = 1).</p><p>These fully labeled scales can be grouped according to the underlying dimension that effects the rank order. We follow <ref type="bibr" target="#b42">Rohrmann (2007)</ref> and identify five major dimensions, which are set out and exemplified in Figure <ref type="figure" target="#fig_0">1</ref>; the illustrative examples are taken from the studies in our survey.</p><p>• Intensity: Intensifying adverbs denote the degree to which a certain attribute is present (e.g., slightly/quite acceptable). • Agreement: The widely familiar Likert-type response format<ref type="foot" target="#foot_2">3</ref> (e.g., strongly/mainly/somewhat disagree), which often involves elements of intensification but forms a separate dimension due to its widespread use and bipolar nature. • Frequency: Expressions denote the rate at which something happens (e.g., rarely, frequently).</p><p>• Probability: Phrases reflect the likelihood of some event (e.g., unlikely, probable).</p><p>• Quality: A 'good'-'bad' continuum, which may also draw on intensifiers but typically relies on different adjectives (e.g., poor, fine), making it a dimension in its own right. Let us examine how often these dimensions appear in our survey. The distribution of the 173 fully verbalized response scales, which is given in Table <ref type="table" target="#tab_2">2</ref>, shows that the most frequently employed scheme are agreement scales, which account for a third of the cases. Intensity features in 18% of the scales, followed by frequency (9%), probability and quality (each at 3%). The category "None/other" (34%) includes sequences that are fully labeled but do not represent an underlying perception, attitude, or belief. Table <ref type="table" target="#tab_2">2</ref> also reports on the number of categories used in fully labeled scales, which hover between 3 and 9, with 5 response options (47%) being the most frequent layout. Next, we consider how data from fully verbalized scales are analyzed statistically. <ref type="foot" target="#foot_4">5</ref> Relevant tallies appear in the right-most columns in Table <ref type="table" target="#tab_2">2</ref>:</p><p>• An analysis was coded as employing numeric conversion (Num) if it relies on a scoring system to convert the ordered categories into numbers and then uses averages or ordinary (mixed-effects) regression. • The label descriptive statistics (Des) denotes analyses that exclusively resort to 'appropriate' descriptive statistics (i.e., measures other than the mean, such as category counts/percentages or medians). • Studies in the class ordinal regression (Ord) employ a form of categorical regression respecting the order of response levels. • The category non-parametric (Non) refers to procedures for ranked observations (e.g., Wilcoxon signed-rank test).</p><p>Clearly, the numeric-conversion approach is the most popular analysis strategy; in 84% of the cases, a scoring system is used to summarize or model the data. Except for a single study, all analyses used a linear scoring system: By assigning running integers to the ordered responses (e.g., from 1 to 5 for a five-point scale), distances between categories are assumed to be evenly spaced.</p><p>We may summarize our findings on the use of fully verbalized scales as follows: They are a frequently employed scheme (42% of the scales in our survey, compared to 49% for endpoint-only layouts; see Table <ref type="table" target="#tab_0">1</ref>), and they usually consist of 4 to 6 categories. About a third of these are agreement scales, followed by intensity scales (18%); the other dimensions (frequency, probability and quality) are less prevalent. In the vast majority of cases (84%), the responses are analyzed as though they had been collected on a continuous scale; almost categorically, studies rely on a linear scoring system with equally-spaced numeric steps along the continuum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Psychometric scale values of verbal response labels</head><p>Our literature survey has shown that fully labeled ordinal response scales in linguistic studies chiefly rely on three dimensions: agreement, intensity, and frequency. This section collects experimental results on the perceived meaning of associated scale point labels.<ref type="foot" target="#foot_5">6</ref> A summary of findings for the two less commonly used classes (probability, quality) are relegated to Web appendix 2 (https://osf.io/v9xph). The data produced by our survey can be found in the accompanying TROLLing post <ref type="bibr">(Sönning, 2024a)</ref>, and R code for reproducing the figures are deposited on the OSF (https://osf.io/wdvx6).</p><p>Rohrmann (2007) investigated the perception of labels that are used to indicate levels of agreement. Subjects performed different tasks, and we will concentrate on the "category scaling" one, where expressions had to be placed on an equally-apportioned 11-point scale. This scale is mapped to the [0,10] interval. Responses were collected from 164 participants, and the results we report here are those for all contexts combined (annoyance by noise, job satisfaction, context-free). Figure <ref type="figure" target="#fig_1">2</ref> shows the results from Rohrmann (2007):</p><p>• The dots reflect the average rating across informants (also reported numerically at the left margin of the graph).</p><p>• The error bars extend ±1 standard deviation around the mean and reflect the variability of responses.</p><p>The set of agreement indicators studied by <ref type="bibr" target="#b42">Rohrmann (2007)</ref> offers fine-grained resolution across the bi-polar spectrum. Terms denoting the neutral scale midpoint are judged consistently (e.g., halfhalf, undecided), as are labels at the extremities of the scale (fully/strongly (dis)agree). For intensity qualifiers, we summarize the findings of three studies that used similar methods to scale the meaning of intensifying adverbs <ref type="bibr" target="#b22">(Krsacok, 2001;</ref><ref type="bibr" target="#b32">Matthews et al., 1978;</ref><ref type="bibr" target="#b42">Rohrmann, 2007)</ref>.</p><p>Informants were asked to locate each phrase on an 11-point scale, which we again map to the [0,10] interval. Figure <ref type="figure" target="#fig_2">3</ref> can be read as follows:</p><p>• The small grey dots indicate the ratings for four speaker groups; <ref type="bibr" target="#b22">Krsacok (2001)</ref> studied two groups, male vs. female subjects. • The black dots denote the average across these four groups, which is recorded at the left end of the graph Again, the set of expressions yields fine increments across the scale. For intensifiers that were included in all three studies, the spread of the grey dots indicates the stability of perceptionsmildly, for instance, appears to be interpreted more consistently than somewhat. Frequency expressions were studied by <ref type="bibr" target="#b35">Mosteller and Youtz (1990)</ref>. Using a mail questionnaire, they asked science writers to give the probability they would attach to 52 phrases. Ratings were obtained from around 230 individuals. Their findings are summarized in Figure <ref type="figure" target="#fig_3">4</ref>:</p><p>• The filled black circles denote the average probability assigned to an expression by the 230 informants. • The error bars extend from the lower to the upper quartile and therefore reflect variability across informants. • The small grey dots show the distribution of estimates from 20 other studies, which are also summarized in <ref type="bibr">Mosteller and Youtz (1990, p. 4</ref>), including the average probability observed in that study; thus, the single grey dot for less often than not shows that only <ref type="bibr" target="#b35">Mosteller and Youtz (1990)</ref> studied this expression. • The values reported at the left margin are averages across studies (weighted by the number of respondents).</p><p>We note that the frequency expressions in Figure <ref type="figure" target="#fig_3">4</ref> provide good coverage of the [0,100] interval.</p><p>The consistency of interpretations varies, however. This can be seen from the error bars reflecting the spread of perceptions across individuals in <ref type="bibr" target="#b35">Mosteller and Youtz (1990)</ref>, and from the dispersion of averages across studies (small grey dots). For instance, the adverbs sometimes and often, which are popular anchors for graded scales, show considerable variation across studies, possibly indicating a lack of stability across contexts. Judging from the error bars, however, often seems to receive similar interpretations from individuals (compared to sometimes and nearby usually). <ref type="bibr" target="#b35">Mosteller and Youtz (1990)</ref> offer a careful discussion of the observed variability across their 230 subjects and also asked respondents to indicate the range of percentages they consider acceptable for each expression. For sometimes, the lower and upper bounds were spread quite widely, on average, which points to a relatively fuzzy meaning of this frequency adverb. Our review of psychometric work provides insight into the quantificational meaning of verbal scale point labels. We now look at how this information can be used in study design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Use in study design</head><p>In this section, we illustrate how the experimental literature summarized above may aid in scale construction (Section 4.1) and demonstrate how psychometric findings may be used to evaluate the composition and statistical analysis of ordinal scales (Section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Scale construction</head><p>When building ordinal response scales that are fully verbalized, it is generally preferable for labels to have meanings that divide up the continuum into approximately equal steps. If responses are expected to span the entire range of the scale, this will reduce measurement error (see Section 5.2.2). Further, the physical layout of a scale (i.e., the distance between tick boxes) typically suggests constant increments, and it has been observed that respondents' interpretations combine the semantics of the scale labels with their relative placement or position <ref type="bibr" target="#b8">(Chase, 1969;</ref><ref type="bibr" target="#b17">Ironson &amp; Smith, 1981;</ref><ref type="bibr" target="#b19">Klockars &amp; Yamagishi, 1988;</ref><ref type="bibr" target="#b44">Schwarz et al., 1998)</ref>.</p><p>We now use the scale values derived in Section 3 (overall averages reported at the left margin of Figures <ref type="figure" target="#fig_1">2</ref> and<ref type="figure" target="#fig_2">3</ref>) to construct agreement and intensity scales that aim for roughly equal psychological intervals. Since previous research suggests that 5 to 7 response categories are optimal, we will concentrate on sequences of this length (for a review covering a number of criteria, see <ref type="bibr" target="#b21">Krosnick &amp; Fabrigar, 1997)</ref>.</p><p>Figure <ref type="figure" target="#fig_4">5a</ref> shows verbal anchors for 5-, 6-and 7-point agreement scales. These extend to the extremes of the dimension and are approximately equidistant. For intensity scales, Figure <ref type="figure" target="#fig_4">5b</ref> gives three sets of labels. Here, scale design is complicated by the fact that attention must also be paid to collocation. Thus, the adverb considerably may not combine well with certain adjectives, in which case preference may have to be given to nearby alternatives (e.g., very). If responses are expected to cluster at one end of the scale, it may not be desirable to aim for equal increments. For instance, an acceptability study that deals with prescriptively ungrammatical constructions may choose verbal anchors that saturate the lower end of the acceptability spectrum, where most responses are expected to hover. Figure <ref type="figure" target="#fig_5">6</ref> illustrates two sets of intensifiers that enhance resolution at relatively high or low levels of intensity. Since it has been observed that respondents pay attention not only to the meaning of scale point labels but also their spatial arrangement, the physical layout of the scale may be adapted to (partly) preserve the unequal increments that are evident in Figure <ref type="figure" target="#fig_5">6</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Scale evaluation</head><p>Psychological evidence may also be used to evaluate existing scales and their statistical treatment.</p><p>To illustrate, let us consider three sets of frequency labels that we encountered in our survey. Figure <ref type="figure" target="#fig_6">7</ref> arranges these on the percentage scale. Set 1 increases in roughly equal steps and provides a good representation of the spectrum. In contrast, set 2 does not divide the continuum into proportionate stretches -sometimes, the middle category, is closer in meaning to seldom. The equidistant numeric conversion used by the authors of that study therefore leads to distorted averages. Finally, set 3 saturates the lower end of the scale, where we find three tightly spaced anchors. The frequency expressions occasionally and frequently, on the other hand, are far apart -about half of the psychometric range covered by the instrument. The statistical analysis relied on a linear scoring system (numbers running from 1 to 6), which does not capture the perceived meaning of these expressions. This brings us to another way in which scaling information may inform empirical research: Instead of relying on a linear scoring system for an interval-scale analysis of ordinal variable (with equallyspaced integers, e.g., 0 to 6 for a 7-point scale), evidence on the quantificational meaning of scale point labels may be used to construct a more meaningful numeric translation. Despite their psychometric grounding, however, the use of custom scoring systems for the analysis of ordinal data must nevertheless proceed with caution. As we discuss in the next section, due consideration must be given to measurement-theoretic and statistical issues surrounding this approach to data analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Use in data analysis</head><p>We now turn to a strategy on which opinions are divided: The use of numeric scores to analyze ordinal data. We start by recapitulating existing practices in language research (Section 5.1) and then look at the enduring controversy from a measurement-theoretic and a statistical perspective (Section 5.2). The aim is to make transparent deeper underlying issues, and to identify the implications they have for empirical work. In Section 5.3 we describe an informed data-analytic perspective that carefully negotiates the intersection between apparent benefits and inherent limitations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Prevalence in linguistic research</head><p>Recall that our survey on the use of ordinal response scales in linguistic research revealed two striking facts: the pervasiveness of the numeric-conversion approach and the near-universal use of linear scoring systems to locate response categories on the number line.</p><p>To understand the majority practice by (language) scholars, let us consider the statistical options of an empirical researcher who has acquired ordinal data. We will compare alternative procedures with regard to two criteria: (i) informativity, by which we mean the nuance, or level of detail, they offer; and (ii) feasibility, which refers to the required know-how and software infrastructure. Figure <ref type="figure" target="#fig_7">8</ref> provides a schematic arrangement of techniques along these two dimensions. As a point of reference, numeric-conversion strategies appear in grey: Arithmetic means are easy to compute and they allow for comparisons to be made at a fine level of detail. The same is true for ordinary linear (mixed-effects) regression, which may be categorized as a moderately sophisticated tool. Let us work our way from the bottom right (easy to implement but not very informative) to the top left (specialized procedures that bring into view fine-grained patterns).</p><p>• The median, though an "appropriate" measure of location for ordinal data, lacks nuance and fails to capture subtle differences between subgroups (see <ref type="bibr">Krug &amp; Sell, 2013, pp. 84-88</ref>). • Non-parametric tests (e.g., the Wilcoxon signed rank test) require statistical software, offer limited flexibility and primarily yield inferential assessments; associated effect size measures lack interpretability (see <ref type="bibr">Grissom &amp; Kim, 2012, pp. 285-305)</ref>. • Random forests for ordinal outcomes call for specialized statistical software but require little (or no) user intervention. While they easily handle multifactorial data arrangements, methods of interpretation are currently limited to differences between predicted category probabilities (see <ref type="bibr" target="#b26">Lechner &amp; Okasa, 2022</ref>). • Ordinal regression models (see <ref type="bibr" target="#b11">Fullerton &amp; Xu, 2017)</ref> are here classified as a relatively advanced technique, since they not only require statistical software but also rely on the user for model specification. Their default output, a regression table with thresholds and slopes on (say) the log odds scale, often proves difficult to interpret without appropriate postprocessing steps. • One type of ordinal regression, the cumulative-link model, has a mathematically equivalent latent-variable formulation (see <ref type="bibr">Long, 1997, pp. 116-122;</ref><ref type="bibr">Agresti, 2010, pp. 53-55)</ref>. This form of model yields fine-grained data summaries on a continuous scale; in terms of interpretability and informativity, it is therefore on a par with the numeric-conversion approach (see <ref type="bibr" target="#b49">Sönning et al., 2024)</ref>.</p><p>Figure <ref type="figure" target="#fig_7">8</ref> shows that the linguist who consciously decides against an interval-scale analysis will be forced to give up nuance, flexibility and/or ease of implementation, unless they resort to a procedure that is technically (much) more demanding and requires advanced statistical software. As this disincentivizes researchers from abandoning the numeric-conversion approach, this strategy will likely continue to permeate the empirical literature. This calls on methodologists to consider in more detail the arguments, viewpoints, and philosophies that have given rise to the continuing controversy surrounding the interval-scale analysis of ordinal data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">The controversy from three perspectives</head><p>To enable informed discussions and decisions about alternative approaches to analyzing rating scale data, it helps to look at underlying issues from a measurement-theoretic perspective (Section 5.2.1) and a statistical perspective (Section 5.2.2). This allows us to appreciate different positions and, more importantly, point out their implications and consequences for empirical work. These are summarized in what we will refer to as a data-analytic perspective (Section 5.2.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">Representational vs. operational theories of measurement</head><p>To contextualize the debate on "appropriate" statistics for ordinal data, we must first recognize two different theories of measurement (see <ref type="bibr" target="#b13">Hand, 1996;</ref><ref type="bibr" target="#b20">Knapp, 1990;</ref><ref type="bibr" target="#b33">Michell, 1986)</ref>. For the empirical researcher, the key contrast between these frameworks is that they give different answers to the question of whether quantitative results reflect reality -i.e., whether patterns in the data can be interpreted at face value (see <ref type="bibr" target="#b33">Michell (1986)</ref> for a lucid summary).</p><p>Stevens' (1946) taxonomy of scale types and "appropriate" statistics is firmly grounded in the representational theory of measurement. Briefly, representationalism is concerned with the mapping between numbers and real-world attributes, and with the question of which numbers preserve verifiable facts. When it comes to the choice of "appropriate" statistics, a key role is played by the notion of permissible transformations. These are changes to the numbers that are permissible in the sense that they still reflect ascertainable attributes of the objects of interest. For ordinal variables, the only confirmable information is their rank order. Any numeric representation that preserves the rank order of categories is therefore permissible. Categories can therefore be represented by any monotonically increasing set of scores, such as the integers 1-2-3-4 or 1-2-4-8. A statistical operation on these numbers (e.g., taking the arithmetic mean) is then considered "appropriate" if (and only if) the results it produces are stable across all permissible transformations.</p><p>Table <ref type="table" target="#tab_3">3</ref> illustrates how a hypothetical group comparison based on arithmetic means depends on the scoring system: Using the set 1-2-3-4, group A has a higher mean; using the set 1-2-4-8, group B has a higher mean. The statistical conclusion based on the median, on the other hand, remains stable: Group A will always have a higher median. It is this invariance across permissible changes to the numerical representations that makes a statistic "appropriate". In exchange for this restriction, results can be interpreted as giving a one-to-one reflection of reality. They transcend the measurement instrument and allow the researcher to draw scale-free conclusions about the objects of study. In contrast, operational measurement theory makes no reference to the real world. It defines the attribute of interest in terms of the (precisely specified) measuring procedure used, and thereby actively embraces the scale-dependence of data summaries. Since the number assigned to an observation emerges from a measurement operation, it is illogical to consider alternative numerical assignments. This renders the notion of permissible transformations irrelevant in this framework, which means that no scale-induced restrictions are imposed on the analysis. At the same time, however, this means that scale-free conclusions have no place in operationalism -results are not reflective of reality, which means that subject-matter interpretations are bounded by the measurement procedure. The empirical linguist adopting this philosophy must therefore exercise additional caution when drawing substantive conclusions from data. <ref type="bibr" target="#b13">Hand (1996)</ref> notes that these measurement theories map onto two different uses to which statistical models are often put (see <ref type="bibr" target="#b27">Lehmann, 1990)</ref>. Descriptive models, whose purpose is to summarize patterns in the data, are content with operationalism. Explanatory (or mechanistic/causal) models, which probe deeper into data-generating mechanisms and seek conclusions that go beyond the measurement scale, are aligned more closely with representationalism. The choice between measurement philosophies therefore also depends on the researcher's objectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">Statistical reservations</head><p>We now turn to statistical limitations of the numeric-conversion approach and provide a brief summary of the main points (see <ref type="bibr">Agresti, 2010, pp. 5-8, 137-140;</ref><ref type="bibr">Long, 1997, pp. 35-40, 116-119)</ref>. These are numbered for cross-reference with Table <ref type="table" target="#tab_4">4</ref>, which provides an overview and summary. First, (1) the choice of scoring system may be ambiguous. To some extent, this point of criticism can be addressed by psychometric research, which may suggest sensible deviations from the nearuniversal use of linear scoring systems. Further, (2) response categories are usually consistent with a range of values on the underlying continuum. On the frequency dimension, for instance, a respondent's assessment may be "very often". If the response scale requires a choice between "often" and "always" (see Figure <ref type="figure" target="#fig_6">7</ref>), the resulting score will be inflated or deflated by measurement error. A third (3) and perhaps minor point is that the researcher may obtain quantities of interest (predictions, estimates) that extend beyond the scale limits (e.g., a confidence interval stretching beyond "always").</p><p>The two final reservations, which arise from the boundedness of the scale, weigh more heavily since they systematically distort measures of location and spread. For one, (4) the variation of scores (as expressed, say, by the standard deviation) is downwardly biased near the endpoints of the scale. Subgroups whose responses gravitate towards the scale limits will therefore typically exhibit less variable ratings. For statistical inference, this may entail a violation of the homoscedasticity assumption (i.e., that the residual variation is approximately equal across conditions). Further, the assumption of normally distributed residuals, which underlies inferential procedures such as the ttest, ordinary regression, and ANOVA models, is untenable. This renders associated error probabilities (p-values and confidence intervals) dubious (see, e.g., <ref type="bibr">Harwell &amp; Gatti, 2001, pp. 111-112)</ref>. Finally, (5) due to floor and ceiling effects, differences between arithmetic means will likewise be compressed near the bounds of any such scale (see <ref type="bibr">Rohrer &amp; Arslan (2021, pp. 5-6)</ref> for an illustration). In particular, this may affect the interpretation of interaction patterns, which may result from such local scale compressions (e.g., <ref type="bibr" target="#b30">Loftus, 1978;</ref><ref type="bibr" target="#b40">Rohrer &amp; Arslan, 2021)</ref>. Now that we have given due attention to measurement-theoretic and statistical issues, we are ready to formulate a data-analytic perspective for situations where psychometric research has shed light on the perceived distances between response categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.">A data-analytic perspective</head><p>Let us start by stating our position on the use of scoring systems for the analysis of ordinal data: If a researcher is able to rationalize and defend their choice of scores as yielding an approximate interval scale, and if they actively take into account the inherent limitations of the approach (i.e., the systematic distortedness and scale-dependence of their statistical conclusions), then they may choose to use numeric conversion as a pragmatic and informative analysis strategy. This view echoes the position of various prominent scholars (e.g., <ref type="bibr">Anderson, 1961, p. 315;</ref><ref type="bibr">Mosteller, 1958, p. 288;</ref><ref type="bibr">Tukey, 1961, p. 246;</ref><ref type="bibr">Vellemann &amp; Wilkinson, 1993)</ref> and <ref type="bibr">Stevens (1946, p. 679</ref>) also gave a nod to this data-analytic perspective:</p><p>"In the strictest propriety […] means and standard deviations ought not to be used with these [i.e., ordinal] scales, for these statistics imply a knowledge of something more than the relative rank-order of data. On the other hand, for this 'illegal' statisticizing there can be invoked a kind of pragmatic sanction:</p><p>In numerous instances it leads to fruitful results. While the outlawing of this procedure would probably serve no good purpose, it is proper to point out that means and standard deviations computed on an ordinal scale are in error to the extent that the successive intervals on the scale are unequal in size."<ref type="foot" target="#foot_6">7</ref> </p><p>Since a conscious awareness of the limitations we have summarized above is an essential component of this data-analytic perspective, let us recapitulate how different analysis strategies fare with regard to the statistical and measurement-theoretic issues outlined above. In Table <ref type="table" target="#tab_4">4</ref>, a filled circle indicates that a procedure fails to sidestep the drawback, hence: the fewer points, the better. We note that only "appropriate" statistics and ordered random forests derive scale-free conclusions from data. The results from numeric-conversion approaches, ordinal regression, and latent-variable models, on the other hand, are scale-dependent. As for the statistical reservations, ordinal regression and the latentvariable formulation of the cumulative-link model (along with ordered random forests and "appropriate" statistics) manage to sidestep all of the weaknesses listed above, which makes them attractive tools for ordinal data analysis. The simpler procedures that rely on scoring systems, on the other hand, suffer from these statistical drawbacks. Note that the use of psychologically grounded scoring systems addresses but one statistical criticism -the ambiguities involved in the choice of scores. Measurement error and boundary effects (i.e., non-constant variance and distortions due to compressions near the scale limits) continue to pose a threat. It follows that questions of (in)appropriateness should be directed at the subject-matter interpretations researchers advance on the basis of ordinal data (rather than the analysis strategy used). We now turn to a case study that relies on an interval-scale analysis of ordinal data. The purpose of this illustrative application is two-fold: First, we demonstrate that the choice between a default (linear) vs. a psychometrically grounded (custom) scoring system can affect the linguistic conclusions suggested by the data. Further, we carefully weigh statistical and measurementtheoretic limitations in light of the linguistic objectives underlying the study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Illustrative application: Quantifier expressions in a survey on morphosyntactic variation</head><p>To illustrate how experimental research may inform the analysis and interpretation of rating scale data, we draw on the Bamberg Survey of Language Variation and Change (BSLVC; see <ref type="bibr" target="#b23">Krug &amp; Sell, 2013)</ref>. We start by briefly sketching the research context (Section 6.1) and then review experimental work on the verbal labels used in the questionnaire (Section 6.2). Section 6.3 then analyzes the data using different scoring systems: an equidistant and a custom set of scores. The data are available from the TROLLing archive <ref type="bibr" target="#b24">(Krug et al., 2024)</ref> and the R code for reproducing the analyses reported in this section can be found in the OSF (https://osf.io/5cfhe).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Background, research focus and questionnaire design</head><p>The BSLVC is a large-scale survey on the use of lexical and grammatical structures in different varieties of English. For details on the design and administration of the questionnaire, see <ref type="bibr" target="#b24">Krug et al. (2024)</ref>. We will turn to data from the grammar part, which asks respondents to indicate, on a 6-point scale, how prevalent a feature is in their home country or region; see Web appendix 3 for an illustration (https://osf.io/hzpqj). Specifically, participants give an estimate of how many speakers use the structure in question by choosing one of the following options: no-one, few, some, many, most, or everyone. These reported usage rates are elicited for two contexts, by asking informants to consider two settings: (i) an informal conversation among friends (informal speech); and (ii) an email to a former teacher (semi-formal writing). Accordingly, each sentence is presented in two modes (auditorily and in writing). For further considerations on the design of the BSLVC, see <ref type="bibr">Krug and Sell (2013, pp. 79-84)</ref>.</p><p>For our case study, we look at a single feature, the second person plural pronoun yous(e), in two varieties: English and Scottish English. Data are available for 43 English informants (22 male, 21 female; mean age 21) and 61 Scottish informants (24 male, 37 female; mean age 21). Each participant provided two ratings (informal speech vs. semi-formal writing) for a single sentence (Why don't youse come along to the restaurant?). We are therefore looking at a mixed design, with one betweensubjects factor (Variety: English vs. Scottish) and one within-subjects factor (Mode: speech vs. writing).</p><p>In general, it has been observed that yous(e) is more widespread in Scottish English (e.g., Smith 2012), and, since it classifies as non-standard, it is expected to be less prevalent in writing. We approach these data with the following questions: Is the usage rate of yous(e), on average, higher (i) in Scottish English and (ii) in speech? For (i) and (ii), we expect affirmative answers from the data. Our third question, in contrast, is exploratory: (iii) Is there evidence for an interaction between Variety and Mode (i.e., does one variety show a detectably greater stylistic difference in usage rate?).</p><p>We start with a descriptive overview of the data. Figure <ref type="figure" target="#fig_8">9</ref> shows the distribution of the responses using a diverging bar chart <ref type="bibr" target="#b16">(Heiberger &amp; Robbins 2014)</ref>; each stack of bars represents a condition (Variety-Mode combination), and the bars are aligned at the scale midpoint, the boundary between some and many. Observed category percentages (i.e., the share of respondents who ticked a particular response option) are given to the right of the graph; for instance, 21% of the Scottish informants reported that "no-one" in their home country would use the sentence in an email to a former teacher (writing), compared to 64% of the English informants. We note that the prevalence judgments are, on average, higher for Scottish English, and for the spoken context. Whether the two varieties show similar stylistic clines is more difficult to see in the graph, and we address this question in Section 6.3 using a statistical model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Quantifier perception: Survey of psychometric work</head><p>The continuum underlying this rating scale can be thought of as a relative frequency: No-one and everybody denote percentages of 0 and 100 and the perception of the intermediate quantifiers (few, some, many, most) can likewise be expressed as a proportion. Our literature search has returned three studies that use experimental techniques to probe how speakers interpret these quantifiers. A typical task asks subjects to consider a total of (say) 100 units -the set size -and to indicate how many units are, in their view, referenced by some. By averaging over multiple participants, the typical percentage denoted by a quantifier can then be estimated.<ref type="foot" target="#foot_7">8</ref> It is of interest to note that previous research has shown that the perceived proportional meaning of quantifiers varies systematically with set size: In smaller sets (e.g., 10 or 20 units), few and some are understood as referring to a greater proportional share (e.g., <ref type="bibr" target="#b36">Newstead et al., 1987)</ref>. Since the target set in our rating task is very large (i.e., a population of speakers), our summary of the literature will disregard set sizes smaller than 30.</p><p>Figure <ref type="figure" target="#fig_0">10</ref>. Survey on the perception of quantifier meanings (see Table <ref type="table" target="#tab_5">5</ref> for details).</p><p>Proportional estimates reported in the literature for the quantifiers few, some, many, and most appear in Figure <ref type="figure" target="#fig_0">10</ref>; information on the corresponding studies can be found in Table <ref type="table" target="#tab_5">5</ref>; for further details, please refer to <ref type="bibr">Sönning (2024a)</ref>. Estimates for the individual items show some variation across studies (and experiments within studies). At the bottom of Table <ref type="table" target="#tab_5">5</ref>, we summarize the percentages with a simple average across studies, and with a weighted average (printed in boldface), where figures are weighted in proportion to the number of subjects. Our scoring system will be based on these weighted means: few (11%), some (27%), many (67%), and most (83%). The two remaining scale labels, no-one and everyone, will be assigned values of 0% and 100%, respectively. The most notable difference to a default (linear) set of equidistant scores, then, is that the spacing between some and many is stretched, in accordance with experimental evidence on speakers' perceptions. Figure <ref type="figure" target="#fig_9">11</ref> illustrates how these custom scores are used to summarize and interpret the data; the illustrative ratings are those from the English informants for semi-formal writing. The bars denote the distribution of responses across the six categories; for instance, 28 informants reported that "no-one" in their home country would use this sentence in an email to a former teacher. If we replace each response with its custom (percentage) score, we can average over the 42 values (one participant failed to respond to this item in the written part of the questionnaire). This gives us a mean rating of 10.7%. We will interpret this average as an estimate of the usage rate of yous(e) in English semi-formal writing: According to the informants of our study, about 11% of the population in England would use yous(e) in semi-formal writing. Similar to the dimensions frequency and probability, then, the psychometric scale values for the set of quantifiers provide a tangible frame of reference, as they are directly interpretable as relative frequencies (i.e., percentages). Accordingly, we will read averages on that scale as rough estimates of the overall prevalence of yous(e) in the varieties and contexts under investigation. As we will see further below, this will throw additional light on the scale-dependence of our statistical conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Numeric-conversion analysis</head><p>We will now analyze our data using two different scoring systems: a psychometrically grounded custom scoring system, and an equidistant linear scoring system. To make results more directly comparable, we will let the linear scoring system run from 0 to 100, in 20-point steps. It should be noted that the choice of scores (i.e., 0-20-40-60-80-100 rather than, say, integers running from 0 to 5) does not affect the insights emerging from the ensuing analyses. The two scoring systems are juxtaposed in Table <ref type="table" target="#tab_6">6</ref>. The two factors (or independent variables) in our analysis, Variety (English vs. Scottish) and Mode (informal speech vs. semi-formal writing), are binary variables and crossed, making this as a 2x2 factorial design. Since we are dealing with a mixed design (with a between-and a within-subjects factor), we will analyze the data using a mixed-effects regression model that includes by-subject random intercepts. <ref type="foot" target="#foot_8">9</ref> The exploratory leg of our analysis probes into a potential interaction between Variety and Mode -that is, whether the usage rate difference, or stylistic cline, between (informal) speech and (semi-formal) writing is comparable in the two varieties or not. A statistical interaction between the two factors would indicate that the stylistic clines reported by English and Scottish participants differ. We will adopt a widespread modeling strategy for this exploratory part of our analysis and rely on statistical criteria to decide whether the addition of an interaction term to our model finds support from the data.</p><p>Before we turn to regression tables and questions of model parsimony ("Occam's razor"), let us compare graphical model summaries (i.e., adjusted predictions) for the two scoring systems, based on a model that does include an interaction between Variety and Mode. These are shown in Figure <ref type="figure" target="#fig_10">12</ref>. The estimates (adjusted predictions), which were obtained using the marginaleffects package (Arel-Bundock, 2023), are given numerically in Table <ref type="table" target="#tab_7">7</ref>, which also lists model-based comparisons (i.e., the reported stylistic cline for each variety and the difference between the English and Scottish clines). Before we consider these in more detail, note that the spacing of the quantifiers on the yaxes in Figure <ref type="figure" target="#fig_10">12</ref> differs: In panel (a), they are evenly spaced, and in panel (b) they are aligned with evidence on their interpretation, leading to a wider gap between some and many.</p><p>Figure <ref type="figure" target="#fig_10">12</ref> shows how the estimated usage rate varies by Variety and Mode: Yous(e) is used at a higher rate in speech and it is more prevalent in Scottish English. Panel (b) suggests that the stylistic cline is more pronounced in the Scottish subgroup: The difference between speech and writing is greater, which is reflected in the steeper slope -the lines fan out. For the linear scoring system, the estimated stylistic clines are more similar: 26.7 points for the Scottish informants and 20.1 points for the English informants. For the custom scoring system, the clines are wider apart: 29.9 vs. 17.3 points. Thus, panel (b) gives stronger indication of an interaction between Variety and Mode. Specifically, for the linear scoring system, the difference between the Scottish and English stylistic cline is estimated at 6.6 points vs. 12.6 points for the custom scoring system.  Let us now consider questions of model complexity and statistical inference. We have used the opportunity of a 2x2 factorial design to scale the regression terms in a way that enhances their interpretation (see <ref type="bibr">Box et al., 2005, pp. 185-188)</ref>. <ref type="foot" target="#foot_9">10</ref> The coefficient estimates for the two predictors, Variety and Mode, can be interpreted as average differences, which provide direct answers to questions (i) and (ii). This means that the coefficient for Variety gives the predicted difference between English and Scottish English, averaging over Mode (i.e., speech and writing). For the linear scoring system, this varietal difference, which was clearly notable in the diverging bar charts in Figure <ref type="figure" target="#fig_8">9</ref>, is at 33.0 points (compared to 35.9 points for the custom scoring system). The difference between speech and writing (averaging over the two varieties), on the other hand, is at 23.4 points for model (a) and 23.6 points for model (b). Both scoring systems therefore yield differences in the expected direction. The standard errors denote the uncertainty surrounding these differences; values within two standard errors of an estimate mark an approximate 95% confidence interval. We observe that the average differences are estimated with sufficient precision, indicating statistically reliable patterns in the data. The coefficient for the interaction addresses question (iii): In model (a), the stylistic cline is 6.6 points steeper in Scottish English. This is the value we noted in the right-most column of Table <ref type="table" target="#tab_7">7</ref> (the estimated difference between stylistic clines). Its standard error in model (a) indicates that, on inferential grounds, we may not be convinced that the interaction is necessary to capture the main patterns in the data. If we look at the interaction coefficient in model (b), however, we observe that it is appreciably greater, both in absolute terms (with 12.6 points about twice as large) and relative to its standard error.</p><p>This is also reflected in information criteria (IC), which assign greater predictive utility to the interaction term in model (b) vs. model (a). 11 This means that the statistical conclusions returned by our exploratory line of inquiry may very well depend on our choice of scoring system: Model (a) appears to favor the conclusion that the usage rate varies by Variety and Mode, and that the difference between speech and writing is roughly similar in the two populations. Model (b), on the other hand, is suggestive of a greater stylistic cline in Scottish English. Our analyses therefore reveal two things: First, when estimating average differences (questions (i) and (ii)), the choice of scoring system does not appear to matter much -both models observe similar differences between the varieties and usage contexts. However, if we go beyond overall trends and conduct subgroup analyses to examine interaction patterns (question (iii)), the choice of scoring system matters.</p><p>Our psychologically grounded choice of scores for the ordered categories therefore leaves us with a statistical interaction that we must now interpret in linguistic terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Scale-dependence of the interaction pattern</head><p>While our model some evidence for the presence of an interaction between Mode and Variety, the statistical reservations we discussed in Section 5.2.2 (see also Table <ref type="table" target="#tab_4">4</ref>) should make us cautious. After all, the difference in stylistic clines need not signal a "real" difference between the varietiesthey could simply be due to floor effects that arise from the hard lower bound at zero. To get a second statistical opinion on the scale-dependence of this interaction, let us switch to an analysis strategy that removes boundary effects. We will redo the analysis using ordinal regression (a parallel cumulative model with a logit link) with the same fixed and random effects. This form of ordered regression has a (mathematically equivalent) latent-variable formulation (see <ref type="bibr" target="#b49">Sönning et al., 2024)</ref>, which facilitates interpretation and comparison with the patterns returned by our numericconversion analysis. Figure <ref type="figure" target="#fig_12">13</ref> shows that there is no statistical indication for an interaction on the latent-variable scale: The trend lines representing the stylistic gap between speech and writing are parallel. This suggests that the interaction is indeed scale-dependent.</p><p>11 Keeping in mind that lower values are better, the addition of this term to the model should yield a lower IC score. Upon adding the interaction to the model, three information criteria (see <ref type="bibr">Sonderegger, 2023, pp. 134-136, 279-280)</ref>   What implications does this have for the linguistic story we should be telling? It helps to call into mind the objectives of our study. The BSLVC is a large-scale questionnaire project that aims to profile and compare varieties of English with regard to a range of lexical and morpho-syntactic features. Based on informants' reports about the perceived usage rate of structures in their speech community, estimates are formed of their prevalence in varieties of English. By aiming for quantitative statements about populations of speakers, the goals of our analysis are descriptive rather than explanatory. This is because the primary purpose of the BSLVC is the documentation of cross-varietal and stylistic differences in the currency of non-standard and/or innovative features.</p><p>Based on informants' reports, it provides estimates of how prevalent a particular feature is in a speech community (and stylistic context) -that is, how many speakers (expressed as a percentage) use it. No attempt is made (here) to explain or account for observed differences. Thus, we are not concerned with the question of why Scottish English may be showing a greater stylistic cline. From the viewpoint of measurement theory, then, we are free in our choice of scale, as we do not intend to attempt deeper causal interpretations.</p><p>After careful deliberation, we decide that the percentage scale (Figure <ref type="figure" target="#fig_10">12</ref>) provides more informative answers to our research questions compared to a latent-variable scale (Figure <ref type="figure" target="#fig_12">13</ref>): Percentages and percentage point differences are useful and interpretable indicators of (differences between) usage rates. This means that, given our applied purposes, the unbounded scale in Figure <ref type="figure" target="#fig_12">13</ref> offers no immediate interpretative advantage. Rather, the continuum on which we wish to describe and interpret our findings is naturally bounded: Floor and ceiling effects are real and we would be hesitant to remove them from the data summaries that form the basis of our linguistic interpretations. The statistical reservations that derive from boundary effects therefore lose some force, at least at the level of data description.</p><p>Nevertheless, several shortcomings of the ordinary mixed-effects regression model used above persist: (i) no allowance is made for measurement error due to the discreteness of the response categories; (ii) model-based quantities may very well extend beyond scale bounds; and (iii) statistical inferences may be unreliable due to violation of the normality and homoscedasticity assumption. For the data at hand, (ii) and (iii) could be partly addressed by modeling percentages on a non-linear scale such as log odds (using, say, fractional logit regression; <ref type="bibr" target="#b38">Papke &amp; Wooldridge, 1996)</ref>. However, unless we make more fundamental changes to our analysis strategy (see Table <ref type="table" target="#tab_4">4</ref>), certain statistical reservations will continue to be a thorn in our side.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Summary and conclusion</head><p>The aim of the present paper was to illustrate how experimental findings may inform the construction of ordinal response scales and the arrangement of custom scoring systems. While the use of psychometric insights for scale design is uncontroversial and has been addressed in previous work, their usefulness for data analysis does not seem to enjoy widespread recognition. Seeing that the numeric-conversion approach to ordinal data is (and will likely remain) prevalent in language research, methodologists must embrace these realities and provide constructive advice that can cater for a vast majority of empirical researchers. A methodology grounded in actual research practice would arguably refrain from issuing overly firm recommendations on "appropriate" statistics and instead give balanced consideration to the tradeoffs involved in switching analysis strategies.</p><p>The fact that researchers almost exclusively rely on equal-spaced integers to analyze rating scale data is arguably unsatisfactory. To see moderate improvements in current practice, the use of custom scoring systems should be encouraged, perhaps drawing on the psychometric insights summarized above. More importantly, however, researchers must be made explicitly aware of the drawbacks and deceptions that may beset the interpretation of their results. Methodological advice should center on underlying measurement-theoretic and statistical arguments and clearly state their consequences for the analysis and interpretation of ordinal variables. The aim should be to foster an informed data-analytic discourse on this topic, and to delineate settings where researchers are particularly likely to be misled. A case in point is the study of interaction patterns, which may depend on the choice of scoring system and/or the analysis strategy used.</p><p>If such a grounded methodology were indeed to emerge, two directions of inquiry appear particularly fruitful. For one, the experimental evidence for the individual rating dimensions remains scarce. More psychometric work is needed on the measurement features of phrases, with a focus on the stability of interpretations across (populations of) subjects. By widening the empirical knowledge base, more informed recommendations for scale design and data analysis may be given. For instance, expressions that are open to a range of interpretations in the same population of speakers, or whose interpretation varies across populations, may be flagged as undesirable. Further, relatively unfamiliar expressions may also be unsuitable anchors on rating scales. Relevant work in this direction has been carried out by <ref type="bibr" target="#b34">Mosteller and</ref><ref type="bibr" target="#b35">Youtz (1990) and</ref><ref type="bibr" target="#b42">Rohrmann (2007)</ref>.</p><p>More systematic research is also needed on the scale-dependence and distortedness of descriptive and inferential results. This could involve sensitivity checks that look into the stability of conclusions across analysis strategies. A (crude) example of this line of inquiry is the comparison we drew with a latent-variable form of ordinal regression, a procedure that appeases statistical objections and thereby allows us to form some judgement on their effects on the scale-dependence of findings (for more thorough studies in this spirit, see <ref type="bibr" target="#b29">Liddell &amp; Kruschke, 2018;</ref><ref type="bibr" target="#b40">Rohrer &amp; Arslan, 2021;</ref><ref type="bibr" target="#b49">Sönning et al., 2024)</ref>. One of the key goals should be a set of heuristics that may be of help to practitioners who must decide on how much credence to lend to the output of a numeric-conversion analysis. This would shift the focus of discussion from the "appropriateness" of statistical procedures to where it is needed: on the linguistic interpretation of quantitative results.</p><p>Ultimately, this discourse must be cultivated in specialist fields and linguistically circumscribed areas of study. After all, the weight given to measurement-theoretic and statistical concerns will depend on the research context and the kinds of questions asked of the data. In experimental syntax, for instance, where interest centers on speakers' mental grammar, representationalist views on measurement cannot easily be dismissed. In applied research, on the other hand, the stated goals of a study may license a data-analytic mentality that takes advantage of custom scoring systems while giving careful attention to their limitations, to avoid drawing false conclusions from data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. The five principal dimensions used in graded scales: Examples. 4</figDesc><graphic coords="4,167.78,144.54,259.75,168.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Scale values for the dimension agreement; data from Rohrmann (2007).</figDesc><graphic coords="6,167.15,181.39,260.70,192.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Scale values for the dimension intensity; data from<ref type="bibr" target="#b32">Matthews et al. (1978)</ref>,<ref type="bibr" target="#b22">Krsacok (2001), and</ref><ref type="bibr" target="#b42">Rohrmann (2007)</ref>.</figDesc><graphic coords="7,185.65,70.85,224.70,253.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Scale values for frequency expressions; data from Mosteller and Youtz (1990).</figDesc><graphic coords="8,187.40,70.85,220.03,227.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Scale construction: Approximately equal-interval scale labels for 5-, 6-, and 7-point (a) agreement and (b) intensity scales.</figDesc><graphic coords="9,156.65,70.85,281.77,202.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Scale construction: Saturation of the lower or higher end of the scale to enhance resolution in settings where ratings are expected (or known) to cluster near the extremes.</figDesc><graphic coords="9,171.35,490.61,252.52,127.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Scale evaluation: Saturation of the lower or higher end of the scale to enhance resolution in settings where responses are expected (or known) to cluster near the extremes.</figDesc><graphic coords="10,161.00,202.23,273.27,116.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Procedures for summarizing the distribution of ordinal variables, arranged along two dimensions: informativity and feasibility.</figDesc><graphic coords="11,196.85,144.54,201.57,141.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Distribution of ratings across responses categories, by variety (Scottish vs. English) and mode (speech vs. writing).</figDesc><graphic coords="16,154.20,216.66,286.87,116.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Illustration of the custom scoring system and its use for the analysis and interpretation of the data.</figDesc><graphic coords="18,197.15,70.85,200.65,203.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 12 .</head><label>12</label><figDesc>Figure 12. Model-based predictions for an analysis based on (a) default linear scoring system and a (b) psychometrically grounded scoring system; error bars denote standard errors (i.e., 68% confidence intervals).</figDesc><graphic coords="19,165.65,463.42,263.39,136.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>show differential drops (Δ) in the two models. AIC: Δ = 4.7 in model (a) (1935.8 → 1931.1), Δ = 6.5 in model (b) (1973.4 → 1966.9); AICc: Δ = 4.5 in model (a) (1936.1 → 1931.6), Δ = 6.3 in model (b) (1973.7 → 1967.4); and BIC: Δ = 1.3 in model (a) (1952.4 → 1951.1), Δ = 3.2 in model (b) (1990.1 → 1986.9).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 13 .</head><label>13</label><figDesc>Figure 13. Model-based predictions for an ordered regression model on the latent-variable scale; error bars denote standard errors (i.e., 68% confidence intervals).</figDesc><graphic coords="22,229.95,70.85,135.37,156.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Table 1, this subset is highlighted in grey. 2 Structure of ordinal scales used in rating tasks.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="5">Number of response categories</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Labels</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell><cell>Total</cell></row><row><cell>Endpoints only</cell><cell></cell><cell>9</cell><cell>61</cell><cell>19</cell><cell>74</cell><cell>1</cell><cell>24</cell><cell>7</cell><cell>4</cell><cell cols="2">199 49%</cell></row><row><cell>Each category</cell><cell>12</cell><cell>29</cell><cell>80</cell><cell>33</cell><cell>14</cell><cell>1</cell><cell>4</cell><cell></cell><cell></cell><cell cols="2">173 42%</cell></row><row><cell>Other  †</cell><cell></cell><cell>1</cell><cell>12</cell><cell>5</cell><cell>10</cell><cell></cell><cell>3</cell><cell>3</cell><cell>3</cell><cell>37</cell><cell>9%</cell></row><row><cell>No information</cell><cell></cell><cell>1</cell><cell>22</cell><cell>5</cell><cell>28</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>1</cell><cell>(64)</cell></row><row><cell>Total</cell><cell>12</cell><cell cols="2">40 175</cell><cell cols="2">62 126</cell><cell>3</cell><cell>34</cell><cell>13</cell><cell>8</cell><cell>473</cell></row><row><cell></cell><cell>3%</cell><cell cols="4">8% 37% 13% 27%</cell><cell>1%</cell><cell>7%</cell><cell>3%</cell><cell>2%</cell><cell></cell></row><row><cell>Note.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Distribution of fully verbalized scales by dimension, number of response categories and analysis strategy.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Number of response categories</cell><cell></cell><cell cols="3">Analysis strategy  †</cell></row><row><cell>Dimension</cell><cell>N</cell><cell>%</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>Num</cell><cell cols="3">Des Ord Non</cell></row><row><cell>Agreement</cell><cell cols="2">57 33%</cell><cell></cell><cell>7</cell><cell>25</cell><cell>17</cell><cell>8</cell><cell></cell><cell></cell><cell>52</cell><cell>5</cell><cell></cell></row><row><cell>Intensity</cell><cell cols="2">32 18%</cell><cell>1</cell><cell>10</cell><cell>16</cell><cell>3</cell><cell>2</cell><cell></cell><cell></cell><cell>23</cell><cell>4</cell><cell></cell><cell>1</cell></row><row><cell>Frequency</cell><cell>16</cell><cell>9%</cell><cell>2</cell><cell>3</cell><cell>9</cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell>13</cell><cell>3</cell><cell></cell></row><row><cell>Probability</cell><cell>6</cell><cell>3%</cell><cell></cell><cell>2</cell><cell>2</cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell>4</cell><cell>2</cell><cell></cell></row><row><cell>Quality</cell><cell>6</cell><cell>3%</cell><cell>1</cell><cell></cell><cell>4</cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>5</cell><cell></cell><cell>1</cell></row><row><cell>None/other</cell><cell cols="2">56 33%</cell><cell>8</cell><cell>7</cell><cell>24</cell><cell>8</cell><cell>4</cell><cell>1</cell><cell>4</cell><cell>45</cell><cell>7</cell><cell>3</cell><cell>1</cell></row><row><cell>Total</cell><cell>173</cell><cell></cell><cell>12</cell><cell>29</cell><cell>80</cell><cell cols="2">33 14</cell><cell>1</cell><cell>4</cell><cell>142</cell><cell>21</cell><cell>4</cell><cell>2</cell></row><row><cell>%</cell><cell></cell><cell></cell><cell cols="7">7% 16% 47% 19% 8% 1% 2%</cell><cell cols="2">84% 12%</cell><cell>2%</cell><cell>1%</cell></row><row><cell cols="13">Note.  † Abbreviations: Numeric conversion, Descriptive statistics, Ordinal regression, Non-</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="7">parameteric procedures (see text for details).</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Arithmetic mean vs. median: Dependence of directionality of group difference on the scoring system.</figDesc><table><row><cell></cell><cell cols="4">Category frequencies</cell><cell></cell><cell cols="2">Scoring system</cell></row><row><cell></cell><cell></cell><cell cols="2">(percentages)</cell><cell></cell><cell cols="2">1-2-3-4</cell><cell cols="2">1-2-4-8</cell></row><row><cell>Group</cell><cell>I</cell><cell>II</cell><cell>III</cell><cell>IV</cell><cell>Mdn</cell><cell>Mean</cell><cell cols="2">Mdn Mean</cell></row><row><cell>A</cell><cell cols="4">20% 20% 50% 10%</cell><cell>3</cell><cell>2.5</cell><cell>4</cell><cell>3.4</cell></row><row><cell>B</cell><cell cols="4">40% 20% 10% 30%</cell><cell>2</cell><cell>2.3</cell><cell>2</cell><cell>3.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Statistical and measurement-theoretic drawbacks of different analysis procedures.</figDesc><table><row><cell></cell><cell cols="2">Numeric conversion:</cell><cell>Ordinal</cell><cell>Latent-</cell><cell>Ordered</cell><cell>"Appro-</cell></row><row><cell></cell><cell cols="2">Use of scoring system</cell><cell>regression</cell><cell>variable</cell><cell>random</cell><cell>priate"</cell></row><row><cell>Limitations</cell><cell>Default</cell><cell>Custom</cell><cell>model  †</cell><cell>model</cell><cell>forest</cell><cell>statistics</cell></row><row><cell>Measurement-theoretic</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Scores do not reflect reality</cell><cell>•</cell><cell>•</cell><cell>•</cell><cell>•</cell><cell></cell><cell></cell></row><row><cell>Statistical (see Section 5.2.2)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(1) Choice of scores unclear</cell><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(2) Measurement error</cell><cell>•</cell><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(3) No hard scale bounds</cell><cell>•</cell><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(4) Heteroscedasticity</cell><cell>•</cell><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(5) Floor and ceiling effects</cell><cell>•</cell><cell>•</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Note.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note><p>† This only includes ordered regression models other than the cumulative-link model, which is in fact mathematically equivalent to a latent-variable model.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Studies on the perception of quantifiers: Details.</figDesc><table><row><cell>Study</cell><cell>Subjects</cell><cell>Set size(s)</cell><cell cols="2">few some many most</cell></row><row><cell>Borges &amp; Sawyers 1974</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Experiment I</cell><cell>26</cell><cell>36, 48</cell><cell cols="2">11% 26% 57% 81%</cell></row><row><cell>Experiment II</cell><cell cols="2">30 36, 60, 84, 108</cell><cell cols="2">12% 32% 77% 94%</cell></row><row><cell>Newstead et al. 1987</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Experiment 1</cell><cell>234</cell><cell>108</cell><cell cols="2">11% 30% 70% 87%</cell></row><row><cell>Experiment 2</cell><cell>18</cell><cell>60, 108, 1000</cell><cell cols="2">16% 32% 74% 85%</cell></row><row><cell>Experiment 2 (additional data)</cell><cell>20</cell><cell>10000</cell><cell>9%</cell><cell>27% 70% 84%</cell></row><row><cell>van Tiel et al. 2021, Exp. 1a</cell><cell>165-489</cell><cell>432</cell><cell cols="2">10% 25% 62% 80%</cell></row><row><cell>Sönning 2024b</cell><cell>20</cell><cell>100</cell><cell cols="2">12% 28% 64% 83%</cell></row><row><cell>Mean</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Equally weighted</cell><cell></cell><cell></cell><cell cols="2">11% 28% 68% 85%</cell></row><row><cell>Weighted by sample size</cell><cell></cell><cell></cell><cell cols="2">11% 27% 67% 83%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Scoring systems used in the analysis.</figDesc><table><row><cell></cell><cell></cell><cell>Response category</cell><cell></cell></row><row><cell>Scoring system</cell><cell cols="3">No-one Few Some Many Most Everyone</cell></row><row><cell>Custom</cell><cell>0%</cell><cell>11% 27% 67% 81%</cell><cell>100%</cell></row><row><cell>Linear</cell><cell>0%</cell><cell>20% 40% 60% 80%</cell><cell>100%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 7 .</head><label>7</label><figDesc>Model-based predictions and comparisons for the two scoring systems (standard errors in parentheses).</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Stylistic cline</cell><cell>Difference between</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(difference between</cell><cell>stylistic clines (difference</cell></row><row><cell>Analysis and variety</cell><cell>Speech</cell><cell>Writing</cell><cell>speech and writing)</cell><cell>between differences)</cell></row><row><cell>Linear scoring system</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>English informants</cell><cell>33.0 (4.1)</cell><cell>12.9 (4.2)</cell><cell>20.1 (5.6)</cell><cell>6.6 (7.3)</cell></row><row><cell>Scottish informants</cell><cell>69.4 (3.5)</cell><cell>42.6 (3.4)</cell><cell>26.7 (4.7)</cell><cell></cell></row><row><cell>Custom scoring system</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>English informants</cell><cell>28.2 (4.5)</cell><cell>10.9 (4.5)</cell><cell>17.3 (6.1)</cell><cell>12.6 (8.0)</cell></row><row><cell>Scottish informants</cell><cell>70.4 (3.8)</cell><cell>40.5 (3.8)</cell><cell>29.9 (5.1)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 .</head><label>4</label><figDesc>Regression coefficients and hypothesis test for an analysis † using a linear and a custom scoring system.</figDesc><table><row><cell></cell><cell>Model (a)</cell><cell></cell><cell>Model (b)</cell><cell></cell></row><row><cell></cell><cell cols="2">Linear scores</cell><cell cols="2">Custom scores</cell></row><row><cell>Coefficient</cell><cell>Estimate</cell><cell>(SE)</cell><cell>Estimate</cell><cell>(SE)</cell></row><row><cell>(Intercept)</cell><cell>39.5</cell><cell>(2.0)</cell><cell>37.5</cell><cell>(2.2)</cell></row><row><cell>Variety: Scottish -English</cell><cell>33.0</cell><cell>(4.0)</cell><cell>35.9</cell><cell>(4.4)</cell></row><row><cell>Mode: speech -writing (Δ)</cell><cell>23.4</cell><cell>(3.6)</cell><cell>23.6</cell><cell>(4.0)</cell></row><row><cell>Interaction: ΔScottish -</cell><cell>6.6</cell><cell>(7.3)</cell><cell>12.6</cell><cell>(8.0)</cell></row><row><cell>ΔEnglish</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Random intercept SD</cell><cell>8.2</cell><cell></cell><cell>8.9</cell><cell></cell></row><row><cell>Residual SD</cell><cell>25.7</cell><cell></cell><cell>28.1</cell><cell></cell></row><row><cell cols="4">Note.  † Model specification: rating ~ variety_c * mode_c + (1|subject)</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>Differences had to occur along (one of) the features of main interest in our survey: number of response categories, the incorporation of verbal labels, and the underlying dimension.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>As an aside, it may be noted that empirical evidence suggests that adding labels to all response options (rather than only to the endpoints) improves the reliability and validity of rating scales (seeKrosnick &amp;  Fabrigar, 1997, pp.  149-152 for a review). With regard to the numeric-conversion approach to data analysis, on the other hand, an advantage of the endpoint-only format is that it makes the use of a linear scoring system (i.e., equal numeric distances between categories) more defensible.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The term "Likert scale" is often used to broadly refer to an ordinal response format. In its original sense<ref type="bibr" target="#b28">(Likert, 1932)</ref>, however, it denotes an aggregated (or summated) scale based on multiple items (see, e.g.,<ref type="bibr" target="#b14">Harpe, 2015)</ref>. Each of these items, in turn, is measured using an ordinal rating scale, where respondents indicate their level of (dis)agreement to a statement.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>All images in this paper have been published under the Creative Commons Attribution 4.0 license (CC BY 4.0, http://creativecommons.org/licenses/by/4.0) in the accompanying OSF project (https://osf.io/8f9q4/). All figures were drawn using the R packages 'lattice'<ref type="bibr" target="#b43">(Sarkar, 2008)</ref> and 'ggplot2'<ref type="bibr" target="#b54">(Wickham, 2016)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>In two studies, two analysis strategies were applied to the data from the same ordinal scale, leading to multiple entries in this part of the table. In</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5"><p>studies, no analysis strategy could be ascertained. The totals therefore add to 169 entries (173 + 2 -6).6  For similar research on German and Chinese scale point labels, see, e.g.,<ref type="bibr" target="#b41">Rohrmann (1978)</ref> and<ref type="bibr" target="#b3">Au et al. (2011)</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6"><p>Here, Stevens reminds us that a linear scoring system may be a poor representation of the actual distances between categories, which is but one of the statistical concerns discussed above (i.e., point (1) in Table4).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7"><p>This procedure disregards the fact that the perception of quantifiers varies across individuals, and that the amount of between-speaker variation may vary among quantifiers. Nevertheless, these averages do provide a useful first approximation to the proportional meaning our informants are likely to attach to the expressions.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8"><p>The model was run using the lme4 package<ref type="bibr" target="#b4">(Bates et al., 2015)</ref> in R (R Core Team, 2022), and specified as follows: lmer(rating ~ variety_c * mode_c + (1|subject)).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9"><p>To obtain the directly interpretable coefficients discussed shortly, all binary input variables are represented using contrast coding, with +0.5/-0.5 representing Scottish/English and speech/writing.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>I would like to thank <rs type="person">Jan Vanhove</rs> and <rs type="person">Manfred Krug</rs> as well as two anonymous reviewers for their constructive comments on an earlier version of this paper. Financial support from the <rs type="funder">German Research Foundation</rs> (DFG, grant number <rs type="grantNumber">548274092</rs>) is gratefully acknowledged.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_jP5n7Fm">
					<idno type="grant-number">548274092</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Analysis of ordinal categorical data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Agresti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scales and statistics: Parametric and nonparametric</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Anderson</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0042576</idno>
		<ptr target="https://doi.org/10.1037/h0042576" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="305" to="316" />
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">marginaleffects: Predictions, comparisons, slopes, marginal means, and hypothesis tests</title>
		<author>
			<persName><forename type="first">V</forename><surname>Arel-Bundock</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=marginaleffects" />
	</analytic>
	<monogr>
		<title level="j">CRAN</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Version 0.13.0) [R package</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Developing equivalent Chinese and English scale-point labels for rating scales used in survey research</title>
		<author>
			<persName><forename type="first">W</forename><surname>Au</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rohrmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yeung</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-839X.2010.01333.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-839X.2010.01333.x" />
	</analytic>
	<monogr>
		<title level="j">Asian Journal of Social Psychology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="111" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Fitting linear mixed-effects models using lme4</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maechler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v067.i01</idno>
		<ptr target="https://doi.org/10.18637/jss.v067.i01" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On measurements and their quality. Paper 4: Verbal anchors and the number of response options in rating scales</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Beckstead</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijnurstu.2013.10.002</idno>
		<ptr target="https://doi.org/10.1016/j.ijnurstu.2013.10.002" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Nursing Studies</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="807" to="814" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Common verbal quantifiers: Usage and interpretation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Borges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Sawyers</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0035829</idno>
		<ptr target="https://doi.org/10.1037/h0035829" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="335" to="338" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Hunter</surname></persName>
		</author>
		<title level="m">Statistics for experimenters: Design, innovation, and discovery</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Often is where you find it</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">I</forename><surname>Chase</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0028186</idno>
		<ptr target="https://doi.org/10.1037/h0028186" />
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">1043</biblScope>
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Five statistical models for Likert-type experimental data on acceptability judgments</title>
		<author>
			<persName><forename type="first">A</forename><surname>Endresen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Janda</surname></persName>
		</author>
		<idno type="DOI">10.1558/jrds.29915</idno>
		<ptr target="https://doi.org/10.1558/jrds.29915" />
	</analytic>
	<monogr>
		<title level="j">Journal of Research Design and Statistics in Linguistics and Communication Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="217" to="250" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rating the rating scales</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Amoo</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.1652231</idno>
		<ptr target="https://doi.org/10.2139/ssrn.1652231" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Marketing Management</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="114" to="123" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Ordered regression models: Parallel, partial, and non-parallel alternatives</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Fullerton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<publisher>CRC Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Grissom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203802841</idno>
		<ptr target="https://doi.org/10.4324/9780203802841" />
		<title level="m">Effect sizes for research: Univariate and multivariate applications</title>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Statistics and the theory of measurement</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Hand</surname></persName>
		</author>
		<idno type="DOI">10.2307/2983325</idno>
		<ptr target="https://doi.org/10.2307/2983325" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series A (Statistics in Society)</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="445" to="492" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">How to analyze Likert and other rating scale data</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Harpe</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cptl.2015.08.001</idno>
		<ptr target="https://doi.org/10.1016/j.cptl.2015.08.001" />
	</analytic>
	<monogr>
		<title level="j">Currents in Pharmacy Teaching and Learning</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="836" to="850" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Rescaling ordinal data to interval data in educational research</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Harwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Gatti</surname></persName>
		</author>
		<idno type="DOI">10.3102/00346543071001105</idno>
		<ptr target="https://doi.org/10.3102/00346543071001105" />
	</analytic>
	<monogr>
		<title level="j">Review of Educational Research</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="131" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Design of diverging stacked bar charts for Likert scales and other applications</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Heiberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Robbins</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v057.i05</idno>
		<ptr target="https://doi.org/10.18637/jss.v057.i05" />
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Anchors away -the stability of meaning of anchors when their location is changed</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Ironson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1744-6570.1981.tb00946.x</idno>
		<ptr target="https://doi.org/10.1111/j.1744-6570.1981.tb00946.x" />
	</analytic>
	<monogr>
		<title level="j">Personnel Psychology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="262" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Likert scales: How to (ab)use them</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jamieson</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1365-2929.2004.02012.x</idno>
		<ptr target="https://doi.org/10.1111/j.1365-2929.2004.02012.x" />
	</analytic>
	<monogr>
		<title level="j">Medical Education</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1217" to="1218" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The influence of labels and positions in rating scales</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Klockars</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yamagishi</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1745-3984.1988.tb00296.x</idno>
		<ptr target="https://doi.org/10.1111/j.1745-3984.1988.tb00296.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Measurement</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="96" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Treating ordinal scales as interval scales: An attempt to resolve the controversy</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Knapp</surname></persName>
		</author>
		<idno type="DOI">10.1097/00006199-199003000-00019</idno>
		<ptr target="https://doi.org/10.1097/00006199-199003000-00019" />
	</analytic>
	<monogr>
		<title level="j">Nursing Research</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="123" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Designing rating scales for effective measurement in surveys</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Krosnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Fabrigar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Survey measurement and process quality</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Lyberg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Biemer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>De Leeuw</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Dippo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Trewin</surname></persName>
		</editor>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="141" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Quantification of adverb intensifiers for use in ratings of acceptability, adequacy, and relative goodness</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Krsacok</surname></persName>
		</author>
		<ptr target="https://ecommons.udayton.edu/graduate_theses/3652" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>University of Dayton eCommons</orgName>
		</respStmt>
	</monogr>
	<note>Doctoral dissertation, University of Dayton</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Designing and conducting interviews and questionnaires</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sell</surname></persName>
		</author>
		<idno type="DOI">10.1017/CBO9781139419322.007</idno>
		<ptr target="https://doi.org/10.1017/CBO9781139419322.007" />
	</analytic>
	<monogr>
		<title level="m">Research methods in language variation and change</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Krug</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Schlüter</surname></persName>
		</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="69" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Background data for: The morpho-syntax of Scottish Standard English: Questionnaire-based insights</title>
		<author>
			<persName><forename type="first">M</forename><surname>Krug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Schützler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sönning</surname></persName>
		</author>
		<idno type="DOI">10.18710/B3NJBT</idno>
		<ptr target="https://doi.org/10.18710/B3NJBT" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Some observations on measurement and statistics</title>
		<author>
			<persName><forename type="first">S</forename><surname>Labovitz</surname></persName>
		</author>
		<idno type="DOI">10.2307/2574436</idno>
		<ptr target="https://doi.org/10.2307/2574436" />
	</analytic>
	<monogr>
		<title level="j">Social Forces</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="160" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Random forest estimation of the ordered choice model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lechner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Okasa</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.1907.02436</idno>
		<ptr target="https://doi.org/10.48550/arXiv.1907.02436" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Model specification: The views of Fisher and Neyman, and later developments</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Lehmann</surname></persName>
		</author>
		<idno type="DOI">10.1214/ss/1177012111</idno>
		<ptr target="https://doi.org/10.1214/ss/1177012111" />
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="160" to="168" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">A technique for the measurement of attitudes</title>
		<author>
			<persName><forename type="first">R</forename><surname>Likert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1932">1932</date>
			<publisher>Columbia University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Analyzing ordinal data with metric models: What could possibly go wrong</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Liddell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jesp.2018.08.009</idno>
		<ptr target="https://doi.org/10.1016/j.jesp.2018.08.009" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="328" to="348" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On interpretation of interactions</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Loftus</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03197461</idno>
		<ptr target="https://doi.org/10.3758/BF03197461" />
	</analytic>
	<monogr>
		<title level="j">Memory &amp; Cognition</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="312" to="319" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Regression models for categorical and limited dependent variables</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Long</surname></persName>
		</author>
		<idno type="DOI">10.4135/9781412984759</idno>
		<ptr target="https://doi.org/10.4135/9781412984759" />
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>SAGE Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The perceived favorableness of selected scale anchors and response alternatives</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Yudowitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Geddie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Palmer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978">1978</date>
		</imprint>
		<respStmt>
			<orgName>U.S. Army Research Institute for the Behavioral and Social Sciences</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Measurement scales and statistics: A clash of paradigms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Michell</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.100.3.398</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.100.3.398" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="398" to="407" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The mystery of the missing corpus</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mosteller</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF02288988</idno>
		<ptr target="https://doi.org/10.1007/BF02288988" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="279" to="289" />
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Quantifying probabilistic expressions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Mosteller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Youtz</surname></persName>
		</author>
		<idno type="DOI">10.1214/ss/1177012258</idno>
		<ptr target="https://doi.org/10.1214/ss/1177012258" />
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="34" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The effect of set size on the interpretation of quantifiers used in rating scales</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Newstead</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Riezebos</surname></persName>
		</author>
		<idno type="DOI">10.1016/0003-6870(87)90060-1</idno>
		<ptr target="https://doi.org/10.1016/0003-6870" />
	</analytic>
	<monogr>
		<title level="j">Applied Ergonomics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="90060" to="90061" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Likert scales, levels of measurement and the &quot;laws&quot; of statistics</title>
		<author>
			<persName><forename type="first">G</forename><surname>Norman</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10459-010-9222-y</idno>
		<ptr target="https://doi.org/10.1007/s10459-010-9222-y" />
	</analytic>
	<monogr>
		<title level="j">Advances in Health Sciences Education</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="625" to="632" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Econometric methods for fractional response variables with an application to 401(K) plan participation rates</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Papke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wooldridge</surname></persName>
		</author>
		<idno type="DOI">10.1002/(SICI)1099-1255(199611)11:6%3c619::AID-JAE418%3e3.0.CO;2-1</idno>
		<idno>AID-JAE418&gt;3.0.CO;2-1</idno>
		<ptr target="https://doi.org/10.1002/(SICI)1099-1255" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Econometrics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="619" to="632" />
			<date type="published" when="1996">1996. 199611</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">R: A language and environment for statistical computing</title>
		<author>
			<orgName type="collaboration">R Core Team.</orgName>
		</author>
		<ptr target="https://www.R-project.org/" />
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<imprint>
			<date type="published" when="2000-02">2022. Version 4.2.0</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Precise answers to vague questions: Issues with interactions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rohrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Arslan</surname></persName>
		</author>
		<idno type="DOI">10.1177/2515245920975120</idno>
		<ptr target="https://doi.org/10.1177/2515245920975120" />
	</analytic>
	<monogr>
		<title level="m">Advances in Methods and Practices in Psychological Science</title>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Empirische Studien zur Entwicklung von Antwortskalen für die sozialwissenschaftliche Forschung</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rohrmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zeitschrift für Sozialpsychologie</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="222" to="245" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Verbal qualifiers for rating scales: Sociolinguistic considerations and psychometric data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rohrmann</surname></persName>
		</author>
		<ptr target="www.rohrmannresearch.net/pdfs/rohrmann-vqs-report.pdf" />
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>University of Melbourne</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Lattice: Multivariate data visualization with R</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sarkar</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-0-387-75969-2</idno>
		<ptr target="https://doi.org/10.1007/978-0-387-75969-2" />
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Formal features of rating scales and the interpretation of question meaning</title>
		<author>
			<persName><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Grayson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Knäuper</surname></persName>
		</author>
		<idno type="DOI">10.1093/ijpor/10.2.177</idno>
		<ptr target="https://doi.org/10.1093/ijpor/10.2.177" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Public Opinion Research</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="177" to="183" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Scottish English and varieties of Scots</title>
		<author>
			<persName><forename type="first">J</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Mouton world atlas of variation in English</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Kortmann</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Lunkenheimer</surname></persName>
		</editor>
		<imprint>
			<publisher>Walter de Gruyter</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Regression modeling for linguistic data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sonderegger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Background data for: Ordinal response scales: Psychometric grounding for design and analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sönning</surname></persName>
		</author>
		<idno type="DOI">10.18710/0VLSLW</idno>
		<ptr target="https://doi.org/10.18710/0VLSLW" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Modeling the interpretation of quantifiers using beta regression</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sönning</surname></persName>
		</author>
		<ptr target="https://lsoenning.github.io/posts/2024-01-11_beta_regression_quantifiers/" />
	</analytic>
	<monogr>
		<title level="m">Statistics for linguist(ic)s blog</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Latent-variable modelling of ordinal outcomes in language data analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sönning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vetter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leucht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Messer</surname></persName>
		</author>
		<idno type="DOI">10.1080/09296174.2024.1135129</idno>
		<ptr target="https://doi.org/10.1080/09296174.2024.1135129" />
	</analytic>
	<monogr>
		<title level="j">Journal of Quantitative Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="106" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">On the theory of scales of measurement</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Stevens</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.103.2684.677</idno>
		<ptr target="https://doi.org/10.1126/science.103.2684.677" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="677" to="680" />
			<date type="published" when="1946">1946. 2684</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Data analysis and behavioral science or learning to bear the quantitative man&apos;s burden by shunning badmandments</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Tukey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The collected works of John W. Tukey III</title>
		<editor>
			<persName><forename type="first">L</forename><forename type="middle">V</forename><surname>Jones</surname></persName>
		</editor>
		<meeting><address><addrLine>Wadsworth</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1961">1961</date>
			<biblScope unit="page" from="187" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Probabilistic pragmatics explains gradience and focality in natural language quantification</title>
		<author>
			<persName><forename type="first">B</forename><surname>Van Tiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Sauerland</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2005453118</idno>
		<ptr target="https://doi.org/10.1073/pnas.2005453118" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2021">2021. 2005453118</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Nominal, ordinal, interval, and ratio typologies are misleading</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Velleman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wilkinson</surname></persName>
		</author>
		<idno type="DOI">10.1080/00031305.1993.10475938</idno>
		<ptr target="https://doi.org/10.1080/00031305.1993.10475938" />
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="72" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24277-4</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-24277-4" />
		<title level="m">ggplot2: Elegant graphics for data analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A statistical examination of the relative precision of verbal scales</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Worcester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Burns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Market Research Society</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="197" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
