<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Running head: KAPPA EFFECTS EXPLAINED BY PERCEPTUAL GROUPING 1 Auditory Kappa Effects Can Be Explained by Perceptual Grouping Based on Feature Similarity</title>
				<funder ref="#_8bDmHs7">
					<orgName type="full">National Institutes of Health</orgName>
					<orgName type="abbreviated">NIH</orgName>
				</funder>
				<funder ref="#_6hjPDXM">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><roleName>Ph.D</roleName><forename type="first">Carolyn</forename><surname>Kroger</surname></persName>
							<email>ckroger@med.umich.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Otolaryngology -Head and Neck Surgery</orgName>
								<orgName type="department" key="dep2">Kresge Hearing Research Institute</orgName>
								<orgName type="department" key="dep3">Department of Otolaryngology -Head</orgName>
								<orgName type="institution" key="instit1">University of Michigan</orgName>
								<orgName type="institution" key="instit2">Neck Surgery University of Michigan</orgName>
								<address>
									<postCode>48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Otolaryngology -Head and Neck Surgery</orgName>
								<orgName type="department" key="dep2">Kresge Hearing Research Institute</orgName>
								<orgName type="department" key="dep3">Department of Otolaryngology -Head</orgName>
								<orgName type="institution" key="instit1">University of Michigan</orgName>
								<orgName type="institution" key="instit2">Neck Surgery University of Michigan</orgName>
								<address>
									<postCode>48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Deborah</forename><forename type="middle">R</forename><surname>Fu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Otolaryngology -Head and Neck Surgery</orgName>
								<orgName type="department" key="dep2">Kresge Hearing Research Institute</orgName>
								<orgName type="department" key="dep3">Department of Otolaryngology -Head</orgName>
								<orgName type="institution" key="instit1">University of Michigan</orgName>
								<orgName type="institution" key="instit2">Neck Surgery University of Michigan</orgName>
								<address>
									<postCode>48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Renee</forename><forename type="middle">M</forename><surname>Banakis Hartl</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Otolaryngology -Head and Neck Surgery</orgName>
								<orgName type="department" key="dep2">Kresge Hearing Research Institute</orgName>
								<orgName type="department" key="dep3">Department of Otolaryngology -Head</orgName>
								<orgName type="institution" key="instit1">University of Michigan</orgName>
								<orgName type="institution" key="instit2">Neck Surgery University of Michigan</orgName>
								<address>
									<postCode>48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Anahita</forename><forename type="middle">H</forename><surname>Mehta</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Otolaryngology -Head and Neck Surgery</orgName>
								<orgName type="department" key="dep2">Kresge Hearing Research Institute</orgName>
								<orgName type="department" key="dep3">Department of Otolaryngology -Head</orgName>
								<orgName type="institution" key="instit1">University of Michigan</orgName>
								<orgName type="institution" key="instit2">Neck Surgery University of Michigan</orgName>
								<address>
									<postCode>48109</postCode>
									<settlement>Ann Arbor</settlement>
									<region>MI</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Running head: KAPPA EFFECTS EXPLAINED BY PERCEPTUAL GROUPING 1 Auditory Kappa Effects Can Be Explained by Perceptual Grouping Based on Feature Similarity</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3DC7337BC05C02E0E94FEFF37B34DCA8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-22T20:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>kappa effect</term>
					<term>time perception</term>
					<term>perceptual interactions</term>
					<term>auditory grouping</term>
					<term>auditory motion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The auditory kappa effect exemplifies this, as larger pitch changes between sequential tones create an illusion of longer time intervals <ref type="bibr" target="#b9">(Cohen et al., 1954)</ref>. Traditionally studied with three-tone sequences ('A-X-B'), this effect shows that varying the middle tone's pitch relative to the first and third tones skews time interval perception. The prevailing auditory motion hypothesis (Henry &amp; McAuley, 2009)  proposes that a "pitch velocity" is inferred from a consistent pitch trajectory. We tested this against the auditory grouping hypothesis, which proposes that feature similarity affects perceived timing. Experiment 1 tested the kappa effect under varying pitch separations, revealing slower pitch velocities produced larger effects, contradicting the motion hypothesis. Experiment 2 examined inconsistent pitch trajectories to challenge the stability of pitch velocity referents, and still found kappa effects, further supporting the auditory grouping hypothesis. Experiment 3 investigated the kappa effect in auditory space, confirming that sounds presented closer in space are judged as occurring closer in time. These findings suggest that the kappa effect results from the grouping of auditory events by feature similarity, opposing the auditory motion hypothesis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Making sense of complex auditory environments requires the integration of various perceptual features such as pitch, spatial location, and onset timing into coherent objects and events <ref type="bibr" target="#b4">(Bizley &amp; Cohen, 2013)</ref>. Such theoretically dissociable acoustic cues produce reliable interactions in perception, as in the case of auditory kappa and tau effects, where greater pitch separation between successive tones leads to longer reported time intervals between them and longer time intervals between tones leads to greater reported pitch separation, respectively <ref type="bibr" target="#b9">(Cohen et al., 1954;</ref><ref type="bibr">Henry &amp; McAuley, 2009;</ref><ref type="bibr">Henry et al., 2009)</ref>. In classic kappa tasks, two intervals are defined by three discrete events (sometimes termed 'A-X-B') and participants compare the duration of the first and second interval, reporting which interval is relatively longer or shorter (between 'A-X' or between 'X-B'). Kappa effects have been shown for visual, auditory, and tactile stimuli, and represent a general temporal bias where events separated by greater distance (e.g., in physical space or other feature space) are judged to be separated by longer time intervals <ref type="bibr" target="#b8">(Cohen et al., 1953;</ref><ref type="bibr" target="#b9">Cohen et al., 1954;</ref><ref type="bibr" target="#b41">Suto, 1952)</ref>. The prevailing explanation for the kappa effect is an imputed velocity model, based on the theory of 'phenomenological motion' that links successive discrete events across space and time, creating the percept of unified motion <ref type="bibr" target="#b33">(Price-Williams, 1954)</ref>. The foundational kappa study in vision presented sequences of three flashes of light with varying distances between them, and participants reported longer durations between more spatially-distant flashes <ref type="bibr" target="#b8">(Cohen et al., 1953;</ref><ref type="bibr">Huang &amp; Jones, 1982)</ref>. Spatial manipulations were performed by keeping the distance between the first and third flash ('A' and 'B') constant and changing the location of the second ('X') flash to be closer to either to A or B. According to <ref type="bibr" target="#b22">Jones and Huang (1982)</ref>, participants impute uniform motion across sequences with an assumption of constant velocity, and thus judge the farther X distance (from A or B) as taking longer to traverse than the shorter one, leading to longer duration judgments for the greater distance.</p><p>The imputed velocity model was later translated from the visuospatial to auditory pitch domain based on an auditory motion hypothesis, which proposes that sequences of pitches have motion-like properties. This model was applied to the auditory kappa effect by computing a "pitch velocity" (change in pitch over time) for tone sequences <ref type="bibr">(Henry &amp; McAuley, 2009)</ref>. In these experiments, "pitch space" is an auditory analog to the visuospatial manipulations studied previously. <ref type="bibr">Henry and McAuley (2009)</ref> found that auditory kappa effects for tone sequences could be predicted by an imputed pitch velocity model that related the objective (t) and expected (E(t)) time intervals based on average pitch velocity between A and B, V = Δp/Δt, with a free weighting parameter, w. If this weighting parameter, w is equal to 1, perceived timing is based solely on the objective timing t, and no kappa effect is observed. If w = 0, perceived timing is based solely on the expected timing, where E(t) = Δp/V. Thus, the value of w represents the extent of response bias in temporal judgments based on imputed pitch velocity, V, and negatively correlates with the magnitude of the kappa effect. Their model equation is thus:</p><formula xml:id="formula_0">R = f [wt + (1 -w)E(t)] (1)</formula><p>Where R is a response probability (i.e., "shorter" vs "longer" time interval) as a function of the relative weighting of objective and expected event timing. In their study, <ref type="bibr">Henry and McAuley (2009)</ref> found support for the auditory motion hypothesis by demonstrating smaller w values in their model for higher-velocity sequences, indicating stronger kappa effects for faster-moving pitch which is proposed to induce stronger motion percepts. Other support comes from studies</p><p>showing that properties of perceptual motion apply to pitch sequences, such as the use of pitchtime trajectory to predict when and where a future melodic note will occur, as demonstrated by pitch-based "representational momentum" effects <ref type="bibr">(Johnston &amp; Jones, 2006)</ref>, and the presence of "inertia" in musical composition (for a review, see: <ref type="bibr" target="#b20">Hubbard, 2017)</ref>. There is also some linguistic evidence, such as the use in Western European languages of spatialized conceptual and linguistic metaphors including "rising" or "falling" to ascribe motion qualities such as direction of change in pitch over time (for a review, see: <ref type="bibr" target="#b10">Eitan, 2013)</ref>.</p><p>A notable shortcoming of this hypothesis, however, is the failure to adequately account for auditory kappa effects in non-pitch features such as spectral centroid and speech vowel quality that are not known to induce auditory motion percepts. <ref type="bibr">Marty et al. (2019)</ref> manipulated both the pitch and brightness (spectral centroid) of tones in an A-X-B kappa paradigm. They found kappa effects for sequences of tones changing only in brightness with fixed pitch (fundamental frequency). Further, they found that the magnitude of the brightness-only kappa effect was not significantly different from sequences with both features changing together (i.e., increasing in both pitch and brightness) and the pitch-only kappa effect was significantly smaller than the other two conditions. This study indicated that relative brightness was a stronger cue for kappa effects than pitch, contrary to predictions of the auditory motion hypothesis.</p><p>In another study, <ref type="bibr" target="#b37">Shigeno (1986)</ref> investigated kappa effects for A-X-B sequences of vowel sounds, where A and B were brief synthesized /i/ and /e/ sounds, and X took on a range of intermediate sounds that did not belong to either phonetic category. Importantly, each possible target X sound was manipulated to be more similar to either the /i/ or /e/ sound. Results showed an auditory kappa effect where participants reported the presentation of X to be closer in time to the vowel sound that was more similar based on the first three formant frequencies. These experiments call into question the auditory motion hypothesis as an explanation for auditory kappa effects, as spectral changes associated with timbral brightness or vowel quality are examples of cues for category boundaries rather than auditory motion.</p><p>An alternative explanation for the kappa effect which can account for the presence of this effect in experiments involving pitch features or category boundary cues is an auditory grouping hypothesis. This hypothesis proposes that two auditory stimuli more similar along a given feature dimension are perceptually grouped as part of an auditory object and thus judged as occurring closer in time than a third, more distinct stimulus. A well-known effect of changing the relative frequency and timing of sequential tones is "auditory streaming" whereby successive tones can be heard as belonging to one coherent stream or object, or to separate streams <ref type="bibr" target="#b7">(Bregman &amp; Campbell, 1971;</ref><ref type="bibr" target="#b30">Moore &amp; Gockel, 2002;</ref><ref type="bibr" target="#b45">van Noorden, 1975)</ref>. Sequential auditory stimuli are perceptually grouped as part of a stream based on acoustic feature similarity such as pitch, spectral shape or timbre, spatial location, or temporal proximity, where sounds that are more similar on a given dimension are more likely to belong to the same stream (for comprehensive reviews see: <ref type="bibr" target="#b4">Bizley &amp; Cohen, 2013;</ref><ref type="bibr" target="#b31">Moore &amp; Gockel, 2012;</ref><ref type="bibr" target="#b39">Snyder &amp; Alain, 2007)</ref>.</p><p>Additionally, the grouping of auditory stimuli into streams influences the perception of temporal relations among stream elements, with judgements of temporal gaps in stimuli across groups or streams being overestimated in duration relative to those within a group <ref type="bibr" target="#b12">(Fitzgibbons et al., 1974;</ref><ref type="bibr" target="#b27">Micheyl et al., 2010;</ref><ref type="bibr" target="#b44">Thorpe &amp; Trehub, 1989)</ref>.</p><p>Considering the stimuli traditionally used to examine the auditory kappa effect, where participants are required to make temporal judgments about sequential tones with varying features in both temporal and non-temporal domains, certain time intervals may be difficult to discriminate while other features (e.g. pitch) are more easily discriminable. When temporal grouping cues are ambiguous, as in the case of nearly-equivalent inter-onset intervals between events, the listener may perceive auditory stimuli that share other feature similarities as belonging to one stream and more dissimilar events as belonging to a separate stream. In previous studies on auditory kappa effects, stimuli that share more feature similarity were judged to be closer in time than those that were more distinct. Beyond frequency and spectral content, kappa effects have been demonstrated for variations in sound intensity (loudness) and sounds presented sequentially to the same or different ear <ref type="bibr" target="#b0">(Alards-Tomalin et al., 2013;</ref><ref type="bibr" target="#b3">Bausenhart &amp; Quinn, 2018)</ref>. These studies manipulated acoustic features that could serve as cues for auditory grouping/streaming, suggesting that a general perceptual mechanism, rather than a motion-based process underlies auditory kappa effects.</p><p>The present study proposes a series of experiments to test the auditory motion hypothesis against the auditory grouping hypothesis as a parsimonious explanation for auditory kappa effects, as well as extending the auditory kappa effect to sequences moving through auditory space. The first experiment revisits the pitch-velocity effects found by <ref type="bibr">Henry and McAuley (2009)</ref> by testing for differences in magnitude of auditory kappa effects across velocity conditions created by changing the overall pitch separation between tones while keeping the overall temporal separation constant. In their study, <ref type="bibr">Henry and McAuley (2009)</ref> manipulated pitch velocity by increasing or decreasing the inter-onset interval (IOI) between bounding tones (A and B), such that the total pitch separation between A and B was constant but sequence duration (IOIT) took on one of three values (728 ms, 1000 ms, or 1600 ms). For sequences with longer IOIs between bounding tones (IOIT), the pitch velocity was slower based on V = Δp/IOIT.</p><p>They interpreted larger kappa effects in faster pitch velocity conditions as evidence for stronger motion percepts according to the auditory motion hypothesis. However, this velocity effect cannot be disentangled from an overall temporal separation effect, as velocity and IOIT were perfectly correlated. We followed up on this experiment by comparing the magnitude of kappa effects across pitch velocity conditions created in the opposite manner, by holding IOIT constant across four different pitch separation conditions (Δp). The auditory motion hypothesis predicts that kappa effects will be stronger for sequences with greater pitch separation between A and B (faster pitch velocity) than sequences with smaller overall pitch separation. However, the auditory grouping hypothesis predicts stronger kappa effects for sequences with smaller pitch separations due to stronger grouping cues among tones that are closer in pitch.</p><p>In a second experiment, we directly tested the auditory motion hypothesis against the auditory grouping hypothesis by introducing a change in auditory motion direction in each sequence to prevent the formation of a stable velocity referent across sequences. Each A-X-B tone sequence took on one of the four possible pitch separation ("pitch velocity") conditions presented in Experiment 1, however, the pitch of target tone X was never between A and B. Thus, each sequence either had a downward-then-upward pitch motion trajectory, or an upward-thendownward trajectory. Because sequences within a given pitch velocity were presented in randomized order, the pitch trajectory per-trial was unpredictable, and uniform motion could not be imputed across the three tones. Thus, the auditory motion hypothesis predicts no kappa effect for these inconsistent pitch trajectory sequences. However, because the target X pitch was always closer to either A or B pitch, the auditory grouping hypothesis predicts a kappa effect based on pitch similarity, where the two tones that are closer in pitch are judged as closer in time due to grouping.</p><p>Finally, in a third experiment, we followed up on previous studies to test whether there is an auditory spatial kappa (ASK) effect. Although the original kappa effect in vision was based on spatial manipulations and the corresponding auditory effect in pitch-space has been described with a velocity-based model initially developed for the visual paradigm, to our knowledge this effect has not been reliably shown for 3-sound sequences moving through auditory space.</p><p>Previous studies that have tested temporal perception for auditory sequences with virtual changes in spatial location have found inconclusive or mixed results. One study by <ref type="bibr">Sarrazin et al. (2007)</ref> had participants reproduce the durations of seven inter-onset intervals separating eight sounds presented at equal-or variable-spatial distances. They simulated spatial separation between sounds by manipulating the presentation delay between two speakers placed two meters apart, where half of trials had constant virtual spatial distance between all tones and the other half had variable virtual distances. They found that participants produced more variable IOIs for sequences that simulated variable spacing compared to sequences that simulated equal spacing.</p><p>However, there was no distance-duration correlation, such that participants did not produce longer intervals for larger apparent distances, in other words, no kappa effect. <ref type="bibr" target="#b35">Roy et al. (2011)</ref> tested for ASK effects with single-interval stimuli, where two tones played from loudspeakers that were separated by 1.1 to 3.3 meters horizontally. They found that participants reported shorter inter-onset interval durations for sounds that were farther apart in space, the inverse of the kappa effect. These findings are surprising in light of the auditory motion hypothesis, which would predict strong kappa effects for sounds moving through auditory space.</p><p>However, a stronger test of ASK effects using real instead of simulated auditory space and a classic two-interval task is needed. Testing for an ASK effect, similar to previously observed visual and auditory pitch kappa effects, is important for understanding which auditory features give rise to kappa effects and whether they depend on spatial/motion percepts or featurebased grouping principles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1: Auditory Kappa Effect with Pitch-Based Velocity Manipulation</head><p>This experiment was carried out as a partial replication and extension of a previous study examining pitch-based auditory kappa effects across sequences with different pitch velocities <ref type="bibr">(Henry &amp; McAuley, 2009)</ref>. The present experiment compared the magnitude of observed kappa effects across tone sequences which varied in total pitch separation (with fixed temporal separation, IOIT) to create different pitch velocities. In contrast to the Henry and McAuley study, the total inter-onset interval (IOIT) between bounding tones ('A and B') was fixed across all conditions and pitch velocity was manipulated by varying the total pitch distance between tones A and B. Our velocity conditions included the fastest pitch velocity from <ref type="bibr">Henry and McAuley (2009)</ref> as well as one slower and two faster conditions. All timing conditions of the target ('X') tone and three out of five target pitch conditions were exactly matched to Experiment 2 of their study. If total pitch velocity, and not total duration, of a tone sequence drives differences in the magnitude of the kappa effect, then we expect to replicate previous pitch velocity effects where kappa effects are larger for faster (i.e., larger pitch separation) than slower velocity sequences, as predicted by the auditory motion hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. Twenty-four naïve participants were recruited from the University of Michigan (UM) and a community-wide health research recruitment database (<ref type="url" target="https://umhealthresearch.org">https://umhealthresearch.org</ref>). Seven participants were excluded from analysis due to accuracy below 80% in the easiest timing conditions, indicating a failure to complete the experiment task as instructed. The final sample included seventeen participants (n = 14 female, n = 3 male) between the ages of 19 and 37 years (M = 24.1, SD = 5.1 years). Thirteen participants reported having some formal music training, ranging from 2 to 16 years (M = 8.1, SD = 4.2 yrs).</p><p>All participants underwent an audiogram and had pure-tone thresholds below 25 dB at octave frequencies from 250 -8000 Hz. They were compensated at a rate of $15 per hour for their participation. This study was approved by the Institutional Review Board -Michigan Medicine at the University of Michigan and all participants provided informed consent prior to participation.</p><p>Design and Stimuli. Experiment 1 implemented a 4 X 5 X 8 within-subjects design. Four pitch velocities (6 ST/728 ms, 8 ST/728 ms, 14 ST/728 ms, 18 ST/728 ms) were crossed with five target pitch levels (-2, -1, 0, +1, +2 ST) and eight target timing levels (+/-4%, 8%, 12%, and 16%). Target tone pitch was set relative to the pitch midpoint (0 ST) between bounding tones and is represented as a signed ST deviation from this midpoint. Target tone timing was set relative to the theoretical bisection point (364 ms), which is half of the total inter-onset interval (IOIT/2) separating bounding tones and is represented as a signed percentage deviation from this bisection interval.</p><p>Stimuli were sequences of three 100 ms pure tones presented in increasing-frequency (pitch) order. Tones were presented in an 'A-X-B' paradigm, with a fixed temporal separation of 728 ms inter-onset interval (IOI) between bounding (A and B) tones. Within each block of trials, bounding tones had a fixed pitch separation of 6, 8, 14, or 18 semitones (ST). This produced the four pitch velocity conditions of 6 ST/728 ms, 8 ST/728 ms, 14 ST/728 ms, and 18 ST/728 ms  In all velocity conditions, the target tone ('X') varied in pitch and timing from trial-totrial in the same manner. Target tone pitch varied relative to the 0 ST (baseline) condition at the pitch midpoint between tones A and B (Figure <ref type="figure" target="#fig_0">1</ref> -left). This baseline condition corresponded to (a target pitch of) 3, 4, 7, or 9 ST between tones A and B for each of the 4 velocity conditions, respectively. All other target pitches were 1 or 2 semitones (ST) closer to the pitch of A or B, creating 5 target tone pitch conditions: -2, -1, 0, +1, +2 ST (from pitch midpoint). All bounding pitch and target pitch manipulations were selected to exclude same-note or octave-equivalent (i.e., 0 or 12 ST) relations among pitches in a sequence.</p><formula xml:id="formula_1">(</formula><p>Target tone onset timing was set relative to the sequence temporal bisection point (IOIT/2 = 364 ms) and took on one of eight values (+/-4, 8, 12, 16%), where negative values were early and positive values were late with respect to the bisection point (Figure <ref type="figure" target="#fig_0">1</ref> -Right panel). For example, the onset of a target tone presented at -12% timing was 43.68 ms early with respect to the bisection point (i.e., 320.32 ms after A). Early target timings created a pattern of "short-long" intervals and late timings created a "long-short" pattern. Target timings were selected based on previous studies on auditory kappa effects to include a range of IOIs that span sub-to suprathreshold temporal discrimination for psychometric analyses (described below). All target timing and target pitch conditions were fully crossed and presented in randomized order once per experimental run, with 8 runs of 40 trials presented for each pitch velocity condition. Thus, a total of 320 trials were presented for each pitch velocity block.</p><p>Equipment and Procedure. Participants listened to 'A-X-B' tone sequences over Sennheiser HD 650 headphones while sitting at a computer terminal in a sound-attenuating booth. Stimuli were delivered and responses recorded via a MATLAB program written using the AFC package <ref type="bibr" target="#b11">(Ewert, 2013)</ref>. Their task was to listen to each three-tone sequence, then respond whether the pattern of time intervals between tones was "long-short" or "short-long" by clicking a labeled button on the computer monitor. Participants were explicitly told to ignore the pitch of the tones and only respond based on the timing.</p><p>Before starting the experiment, participants were shown a short slide deck with task instructions and given the opportunity to ask clarification questions to the experimenter. They then completed a practice block with correct/incorrect feedback consisting of five trials (one per target pitch condition) at each of the four easiest (+/-12 and 16%) target timing conditions for a total of 20 practice trials. Participants repeated the practice as necessary until they scored 75% correct or higher. Participants who failed to meet this criterion after three or more attempts were not allowed to participate in the experiment. A PSE of 0 would indicate no systematic timing bias with equal 50% rate for "long-short" and "short-long" responses at the temporal bisection point. Following <ref type="bibr">Henry and McAuley (2009)</ref>, a relative Constant Error (CE) measure was calculated by subtracting PSE from the bisection IOI (half of the total sequence IOI). This measure is represented as a percentage deviation which can be compared across perceptual experiments with differing base IOIs <ref type="bibr" target="#b14">(Gescheider, 1985)</ref>. Positive relative CE corresponds to negative PSE (representing a bias to respond "long-short" more) and vice-versa. As a measure of discrimination threshold, we calculated just-noticeable difference (JND) as the semi-interquartile range, and percent correct responses were also calculated for each experimental condition.</p><p>Effects of target pitch and pitch velocity on CE and JND were analyzed using linear mixed effects models with the lmer4 package <ref type="bibr" target="#b2">(Bates et al., 2015)</ref> and p-values were obtained with the lmerTest package <ref type="bibr" target="#b24">(Kuznetsova et al., 2017)</ref> in the R environment (R Core Team, 2024).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>To test for kappa effects across pitch conditions in this experiment, a linear mixed-effects model was performed on the CE with target pitch (ST deviation from midpoint), pitch velocity, and their interaction as fixed effects and participant as a random effect. The effect of target pitch on CE was significant, where CE increased by 2.33% on average for every semitone (ST) shift in target pitch (95% CI [1.80, 2.86], p &lt;.001). Positive slopes indicate the presence of a kappa effect, where participants showed greater bias to respond "long-short" when the target pitch was closer to the pitch of tone B than tone A (Figure <ref type="figure" target="#fig_3">2</ref>). There was no effect of pitch velocity on CE, however there was a significant interaction between target pitch and pitch velocity (β = -0.</p><p>10, 95% CI [-0.14, -0.05], p &lt;.001), with the slope of target pitch and CE being largest for the slowest (6 ST/728 ms) pitch-velocity. Steeper slopes indicated a greater magnitude of kappa effect for slower compared to faster pitch velocities. Average CE across all velocity and target pitch conditions was 2.41%, and a one-sample t-test against 0 was significant (t(339) = 10.97, p &lt; .001, 95% CI [1.98, 2.84]), indicating a general response bias. A similar linear mixed-effects model on JND showed no effect of pitch but a significant effect of velocity on temporal discrimination threshold (β = 0.47, 95% CI [0.29, 0.66], p &lt;.001), with the largest JNDs observed for the fastest velocity condition (18 ST / 728 ms), and no interaction between target pitch and velocity. Thus, discrimination thresholds (JNDs) were not affected by target pitch deviations but were larger for faster pitch velocity conditions. JNDs ranged from 18.82 to 27.97 (M = 22.08) across all pitch and velocity conditions and were comparable to previous studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In Experiment 1, average CE overall was positive, indicating a general bias toward responding that sequences had a "long-short" timing pattern. Our results also replicated the pitch-based auditory kappa effect found in previous studies: participants showed greater bias to respond "long-short" when the target pitch level was higher compared to when it was 0 or lower.</p><p>Thus, when the pitch of the target tone was closer to the pitch of tone B than tone A, participants judged the target to be closer in time to B than A. However, in contrast to previous findings, our results showing an interaction between target pitch and velocity demonstrated a larger kappa effect for slower compared to faster velocities when pitch velocity was manipulated by changing only the pitch separation while keeping the time interval between A and B (IOIT) constant. This effect was in the opposite direction of previous results from the study by <ref type="bibr">Henry and McAuley (2009)</ref> who found larger kappa effects for faster velocities created by manipulating only IOIT.</p><p>Additionally, temporal discrimination thresholds (JNDs) were generally larger for faster velocities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2: Auditory Kappa Effect with Inconsistent Pitch Trajectories</head><p>Experiment 2 served as a test of the competing auditory motion and auditory grouping hypotheses by examining whether the auditory kappa effect is present for sequences with unpredictable auditory motion trajectories. In contrast to Experiment 1, 'A-X-B' tone sequences did not have pitches presented in increasing-frequency order. Instead, all sequences in Experiment 2 included a change in pitch motion direction, from downward-to-upward or from upward-to-downward, by manipulating the target tone pitch from trial-to-trial such that it was never between the pitch of tone A and tone B. Within a block, these inconsistent pitch motion trajectories were presented in randomized order. Sequences with unpredictable changes in pitch motion direction should prevent listeners from forming expectations of constant velocity previously proposed to give rise to auditory kappa effects. Thus, the auditory motion hypothesis predicts no kappa effect for sequences with sudden changes in pitch motion direction, due to a lack of reliable pitch/time trajectory predictions across sequences. However, the auditory grouping hypothesis predicts a kappa effect for these sequences due to participants perceptually grouping together the two tones that are more similar in pitch, and streaming out the third, more pitch-distant, tone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Participants. Twenty-nine naïve participants recruited from the University of Michigan community took part in the experiment. Twelve participants were excluded from analysis due to accuracy below 80% in the easiest timing conditions, indicating a failure to complete the experiment task as instructed. The final sample included seventeen participants (n = 9 female, n = 8 male) between the ages of 18 and 41 years (M =24.1, SD = 7.4 years). Fifteen participants reported having some formal music training, ranging from 2 to 11 years (M = 7.7, SD = 3.0 yrs).</p><p>Design and Stimuli. Experiment 2 implemented a 8 X 8 within-subjects design. Eight relative target pitch distances (+/-6, 8, 14, 18 ST) were presented across eight target timing levels (+/-4%, 8%, 12%, and 16%). The eight target pitch conditions included four target pitch conditions below the pitch of tone A (-ST) and four above tone B (+ ST). This created two types of pitch contours where half of target pitches introduced a change in pitch motion direction from decreasing-to-increasing frequency and the other half changed direction from increasing-todecreasing (Figure <ref type="figure" target="#fig_4">3</ref> -top left panel). Thus, when the pitch of X was below that of A (-ST), the pitch was relatively closer to A than B and vice-versa. Within each relative pitch distance condition, the pitch was roved by 1 ST. Bounding and target timing conditions were identical to those described in Experiment 1 (Figure <ref type="figure" target="#fig_0">1</ref> -right panel).</p><p>Just as Experiment 1, stimuli were three-tone sequences in an 'A-X-B' paradigm where tone A and tone B were separated by 728 ms and B was always 6, 8, 14, or 18 ST higher than A, as in Experiment 1. In Experiment 2, however, the three tones were not in increasing-frequency order. Target ('X') tone pitches were always lower than tone A or higher than tone B, thus, target pitch conditions introduced a change in the direction of pitch motion within each sequence.</p><p>Randomized changes in the direction of pitch motion should prevent the formation of expected constant pitch velocities. When the target pitch was lower than A (negative X pitch), it was relatively closer to A than B pitch and when the target pitch was higher than B (positive X pitch), it was relatively closer to B than A. Within a condition, A and B had fixed pitch separation (analogous to pitch velocity in Experiment 1) equal to the magnitude of target relative pitch. The relative target pitch distance is summarized as the difference in absolute values of pitch leap size (in ST) from A to X and from X to B (|AX| -|XB|). Thus, relative pitch difference of X is a signed measure characterized by magnitude and direction of pitch proximity to A compared to B.</p><p>For example, if the bounding tones were 6 ST apart, the target tone, X, was always either 6 ST closer to A than B (-X conditions) or 6 ST closer to B than A (+ X conditions). The proximity of pitch X to pitch A compared to pitch B was always such that the difference in pitch distance from A to X and from X to B was equal to the total pitch displacement between A and B. The sign of X indicates the direction of pitch change: a negative sign (-) signifies that pitch X moved below A, while a positive sign (+) signifies that pitch X moved above B. There were 2 possible pitch values for X in each pitch distance condition, for a total of 16 possible target pitches. All absolute pitch values for each condition are shown in Figure <ref type="figure" target="#fig_4">3</ref> (bottom left). Because tone A was fixed across pitch distance conditions, we roved the pitch of X by 1 ST such that target pitches were not identical across all conditions. In the +/-6 ST conditions, X was 1 to 2 ST below A or above B, in the +/-8 ST condition, X was 2 to 3 ST below A or above B, in the +/-14 ST conditions, X was 3 to 4 ST below A or above B, and in the +/-18 ST conditions, X was 4 to 5 ST below A or above B (Figure <ref type="figure" target="#fig_4">3</ref> -right). As in Experiment 1, pitch manipulations excluded same-note or octave-equivalent relations among pitches presented within a sequence. There were 4 blocks of trials corresponding to +/-6 ST, +/-8 ST, +/-14 ST, and +/-18 ST conditions with 10 runs of 32 trials in each block for a total of 320 trials per block. Each trial run had 1 presentation of each of the 4 possible target pitch and timing offset combinations presented in randomized order.</p><p>Equipment and Procedure. All equipment and procedures were identical to Experiment 1.</p><p>Data Analysis. All procedures for computing dependent variables were identical to Experiment 1. Effects of pitch distance on CE and JND were analyzed using linear mixed effects models using the same R packages as in Experiment 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Figure <ref type="figure" target="#fig_5">4</ref> shows average CE as a function of relative target pitch distance. Upon visual inspection, CE was more negative for more negative relative pitch distances and more positive for larger positive distances, indicating more "short-long" responses when the target pitch was closer to the pitch of tone A than B, and more "long-short" responses when the target pitch was closer to B than A. To test for kappa effects as a function of pitch proximity in sequences with inconsistent pitch trajectories, a linear mixed-effects model was performed on constant error (CE) with target relative pitch distance (ST) as a fixed effect and participant as a random effect.</p><p>The effect of target pitch on CE was significant, where CE increased by .22% for every 1 ST shift in target pitch closer to B than A (95% CI [0.18, 0.27], p &lt;.001). This significant slope indicates the presence of a kappa effect, where participants showed greater bias to respond "longshort" when the target pitch was closer to the pitch of tone B than tone A. Average CE across all velocity and target pitch conditions was .51%, and a one-sample t-test against 0 was not significant (t(271) = 1.50, p = .14, 95% CI <ref type="bibr">[-0.16, 1.19]</ref>). showed a kappa effect in all conditions where participants were biased to report "short-long" more when X pitch was closer to A (negative relative pitch) and "long-short" when X pitch was closer to B (positive relative pitch).</p><p>To consider the possibility that the total pitch motion across the three tones systematically biased timing judgments in this study, we computed the summed absolute value of pitch change across all 'A-X-B' sequences. The absolute change in pitch from A to X and from X to B represents the total pitch distance moved in each sequence, regardless of motion direction (whereas the distance from tone A to tone B is analogous to total pitch 'displacement'). We then performed a similar linear mixed effects analysis on CE with total pitch change and bounding pitch distance and their interaction as fixed effects and participant as a random effect. The total pitch distance across all 3 tones did not have a significant effect on CE (β = 0.1, 95% CI [-0.23, 0.43], p = .56) nor did bounding pitch distance (i.e., pitch displacement) (β = 0.54, 95% CI <ref type="bibr">[-0.29, 1.38]</ref>, p = .20), and the interaction was not significant (β = -0.02, 95% CI [-0.05, 0.01], p = .19). Thus, the total change in pitch over each sequence was not associated with a systematic bias in timing, whether considering the pitch change from A to X to B or the pitch displacement from A to B regardless of target pitch X. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The results of Experiment 2 showed a pitch-based auditory kappa effect for sequences of tones with unpredictable (i.e., randomized) changes in pitch motion direction per trial.</p><p>Participants responded that the timing pattern was "long-short" more when the target tone (X)</p><p>was relatively closer in pitch to tone B than tone A, and responded "short-long" more when X was relatively closer in pitch to tone A, despite all sequences having inconsistent pitch trajectories. There was no difference in the magnitude of kappa effect between A-B pitch conditions which were analogous to different pitch velocities from Experiment 1. Furthermore, there was no systematic timing bias (i.e., no kappa effect) based on the total pitch motion or pitch displacement of sequence conditions. Taken together, these results support the auditory grouping hypothesis over the auditory motion hypothesis as an underlying explanation of auditory kappa effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3: Auditory Spatial Kappa Effect</head><p>Experiment 3 tested how the locations of sequential sounds moving through auditory space in a free-field setting bias listeners' judgments of temporal onsets. This experiment tested for an auditory spatial kappa (ASK) effect by varying the spatial proximity of the target sound relative to the bounding sounds in an 'A-X-B' paradigm similar to Experiments 1 and 2. This experiment extends previous studies on visuospatial kappa effects to the auditory-spatial domain.</p><p>Previous studies on ASK effects have produced mixed results. One study using simulated or 'virtual' space failed to show kappa effects for 8-tone sequences <ref type="bibr">(Sarrazin et al., 2007)</ref>, and two studies using pure-tones played from loudspeakers at varying distances (i.e., in "real" space)</p><p>showed either the inverse of the kappa effect (i.e., shorter durations associated with longer distances) with 2-tone sequences <ref type="bibr" target="#b35">(Roy et al., 2011)</ref> or mixed results across conditions with 4tone sequences <ref type="bibr" target="#b15">(Grondin &amp; Plourde, 2007)</ref>. Because pure-tones are difficult to accurately localize, we tested for this effect using narrowband noise (NBN) bursts in three differing sound fields, each spanning 90º, within the front hemifield to examine how varying auditory spatial resolution as a function of sound source location moderated temporal judgment effects <ref type="bibr" target="#b16">(Hartmann, 1983;</ref><ref type="bibr" target="#b13">Fostick &amp; Fink, 2021;</ref><ref type="bibr" target="#b38">Shigeno &amp; Oyama, 1983;</ref><ref type="bibr" target="#b40">Stevens &amp; Newman, 1936)</ref>.</p><p>Furthermore, we tested two frequency bands to compare contributions of interaural level and timing cues for sound source location on the proposed ASK effect, as lower frequencies (below ~1500 Hz) have more reliable timing cues and higher frequencies (above ~3000 Hz) have more reliable level cues for localization (for a review see: <ref type="bibr" target="#b29">Middlebrooks &amp; Green, 1991)</ref>.</p><p>Participants. Twenty-eight naïve participants recruited from the University of Michigan community took part in the experiment. Six participants were excluded from analysis due to accuracy below 80% in the easiest timing conditions, indicating a failure to complete the experiment task as instructed. The final sample included 22 participants (n = 12 female, n = 9 male, n = 1 non-binary) between the ages of 20 and 57 years (M = 29.4, SD = 8.3 years). Twenty participants reported having some formal music training, ranging from 3 to 18 years (M = 7.6 , SD = 3.7 yrs).</p><p>Design and Stimuli. Experiment 3 implemented a 2 X 3 X 5 X 8 within-subjects design.</p><p>Two frequency bands (500 and 4000 Hz center) and three sound fields (left, front, and right 90º)</p><p>were crossed with five target locations (-30, -15, 0, +15, +30º azimuth) and eight target timing levels (+/-4, 8, 12, and 16%). Target timing levels were the same as previous experiments in terms of percent deviation from the temporal bisection point (Figure <ref type="figure" target="#fig_0">1</ref> -Right panel).</p><p>Sequences of three 200 ms narrowband noise (NBN) bursts were presented in an 'A-X-B' paradigm similar to Experiment 1 and 2. Bounding (A and B) sounds had fixed spatial and temporal separation of 90º azimuth and 1000 ms IOIT, respectively. The target (X) location was always between A and B, with five target location conditions that were spatial analogues to target pitch conditions from Experiment 1. Target sounds were presented at the spatial midpoint between bounding sounds as well as 15º and 30º closer in space to sound A or B. Target locations are represented relative to the spatial midpoint (0), where negative spatial deviations represent target sounds closer in space to A and positive deviations were closer to B. Each sound field spanned 90º between A and B, and the three sound fields covered the front half of the speaker array such that no sounds were ever presented behind the participant (Figure <ref type="figure" target="#fig_7">5</ref>). Sound field conditions were blocked, with the order of fields counterbalanced across participants according to a Latin-squares scheme. Thus, sounds within a block were always presented in a consistent direction, with sounds in the right and left fields starting directly in front of the participant (0º azimuth) and moving to the side, ending at 90º (right) or 270º (left), and in the front field always moved from left to right, starting at 315º and ending at 45º azimuth. NBN sounds had a bandwidth of one-octave and either 500 ('low') or 4000 Hz ('high') center frequency.</p><p>The eight target timing and five target location conditions were fully crossed and presented in randomized order once per run, with 8 runs of 40 trials for each sound field for a total of 320 trials per block. There was a short mandatory break (1+ min) between each block before moving on to the next sound field condition. Participants completed all 960 trials in the high or low frequency condition in one session, then returned 1 to 49 days later (M = 11, SD = 15) to complete the other frequency condition, with the order of frequencies counterbalanced across participants.</p><p>Equipment. This experiment took place in a hemi-anechoic chamber equipped with a 24channel 360-degree surround loudspeaker system under the control of a dedicated PC using a custom MATLAB program. Sounds were presented over Orb Audio loudspeakers through an Antelope Orion 32+ D/A multi-channel converter and Crown CT8150 amplifier for audio rendering and output. Loudspeakers were positioned every 15º in the azimuthal plane (Figure <ref type="figure" target="#fig_7">5</ref>) and 44 inches vertically, corresponding to roughly ear-height when seated. Responses were collected via a wireless Bluetooth numeric keypad with printed labels on two buttons displaying "short-long" and "long-short" response options. Procedure. Participants listened 'A-X-B' NBN burst sequences while seated in the center of the 360º speaker array and facing a fixation '+' positioned at 0º azimuth. As in experiments 1 and 2, they heard each sequence and responded whether the pattern of time intervals between tones was 'long-short' or 'short-long' by clicking a labeled button on the handheld keypad. Participants were explicitly told to ignore the spatial location of the sounds and only respond based on the timing. Prior to starting the experiment, participants completed practice trials with feedback following the same procedure as Experiment 1 and 2. Participants then completed three blocks of 320 experimental trials, one for each sound field condition, for a total of 960 trials per session, and each session lasted around 2.5 hours in total. All other aspects of the practice and testing procedure for this task were identical to previous experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Figure <ref type="figure" target="#fig_8">6</ref> shows average CE as a function of target location for all sound fields in low (left panel) and high frequency band (right panel) conditions. Upon visual inspection, CE was lower for negative location deviations and higher for positive locations, indicating relatively more "short-long" timing responses when the target sound was closer in space to sound A, and more "long-short" responses when the target sound was closer to B. To test for kappa effects as a function of spatial location in each sound field and frequency in this experiment, a linear mixedeffects model was performed on constant error (CE) with target location (degree deviation from midpoint), sound field, frequency, and their two-way and three-way interactions as fixed effects and participant as a random effect. The effect of target location on CE was significant, where CE changed by .20% for every one-degree shift in target location in the azimuthal plane (95% CI [0.14, 0.26], p &lt;.001). Significant slopes indicated the presence of a kappa effect, where participants showed greater bias to respond "long-short" when the target sound location was closer to sound B. The effect of sound field on CE was also significant. Average CE for the right quarter-field was on average 2.1% higher than the front quarter-field (95% CI [0.36, 3.78], p = .02), and average CE for the left quarter-field was on average 1.9% higher than the front quarterfield (95% CI [0.20, 3.62], p = .03). There were no effects of frequency or significant two-way or three-way interactions (all p &gt; .063). Average CE across all locations, sound fields and frequencies was 4.73%, and a one-sample t-test against 0 was significant (t(659) = 13.94, p &lt; .001, 95% <ref type="bibr">CI [4.06,</ref><ref type="bibr">5.40]</ref>), indicating a general response bias.</p><p>To investigate temporal discrimination thresholds across conditions in this experiment, a similar linear mixed-effects regression model was performed on JND scores as in previous experiments. This analysis showed no significant effects or interactions (all p &gt; .061). Thus, we did not find an effect of target location, sound field condition, or frequency band on discrimination thresholds in this experiment. Average JNDs ranged from 21.72 to 34.47 (M = 27.05) across all conditions, comparable to previous experiments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Results of Experiment 3 provided strong evidence for an auditory spatial kappa (ASK) effect using NBN sequences moving through space (with consistent center frequencies). In general, participants showed a relative bias to respond "short-long" more when the target location was closer to A , and a bias to respond "long-short" more when the target X spatial location was closer to B than A. Similar to Experiment 1, average CE overall was positive, indicating a general bias toward responding that sequences had a "long-short" timing pattern in this experiment. A significant effect of sound field was also found, where point estimates for CE were higher for the right and left quarter-fields compared to the front, indicating that this general "long-short" response bias was greater for sounds moving from directly in front of participants to the right or left side compared to sounds moving within the front quarter field (from left to right) crossing the sagittal midline. No significant effects of frequency were found, such that ASK effects were present for NBN sounds in lower and higher frequency bands (centered around 500 and 4000 Hz, respectively). In sum, these results support the generalizability of kappa effects from visual space and pitch space to auditory space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>The primary goals of the present study were to test the prevailing auditory motion hypothesis against an auditory grouping hypothesis as a parsimonious alternative explanation for auditory kappa effects and to test for a reliable auditory spatial kappa (ASK) effect with sounds moving through space. Three experiments were conducted in which three sequential sounds (A-X-B) changed in pitch or spatial location and participants reported the relative durations of the first (A-X) and second (X-B) inter-onset interval (IOI) by responding that the timing pattern was "short-long" or "long-short." Experiment 1 tested the prediction of the auditory motion hypothesis that tone sequences with faster pitch velocity cause larger-magnitude kappa effects than slower velocities for differing velocity conditions created by manipulating the overall pitch separation (rather than overall temporal separation) among tones. Experiment 2 tested the prediction of the auditory grouping hypothesis that kappa effects would be observed for tone sequences with inconsistent pitch trajectories, regardless of non-uniform pitch motion.</p><p>Experiment 3 tested for ASK effects using sequences of three narrowband noise (NBN) bursts moving through auditory space in three sound field and two frequency band conditions.</p><p>Experiment 1 replicated and extended previous findings on pitch-based kappa effects with one key difference in the pattern of our results. Kappa effects were larger for sequences with slower velocities when pitch velocity was manipulated by changing the overall pitch separation of tones. The interaction between target pitch level and velocity condition demonstrated that CE slopes were steeper for slower velocity conditions compared to faster velocity conditions, contradicting previous studies showing the reverse pattern of results when manipulating pitch velocity by changing the overall temporal separation between tones <ref type="bibr">(Henry &amp; McAuley, 2009)</ref>. These results contradict the predictions of the auditory motion hypothesis, supporting instead the auditory grouping hypothesis as the pitches of sequential tones in slower velocity conditions (i.e., 6 ST/ 728 ms) were closer together, supporting grouping of tones more than in faster velocity conditions (i.e., 18 ST/ 728 ms) which had tones that were more likely to be perceptually segregated into independent streams <ref type="bibr" target="#b30">(Moore &amp; Gockel, 2002;</ref><ref type="bibr" target="#b46">Vliegen et al., 1999)</ref>. For example, when target tone X was shifted 2 semitones (ST) closer to A relative to the pitch midpoint in the slowest velocity condition, the pitch separation between AX was 1 ST, and between XB was 5 ST, supporting grouping of A and X into one stream and segregation of B into a separate stream. However, the analogous pitch shift (-2 ST) in the fastest velocity condition resulted in a pitch separation between AX of 7 ST and between XB of 11 ST. Thus, relative pitch proximity of the target tone provided a weaker grouping cue in the faster compared to the slower pitch velocity conditions. While results of this experiment may appear to contradict the findings of <ref type="bibr">Henry and McAuley (2009)</ref> that faster velocity sequences elicit stronger kappa effects, auditory streaming models have demonstrated that both greater pitch separation and smaller temporal separation among tones more reliably induces stream segregation <ref type="bibr" target="#b6">(Bregman, 1990;</ref><ref type="bibr" target="#b45">van Noorden, 1975)</ref>. Thus, the overall reduction of IOIs between all tones in their faster velocity sequences would predict a stronger segregation of the more distinct pitch, resulting in a greater duration overestimation for gaps across streams.</p><p>The results of Experiment 2 provided further support for the auditory grouping hypothesis by showing an auditory kappa effect based on relative pitch proximity for sequences of tones with inconsistent pitch trajectories. As in previous studies of pitch-based kappa effects, participants were biased to report that the two A-X-B tones closer in pitch were closer in time.</p><p>However, in our experiment, each sequence had non-uniform motion such that there was a change in direction of pitch change from downward-to-upward or from upward-to-downward that was randomized across trials to prevent the formation of a stable velocity referent. Thus, this kappa effect cannot be explained by violations of target pitch expectations based on imputing average constant pitch velocity across sequences. When we considered only the overall distance of pitch motion across all three tones (absolute value of pitch change from A to X to B) or the pitch displacement from A to B (regardless of X), no systematic difference in timing bias was observed as a function of pitch velocity, where V = Δp/Δt.</p><p>Finally, the results of Experiment 3 showed robust kappa effects for A-X-B sounds presented from different speaker locations, confirming the generalizability of visuospatial kappa effects to the auditory spatial domain. When tested previously with tone sequences, results</p><p>showed mixed support for ASK effects with some studies showing null results <ref type="bibr">(Sarrazin et al., 2007)</ref> or an inverse kappa effect <ref type="bibr" target="#b35">(Roy et al., 2011)</ref>, and only one study showing mixed evidence with a kappa effect present for a subset of duration conditions <ref type="bibr" target="#b15">(Grondin &amp; Plourde, 2007)</ref>. Our results demonstrated an ASK effect for NBN sequences moving through auditory space, where participants were biased to report that the target 'X' sound was closer in time to the bounding 'A'</p><p>or 'B' sound that was closer in space. This supports our hypothesis that previous studies failing to show this effect were due to insufficient cues for spatial location with pure-tone stimuli, which may have prevented space-based temporal biases <ref type="bibr">(Fostnick &amp; Fink, 2021;</ref><ref type="bibr" target="#b38">Shigeno &amp; Oyama, 1983;</ref><ref type="bibr" target="#b40">Stevens &amp; Newman, 1936)</ref>. Our results showing an ASK effect for NBN sounds presented in both low (500 Hz) and high (4000 Hz) frequency bands indicates that this is a general effect of spatial location, regardless of dominant interaural level or interaural timing cues. Interestingly, the magnitude of ASK effect was equivalent across sound field conditions, although localization performance tends to be better for sounds presented in front of the listener than directly to the side <ref type="bibr" target="#b29">(Middlebrooks &amp; Green, 1991;</ref><ref type="bibr" target="#b40">Stevens &amp; Newman, 1936)</ref>. One possibility is that our smallest spatial separation between sequential sounds of 15º was large enough to be readily discriminated (i.e., suprathreshold) regardless of sound field condition.</p><p>When considered with previous studies on auditory kappa effects, results of the present experiments support the streaming-based auditory grouping hypothesis over the auditory motion hypothesis as an explanation for these effects. Our findings are in line with a long-standing literature on auditory streaming paradigms that have demonstrated perceptual grouping based on features including pitch, spatial location, spectral content, intensity, and temporal structure <ref type="bibr" target="#b4">(Bizley &amp; Cohen, 2013;</ref><ref type="bibr" target="#b28">Micheyl et al., 2013;</ref><ref type="bibr" target="#b31">Moore &amp; Gockel, 2012;</ref><ref type="bibr" target="#b46">Vliegen et al., 1999)</ref>. In general, auditory features that serve as cues for grouping or segregating stimuli into objects or streams also bias time perception among sequential events. This applies not only to kappa effects, but also to previously-established temporal ordering effects where listeners fail to judge the order of rapid events across streams although able to accurately judge sequential order within a stream <ref type="bibr" target="#b1">(Barsz, 1991;</ref><ref type="bibr" target="#b7">Bregman &amp; Campbell, 1971;</ref><ref type="bibr" target="#b27">Micheyl &amp; Oxenham, 2010)</ref>. More broadly, feature binding that contributes to object perception and scene analysis is well-established based on heuristics and Gestalt principles of figure-ground organization across sensory domains. This may form a common neurological and cognitive basis for feature-based perceptual time illusions (i.e., dilation or contraction) in the presence of temporal ambiguities.</p><p>The current study has broad implications for models of stream segregation and our understanding of how different stimulus features influence time perception. Several models of stream segregation are based on temporal coherence, suggesting that cross-feature temporal alignment facilitates grouping of sound sources <ref type="bibr" target="#b25">(Krishnan et al., 2014;</ref><ref type="bibr" target="#b32">Lu et al., 2024;</ref><ref type="bibr" target="#b36">Shamma et al., 2011;</ref><ref type="bibr">Szabo et al., 2016;</ref><ref type="bibr" target="#b43">Teki et al., 2013)</ref>. However, these models must also consider bidirectional interactions, including how non-temporal features affect temporal judgments. The confluence of evidence for kappa across various stimulus attributes and tasks suggests these time-perception phenomena are influenced by perceptual context effects. Future research should test current models' ability to account for dynamically-changing contextual features to improve time perception models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 -</head><label>1</label><figDesc>Left panel). Tone A pitch was always fixed at a C4 (261.63 Hz) and tone B pitches corresponding to each velocity condition were: F#4, (369.99 Hz), G#4 (415.30 Hz),D5 (587.33   Hz), and F#5 (739.99). This range of pitch velocities was chosen to match the velocity showing the strongest kappa effect (8 ST/728 ms) in the previous study byHenry &amp; McAuley (2009)  and extended slightly slower (6 ST/728 ms) and faster (14 ST/728 ms &amp; 18 ST/728 ms). Trials were blocked within a pitch velocity, and the order of pitch velocity condition was counterbalanced across participants using a Latin-square design.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure1. Experiment 1 stimulus schematics. Left: Five possible target ('X') pitch conditions. Bounding sounds 'A' and 'B' were fixed in pitch and temporal separation per block. The pitch of X (open circles) varied between 0 (pitch midpoint) and 2 semitones (ST) higher and lower from trial-to-trial. Four pitch velocity conditions (calculated as pitch distance in semitones over time) were created by changing the pitch separation between A and B while keeping the time interval between them (IOIT) constant. Dashed line represents the expected pitch trajectory according to the imputed pitch velocity model(Henry &amp; McAuley, 2009). Right: Eight possible target timing conditions for all three experiments. The target tone was presented early (-) or late (+) with respect to the temporal bisection point (IOIT/2) by 4, 8, 12 or 16 %. Early targets created "shortlong" IOI patterns, and late targets created "long-short" patterns.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Following</head><figDesc>practice trials, participants completed four blocks of 320 experimental trials, one for each pitch velocity condition, for a total of 1280 trials. Each of the four blocks were separated by a mandatory break. After all experimental trials, participants completed a short survey about demographics, music training, and any strategies used to perform the experiment task. The entire experimental session lasted around 2 hours in total. Data Analysis. Proportions of "long-short" responses were computed for each experimental condition for each participant, and psychometric functions were fit to individual data. Point of Subjective Equality (PSE) was calculated for each pitch level at each velocity by computing the value of x when y = .5 (corresponding to 50% long-short responses), then PSEs were averaged across participants. The PSE represents the theoretical time interval where the target sound should be presented (relative to the temporal midpoint between bounding sounds) to produce two perceptually-equivalent inter-onset intervals (IOIs). Negative PSE values correspond to a leftward shift in the psychometric function and represent a bias to respond "longshort," and positive PSE values correspond to a rightward shift and bias to respond "short-long."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2</head><label>2</label><figDesc>Figure 2 Experiment 1 results showing mean relative CE with standard error bars as a function of target pitch deviation in the four pitch velocity conditions. Kappa effects were larger (steeper slopes) for slower (e.g., 6 ST) compared to faster (e.g., 18 ST) velocity conditions.</figDesc><graphic coords="16,126.00,72.00,360.00,360.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Experiment 2 stimulus schematics. Top Left: Inconsistent pitch trajectories formed by altering the pitch of X such that it was never between A and B. The A-B pitch conditions were identical to the pitch velocities from Experiment 1. Bottom Left: Table of all tone frequencies (in Hz) with musical pitch names in parentheses. Rows display all possible pitch values for a given A-B pitch condition. Tone A was always 261.63 Hz, and tone B was 6, 8, 14, or 18 semitones (ST) higher than tone A. The pitch of target tone X varied across conditions and was 6, 8, 14, or 18 semitones (ST) closer to A than B (-), or vice-versa (+). X1 and X2 are roved values of target pitches closer to A (corresponding to dashed circles in other panels), X3 and X4 are roved pitches closer to B. Right: Graphical representation of all possible pitch conditions. The relative pitch distance of X (|AX| -|XB|) was always equal to A-B pitch distance, where negative pitch distances (dashed circles) represent X pitch closer to A and positive distances (solid circles) represent X pitch closer to B. The X pitch was roved between two values per condition.</figDesc><graphic coords="20,375.60,72.10,164.40,403.10" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Experiment 2 results showing mean relative CE with standard error bars as a function of relative target pitch distance. Negative relative pitch difference values represent targets ('X') closer in pitch to A than B, and positive values were closer in pitch to B than A. The absolute value of relative target pitch distance was equal to A-B pitch distance (colored lines). Resultsshowed a kappa effect in all conditions where participants were biased to report "short-long" more when X pitch was closer to A (negative relative pitch) and "long-short" when X pitch was closer to B (positive relative pitch).</figDesc><graphic coords="23,126.00,72.00,360.00,360.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Finally</head><figDesc>, a linear mixed-effects model on JND showed a significant effect of relative pitch distance (|AX| -|XB|) on temporal discrimination threshold (β = 0.19, 95% CI [0.11, 0.27], p &lt;.001), where discrimination thresholds increased as pitch distance grew more positive. Average JNDs ranged from 17.21 to 25.98 (M = 20.88) for this experiment, in line with previous experiments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Schematic showing an overhead view of participant seated in center of 360º azimuth speaker array with 3 sound fields labeled. All fields spanned 90º (i.e., a "quarter-field") between sounds 'A and B', with sound sequences moving from 315º to 45º in front, from 0º to 270º on the left, 0º to 90º on the right. Example of A-X-B locations for the front field are displayed with five possible target X locations shown in open circles.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Experiment 3: Mean relative CE with standard error bars as a function of target location deviation in the three sound field conditions with low frequency (left panel) and high frequency (right panel) NBN sounds. Results showed ASK effects (significant positive slopes) in all location and frequency conditions.</figDesc><graphic coords="30,306.00,199.07,216.00,215.97" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">Dr. Nori Jacoby</rs> and <rs type="person">Ilhan Onder</rs> for helpful discussions at the start of this research, research assistants <rs type="person">Zhiqing Yin</rs> and <rs type="person">Deshaun Omane</rs> for their help with programming and data collection for Experiments 1 and 2, and <rs type="person">Dr. Ruth Litovsky</rs> for valuable comments and feedback during the planning and conceptualization of Experiment 3. This project was supported by grants <rs type="funder">NIH</rs> <rs type="grantNumber">T32DC00011</rs> and <rs type="grantNumber">F32DC022162</rs> (CK).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8bDmHs7">
					<idno type="grant-number">T32DC00011</idno>
				</org>
				<org type="funding" xml:id="_6hjPDXM">
					<idno type="grant-number">F32DC022162</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Examining auditory kappa effects through manipulating intensity differences between sequential tones</title>
		<author>
			<persName><forename type="first">D</forename><surname>Alards-Tomalin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Leboe-Mcgowan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">A</forename><surname>Mondor</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00426-012-0438-8</idno>
		<ptr target="https://doi.org/10.1007/s00426-012-0438-8" />
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="480" to="491" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Auditory pattern perception: The effect of tone location on the discrimination of tonal sequences</title>
		<author>
			<persName><forename type="first">K</forename><surname>Barsz</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03206752</idno>
		<ptr target="https://doi.org/10.3758/BF03206752" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="290" to="296" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Package &apos;lme4</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maechler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H B</forename><surname>Christensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Singmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Convergence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the interplay of visuospatial and audiotemporal dominance: Evidence from a multimodal kappa effect</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Bausenhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Quinn</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-017-1437-z</idno>
		<ptr target="https://doi.org/10.3758/s13414-017-1437-z" />
	</analytic>
	<monogr>
		<title level="j">Attention, Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="535" to="552" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The what, where and how of auditory-object perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Bizley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">E</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn3565</idno>
		<ptr target="https://doi.org/10.1038/nrn3565" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="693" to="707" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The processing of temporal and nontemporal information in the remembering of event durations and musical structure</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Boltz</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.24.4.1087</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.24.4.1087" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1087" to="1104" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Auditory grouping based on fundamental frequency and formant peak frequency</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Bregman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Levitan</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0084255</idno>
		<ptr target="https://doi.org/10.1037/h0084255" />
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Psychology/Revue Canadienne de Psychologie</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="413" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Primary auditory stream segregation and perception of order in rapid sequences of tones</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Bregman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Campbell</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0031163</idno>
		<ptr target="https://doi.org/10.1037/h0031163" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="244" to="249" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A new phenomenon in time judgment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E M</forename><surname>Hansel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Sylvester</surname></persName>
		</author>
		<idno type="DOI">10.1038/172901a0</idno>
		<ptr target="https://doi.org/10.1038/172901a0" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">4385</biblScope>
			<biblScope unit="page" from="901" to="901" />
			<date type="published" when="1953">1953</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Interdependence of temporal and auditory judgments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E M</forename><surname>Hansel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Sylvester</surname></persName>
		</author>
		<idno type="DOI">10.1038/174642a0</idno>
		<ptr target="https://doi.org/10.1038/174642a0" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="issue">4431</biblScope>
			<biblScope unit="page" from="642" to="644" />
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">How pitch and loudness shape musical space and motion</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Eitan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The psychology of music in multimedia</title>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Tan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Cohen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Cohen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Lipscomb</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Kendall</surname></persName>
		</editor>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="165" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">AFC -A modular framework for running psychoacoustic experiments and computational perception models</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Ewert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Acoustics AIA-DAGA 2013</title>
		<meeting>the International Conference on Acoustics AIA-DAGA 2013<address><addrLine>Merano, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>German Acoustical Society (DEGA</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1326" to="1329" />
		</imprint>
	</monogr>
	<note>German Acoustical Society (DEGA)</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Detection of temporal gaps within and between perceptual tonal groups</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Fitzgibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pollatsek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">B</forename><surname>Thomas</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03198581</idno>
		<ptr target="https://doi.org/10.3758/BF03198581" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="522" to="528" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Situational awareness: The effect of stimulus type and hearing protection on sound localization</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fostick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Fink</surname></persName>
		</author>
		<idno type="DOI">10.3390/s21217044</idno>
		<idno type="PMID">34770351</idno>
		<idno type="PMCID">PMC8587889</idno>
		<ptr target="https://doi.org/10.3390/s21217044" />
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page">7044</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Psychophysics: Method, theory, and application</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gescheider</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985">1985</date>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<pubPlace>Hillsdale, NJ</pubPlace>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Judging multi-minute intervals retrospectively</title>
		<author>
			<persName><forename type="first">S</forename><surname>Grondin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Plourde</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470210600988976</idno>
		<ptr target="https://doi.org/10.1080/17470210600988976" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1303" to="1312" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Localization of sound in rooms</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Hartmann</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.390163</idno>
		<ptr target="https://doi.org/10.1121/1.390163" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1380" to="1391" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Evaluation of an imputed pitch velocity model of the auditory kappa effect</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mcauley</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.35.2.551</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.35.2.551" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">551</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evaluation of an imputed pitch velocity model of the auditory tau effect</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mcauley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaleha</surname></persName>
		</author>
		<idno type="DOI">10.3758/APP.71.6.1399</idno>
		<ptr target="https://doi.org/10.3758/APP.71.6.1399" />
	</analytic>
	<monogr>
		<title level="j">Attention, Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="1399" to="1413" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On the interdependence of temporal and spatial judgments</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03204862</idno>
		<ptr target="https://doi.org/10.3758/BF03204862" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="7" to="14" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Momentum in music: Musical succession as physical motion</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Hubbard</surname></persName>
		</author>
		<idno type="DOI">10.1037/pmu0000171</idno>
		<ptr target="https://doi.org/10.1037/pmu0000171" />
	</analytic>
	<monogr>
		<title level="j">Psychomusicology: Music, Mind, and Brain</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="14" to="30" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Higher order pattern structure influences auditory representational momentum</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-1523.32.1</idno>
		<ptr target="https://doi.org/10.1037/0096-1523.32.1" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="17" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Space-time dependencies in psychophysical judgment of extent and duration: Algebraic models of tau and kappa effects</title>
		<author>
			<persName><forename type="first">B</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.91.1.128</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.91.1.128" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="128" to="142" />
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Effects of auditory pattern structure on anticipatory and reactive attending</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Puente</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cogpsych.2006.01.003</idno>
		<ptr target="https://doi.org/10.1016/j.cogpsych.2006.01.003" />
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="96" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">lmerTest package: tests in linear mixed effects models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H B</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">13</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Segregating complex sound sources through temporal coherence</title>
		<author>
			<persName><forename type="first">L</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elhilali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shamma</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1003985</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1003985" />
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">1003985</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Relative contribution of pitch and brightness to the auditory kappa effect</title>
		<author>
			<persName><forename type="first">N</forename><surname>Marty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Marty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pfeuty</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00426-019-01233-y</idno>
		<ptr target="https://doi.org/10.1007/s00426-019-01233-y" />
	</analytic>
	<monogr>
		<title level="j">Psychological Research</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="55" to="67" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Auditory stream segregation and the perception of across-frequency synchrony</title>
		<author>
			<persName><forename type="first">C</forename><surname>Micheyl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Oxenham</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0017601</idno>
		<ptr target="https://doi.org/10.1037/a0017601" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1029" to="1039" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Auditory frequency and intensity discrimination explained using a cortical population rate code</title>
		<author>
			<persName><forename type="first">C</forename><surname>Micheyl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Schrater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Oxenham</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1003336</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1003336" />
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1003336</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Sound localization by human listeners</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Middlebrooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Green</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev.ps.42.020191.001031</idno>
		<ptr target="https://doi.org/10.1146/annurev.ps.42.020191.001031" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Psychology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="135" to="159" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Factors influencing sequential stream segregation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gockel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Acustica United with Acustica</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="320" to="333" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Properties of auditory stream formation</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Gockel</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2011.0355</idno>
		<ptr target="https://doi.org/10.1098/rstb.2011.0355" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="page" from="919" to="931" />
			<date type="published" when="1591">2012. 1591</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Temporal-coherence induces binding of responses to sound sequences in ferret auditory cortex</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elhilali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shamma</surname></persName>
		</author>
		<idno type="DOI">10.1101/2024.05.21.595170</idno>
		<ptr target="https://doi.org/10.1101/2024.05.21.595170" />
	</analytic>
	<monogr>
		<title level="j">bioRxiv</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The kappa effect</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Price-Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="issue">4399</biblScope>
			<biblScope unit="page" from="363" to="364" />
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">R: A language and environment for statistical computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
		<ptr target="&lt;https://www.R-project.org/" />
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Effect of space on auditory temporal processing with a single-stimulus method</title>
		<author>
			<persName><forename type="first">M</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kuroda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grondin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in sound localization</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Strumillo</surname></persName>
		</editor>
		<imprint>
			<publisher>BoD-Books on Demand</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Temporal coherence and attention in auditory scene analysis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elhilali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Micheyl</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tins.2010.11.002</idno>
		<ptr target="https://doi.org/10.1016/j.tins.2010.11.002" />
	</analytic>
	<monogr>
		<title level="j">Trends in Neurosciences</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="114" to="123" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The auditory tau and kappa effects for speech and nonspeech stimuli</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shigeno</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03207588</idno>
		<ptr target="https://doi.org/10.3758/BF03207588" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="9" to="19" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Localization of speech and non-speech sounds</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shigeno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Oyama</surname></persName>
		</author>
		<idno type="DOI">10.4992/psycholres1954.25.112</idno>
		<ptr target="https://doi.org/10.4992/psycholres1954.25.112" />
	</analytic>
	<monogr>
		<title level="j">Japanese Psychological Research</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="112" to="117" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Toward a neurophysiological theory of auditory stream segregation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Alain</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-2909.133.5.780</idno>
		<ptr target="https://doi.org/10.1037/0033-2909.133.5.780" />
	</analytic>
	<monogr>
		<title level="j">Psychological Bulletin</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">780</biblScope>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The localization of actual sources of sound</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Newman</surname></persName>
		</author>
		<idno type="DOI">10.2307/1415748</idno>
		<ptr target="https://doi.org/10.2307/1415748" />
	</analytic>
	<monogr>
		<title level="j">The American Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="297" to="306" />
			<date type="published" when="1936">1936</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The effect of space on time estimation (S-effect) in tactual space</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Suto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Japanese Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="189" to="200" />
			<date type="published" when="1952">1952</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Computational models of auditory scene analysis: A review</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Szabó</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Denham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Winkler</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2016.00524</idno>
		<ptr target="https://doi.org/10.3389/fnins.2016.00524" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">524</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Segregation of complex acoustic scenes based on temporal coherence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Teki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Griffiths</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.00699</idno>
		<ptr target="https://doi.org/10.7554/eLife.00699" />
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">699</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Duration illusion and auditory grouping in infancy</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Thorpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Trehub</surname></persName>
		</author>
		<idno type="DOI">10.1037/0012-1649.25.1.122</idno>
		<ptr target="https://doi.org/10.1037/0012-1649.25.1.122" />
	</analytic>
	<monogr>
		<title level="j">Developmental Psychology</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">122</biblScope>
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Temporal coherence in the perception of tone sequences</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P A S</forename><surname>Van Noorden</surname></persName>
		</author>
		<idno type="DOI">10.6100/IR152538</idno>
		<ptr target="https://doi.org/10.6100/IR152538" />
		<imprint>
			<date type="published" when="1975">1975</date>
			<pubPlace>Eindhoven</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Institute for Perception Research ; Technical Univ</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The role of spectral and periodicity cues in auditory stream segregation, measured using a temporal discrimination task</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vliegen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Oxenham</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.427140</idno>
		<ptr target="https://doi.org/10.1121/1.427140" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="938" to="945" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
