<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Repairing misperceptions of words early in a sentence is more effortful than repairing later words, especially for listeners with cochlear implants</title>
				<funder ref="#_9APXRJS #_YBZsKPe">
					<orgName type="full">NIH-NIDCD</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Matthew</forename><forename type="middle">B</forename><surname>Winn</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Speech-Language-Hearing Sciences</orgName>
								<orgName type="institution">University of Minnesota</orgName>
								<address>
									<settlement>Minneapolis</settlement>
									<region>MN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Shevlin Hall</orgName>
								<address>
									<addrLine>164 Pillsbury Dr SE</addrLine>
									<postCode>55455</postCode>
									<settlement>Minneapolis</settlement>
									<region>MN</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Repairing misperceptions of words early in a sentence is more effortful than repairing later words, especially for listeners with cochlear implants</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3108EAFDD273886D21D5D89AF6EF54F1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cochlear implants</term>
					<term>listening effort</term>
					<term>pupillometry</term>
					<term>speech perception</term>
					<term>perceptual restoration</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The process of repairing misperceptions has been identified as a contributor to effortful listening in people who use cochlear implants (CIs). The current study was designed to examine the relative cost of repairing misperceptions at earlier or later parts of a sentence that contained contextual information that could be used to infer words both predictively or retroactively. Misperceptions were enforced at specific times by replacing single words with noise. Changes in pupil dilation were analyzed to track differences in the timing and duration of effort, comparing listeners with typical hearing or with CIs. Increases in pupil dilation were time-locked to the moment of the missing word, with longer-lasting increases when the missing word was earlier in the sentence. CI listeners showed elevated pupil dilation for longer periods of time after listening, suggesting lingering effects of effort compared to listeners with TH. When needing to mentally repair missing words, CI listeners also made more mistakes on words elsewhere in the sentence, even though these words were not masked. Stimulus-related effects were not evident in basic measures like peak pupil dilation, and only emerged when the full-time course was analyzed, suggesting the timing analysis adds new information to our understanding of listening effort. Taken together, these results demonstrate that some mistakes are more costly than others and incur different levels of mental effort to resolve the mistake, underscoring the information lost when characterizing speech perception with simple measures like percentcorrect scores.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>There is a growing appreciation for listening effort in clinical hearing science <ref type="bibr" target="#b24">(Pichora-Fuller et al., 2016;</ref><ref type="bibr" target="#b48">Zekveld et al., 2018)</ref>, complemented by studies aimed at understanding the mechanisms of what aspects of speech communication are effortful for listeners who are hardof-hearing. Repetition accuracy is the most common outcome measure of speech perception abilities, but a percent correct score fails to capture how the listener arrived at their answerparticularly the cost of recovering from a perceptual mistake in the process of inferring the correct answer.</p><p>In virtually any study of speech recognition, misperceptions are uncontrolled and emerge unpredictably at any moment during listening. Two listeners who both show 75% correct repetition accuracy could be making different mistakes, and it would not be possible to explain their different listening experiences without understanding the difference between those mistake patterns. There are various types of misperceptions a listener can make during perception (phonetic mistakes, segmentation errors, syntactic errors, semantic substitutions, etc.), and these different types of misperceptions incur different amounts of listening effort <ref type="bibr" target="#b44">(Winn &amp; Teece, 2021)</ref>. However, when using commonly used testing materials, it can be difficult to prospectively control when misperceptions occur during an experiment, relegating comparison of these mistakes to retrospective analyses. <ref type="bibr" target="#b44">Winn and Teece (2021)</ref> used such a retrospective design to reveal that mistakes on earlier words in a sentence are more costly than making mistakes on later words, and the observed effort was linked specifically to semantic processing, rather than the degree of acoustic-phonetic matching of the stimulus and response. These observations underscore the notion that listening effort cannot be captured by a mere tally of repeated correct and incorrect words or degree of phonetic match to the original stimulus. Incidentally, that study also introduced a testing method to prospectively induce misperceptions at a specific time during a sentence to estimate the effort of mentally repairing misperceived words. However, that design only included mistakes early in a sentence, toward the goal of specifically examining retroactive use of context. The present study extends that study design by controlling the time of misperceptions and the contextual information listeners have available to resolve the ensuing ambiguity, toward the goal of discerning the impact of misperceptions earlier or later in a sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupillometry as a Measure of Listening Effort</head><p>While there are multiple methodological tools that can be used to quantify listening effort, such as changes in reaction time or subjective report, the current research question demands the ability to measure moment-by-moment changes in effort as language processing unfolds in real time, because the core question is about earlier and later moments of processing within the same sentence. Pupillometry is a tool that can measure changes in pupil dilation before, during, and after language processing <ref type="bibr" target="#b8">(Engelhardt et al., 2010;</ref><ref type="bibr" target="#b40">Winn, 2023)</ref>, and can reflect degrees of ambiguity and post-sensory processing of the input <ref type="bibr" target="#b27">(Satterthwaite et al., 2007)</ref>. Changes in pupil dilation have a long history of being correlated with changes in cognitive demand across a variety of tasks <ref type="bibr" target="#b17">(Kahneman &amp; Beatty, 1966;</ref><ref type="bibr" target="#b29">Sirois &amp; Brisson, 2014)</ref>, with pupil dilation generally increasing when more effort is exerted <ref type="bibr" target="#b32">(van der Wel &amp; van Steenbergen, 2018)</ref>, so long as there is sufficient motivation to complete the task. As opposed to the slowly-varying changes in tonic pupil size that are thought to reflect alertness <ref type="bibr" target="#b19">(McGinley et al., 2015)</ref>, short phasic changes in pupil size are the key physiological signature of momentary listening effort used in previous studies <ref type="bibr" target="#b3">(Beatty, 1982;</ref><ref type="bibr" target="#b11">Gabay et al., 2011;</ref><ref type="bibr" target="#b48">Zekveld et al., 2018)</ref> and are what will be examined in the present study.</p><p>The key advantage of analyzing phasic pupil dilations is the ability to quantify precisely when effort occurs and how long effort lasts, rather than just how much. Although it is customary to report summarized response of peak pupil dilation and peak latency to quantify the amount of effort in a given task <ref type="bibr" target="#b0">(Ayasse et al., 2021;</ref><ref type="bibr" target="#b38">Wendt et al., 2018;</ref><ref type="bibr" target="#b49">Zekveld et al., 2010)</ref>, there is additional information that can be gained by observing the full-time course of changes in pupil dilation by designing experiments with this specific goal in mind <ref type="bibr" target="#b16">(Johns et al., 2024;</ref><ref type="bibr" target="#b30">Steinhauer et al., 2022;</ref><ref type="bibr" target="#b40">Winn, 2023)</ref> . Sustained increases in pupil dilation following the peak could reflect the listener having to reconcile remaining linguistic ambiguity after the initiation of that effort.</p><p>Quantifying the precise timing of when effort occurs during listening, and the duration for how long this increase in effort lasts, can offer new insight into the relative cost of mistakes at different times during a sentence, as well as the ways that contextual cues and hearing status might interact with that cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence Context</head><p>Sentence context will play an important role in the current study for two reasons. First, people who are deaf or hard-of-hearing have been shown to rely more heavily on contextual cues, which can be shown in both accuracy scores <ref type="bibr" target="#b14">(Hunter, 2021;</ref><ref type="bibr" target="#b22">O'Neill et al., 2021;</ref><ref type="bibr" target="#b23">Patro &amp; Mendel, 2016;</ref><ref type="bibr" target="#b25">Pichora-Fuller et al., 1995;</ref><ref type="bibr" target="#b36">Vickery et al., 2022)</ref> and listening effort <ref type="bibr" target="#b15">(Hunter &amp; Humes, 2022;</ref><ref type="bibr" target="#b39">Winn, 2016)</ref>. This is especially true for CI listeners <ref type="bibr" target="#b2">(Başkent et al., 2016;</ref><ref type="bibr" target="#b7">Dingemanse &amp; Goedegebure, 2022;</ref><ref type="bibr" target="#b39">Winn, 2016)</ref>, likely because they hear an auditory signal that is highly degraded, requiring more compensation from non-auditory cognitive processes.</p><p>The second reason is that the ability to repair misperceptions likely depends on the availability of remaining contextual cues within the utterance (or across utterances) to resolve linguistic ambiguity.</p><p>In ideal situations, listeners can use context to rapidly predict upcoming words as the speech signal unfolds in real time <ref type="bibr" target="#b10">(Federmeier, 2007)</ref>. However, some evidence suggests that CI listeners are less likely to use context quickly <ref type="bibr" target="#b39">(Winn, 2016;</ref><ref type="bibr" target="#b43">Winn &amp; Moore, 2018)</ref>, perhaps as a result of refraining from full commitment to lexical decisions until they can be more certain in what they heard <ref type="bibr" target="#b9">(Farris-Trimble et al., 2014;</ref><ref type="bibr" target="#b20">McMurray et al., 2017)</ref>. CI listeners may rely more heavily on using context retroactively, which has been shown to be an effortful process <ref type="bibr" target="#b45">(Winn &amp; Teece, 2022)</ref>. It is tempting to speculate on the comparisons between CI listeners using context in a way that is typically framed as predictive (e.g. Winn 2016; <ref type="bibr" target="#b15">(Hunter &amp; Humes, 2022)</ref> versus using context framed as retroactive <ref type="bibr" target="#b45">(Winn &amp; Teece 2022)</ref>. However, studies focusing on these uses of context have used different methods in terms of stimulus design and outcome measures that prevent fair comparison. For example, while the study by <ref type="bibr" target="#b45">Winn and Teece (2022)</ref> verified that listeners used context to mentally repair misperceptions early in a sentence, previous work on predictive context mainly inferred the use of context through accuracy scores for sentencefinal words, without being able to confirm if any earlier misperception took place. Therefore, it remains unclear whether the use of context to repair words at different time points during a sentence elicits a different amount or duration of effort.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Present Study</head><p>Combining the previous described impact of sentence context on listening effort, the present study aims to evaluate how listeners use context in different parts of the sentence to resolve linguistic ambiguity and the effect this has on listening effort. By designing stimuli where the same sentence could have a word missing either earlier or later in the same sentence, we can directly compare how different types of sentence context impacts the timing of changes in pupil dilation, the impact on the duration of the pupil response, and the potential differences in effort between CI and older and younger TH listeners. The approach of distorting or removing a portion of the signal was introduced by <ref type="bibr" target="#b37">Warren (1970)</ref> as perceptual restoration, and later extended by <ref type="bibr" target="#b44">Winn and Teece (2021)</ref> to address situations where the listener does not feel a sense of actually having heard the word, but instead needs to actively infer it based on later information.</p><p>The present study has three main hypotheses: 1) the timing of pupil dilation resulting from missing words will be related to the position of those words within the sentence, as opposed to being a general increase in dilation; 2) Sentences with earlier-masked words will have a larger increase and duration of pupil size compared to sentences with late-masked words, because for words early in a sentence, listeners cannot take advantage of preceding contextual information to help resolve any linguistic ambiguity; they must hold that ambiguous word in memory while they wait to accumulate more information; 3) Consistent with previous studies, CI listeners will show prolonged pupil dilation because they could be less likely to take advantage of sentence context as it unfolds in real time; 4) Responses that demand repair but which are not repaired successfully will produce prolonged pupil responses as a result of the listener's persistent effort to resolve ambiguity in the sentence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>All participants in this study were native speakers of North American English and reported no history of language or learning disabilities. Two groups of listeners were recruited.</p><p>For the CI group a total of 20 listeners participated in this study (14 female, 6 male) with an average age of 65.3 years old (sd = 11.3 years old, range = 34-77 years old). All CI listeners were able to converse freely during face-to-face communication, and none reported cognitive difficulties. To account for the effect of age, 20 older and 21 younger TH listeners were also recruited (32 female, 9 male, mean = 47.4 years old, sd = 23.7 years, range = 20-84 years old).</p><p>Listener ages are shown in Figure <ref type="figure" target="#fig_0">1</ref>. Normal hearing status was confirmed by pure-tone audiometry screening via air-conduction at 25 dB HL from 250-4000 Hz. Participants were not evaluated for visual acuity. All gave informed written consent of procedures that were approved by the Institutional Review Board at the University of Minnesota, which stands on Miní Sóta Makhóčhe the homelands of the Dakhóta Oyáte.</p><p>CI listeners all had at least 1 year of experience with their device (median experience 7 years). There was a median of 30 years duration of deafness until first implantation among the CI group, which included 5 unilaterally and 11 bilaterally implanted individuals, along with 4 bimodal listeners. Those listeners who regularly used a hearing aid in the contralateral ear to manage moderate to profound hearing loss continued using the hearing aid during the experiment to best simulate their everyday listening experience. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[[ Figure 1: Age Distributions ]]</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimulus variations</head><p>Stimuli included 108 sentences written and recorded by our lab. Each sentence was designed so that there were at least three semantically related key words, such that when the earliest or latest of these words were masked by noise, it could be inferred from the remaining related words that were intact. Importantly, this enabled the same sentence to be used as a stimulus in either the early-or late-missing word variations, which is crucial in order to address the research question. The "Fully Intact" version was the fully spoken sentence with no alterations. The other two versions were designed to force the listener to engage in the mental repair process to disambiguate the missing word. In the "Early Repair" condition an early target word was replaced with noise, and in the "Late Repair" condition the final word was replaced with noise. The stimulus types are illustrated in Figure <ref type="figure">2</ref>. The noise used to replace the words was matched in duration and intensity to the target word, and the frequency spectrum matched the long-term spectrum of the entire stimulus corpus.</p><p>The contextual constraint on the words was verified using an online cloze probability test <ref type="bibr" target="#b18">(Kutas &amp; Hillyard, 1984)</ref>, where a separate group of 30 online participants were shown text versions of the sentences with missing words and had to type what they thought the missing word was. These responses were then analyzed to determine if a particular sentence had either high or low cloze probability, with high probability considered to be situations in which at least 67% agreement in responses to any individual item <ref type="bibr" target="#b5">(Block &amp; Baldwin, 2010)</ref>. Both missing-word variations of a given sentence had to have a high cloze probability in order to be included in the final stimulus list. Using this criterion, 108 of the original set of 119 candidate sentences had high cloze probability and were included as stimuli for the experiment. The sentences were divided into three lists of 28 and one list of 24 sentences, with sentences having an average of 9 words and an average duration of 2.98 seconds. It was important the sentences be highly intelligible to minimize mistakes on other words in the sentence. Sentences were recorded by a person who was sex assigned female at birth from Wisconsin, with an emphasis on a clear speaking style and effort to minimize regional dialects of particular vowels (e.g. /ae/-/eɪ/ variation in "bag").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[[ Figure 2: Stimuli schematic here ]]</head><p>Figure <ref type="figure">2</ref>: Three different stimulus types, all variations of an example sentence "We built sandcastles on the beach". Replacing either "sand" or "beach" with speech-shaped noise would create the early-masked or late-masked conditions, respectively. (color online).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Each participant completed a sentence-repetition task with a total of 108 stimuli, which resulted in 36 trials for sentences that were in the intact, backward, and forward condition, respectively. Each stimulus list began with an intact sentence, followed by a pseudo-random ordering of sentence type, with no more than three consecutive trials of the same sentence type. Presentation lists were rotated and counterbalanced across listeners, and the sentence type (fully intact, early word masked, late word masked) for each item was rotated for each listener, except the first trial in each list, which was always intact.</p><p>During the experiment, listeners sat in a chair with their forehead position stabilized by the upper bar of a chinrest whose base was sufficiently lowered to allow comfortable jaw movement for speaking. They visually fixated on a red cross in the middle of a medium-dark gray background on a computer screen that was 50 cm away. Each trial was initiated by the experimenter, and the participant heard a beep marking the onset of the trial. There was 2 seconds of silence and then the sentence was played at 65 dBA through a single loudspeaker in front of the listener. Two seconds after the offset of the sentence, the red cross turned green, which was the cue for the listener to give their verbal response. They were instructed to repeat what they thought was spoken, filling in missing words when necessary. The participants' verbal responses were scored on paper, with incorrect responses documented for further analysis of error patterns. The participant's eye position and pupil size were recorded by an SR Research Eyelink 1000 Plus eye tracker recording at 1000 Hz sampling rate, tracking pupil diameter in the remote-tracking mode, using the desktop-mounted 25mm camera lens. Lighting in the testing room was kept constant. A schematic of an example trial is shown in Figure <ref type="figure">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis Intelligibility</head><p>Repetition accuracy was scored in real time by the experimenter and participant responses were manually entered into a data-tracking spreadsheet after the experiment visit for further analysis. For trials where a target word was replaced with noise, any response that was not semantically coherent with the stimulus was counted as an error, as well as any errors elsewhere in the sentence. If the participant's guess at the word replaced by noise was not the "intact" version of the word but still made sense (e.g. "Please clean the floor with this broom", instead of "please sweep the floor with this broom"), it was counted as correct. In the case of intact sentences, the target word was defined as the word that would have been masked by noise in the alternate version of the stimulus, to facilitate fair comparison across stimulus types.</p><p>We also tracked whether participant responses were linguistically coherent, and the presence of multiple errors within trials. An example of an incoherent response would be "The plant hit the soccer ball with the door" (see Winn &amp; Teece 2021 for further discussion of incoherent responses). The goal of evaluating repetition accuracy in this way was to track whether participant responses had any errors, rather than only focusing on the number of errors within the response. This approach was taken specifically because the words in high-context sentences are not independent; multiple errors within a sentence would not be a conclusive sign that multiple words were misperceived. For example, misperception of a word might result from the listener trying to create coherence with an earlier word that was misperceived, and participants tend to produce these secondary errors when trying to resolve linguistic ambiguity.</p><p>Winn and Teece (2021) and <ref type="bibr" target="#b12">Gianakas et al. (2022)</ref> provided evidence of this effect in both forward-and backward direction within the sentence, and suggestion that a secondary error tends to reduce effort because it promotes coherence.</p><p>To evaluate the differences in overall intelligibility between listener groups, errors were estimated on a per-trial level using a binomial (i.e., logistic) mixed-effects model that included fixed effects and interactions between stimulus type and condition, as well as random intercepts and correlated random effects of condition per listener. Estimated marginal means were calculated from this model to statistically compare the difference in intelligibility scores across hearing groups and express them in plain terms. The following model formula was used in the prevailing model:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>glmer( AnyError ~ Condition + Hearing + Condition*Hearing + (1 + Condition | Listener) )</head><p>Although tracking any error in the participants' verbal responses already reveals the impact of stimulus type and listener group, there is additional information to be gained from analyzing the different types of errors that were made by CI listeners and how those errors may be related to mental repair. Sentence repetition scores were analyzed in more depth for the CI group using a series of GLMMs that estimated various outcome measures, including, 1) the presence of any error within the response, and 2) errors on words other than the target word. These models were restricted only to CI listeners because TH listeners did not make many errors, resulting in implausibly high or low beta estimates due to model estimates including values at or close to zero. The model for estimating the presence of an error on words other than the target had the same structure as the model for any errors. Other types of errors, such as target word errors and incoherent responses, were also counted, however these errors were not frequent enough to be statistically evaluated. The model formula was declared as follows: For the two models described above, when a specific comparison was not available in the original model because both sides of the comparison were deviations from the default (and therefore not directly compared to each other), comparisons were obtained by rotating the same model with the default reassigned, rather than running a post-hoc model limited to the specific comparison of interest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupillometry Data Preprocessing</head><p>Pupil data were processed as described by <ref type="bibr" target="#b43">Winn et al. (2018)</ref> and <ref type="bibr" target="#b45">Winn and Teece (2022)</ref>. Blinks were detected as a decrease in pupil size to 0 pixels, with the stretch of time corresponding to the blink expanding backward by 80ms and forward by 120ms to account for the partial occlusion of the pupil by the eyelids during blinks. The signal was low-pass filtered at 5 Hz using a 4 th -order Butterworth filter and then down-sampled to 25 Hz. The baseline pupil size was calculated as the mean pupil size in the time spanning 500ms before stimulus onset to 500ms after sentence onset. Each pupil size data point in the trial was expressed as the proportional difference from the trial-level baseline.</p><p>Trials were discarded if 30% or more data points were missing between the start of the baseline to three seconds past the onset of the stimulus. CI listeners on average had fewer trials discarded due to missing data (14.2%) and less variation among individuals (s.d. of 10.4%) compared to TH listeners (average of 22.1% trials discarded with s.d. of 14.8%). Other outliers and contaminations were automatically detected through an algorithm that accumulated multiple "flags", such as high-intensity low-frequency fluctuations (hippus) activity during baseline, baselines that had extraordinary deviation from both the previous and the next baseline, significant slope of change in pupil size during the baseline, or a significant negative swing in proportional dilation immediately after the stimulus onset. Three or more flags resulted in a trial being dropped. If a participant had fewer than 12 trials remaining in any condition following outlier detection, that participant's entire dataset was dropped. One listener was excluded from analysis for this reason, leaving 61 total listeners to be included for analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupillometry Data Analysis: Generalized Additive Mixed-effects Modeling (GAMMs)</head><p>Our goal is to quantify differences in the timing and duration of listening effort when listeners have to mentally repair a missing word. To achieve this goal, filtered data that were summarized for each individual in each stimulus condition were estimated using generalized additive mixed-effects models (GAMMs; <ref type="bibr" target="#b34">van Rij et al., 2019)</ref>. One of the distinct advantages of using GAMMs is the ability to identify stretches of time where there is a meaningful difference between curves, and this can be done during the entire time-course of the pupil response during listening and linguistic processing. GAMMs model the data using a combination of Gaussian basis functions that are summed in weighted combination to match the shape of non-linear data (e.g the pupil response) allowing for statistical analysis of the entire pupil response function without the need for different analysis windows. The number of basis functions to calculate each smooth function can be specified for each predictor variable and each interaction term, as well as the specified random effects. Another advantage of GAMMs is accounting for the autocorrelation of time-series data <ref type="bibr" target="#b1">(Baayen et al., 2016)</ref>, or the tendency for the data point at time t to be similar to its preceding data point at time t-1, which is problematic because it increases the probability of Type I errors. GAMMs have previously been used to model pupillometry data in studies of listening effort <ref type="bibr" target="#b6">(Boswijk et al., 2020;</ref><ref type="bibr" target="#b26">Porretta &amp; Tucker, 2019;</ref><ref type="bibr" target="#b41">Winn, 2024)</ref>. The details of the GAMMs model presented here are below, and we refer to van Rij et al (2019) for a more thorough overview of using GAMMs to analyze pupillometry data.</p><p>All the models and statistical analyses were executed in R (R Core Team, 2021) and R Studio (RStudio Team, 2020). GAMMs were implemented using the R package "mgcv" version 1.8-42 (S. Wood, 2023; S. N. <ref type="bibr" target="#b47">Wood, 2017)</ref>  # inputs for computational efficiency method = "fREML", discrete = TRUE, family = "scat", # account for autocorrelation of each timepoint in the data <ref type="bibr">AR.start = start_event,</ref><ref type="bibr">rho = 0.986,</ref><ref type="bibr">data = df)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intelligibility</head><p>Intelligibility scores (percentage of sentences that were repeated with all words correct) were high for all sentence types for both listener groups, with performance at 85.5% for CI listeners and 96.5% for listeners with TH. These high intelligibility scores indicate that performance did not decrease into the range where motivation and effort to complete the task would render the pupil data difficult to interpret <ref type="bibr" target="#b38">(Wendt et al., 2018)</ref>. CI listeners made a statistically greater number of errors on sentences that demanded mental repair, as shown by the estimated marginal means and confidence intervals for this analysis in Figure <ref type="figure">4</ref>. There was no statistical difference in the error rates for sentences that involved early versus late repair for CI listeners. When separated by sentence type, CI listeners had intelligibility scores of 79.2% when an early word was masked, 84% when a late word was masked, and 93.3% when the sentence was fully intact. Listeners with TH showed near ceiling levels of performance, with 95.9%, 95.6%, and 97.9% for each sentence type, respectively, with no statistical difference between performance for the three stimulus types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[[ Figure 4: Any Error Marginal Means ]]</head><p>Figure <ref type="figure">4</ref>: Model estimates of the prevalence of making an error on any word in the sentence, represented as model-inherent log-odds (top x-axis) and converted to percentage (bottom xaxis) for ease of reading. The marginal means estimates for each of the different sentence types are shown with the shaded ribbons indicating the estimated 95% confidence interval (color online).</p><p>There was a clear ordering effect of sentence type, with CI listeners making the most errors when an earlier word was missing compared to a late missing word (β = 0.36, z = 2.32, p = 0.02), and fewer errors overall when the sentence was fully intact (β = -1.00, z = -4.71, p &lt; 0.001). The estimated marginal means shows that there was no overlap in the 95% confidence bands across the listener groups for any stimulus type, suggesting a significant increase in errors for the CI group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Different kinds of Errors for CI Listeners</head><p>Figure <ref type="figure" target="#fig_5">5</ref> shows the percentage of errors by CI listeners for each specific error types, along with a panel showing data for the previous tally of any error. The number of true target errors (not correctly repairing the masked word, or in the case of intact sentences, making an error on the word that would have been masked) was small enough that no statistics were conducted. A raw count of target-word errors for CI listeners revealed more errors for sentences with early (n = 45) or late (n = 26) missing words compared to those same words when the sentence was fully intact (n = 10).</p><p>The third panel of Figure <ref type="figure" target="#fig_5">5</ref> illustrates how mentally repairing a missing word affected perception elsewhere in the sentence. Compared to when the sentences were fully intact, there were more errors on non-target words when CI listeners had to repair earlier (β = 1.02, z = 4.27, p &lt; 0.001) or later (β = 0.69, z = 2.86; p = 0.004) missing words. Although CI listeners made more errors elsewhere in the sentence when forced to repair an early missing word (n = 112) versus a late missing word (n = 86), this difference did not reach the conventional criterion for statistical significance (z = 1.715; p = 0.086).</p><p>No statistical comparisons were made for incoherent response, although they occurred more often when repairing early (n = 30) or late (n = 20) missing words compared to when the sentence was intact (n = 7).  The stimuli with missing early words elicited greater pupil dilation in multiple time windows. First, TH listeners showed larger increases compared to intact sentences between -1.53 to 4 s relative to sentence offset, and a similar time window was observed for CI listeners (between -1.22 to 4 s relative to sentence offset). Second, sentences with early missing words also elicited greater pupil dilation than sentences with later missing words. Both hearing groups showed a similar duration of increased pupil dilation during listening (TH: -1.68 -0.58 s relative to sentence offset; CI: -1.45 -0.65 s relative to sentence offset); however, CI listeners showed a longer duration of increased pupil dilation after listening (1.33 -4 s relative to sentence offset) compared to TH listeners where no difference was observed. The stimuli with late missing words also elicited larger increases in pupil dilation compared to intact sentences, but the effect emerged later in time, both for TH listeners (between 0.43 to 4 s relative to sentence offset), and for CI listeners (between 0.58 to 4 s relative to sentence offset). The pupil response to the fully intact sentences was larger than sentences with a late-masked word for a brief window from -0.85 to 0.05 s for TH listeners, and -1.15 to 0.13 s for CI listeners. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Differences between TH and CI groups</head><p>Whereas both groups demonstrated increased pupil size in response to stimuli that demanded mental repair, the degree of this increase was different across groups. The difference of pupil dilation between repair conditions and intact conditions was compared across groups using a GAMM that included interaction terms between stimulus type and hearing group.</p><p>Figure <ref type="figure" target="#fig_8">7</ref> shows the modeled differences of pupil responses within groups for each stimulus comparison (left panels; significant stretches already described above), and the comparison of these difference curves between hearing groups (right panels). The increase in pupil dilation resulting from repair of an early masked word in the sentence was greater and longer lasting for the CI listener group, specifically during the stretch of time spanning 0.73 to 4 s relative to sentence offset (top panel Figure <ref type="figure" target="#fig_8">7B</ref>). CI listeners also showed a relatively larger effect of latemasked words compared to the TH group during two small time windows from 0.80 to 1.25 s and 2.61 to 3.66 s relative to sentence offset (bottom panel Figure <ref type="figure" target="#fig_8">7B</ref>). No differences were observed for responses to early-versus late-masked words between hearing groups (middle panel Figure <ref type="figure" target="#fig_8">7B</ref>).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of repetition accuracy on pupil responses</head><p>Incorrect responses tend to result in a larger or more sustained increase in pupil dilation <ref type="bibr" target="#b42">(Winn et al., 2015;</ref><ref type="bibr" target="#b50">Zhang et al., 2021)</ref>, and the difference in performance scores across stimulus types invites analysis of intelligibility effects on the current data from CI listeners (there were not enough incorrect trials for TH listeners to analyze). Pupil responses for the CI listener group for correct and incorrect trials for each sentence type are shown in Figure <ref type="figure">8</ref>. The elevation in pupil size observed when sentences demand repair is sustained for a longer amount of time when the repair was not fully successful (i.e. when there was still a mistake in the response), compared to when the word was correctly inferred. For sentences with an earlymasked words, incorrect responses led to increased pupil dilation from 0.99 to 4 seconds relative to sentence offset, which was a longer duration than the corresponding effect for errors in sentences with later-masked words (1.33 to 4 seconds relative to sentence offset). This result is consistent with generally larger effects of early mistakes in semantically coherent sentences <ref type="bibr" target="#b12">(Gianakas et al., 2022;</ref><ref type="bibr" target="#b44">Winn &amp; Teece, 2021)</ref>. For sentences that were presented fully intact, the pattern of sustained pupil dilation for incorrect responses was only briefly different than when the response was correct (2.03 to 3.13 seconds relative to sentence offset), although fewer errors were made for those stimuli overall (n = 49) compared to sentences with an early-masked word (n= 150) or a late-masked word (n = 116). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The present study aimed to address the question of how the position of a misperceived word impacts listening effort and intelligibility. By prospectively designing sentences with missing words at different word positions within a sentence, we could ensure the mental repair process happened at specific moments, even though it can normally be uncontrollable or undetectable simply based on the participant response. Crucially, the stimuli with early-and late-position words were drawn from the same set of sentences, toward the goal of comparisons that were unavailable in previous studies.</p><p>Consistent with previous work, listeners exerted more cognitive resources to disambiguate sentences with missing words, as indicated by increases in pupil dilation that were larger and more rapid compared to when all the words in a sentence were available (Figure <ref type="figure" target="#fig_8">7</ref>).</p><p>The main novel result was that sentences with earlier-masked words had larger increase and duration of extra pupil dilation compared to sentences with late-masked words. This is most likely because the late-masked words have the advantage of preceding disambiguating information before the missing word that could help resolve any linguistic ambiguity in advance, whereas stimuli with early-masked words forced the listener to hold some uncertainty until gathering sufficient contextual clues later on. These results suggest that a mere tally of the number (or percent) of errors in a sentence loses valuable information about the unequal impact of making perceptual mistakes earlier or later in an utterance.</p><p>Compared to listeners with TH, CI listeners showed increased duration of increased pupil size when disambiguating missing words, suggesting more time needed to recover from the process of mentally repairing missing words. This result is consistent with CI listeners being less likely to be able to take advantage of sentence context as it unfolds in real time <ref type="bibr" target="#b39">(Winn 2016)</ref>, which may stem from contextual information being degraded by the device itself.</p><p>Consistent with previous literature <ref type="bibr" target="#b42">(Winn et al., 2015;</ref><ref type="bibr" target="#b50">Zhang et al., 2021)</ref>, incorrect responses in the current study produced greater pupil dilation in the moments after the sentence ended. The larger increase in pupil dilation for incorrect responses could be an indication that the listener is still grappling with some unresolved linguistic ambiguity created by the missing word, resulting in lingering effort after the sentence.</p><p>On the importance of measuring the timing (not just the magnitude) of effort</p><p>The observation of lingering effort in cases of successful and unsuccessful mental repair of missing words invites concern about the potential implications for perceiving continuous speech, which typically lacks extended moments of silence that the listener can use to reevaluate and repair previous perceptions. Listeners with severe-profound hearing impairment have suggested there is a significant time lag between hearing and understanding, and feelings of being "behind" due to the extra effort needed to follow the conversation <ref type="bibr" target="#b13">(Hughes et al., 2018)</ref>.</p><p>Recent work verifies that misperceiving one word has down-stream consequences for the accurate perception of later sentences if the listener cannot quickly resolve the mistake <ref type="bibr" target="#b41">(Winn, 2024)</ref>. Testing with two full sentences reveals that some listeners experience severe reduction in performance that would not have been evident by testing one sentence <ref type="bibr" target="#b31">(Svirsky et al., 2024)</ref>, validating the notion that lingering effort in single-sentence stimuli might overlook difficulties that have implications for real-world interaction.</p><p>A caveat on interpreting the use of context and sentence coherence Taking advantage of sentence context as a compensatory listening strategy is one potential approach to explore how language processing interacts with listening effort. A common method for evaluating the influence of sentence context on perception is to have high-or lowprobability sentences <ref type="bibr" target="#b4">(Bilger et al., 1984)</ref>, or to have sentences that are either semantically coherent or incoherent <ref type="bibr" target="#b21">(O'Neill et al., 2020;</ref><ref type="bibr" target="#b28">Signoret et al., 2018;</ref><ref type="bibr" target="#b33">Van Engen &amp; Peelle, 2014)</ref>. In several recent studies involving CI listeners, incoherent responses are shown to elicit larger signatures of effort compared to other types of responses or planned stimulus variations <ref type="bibr" target="#b41">(Winn, 2024;</ref><ref type="bibr" target="#b44">Winn &amp; Teece, 2021</ref><ref type="bibr">, 2022)</ref>. However, a crucial caveat that must be considered when interpreting these studies is the increase in effort resulting from incoherent perceptions might hinge on the listener's expectation that the sentences should be coherent. This caveat might explain why observed the unexpected result of larger pupil responses for a clear speaking style compared to a conversational style. All of the stimuli in that study were contextually incoherent, which might have resulted in the clear speaking style highlighting the unnaturalness of the anomalous sentence content. The influence of the listener's expectation for sentence coherence (or expectation of any other reliable pattern) could alter their approach to listening and their allocation of effort in the task. This idea could be explored by a study that directly compares responses from a random mix of stimulus types against results from a blocked design where the listener has clear expectations for stimulus type. The current study can also be contextualized by this idea; perhaps the increased signs of effort for repaired sentences would be diminished if the listener expected to repair every sentence, and increased if the repaired stimuli were less frequent (i.e. more surprising).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Mentally repairing a misperceived word elicits increased effort, particularly when that word occurred earlier in the sentence, and especially when the repair process was unsuccessful. Elevated listening effort lingers longer after the sentence for CI listeners, especially when needing to repair an earlier missing word. These patterns suggest that not all words should be weighted equally when assessing a listener's perceptual accuracy for words within a sentence. When CI listeners repair missing words, they are also more likely to make mistakes on words elsewhere in the sentence (both earlier and later), even though those words were presented in the clear. These patterns further highlight how participant responses do not reflect the perceptual accuracy itself, but rather the processing of the entire utterance, which builds a foundation at the beginning of the sentence and continues to solidify by the end of the sentence.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Distributions of listener ages for the two different hearing groups (color online).</figDesc><graphic coords="7,72.00,359.46,389.92,221.15" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 3: Schematic of overall task design. Listeners were instructed to fixate on the red</figDesc><graphic coords="11,72.00,109.30,467.92,174.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>glmer(AnyError ~ Condition + (1 + Condition | Listener) ) glmer(ErrorElsewhere ~ Condition + (1 + Condition | Listener) )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>and the R package "itsadug" version 2.4.1 (van Rij et al., 2022) was used for interpretation, validation, and visualization of the statistical analyses. An initial model was used to calculate the autocorrelation lag value (rho) that would be used in the final model. The final model included hearing group (CI and TH) and stimulus type (early masked word, late masked word, fully intact) as fixed effects with different smooth functions fitted over time for each interaction of hearing status and stimulus type. There were random effects of time as a smooth factor for each listener for each stimulus type. The final model terms are shown below. bam(pupil ~ # parametrics is_CI + is_early + is_late + is_early_CI + is_late_CI + # basic smooth for time s(time, k = 20, bs = "cr") + # difference curve for hearing group s(time, by = is_CI, k = 20, bs = "cr") + # interactions of condition x hearing s(time, by = is_early, k = 20, bs = "cr") + s(time, by = is_late, k = 20, bs = "cr") + s(time, by = is_early_CI, k = 20, bs = "cr") + s(time, by = is_late_CI, k = 20, bs = "cr") + # random time smooth per listener s(time, Listener, bs = 'fs', m = 1, k = 5) + # random time smooth per listener interacting with condition s(time, Listener, by = is_early, bs = 'fs', m = 1, k =5), s(time, Listener, by = is_late, bs = 'fs', m = 1, k = 5),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>[[ Figure 5: CI Intelligibility here ]]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Percentage of responses that contained any errors, for the CI listener group only.</figDesc><graphic coords="19,72.00,312.38,467.95,191.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>[</head><label></label><figDesc>Figure 6: Average proportional change in pupil size for each listener group in response to the</figDesc><graphic coords="21,72.00,109.30,493.70,243.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>[[ Figure 7: Diff curves]]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Difference curves from the GAMMs results, illustrating differences between curves from Figure 6, and also illustrating differences between groups. A) The curve represents the</figDesc><graphic coords="22,72.00,340.98,502.70,253.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>[</head><label></label><figDesc>Figure 8: Effect of repetition errors on pupil responses, for CI listeners only. Pupil responses for</figDesc><graphic coords="24,72.00,109.30,467.95,193.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="9,116.50,259.79,379.00,249.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="17,72.00,376.28,284.34,298.80" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>Participant recruitment and data collection were assisted by <rs type="person">Katherine Teece</rs>, <rs type="person">Emily Hugo</rs>, <rs type="person">Tereza Krogseng</rs>, <rs type="person">Miski Mohamed</rs>, and <rs type="person">Lexi Olson</rs>. Statistical analysis was aided by input from <rs type="person">Stefanie Kuchinsky</rs>, <rs type="person">Nick Pandža</rs>, and <rs type="person">Michael Johns</rs>. The experiment design was assisted by our late colleague <rs type="person">Akira Omaki</rs>. This research was supported by <rs type="funder">NIH-NIDCD</rs> <rs type="grantNumber">F32 DC021076</rs> (Smith) and <rs type="grantNumber">R01 DC017114</rs> (Winn).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_9APXRJS">
					<idno type="grant-number">F32 DC021076</idno>
				</org>
				<org type="funding" xml:id="_YBZsKPe">
					<idno type="grant-number">R01 DC017114</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Principle of Least Effort and Comprehension of Spoken Sentences by Younger and Older Adults</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Ayasse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hodson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wingfield</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2021.629464</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2021.629464" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">629464</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Autocorrelated errors in experimental data in the language sciences</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Van Rij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>De Cat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Wood</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.02043</idno>
		<ptr target="http://arxiv.org/abs/1601.02043" />
	</analytic>
	<monogr>
		<title level="m">Some solutions offered by Generalized Additive Mixed Models</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cognitive Compensation of Speech Perception With Hearing Impairment, Cochlear Implants, and Aging: How and to What Degree Can It Be Achieved?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Başkent</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pals</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Benard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Saija</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sarampalis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gaudrain</surname></persName>
		</author>
		<idno type="DOI">10.1177/2331216516670279</idno>
		<ptr target="https://doi.org/10.1177/2331216516670279" />
	</analytic>
	<monogr>
		<title level="j">Trends in Hearing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">233121651667027</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Task-Evoked Pupillary Responses</title>
		<author>
			<persName><forename type="first">J</forename><surname>Beatty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Processing Load, and the Structure of Processing Resources</title>
		<meeting>essing Load, and the Structure of essing Resources</meeting>
		<imprint>
			<date type="published" when="1982">1982</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Standardization of a test of speech perception in noise</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Bilger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Nuetzel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">M</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rzeczkowski</surname></persName>
		</author>
		<idno type="DOI">10.1044/jshr.2701.32</idno>
		<ptr target="https://doi.org/10.1044/jshr.2701.32" />
	</analytic>
	<monogr>
		<title level="j">Journal of Speech and Hearing Research</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="48" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Cloze probability and completion norms for 498 sentences: Behavioral and neural validation using event-related potentials</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Block</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Baldwin</surname></persName>
		</author>
		<idno type="DOI">10.3758/BRM.42.3.665</idno>
		<ptr target="https://doi.org/10.3758/BRM.42.3.665" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="665" to="670" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Salience is in the eye of the beholder: Increased pupil size reflects acoustically salient variables</title>
		<author>
			<persName><forename type="first">V</forename><surname>Boswijk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Loerts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Hilton</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.amper.2020.100061</idno>
		<ptr target="https://doi.org/10.1016/j.amper.2020.100061" />
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">100061</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Listening Effort in Cochlear Implant Users: The Effect of Speech Intelligibility, Noise Reduction Processing, and Working Memory Capacity on the Pupil Dilation Response</title>
		<author>
			<persName><forename type="first">G</forename><surname>Dingemanse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goedegebure</surname></persName>
		</author>
		<idno type="DOI">10.1044/2021_JSLHR-21-00230</idno>
		<ptr target="https://doi.org/10.1044/2021_JSLHR-21-00230" />
	</analytic>
	<monogr>
		<title level="j">Journal of Speech, Language, and Hearing Research</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="392" to="404" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Pupillometry reveals processing load during spoken language comprehension</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Engelhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Patsenko</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470210903469864</idno>
		<ptr target="https://doi.org/10.1080/17470210903469864" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="639" to="645" />
			<date type="published" when="2006">2010. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The process of spoken word recognition in the face of signal degradation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Farris-Trimble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Cigrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tomblin</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0034353</idno>
		<ptr target="https://doi.org/10.1037/a0034353" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology. Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="308" to="327" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Thinking ahead: The role and roots of prediction in language comprehension</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Federmeier</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-8986.2007.00531.x</idno>
		<ptr target="https://doi.org/10.1111/j.1469-8986.2007.00531.x" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="491" to="505" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Orienting of attention, pupil size, and the norepinephrine system</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gabay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Pertzov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Henik</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-010-0015-4</idno>
		<ptr target="https://doi.org/10.3758/s13414-010-0015-4" />
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="129" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Identifying Listeners Whose Speech Intelligibility Depends on a Quiet Extra Moment After a Sentence</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Gianakas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Winn</surname></persName>
		</author>
		<idno type="DOI">10.1044/2022_JSLHR-21-00622</idno>
		<ptr target="https://doi.org/10.1044/2022_JSLHR-21-00622" />
	</analytic>
	<monogr>
		<title level="j">Journal of Speech, Language, and Hearing Research</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4852" to="4865" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Social Connectedness and Perceived Listening Effort in Adult Cochlear Implant Users: A Grounded Theory to Establish Content Validity for a New Patient-Reported Outcome Measure</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Hutchings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">L</forename><surname>Rapport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Mcmahon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Boisvert</surname></persName>
		</author>
		<idno type="DOI">10.1097/AUD.0000000000000553</idno>
		<ptr target="https://doi.org/10.1097/AUD.0000000000000553" />
	</analytic>
	<monogr>
		<title level="j">Ear &amp; Hearing</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="922" to="934" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dual-Task Accuracy and Response Time Index Effects of Spoken Sentence Predictability and Cognitive Load on Listening Effort</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</author>
		<idno type="DOI">10.1177/23312165211018092</idno>
		<ptr target="https://doi.org/10.1177/23312165211018092" />
	</analytic>
	<monogr>
		<title level="j">Trends in Hearing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">233121652110180</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Predictive Sentence Context Reduces Listening Effort in Older Adults With and Without Hearing Loss and With High and Low Working Memory Capacity</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Humes</surname></persName>
		</author>
		<idno type="DOI">10.1097/AUD.0000000000001192</idno>
		<ptr target="https://doi.org/10.1097/AUD.0000000000001192" />
	</analytic>
	<monogr>
		<title level="j">Ear and Hearing</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">1164</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Johns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Calloway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M D</forename><surname>Karunathilake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">P</forename><surname>Decruy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Kuchinsky</surname></persName>
		</author>
		<idno type="DOI">10.1177/23312165241245240</idno>
		<ptr target="https://doi.org/10.1177/23312165241245240" />
		<title level="m">Attention Mobilization as a Modulator of Listening Effort: Evidence From Pupillometry. Trends in Hearing</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page">23312165241245240</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pupil diameter and load on memory</title>
		<author>
			<persName><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Beatty</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.154.3756.1583</idno>
		<ptr target="https://doi.org/10.1126/science.154.3756.1583" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">3756</biblScope>
			<biblScope unit="page" from="1583" to="1585" />
			<date type="published" when="1966">1966</date>
			<pubPlace>New York, N.Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Brain potentials during reading reflect word expectancy and semantic association</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kutas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Hillyard</surname></persName>
		</author>
		<idno type="DOI">10.1038/307161a0</idno>
		<ptr target="https://doi.org/10.1038/307161a0" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">307</biblScope>
			<biblScope unit="issue">5947</biblScope>
			<biblScope unit="page" from="161" to="163" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Waking State: Rapid Variations Modulate Neural and Behavioral Responses</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcginley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vinck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Batista-Brito</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zagha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Cadwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Tolias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Cardin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Mccormick</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2015.09.012</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2015.09.012" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1143" to="1161" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Waiting for lexical access: Cochlear implants or severely degraded input lead listeners to process speech less incrementally</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Farris-Trimble</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rigler</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2017.08.013</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2017.08.013" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="147" to="164" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Development and Validation of Sentences Without Semantic Context to Complement the Basic English Lexicon Sentences</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>O'neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Parke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Kreft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Oxenham</surname></persName>
		</author>
		<idno type="DOI">10.1044/2020_JSLHR-20-00174</idno>
		<ptr target="https://doi.org/10.1044/2020_JSLHR-20-00174" />
	</analytic>
	<monogr>
		<title level="j">Journal of Speech, Language, and Hearing Research: JSLHR</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3847" to="3854" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Role of semantic context and talker variability in speech perception of cochlear-implant users and normal-hearing listeners</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>O'neill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Parke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Kreft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Oxenham</surname></persName>
		</author>
		<idno type="DOI">10.1121/10.0003532</idno>
		<ptr target="https://doi.org/10.1121/10.0003532" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1224" to="1239" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Role of contextual cues on the perception of spectrally reduced interrupted speech</title>
		<author>
			<persName><forename type="first">C</forename><surname>Patro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Mendel</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.4961450</idno>
		<ptr target="https://doi.org/10.1121/1.4961450" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">140</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">1336</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Pichora-Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Eckert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W Y</forename><surname>Hornsby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Humes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Lemke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lunner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Matthen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Mackersie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Naylor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rudner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Sommers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Tremblay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wingfield</surname></persName>
		</author>
		<idno type="DOI">10.1097/AUD.0000000000000312</idno>
		<ptr target="https://doi.org/10.1097/AUD.0000000000000312" />
	</analytic>
	<monogr>
		<title level="m">Hearing Impairment and Cognitive Energy: The Framework for Understanding Effortful Listening (FUEL)</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="5S" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">How young and old adults listen to and remember speech in noise</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Pichora-Fuller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Daneman</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.412282</idno>
		<ptr target="https://doi.org/10.1121/1.412282" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="593" to="608" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Eyes Wide Open: Pupillary Response to a Foreign Accent Varying in Intelligibility</title>
		<author>
			<persName><forename type="first">V</forename><surname>Porretta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">V</forename><surname>Tucker</surname></persName>
		</author>
		<idno type="DOI">10.3389/fcomm.2019.00008</idno>
		<ptr target="https://www.frontiersin.org/articles/10.3389/fcomm.2019.00008" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Communication</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dissociable but inter-related systems of cognitive control and reward during decision making: Evidence from pupillometry and event-related fMRI</title>
		<author>
			<persName><forename type="first">R</forename><surname>Satterthwaite</surname></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team.</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Green</surname></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team.</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Myerson</surname></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team.</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Parker</surname></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team.</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramaratnam</surname></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team.</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Buckner</surname></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team.</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team.</orgName>
			</affiliation>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2007.04.066</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2007.04.066" />
	</analytic>
	<monogr>
		<title level="m">R: The R Project for Statistical Computing</title>
		<imprint>
			<date type="published" when="2007">2021. 2020. 2007</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1017" to="1031" />
		</imprint>
	</monogr>
	<note>RStudio: Integrated Development Environment for</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Combined effects of form-and meaning-based predictability on perceived clarity of speech</title>
		<author>
			<persName><forename type="first">C</forename><surname>Signoret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Johnsrude</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Classon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rudner</surname></persName>
		</author>
		<idno type="DOI">10.1037/xhp0000442</idno>
		<ptr target="https://doi.org/10.1037/xhp0000442" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology. Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="277" to="285" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Pupillometry</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sirois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brisson</surname></persName>
		</author>
		<idno type="DOI">10.1002/wcs.1323</idno>
		<ptr target="https://doi.org/10.1002/wcs.1323" />
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews. Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="679" to="692" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Publication guidelines and recommendations for pupillary measurement in psychophysiological studies</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Steinhauer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Siegle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Roecklein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dix</surname></persName>
		</author>
		<idno type="DOI">10.1111/psyp.14035</idno>
		<ptr target="https://doi.org/10.1111/psyp.14035" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">14035</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Communication Under Sharply Degraded Auditory Input and the &quot;2-Sentence</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Svirsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Neukam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Capach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Amichetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lavender</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wingfield</surname></persName>
		</author>
		<idno type="DOI">10.1097/AUD.0000000000001500</idno>
		<ptr target="https://doi.org/10.1097/AUD.0000000000001500" />
	</analytic>
	<monogr>
		<title level="j">Problem. Ear and Hearing</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Pupil dilation as an index of effort in cognitive control tasks: A review</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Der Wel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Steenbergen</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-018-1432-y</idno>
		<ptr target="https://doi.org/10.3758/s13423-018-1432-y" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2005" to="2015" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Listening effort and accented speech</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Van Engen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Peelle</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2014.00577</idno>
		<ptr target="https://www.frontiersin.org/articles/10.3389/fnhum.2014.00577" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Analyzing the Time Course of Pupillometric Data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Van Rij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hendriks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Rijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.1177/2331216519832483</idno>
		<ptr target="https://doi.org/10.1177/2331216519832483" />
	</analytic>
	<monogr>
		<title level="j">Trends in Hearing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">2331216519832483</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Van Rij</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wieling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Baayen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Rijn</surname></persName>
		</author>
		<ptr target="https://cran.r-project.org/web/packages/itsadug/index.html" />
		<title level="m">itsadug: Interpreting Time Series and Autocorrelated Data Using GAMMs</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Phonological and semantic similarity of misperceived words in babble: Effects of sentence context, age, and hearing loss</title>
		<author>
			<persName><forename type="first">B</forename><surname>Vickery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fogerty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Dubno</surname></persName>
		</author>
		<idno type="DOI">10.1121/10.0009367</idno>
		<ptr target="https://doi.org/10.1121/10.0009367" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="650" to="662" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Perceptual restoration of missing speech sounds</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Warren</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.167.3917.392</idno>
		<ptr target="https://doi.org/10.1126/science.167.3917.392" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">3917</biblScope>
			<biblScope unit="page" from="392" to="393" />
			<date type="published" when="1970">1970</date>
			<pubPlace>New York, N.Y.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Toward a more comprehensive understanding of the impact of masker type and signal-to-noise ratio on the pupillary response while performing a speech-in-noise test</title>
		<author>
			<persName><forename type="first">D</forename><surname>Wendt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koelewijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Książek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lunner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.heares.2018.05.006</idno>
		<ptr target="https://doi.org/10.1016/j.heares.2018.05.006" />
	</analytic>
	<monogr>
		<title level="j">Hearing Research</title>
		<imprint>
			<biblScope unit="volume">369</biblScope>
			<biblScope unit="page" from="67" to="78" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Rapid Release From Listening Effort Resulting From Semantic Context, and Effects of Spectral Degradation and Cochlear Implants</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Winn</surname></persName>
		</author>
		<idno type="DOI">10.1177/2331216516669723</idno>
		<ptr target="https://doi.org/10.1177/2331216516669723" />
	</analytic>
	<monogr>
		<title level="j">Trends in Hearing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">233121651666972</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Time Scales and Moments of Listening Effort Revealed in Pupillometry</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Winn</surname></persName>
		</author>
		<idno type="DOI">10.1055/s-0043-1767741</idno>
		<ptr target="https://doi.org/10.1055/s-0043-1767741" />
	</analytic>
	<monogr>
		<title level="j">Seminars in Hearing</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="106" to="123" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The Effort of Repairing a Misperceived Word Can Impair Perception of Following Words, Especially for Listeners With Cochlear Implants</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Winn</surname></persName>
		</author>
		<idno type="DOI">10.1097/AUD.0000000000001537</idno>
		<ptr target="https://doi.org/10.1097/AUD.0000000000001537" />
	</analytic>
	<monogr>
		<title level="j">Ear and Hearing</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The Impact of Auditory Spectral Resolution on Listening Effort Revealed by Pupil Dilation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Y</forename><surname>Litovsky</surname></persName>
		</author>
		<idno type="DOI">10.1097/AUD.0000000000000145</idno>
		<ptr target="https://doi.org/10.1097/AUD.0000000000000145" />
	</analytic>
	<monogr>
		<title level="j">Ear and Hearing</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="153" to="165" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Pupillometry Reveals That Context Benefit in Speech Perception Can Be Disrupted by Later-Occurring Sounds, Especially in Listeners With Cochlear Implants</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.1177/2331216518808962</idno>
		<ptr target="https://doi.org/10.1177/2331216518808962" />
	</analytic>
	<monogr>
		<title level="j">Trends in Hearing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">233121651880896</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Listening Effort Is Not the Same as Speech Intelligibility Score</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Teece</surname></persName>
		</author>
		<idno type="DOI">10.1177/23312165211027688</idno>
		<ptr target="https://doi.org/10.1177/23312165211027688" />
	</analytic>
	<monogr>
		<title level="j">Trends in Hearing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">233121652110276</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Effortful Listening Despite Correct Responses: The Cost of Mental Repair in Sentence Recognition by Listeners With Cochlear Implants</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Teece</surname></persName>
		</author>
		<idno type="DOI">10.1044/2022_JSLHR-21-00631</idno>
		<ptr target="https://doi.org/10.1044/2022_JSLHR-21-00631" />
	</analytic>
	<monogr>
		<title level="j">Journal of Speech, Language, and Hearing Research : JSLHR</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3966" to="3980" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Wood</surname></persName>
		</author>
		<ptr target="https://cran.r-project.org/web/packages/mgcv/index.html" />
		<title level="m">mgcv: Mixed GAM Computation Vehicle with Automatic Smoothness Estimation (1.9-0)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Computer software</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">N</forename><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.1201/9781315370279</idno>
		<ptr target="https://doi.org/10.1201/9781315370279" />
		<title level="m">Generalized Additive Models: An Introduction with R, Second Edition</title>
		<imprint>
			<publisher>Chapman and Hall/CRC</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The Pupil Dilation Response to Auditory Stimuli: Current State of Knowledge</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Zekveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koelewijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Kramer</surname></persName>
		</author>
		<idno type="DOI">10.1177/2331216518777174</idno>
		<ptr target="https://doi.org/10.1177/2331216518777174" />
	</analytic>
	<monogr>
		<title level="j">Trends in Hearing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">233121651877717</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Pupil response as an indication of effortful listening: The influence of sentence intelligibility</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Zekveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Festen</surname></persName>
		</author>
		<idno type="DOI">10.1097/AUD.0b013e3181d4f251</idno>
		<ptr target="https://doi.org/10.1097/AUD.0b013e3181d4f251" />
	</analytic>
	<monogr>
		<title level="j">Ear and Hearing</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="480" to="490" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Disentangling listening effort and memory load beyond behavioural evidence: Pupillary response to listening effort during a concurrent memory task</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Deroche</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0233251</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0233251" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">233251</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
