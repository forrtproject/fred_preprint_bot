<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Integrating large language models into the psychological sciences</title>
				<funder ref="#_qPDVSFq">
					<orgName type="full">MRC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Aamir</forename><surname>Sohail</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="laboratory">Centre for Human Brain Health</orgName>
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Centre for Integrative Neuroscience and Neurodynamics</orgName>
								<orgName type="institution">University of Reading</orgName>
								<address>
									<settlement>Reading</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Psychology and Clinical Language Sciences</orgName>
								<orgName type="institution">University of Reading</orgName>
								<address>
									<settlement>Reading</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Institute for Mental Health</orgName>
								<orgName type="department" key="dep2">School of Psychology</orgName>
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Lei</forename><surname>Zhang</surname></persName>
							<email>l.zhang.13@bham.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="laboratory">Centre for Human Brain Health</orgName>
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Institute for Mental Health</orgName>
								<orgName type="department" key="dep2">School of Psychology</orgName>
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department" key="dep1">Centre for Developmental Science</orgName>
								<orgName type="department" key="dep2">School of Psychology</orgName>
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">School of Psychology</orgName>
								<orgName type="laboratory">Centre for Human Brain Health</orgName>
								<orgName type="institution">University of Birmingham</orgName>
								<address>
									<postCode>B15 2TT</postCode>
									<settlement>Birmingham</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Integrating large language models into the psychological sciences</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">17596D5FBA4FF536A3DC8686DE349E9A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>large language models (LLMs)</term>
					<term>academia</term>
					<term>psychology</term>
					<term>education</term>
					<term>human behavior</term>
					<term>teaching</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large Language Models (LLMs) have significantly shaped working practices across a variety of fields including academia. Demonstrating a remarkable versatility, these models can generate responses to prompts with information in the form of text, documents, and images, show ability to summarise documents, perform literature searches, and even more, understand human behavior. However, despite providing many clear benefits, barriers remain towards their integration into academic work. Ethical and practical concerns regarding their suitability for various tasks further complicate their appropriate use. Here, we summarise recent literature assessing the capacity of LLMs for different components of academic research and teaching, focusing on three key areas in the psychological sciences: education and assessment, academic writing, and simulating human behavior. We discuss how LLMs can be used to aid each area, describe current challenges and good practices, and propose future directions. In doing so, we aim to increase the awareness and proper use of LLMs in various components of academic work, which will only feature more heavily over time.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Academics are expected to carry out teaching and research duties, having both a commitment to lecturing and grading student work, as well as designing and performing experiments, writing grant/funding applications, and publishing papers. This workload is often excessive, leading to long working hours and feelings of heightened anxiety and inefficiency <ref type="bibr" target="#b10">(Barrett &amp; Barrett, 2008)</ref>. These burdens may be potentially alleviated by the recently developed large language models (LLMs). LLMs, a specific type of artificial neural networks that are pretrained on statistical relationships in language that ultimately generate a list of outcomes probabilistically representing the most suitable option in response to a given prompt (e.g., "Explain XYZ to first-year undergraduate students, are particularly suitable for specific tasks such as text summarization, knowledge retrieval, and cases where information can be concisely and accurately presented. Subsequently, these models can aid various components of academic work <ref type="bibr" target="#b54">(Meyer et al., 2023)</ref>, including in the psychological sciences <ref type="bibr" target="#b0">(Abdurahman et al., 2023;</ref><ref type="bibr" target="#b23">Demszky et al., 2023)</ref>, by summarising and revising text, analysing and debugging computer code, and performing literature searches.</p><p>Teaching and academic writing are activities which particularly stand to benefit from the incorporation of LLMs, given that tasks in the psychological sciences heavily rely on text, verbal or written alike. Academics can use LLMs to freely generate content-relevant material (e.g., numerical cognition in infancy) and automate the grading of assessments, whilst students benefit from LLMs' utility as a knowledge base and ability to assist learning of practical skills including statistics and programming (e.g., general linear modelling in R). Similarly, LLMs also have significantly altered the writing process for academics, with its ability to propose templated articles, revise and re-word text, and perform literature searches in response to specific queries. However, questions remain regarding their implementation for certain tasks, as LLMs often generate false information in response to specific prompts <ref type="bibr" target="#b77">(Zhang et al., 2023)</ref> and false references when performing literature searches <ref type="bibr" target="#b1">(Agrawal et al., 2024)</ref>. Furthermore, students and academics, whilst benefitting from increased productivity, conversely face issues relating to plagiarism <ref type="bibr" target="#b36">(Hutson, 2024)</ref>, critical thinking <ref type="bibr" target="#b53">(Messeri &amp; Crockett, 2024)</ref>, and hinderances to the learning process <ref type="bibr" target="#b73">(Yan et al., 2023)</ref>.</p><p>Inherently rooted in the psychological sciences (particularly cognitive psychology), a common benchmark for understanding the capability of LLMs involves measuring the response to cognitive tasks and logic puzzles requiring 'human-like' reasoning. Early success in this domain <ref type="bibr" target="#b43">(Kojima et al., 2022)</ref> prompted research towards using LLMs as proxies for human participants in behavioral experiments, potentially offering the ability to perform complex cognitive tasks more quickly, reliably and cheaply. Responding to behavioral tasks and other assessments submitted as prompts, LLMs are found to replicate classic economic, psycholinguistic, and social psychology experiments <ref type="bibr" target="#b2">(Aher et al., 2023)</ref>, ultimately demonstrating similarities with human cognition and behavior <ref type="bibr" target="#b34">(Huijzer &amp; Hill, 2023;</ref><ref type="bibr" target="#b40">Ke et al., 2024)</ref>. However, others have noted the various biases inherent with LLMs, including differences between other measures of human decision-making and inference <ref type="bibr" target="#b19">(Crockett &amp; Messeri, 2023)</ref>, and the inability to reflect more current or constantly changing societal views <ref type="bibr" target="#b29">(Harding et al., 2023)</ref>. It therefore currently remains unclear for academics in the psychological sciences to which extent LLMs can accurately represent human cognition, and the circumstances where they can accurately provide a substitution for human participants.</p><p>To reflect the state-of-the-art, this review summarizes the current development of research on LLMs in teaching, academic writing, and simulating human behavior, in which we highlight the potential benefits and limitations for each. We then discuss the ethical considerations they present and suggest future directions in this rapidly evolving field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Large language models in academic education</head><p>Psychology and related courses within higher education involve both theoretical and practical learning. Academics conceive and deliver concepts, theories, and empirical evidence for key topics in psychology, whereas students are expected to learn and portray critical insight towards those theories, and develop practical skills including statistics, experimental design, and programming. The underlying structure of LLMs make them highly suitable for aiding both theoretical and practical modes of learning, offering a clear benefit to both academics and students alike (Figure <ref type="figure">1</ref>). Whilst the benefit for students is more apparent, teaching, at and above the undergraduate level, covers extensive amounts of conceptual information. As certain topics may initially be unfamiliar to the lecturer who will need to refresh their own subject knowledge, LLMs summarise complex topics at an appropriate level relevant for their teaching. LLMs can also be used to plan entire modules and how the content is delivered by creating quizzes and assessments that test students' understanding of the material throughout the entire semester. This includes generating specific learning materials for those with learning difficulties (e.g., creating Concept Maps from conversations for dyslexic students) (D'Urso &amp; Sciarrone, 2024) and translating materials into different languages for those whose primary language is not English <ref type="bibr" target="#b51">(Lo, 2023)</ref>. These elements are getting increasingly important considering equality, diversity, and inclusion in higher education. Ultimately, LLMs employed through chatbots such as ChatGPT benefit the teaching and learning process for both students and academics, improving student performance, motivation, organization and time management, and promotes a more effective and collaborative learning environment <ref type="bibr" target="#b73">(Yan et al., 2023)</ref>.</p><p>Figure <ref type="figure">1</ref>. How academics and students can benefit from large language models (LLMs) in higher education. Demonstrating their versatility, large language models offer many benefits for both academics and students, most commonly by providing a knowledge base for key theories and concepts, and as a programming assistant. For students, LLMs can also assist with the revision process and at various stages of written coursework. Teachers can additionally benefit by using LLMs to plan courses and as an exam grader. Icons by Icons8.</p><p>From the students' perspective, LLMs can further benefit learning by generating educational materials such as reading comprehension tasks, interactive code explanations and assessment questions, and by improving student-based feedback of another's work. However, whether LLMs generally lead to an improvement in academic performance cannot be definitively stated, as there currently is a lack of empirically designed studies, particularly within the context of higher education <ref type="bibr" target="#b45">(Kurtz et al., 2024)</ref>.</p><p>The extent to which LLMs can bolster education is also dependent on the user's technical ability and personal attitudes. Certain academics report being reluctant to include LLMs as part of the learning process due to ethical concerns or unfamiliarity <ref type="bibr" target="#b42">(Kiryakova &amp; Angelova, 2023)</ref>. Indeed, teachers in higher education also report confusion with adopting their curriculum accordingly given the prevalence of LLMs <ref type="bibr" target="#b78">(Zhou et al., 2024)</ref>. Conversely, many students also do not employ LLMs in their own learning, and if so, are not fully aware of its subtle nuances. Students new to programming -a common scenario in the psychological sciences -whilst aware that ChatGPT and other LLM-chatbots can be used to generate and fix code provided as prompts, may be under-educated in prompt engineering <ref type="bibr" target="#b50">(Lin, 2024)</ref>, the specific construction of prompts to receive a more suitable response. This is an important skill, as ChatGPT tends to be less capable in providing responses to programming questions if not well prompted <ref type="bibr" target="#b39">(Kabir et al., 2023)</ref>.</p><p>However, some have argued that an over-reliance on LLMs will have a negative influence on the skills and working practices accrued by students <ref type="bibr" target="#b6">(Anders, 2023)</ref>. Indeed, when using LLM tools to complete a programming project, students demonstrate practical progress but report hindered learning <ref type="bibr" target="#b65">(Tanay et al., 2024)</ref>, and a negative correlation has been observed between LLM reliance for programming tasks and performance on critical thinking assessments <ref type="bibr" target="#b38">(Jošt et al., 2024)</ref>. By over-relying on the LLM to provide the solution, students may not think practically about the specific components of the code, resorting to simply copying and pasting generated code ad nauseum. We therefore suggest that students use LLMs in programming tasks (and similar tasks) in a scaffolding fashion -utilizing structures and pointers generated by LLMs as an "extra brain" yet independently evaluating and internalizing the actual solution, akin to the concept of zone of proximal development in development psychology <ref type="bibr" target="#b69">(Vygotsky, 2012</ref>).</p><p>Yet, the lines regarding the appropriate use of LLMs in certain areas of education remain blurred. For example, in a programming class, should students be allowed to use code directly generated by an LLM? As employees are not restricted in the materials and resources available in their profession, some argue that universities should instead embrace LLMs and assess the efficacy in which students can use them to retrieve information and generate solutions <ref type="bibr" target="#b44">(Koplin et al., 2023)</ref>. Fully educating students on when (and when not) to use LLMs as part of their degree should therefore constitute a critical part of university-level education, avoiding the potential for an "unfair academic playing field", created by students unaware of the full capabilities of AI tools <ref type="bibr" target="#b18">(Cotton et al., 2023)</ref>, or those who choose not to use it due to ethical considerations. In fact, a substantial number of universities worldwide have published student guidelines and guidance on using LLMs and generative artificial intelligence tools<ref type="foot" target="#foot_0">1</ref> . Meanwhile, online tools and platforms are publicly available (e.g., ChatGPT Detector, GPTZero) to detect work generated by LLMs to avoid overuse and misuse of LLMs in higher education.</p><p>Understanding the capabilities of LLMs also allows for academics, lecturers, and module convenors to set the appropriate examinations and assessments for their class. As these aim to measure subject knowledge, practical skills and critical thinking, abilities which can be replicated by LLMs to a degree, certain assessments in the psychological sciences may also need to be adjusted <ref type="bibr" target="#b18">(Cotton et al., 2023)</ref>. Attempts to prevent the use of LLMs for aiding assessments include employing AIdetectors for essays and reverting to oral presentations <ref type="bibr" target="#b47">(Lemasters &amp; Hurshman, 2024)</ref> and inperson written examinations. However, with the proven benefit in improving the learning process for certain areas, academics should remain open with students using LLMs in specific cases where the benefits in productivity can, but do not necessarily lead to, reduced learning. We ultimately advocate that academics are educated, well informed and develop a clear agenda before employing LLMs as a practical tool in their teaching.</p><p>Using large language models to aid academic writing One of the more controversial issues regarding the use of LLMs within academia is their role with aiding the writing process. As LLMs can summarise, generate, and re-phrase text, journals have been quick to demonstrate their position on the matter, with some disallowing any LLM-generated text, and others requiring clear guidance as to which components of the research paper were influenced or generated. Discerning to which extent LLMs should be used presents a difficult situation. Most would agree that entire paragraphs should not be written, re-written or paraphrased by LLMs; however, if, hypothetically, a human writer re-phrased a paragraph of academic text that coincidentally matched word-for-word an LLM-rephrased paragraph of the same text, should neither be used? Ethical dilemmas also exist on a smaller scale as the writing process naturally involves the repetition of others' work (this is particularly true for Methods sections in journal articles). Given that summarising the key results of a paper in a sentence or two can only contain a specific set of words, should LLMs be used to re-format a single sentence to avoid plagiarism? Some consider the use of such programs even to re-structure single sentences as unacceptable in scientific research <ref type="bibr" target="#b58">(Salvagno et al., 2023)</ref>.</p><p>In a related but separate scenario, LLMs are often used to generate text intended for a research article or review paper from scratch by providing descriptions of scientific principles or an overview of a research topic. However, the underlying architecture of LLMs cautions against both uses. Answers provided by LLMs in response to open scientific questions can often be incorrect, or irrelevant, necessitating factual checking from the human user, whilst using LLMs to summarise research produces fabricated references <ref type="bibr" target="#b27">(Giray, 2023)</ref>. These false references may be entirely madeup, or legitimate articles with errors, making it difficult for researchers to distinguish between the legitimate and illegitimate. Furthermore, using LLMs to summarise research areas has been found to generate inaccuracies compared to the published original work <ref type="bibr" target="#b60">(Semrl et al., 2023)</ref>. Paradoxically, however, the same study also demonstrated an ability to generate conclusions from provided abstracts indistinguishable from human-generated summaries, demonstrating an efficacy towards specific uses.</p><p>More recently, the performance of LLMs towards summarizing literature has improved due to the development of advanced models with larger training sets. Advanced and specialized search engines primarily implementing GPT-4 (e.g., SciSpace) can highlight relevant papers with fewer hallucinations and false references than earlier models. Whilst promising, these tools are still in their infancy and face several challenges, including hallucination and relevancy of papers to the prompt. Models trained upon enormous volumes of data are still commonly not able to provide the domain-specific accuracy and precision in the information retrieved often essential for literature reviews <ref type="bibr" target="#b64">(Susnjak et al., 2024)</ref>. One strategy restricts LLMs to aiding specific components of the literature review. For example, ChatGPT is able to generate research questions, suggest research terms and performs well in filtering and categorizing articles, rivalling human performance for certain review tasks including title/abstract screening, full-text review and data extraction <ref type="bibr" target="#b41">(Khraisha et al., 2024)</ref>. A two-stage hybrid model where LLMs identify relevant papers and themes, for the subsequent human-centred screening of relevant material presents one such approach <ref type="bibr" target="#b75">(Ye et al., 2024)</ref>, reducing errors and improving the accuracy of the literature review compared to a human-only workflow. Similar hybrid frameworks have been proposed for identifying elements in empirical papers, where LLMs present a time-and cost-effective approach whilst maintaining the accuracy observed in human reviewers <ref type="bibr" target="#b67">(Uittenhove et al., 2024)</ref>.</p><p>Using LLMs for proof-reading, editing, and shortening original text generated by the user are generally less contested within academia, as this occurs at the end of the creative process and leads to only minor changes from the original text. Some have likened this particular use of LLMs akin to asking a friend or colleague to proof-read a writing sample, which is unlikely to raise ethical concerns such as plagiarism that may arise under text summarization and generation <ref type="bibr" target="#b54">(Meyer et al., 2023)</ref>. Whilst early models were only able to process prompts in the form of text, more recently developed models can process entire documents, providing feedback on manuscripts within the order of seconds. Indeed, some authors when presented with LLM-generated feedback on their published articles, find it helpful and more beneficial than feedback from some human reviewers <ref type="bibr" target="#b49">(Liang et al., 2023)</ref>. However, base models such as GPT-4 have been criticized for producing generic, nonmeaningful comments, leading for tailored frameworks to be developed. Such frameworks typically levy multiple LLMs, assigning each LLM a specific task ultimately providing more meaningful and specific comments than the conventional single-model approach (D' <ref type="bibr">Arcy et al., 2024)</ref>. In any case, the accessibility of proof-reading and editing services through LLMs can additionally provide highquality English language to non-native speakers and early-career researchers who would otherwise be placed at a disadvantage when submitting publications <ref type="bibr" target="#b60">(Semrl et al., 2023)</ref>. Proof-reading in the academic sphere can also be implemented to facilitate grant writing <ref type="bibr" target="#b54">(Meyer et al., 2023)</ref> and to aid peer review <ref type="bibr" target="#b32">(Hosseini &amp; Horbach, 2023)</ref>, allowing academics to focus more on new research.</p><p>LLMs, whilst able to summarise and generate text as part of the academic writing process, currently demonstrate limitations in accuracy and legitimacy in certain domains, benefitting understanding and text analysis tasks more compared to literature review tasks. Therefore, whilst LLMs are able to rapidly generate a rapid, general overview of a subject, they currently fall short of being able to generate a literature review of the standards required in academia <ref type="bibr" target="#b76">(Zimmermann et al., 2024)</ref>. Assigning certain components of the workflow (e.g., identifying relevant papers) to LLMs can present a more time-effective approach whilst maintaining accuracy. Similar to other uses, benchmarking performance specific to searching and summarising scientific literature is key for identifying their strengths and limitations within this space and supports the ongoing development of LLM workflows in scientific literature analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simulating human participants with large language models</head><p>Multiple fields of research including psychology, sociology, economics, and neuroscience utilise experiments to assess behaviors as part of their research methodology repertoire. However, despite its importance and usefulness, this process has several challenges and potential limitations, including high financial costs and data quality concerns. Furthermore, human participants testing is also slowed by usually time-consuming ethical and practical components of the research process, requiring informed consent from participants, ethical approval, and additional requirements necessary for studying vulnerable groups. Some of the limitations and challenges associated with running behavioral experiments may therefore be avoided by employing artificial agents, with LLMs substituting for human participants.</p><p>Before diving into how LLMs can be useful in understanding human cognition, it is, first of all, important to unpack what "ability" is entailed in LLMs. One of the original motivations of developing LLMs and/or generative AI was to develop machines that could "think like humans" <ref type="bibr" target="#b46">(Lake et al., 2017)</ref>. The capacity of LLMs to do so stems from the numerous computational properties that allow these models to mimic and imitate human reasoning and inference <ref type="bibr" target="#b2">(Aher et al., 2023)</ref>. Certain models are further able to exhibit complex behavior consistent with mentalistic inference <ref type="bibr" target="#b62">(Strachan et al., 2024)</ref> and demonstrate similar heuristics and context-sensitive responses akin to loss aversion and effort reduction commonly observed in humans <ref type="bibr" target="#b63">(Suri et al., 2024)</ref>. LLMs are also more likely to succeed in some tasks and fail other tasks, just as human participants do <ref type="bibr" target="#b22">(Dasgupta et al., 2023)</ref>, leading for some researchers to state that the particular model tested could pass as a valid subject for some experiments that have been administered <ref type="bibr" target="#b14">(Binz &amp; Schulz, 2023b)</ref>. The appropriability for LLMs to do so is also improving over time, as important differences with human-like reasoning prevalent in older models disappear almost entirely in more recent ones <ref type="bibr" target="#b74">(Yax et al., 2024)</ref>, demonstrating the importance of model size and complexity that could match the richness of human behaviors. Certain LLMs also demonstrate zero-shot learning (or generalisation), the ability to infer on data that the model have never seen in training, by accurately simulating human responses towards previously unseen cognitive tasks <ref type="bibr" target="#b13">(Binz &amp; Schulz, 2023a)</ref>. Future research may seek to train LLMs on additional tasks, and novel tasks may eventually be tested on simulated cohorts, reducing time and financial costs in developing behavioral studies.</p><p>LLMs can also be experimentally induced into specific behavioral states through prompt engineering. For example, prompting LLMs with positive or negative components (e.g., adding the suffix 'This is very important to my career' or 'Perhaps this task is just beyond your skill set') has been found to affect the response generated <ref type="bibr" target="#b48">(Li et al., 2023;</ref><ref type="bibr" target="#b71">X. Wang et al., 2024)</ref>. This approach has subsequently been applied to understand psychopathology by inducing behavioral states observed among human cohorts with mental health conditions. By experimentally manipulating the level of 'anxiety' through anxiety-inducing and happiness-inducing scenarios, GPT-3.5 recreates performance characteristics observed in humans with high anxiety during a simple multi-armed bandit task, engaging in less exploitation and more exploration, and ultimately leading to worse behavior <ref type="bibr" target="#b17">(Coda-Forno et al., 2023)</ref>. This and similar results have far-reaching implications for validating diagnostic measures and determining the efficacy of cognitive therapies, potentially in combination with computational and neuroimaging data of mental health conditions <ref type="bibr" target="#b61">(Sohail &amp; Zhang, 2024)</ref>. Indeed, mindful-based interventions have been shown to reduce high levels of anxiety experimentally induced through traumatic narratives <ref type="bibr" target="#b12">(Ben-Zion et al., 2024)</ref>. As engineering positively themed prompts to LLMs shares similarities with delivering cognitive-based therapies in humans, prompts can be firstly finetuned in LLMs, with winning prompts subsequently tested in human patients. Early research has implemented such an LLM-informed treatment approach by generating dialogue systems based on Cognitive Behavioral Therapy (CBT) scenarios. Subsequently, patients report improved mood change and empathy to prompts generated by GPT-4, with no improvements to those generated by a dialogue model <ref type="bibr" target="#b37">(Izumi et al., 2024)</ref>.</p><p>Future studies could further utilize the same framework (i.e., first establish protocols in LLMs, then test it in humans) to investigate developmental psychopathology. Large language models display a pattern of increasing cognitive ability and rising language complexity in correspondence with child development, if prompted to do so <ref type="bibr" target="#b55">(Milička et al., 2024)</ref>. However, in the same study, task type, prompt type, and the choice of language model were all found to influence developmental patterns, demonstrating variability with this approach. Whilst LLMs offer a novel framework towards understanding human development, cognitive processes arising during childhood such as conceptual abstraction, should ideally be assessed using different tasks, and at multiple time points <ref type="bibr" target="#b25">(Frank, 2023)</ref>. Altogether, this recent and exciting field reflects similarities in computation between humans and machines, with the potential for a computational psychiatric approach <ref type="bibr" target="#b59">(Schulz &amp; Dayan, 2020)</ref>, informed by large language models. Whilst LLMs can -in principle -be used as proxies for human participants, some have advised that this should only be done "when studying specific topics, when using specific tasks, at specific research stages, and when simulating specific samples" <ref type="bibr" target="#b24">(Dillion et al., 2023)</ref>, reflecting the differences in cognition and behavior observed between humans and machines (Figure <ref type="figure" target="#fig_0">2</ref>.). Albeit the important insights LLMs can offer in simulating human behaviors, LLMs have been shown to perform differently to human participants in many cognitive tasks, such as those necessitating directed exploration and causal reasoning <ref type="bibr" target="#b14">(Binz &amp; Schulz, 2023b)</ref>, and during finitely-repeated economic games <ref type="bibr" target="#b3">(Akata et al., 2023)</ref>. Further differences between LLM and human task performance are illuminated through the "correct answer" effect, where questions probing political orientation, economic preference, judgement, and moral philosophy are answered with zero or near-zero variation <ref type="bibr" target="#b56">(Park et al., 2023)</ref>, ruling out the substitution of LLMs as human participants for certain tasks.</p><p>There are also questions into whether LLMs should be used at all in this manner concerning generalisability, as the training sets of LLMs are "HYPER-WEIRD", overinfluenced by those from Western, Educated, Industrialized, Rich, Democratic (WEIRD) countries as well as those with attitudes that are Hegemonic, Young, and Publicly ExpRessed <ref type="bibr" target="#b19">(Crockett &amp; Messeri, 2023)</ref>. Consequently, these models may lack sufficient diversity in their responses to accurately represent a representative population sample (A. <ref type="bibr">Wang et al., 2024</ref>). ChatGPT, for example, demonstrates gender <ref type="bibr" target="#b26">(Ghosh &amp; Caliskan, 2023)</ref>, cultural <ref type="bibr" target="#b15">(Cao et al., 2023)</ref>, and political <ref type="bibr" target="#b30">(Hartmann et al., 2023)</ref> biases in its responses, and shows significantly less variance compared to human participants across a range of self-report measures spanning various psychological domains, such as personality, cognition, political orientation, and emotions <ref type="bibr" target="#b8">(Atari et al., 2023)</ref>. Indeed, GPT-4 has been described as having both increased honesty and humility and demonstrating masculine and anxious traits <ref type="bibr" target="#b11">(Barua et al., 2024)</ref>. Substituting participants for LLMs could therefore propagate the over-sampling of a specific sub-population, the antithesis of psychological research which is often to obtain samples from and to make inferences towards diverse populations. In addition, LLMs also demonstrate -relative to human responses -increased susceptibility to biases such as irrationality <ref type="bibr" target="#b5">(Alsagheer et al., 2024)</ref>, and response inconsistency (Macmillan-Scott &amp; Musolesi, 2024), and are influenced by unknowingly biased features of model inputs, including language <ref type="bibr" target="#b28">(Goli &amp; Singh, 2024)</ref>. Despite these concerns, LLMs provide a tangible benefit as proxies for human participants for specific experimental designs not susceptible to cognitive or variational biases. Looking forward, this promising field should further identify the similarities and differences between LLMs and human behavior by developing testable and ethologically meaningful benchmarks <ref type="bibr" target="#b33">(Huang et al., 2024)</ref>, frameworks guiding experimenters whether to integrate LLM-generated data into their research pipeline, and prompt datasets for mitigating against cognitive biases. Furthermore, making publicly available articles, tutorials, and notebooks detailing how the lay-psychology researcher can substitute LLMs for human participants <ref type="bibr" target="#b35">(Hussain et al., 2023)</ref> will make this often technically difficult research more accessible within the psychological sciences. It is worth noting several challenges towards future development in this vein. Developing benchmarks for social biases are often subjective and context-dependent, and are not detected by automated benchmarks and objective metrics such as accuracy <ref type="bibr" target="#b7">(Aoyagui et al., 2024)</ref>. Furthermore, the varying accuracy observed between different models and human responses with defining broad concepts has led for some to necessitate the definition of more specified cognitive measures <ref type="bibr" target="#b4">(Almeida et al., 2024)</ref>. In the face of these challenges, if appropriately used, LLMs have the potential to significantly change how academic experiments are conducted <ref type="bibr" target="#b34">(Huijzer &amp; Hill, 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>LLMs contest a highly debated area of academic research including the psychological sciences. Whilst it is not quite the 'academic panacea' <ref type="bibr">(Quintans-Júnior et al., 2023</ref>) some have made it to be, LLMs constitute an integral part of the academic workflow for an increasing number. Academics currently use LLMs to write essays and talks, summarize literature, draft and improve papers, identify research gaps, write computer code and perform statistical analyses. As time progresses, this capability will only increase, evolving to the point that LLMs are expected to design experiments, write and complete manuscripts, conduct peer review and support editorial decisions to accept or reject manuscripts. Furthermore, domain-specific LLMs will further increase academic performance and productivity within specific fields. For those with little experience, a progressive adoption model, where LLMs are gradually incorporated into academic work is recommended. Whilst managing a balance between efficiency and legitimacy of both teaching and research will be a difficult challenge, we nevertheless advocate for LLMs to be openly endorsed by academics in psychology and beyond.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Considerations of employing large language models (LLMs) as proxies for human participants. (A) Models are trained upon large quantities of online data influenced by those with access to the internet, unrepresentative of the human population. (B) LLMs demonstrate several biases including cognitive, racial, gender and political inclinations in their responses to specific prompts. (C) In response to questions probing political orientation, economic preference, and moral philosophy, human cohorts demonstrate significant response variability whereas LLMs demonstrate near-zero variation, a phenomenon dubbed the 'correct answer effect'. (D) Prompt engineering significantly influences the response provided by LLMs, whilst having little effect on human-based reasoning<ref type="bibr" target="#b74">(Yax et al., 2024)</ref>. Depicted is the 'Chain-of-Thought' prompt engineering strategy which improves LLMbased reasoning by breaking down the response into discrete steps. Icons by Icons8.</figDesc><graphic coords="9,109.25,125.71,376.23,255.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="4,151.48,72.00,292.05,268.83" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>One of the example guidance is from the authors' affiliation: University of Birmingham (UK)'s Student guidance on using Generative Artificial Intelligence tools ethically for study. [retrieved on 09 July</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p>2024]. https://intranet.birmingham.ac.uk/as/libraryservices/asc/student-guidance-gai.aspx</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>is supported by an <rs type="funder">MRC</rs> <rs type="grantName">AIM iCASE Grant</rs> (Ref: <rs type="grantNumber">MR/W007002/1</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_qPDVSFq">
					<idno type="grant-number">MR/W007002/1</idno>
					<orgName type="grant-name">AIM iCASE Grant</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Abdurahman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Atari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Karimi-Malekabadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Trager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Golazizian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Omrani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/d695y</idno>
		<ptr target="https://doi.org/10.31234/osf.io/d695y" />
		<title level="m">Perils and Opportunities in Using Large Language Models in Psychological Research</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Suzgun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mackey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Kalai</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.18248</idno>
		<idno type="arXiv">arXiv:2305.18248</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.18248" />
		<title level="m">Do Language Models Know When They&apos;re Hallucinating References?</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">G</forename><surname>Aher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">I</forename><surname>Arriaga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Kalai</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2208.10264</idno>
		<idno type="arXiv">arXiv:2208.10264</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2208.10264" />
		<title level="m">Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Coda-Forno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.16867</idno>
		<idno type="arXiv">arXiv:2305.16867</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.16867" />
		<title level="m">Playing repeated games with Large Language Models</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exploring the psychology of LLMs&apos; moral and legal reasoning</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">F C F</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Nunes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Araújo</surname></persName>
		</author>
		<author>
			<persName><surname>De</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2024.104145</idno>
		<ptr target="https://doi.org/10.1016/j.artint.2024.104145" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">333</biblScope>
			<biblScope unit="page">104145</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Alsagheer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Karanjai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Diallo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Beydoun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2403.09798</idno>
		<idno type="arXiv">arXiv:2403.09798</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2403.09798" />
		<title level="m">Comparing Rationality Between Large Language Models and Humans: Insights and Open Questions</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Is using ChatGPT cheating, plagiarism, both, neither, or forward thinking?</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Anders</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.patter.2023.100694</idno>
		<ptr target="https://doi.org/10.1016/j.patter.2023.100694" />
	</analytic>
	<monogr>
		<title level="j">Patterns</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">100694</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Aoyagui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kuzminykh</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2405.11048</idno>
		<idno type="arXiv">arXiv:2405.11048</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2405.11048" />
		<title level="m">Exploring Subjectivity for more Human-Centric Assessment of Social Biases in Large Language Models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">M</forename><surname>Atari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Blasi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Henrich</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/5b26t</idno>
		<ptr target="https://doi.org/10.31234/osf.io/5b26t" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>Which Humans? OSF</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The interactive reading task: Transformer-based automatic item generation</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Attali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Runge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">T</forename><surname>Laflair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Yancey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Goodwin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Davier</surname></persName>
		</author>
		<idno type="DOI">10.3389/frai.2022.903077</idno>
		<ptr target="https://doi.org/10.3389/frai.2022.903077" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Barrett</surname></persName>
		</author>
		<ptr target="https://salford-repository.worktribe.com/output/1472770" />
		<title level="m">The management of academic workloads: Full report on findings</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Brase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hitzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Vasserman</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2402.01777</idno>
		<idno type="arXiv">arXiv:2402.01777</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2402.01777" />
		<title level="m">On the Psychology of GPT-4: Moderately anxious, slightly masculine, honest, and humble</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">Z</forename><surname>Ben-Zion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Witte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Duek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Harpaz-Rotem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-C</forename><surname>Khorsandian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Burrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Seifritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Homan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Spiller</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/j7fwb</idno>
		<ptr target="https://doi.org/10.31234/osf.io/j7fwb" />
		<title level="m">Chat-GPT on the Couch&quot;: Assessing and Alleviating State Anxiety in Large Language Models. OSF</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2306.03917</idno>
		<idno type="arXiv">arXiv:2306.03917</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2306.03917" />
		<title level="m">Turning large language models into cognitive models</title>
		<imprint>
			<date type="published" when="2023">2023a</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Using cognitive psychology to understand GPT-3</title>
		<author>
			<persName><forename type="first">M</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.2218523120</idno>
		<ptr target="https://doi.org/10.1073/pnas.2218523120" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">2218523120</biblScope>
			<date type="published" when="2023">2023b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cabello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hershcovich</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.17466</idno>
		<idno type="arXiv">arXiv:2303.17466</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.17466" />
		<title level="m">Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">How is ChatGPT&apos;s behavior changing over time?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zaharia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2307.09009</idno>
		<idno type="arXiv">arXiv:2307.09009</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2307.09009" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Coda-Forno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Witte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Jagadish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2304.11111</idno>
		<idno type="arXiv">arXiv:2304.11111</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2304.11111" />
		<title level="m">Inducing anxiety in large language models increases exploration and bias</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Chatting and cheating: Ensuring academic integrity in the era of ChatGPT</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R E</forename><surname>Cotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Cotton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Shipway</surname></persName>
		</author>
		<idno type="DOI">10.1080/14703297.2023.2190148</idno>
		<ptr target="https://doi.org/10.1080/14703297.2023.2190148" />
	</analytic>
	<monogr>
		<title level="j">Innovations in Education and Teaching International</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Crockett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Messeri</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/4zdx9</idno>
		<ptr target="https://doi.org/10.31234/osf.io/4zdx9" />
		<title level="m">Should large language models replace human participants? PsyArXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>D'arcy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Hope</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Downey</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2401.04259</idno>
		<idno type="arXiv">arXiv:2401.04259</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2401.04259" />
		<title level="m">MARG: Multi-Agent Review Generation for Scientific Papers</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">AI4LA: An Intelligent Chatbot for Supporting Students with Dyslexia, Based on Generative AI</title>
		<author>
			<persName><forename type="first">S</forename><surname>D'urso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sciarrone</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-63028-6_31</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-63028-6_31" />
	</analytic>
	<monogr>
		<title level="m">Generative Intelligence and Intelligent Tutoring Systems</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Sifaleras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Lin</surname></persName>
		</editor>
		<meeting><address><addrLine>Nature Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="369" to="377" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Lampinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C Y</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Sheahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kumaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2207.07051</idno>
		<idno type="arXiv">arXiv:2207.07051</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2207.07051" />
		<title level="m">Language models show human-like content effects on reasoning tasks</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using large language models in psychology</title>
		<author>
			<persName><forename type="first">D</forename><surname>Demszky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Yeager</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Bryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Clapper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chandhok</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Eichstaedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Krettek-Cobb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Jonesmitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Dweck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<idno type="DOI">10.1038/s44159-023-00241-5</idno>
		<ptr target="https://doi.org/10.1038/s44159-023-00241-5" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Psychology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="688" to="701" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Can AI language models replace human participants?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dillion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tandon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2023.04.008</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2023.04.008" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="597" to="600" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Baby steps in evaluating the capacities of large language models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.1038/s44159-023-00211-x</idno>
		<ptr target="https://doi.org/10.1038/s44159-023-00211-x" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Psychology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="451" to="452" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caliskan</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.10510</idno>
		<idno type="arXiv">arXiv:2305.10510</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.10510" />
		<title level="m">ChatGPT Perpetuates Gender Bias in Machine Translation and Ignores Non-Gendered Pronouns: Findings across Bengali and Five other Low-Resource Languages</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">ChatGPT References Unveiled: Distinguishing the Reliable from the Fake</title>
		<author>
			<persName><forename type="first">L</forename><surname>Giray</surname></persName>
		</author>
		<idno type="DOI">10.1080/10875301.2023.2265369</idno>
		<ptr target="https://doi.org/10.1080/10875301.2023.2265369" />
	</analytic>
	<monogr>
		<title level="j">Internet Reference Services Quarterly</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Goli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.1287/mksc.2023.0306</idno>
		<ptr target="https://doi.org/10.1287/mksc.2023.0306" />
		<title level="m">Frontiers: Can Large Language Models Capture Human Preferences? Marketing Science</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">AI language models cannot replace human research participants</title>
		<author>
			<persName><forename type="first">J</forename><surname>Harding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>D'alessandro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Laskowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Long</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-023-01725-x</idno>
		<ptr target="https://doi.org/10.1007/s00146-023-01725-x" />
	</analytic>
	<monogr>
		<title level="j">AI &amp; SOCIETY</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schwenzow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Witte</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2301.01768</idno>
		<idno type="arXiv">arXiv:2301.01768</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2301.01768" />
		<title level="m">The political ideology of conversational AI: Converging evidence on ChatGPT&apos;s pro-environmental, left-libertarian orientation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Horton</surname></persName>
		</author>
		<idno type="DOI">10.3386/w31122</idno>
		<ptr target="https://doi.org/10.3386/w31122" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>National Bureau of Economic Research</publisher>
		</imprint>
	</monogr>
	<note>Working Paper 31122</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Fighting reviewer fatigue or amplifying bias? Considerations and recommendations for use of ChatGPT and other large language models in scholarly peer review</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P J M</forename><surname>Horbach</surname></persName>
		</author>
		<idno type="DOI">10.1186/s41073-023-00133-5</idno>
		<ptr target="https://doi.org/10.1186/s41073-023-00133-5" />
	</analytic>
	<monogr>
		<title level="j">Research Integrity and Peer Review</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2310.01386</idno>
		<idno type="arXiv">arXiv:2310.01386</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2310.01386" />
		<title level="m">Who is ChatGPT? Benchmarking LLMs&apos; Psychological Portrayal Using PsychoBench</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Huijzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Hill</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/munc9</idno>
		<ptr target="https://doi.org/10.31234/osf.io/munc9" />
		<title level="m">Large Language Models Show Human Behavior</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">A tutorial on open-source large language models for behavioral science</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Hussain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Binz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">U</forename><surname>Wulff</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/f7stn</idno>
		<ptr target="https://doi.org/10.31234/osf.io/f7stn" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Rethinking Plagiarism in the Era of Generative AI</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hutson</surname></persName>
		</author>
		<idno type="DOI">10.54963/jic.v4i1.220</idno>
		<ptr target="https://doi.org/10.54963/jic.v4i1.220" />
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligent Communication</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Izumi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Shidara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Adachi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kanayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nakamura</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2401.15966</idno>
		<idno type="arXiv">arXiv:2401.15966</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2401.15966" />
		<title level="m">Response Generation for Cognitive Behavioral Therapy with Large Language Models: Comparative Study with Socratic Questioning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The Impact of Large Language Models on Programming Education and Student Learning Outcomes</title>
		<author>
			<persName><forename type="first">G</forename><surname>Jošt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Taneski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Karakatič</surname></persName>
		</author>
		<idno type="DOI">10.3390/app14104115</idno>
		<ptr target="https://doi.org/10.3390/app14104115" />
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Kabir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">N</forename><surname>Udo-Imeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2308.02312</idno>
		<idno type="arXiv">arXiv:2308.02312</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2308.02312" />
		<title level="m">Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Peng</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2401.01519</idno>
		<idno type="arXiv">arXiv:2401.01519</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2401.01519" />
		<title level="m">Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Can large language models replace humans in systematic reviews? Evaluating GPT-4&apos;s efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Khraisha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Put</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kappenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Warraitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hadfield</surname></persName>
		</author>
		<idno type="DOI">10.1002/jrsm.1715</idno>
		<ptr target="https://doi.org/10.1002/jrsm.1715" />
	</analytic>
	<monogr>
		<title level="j">Research Synthesis Methods</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">ChatGPT-A Challenging Tool for the University Professors in Their Teaching Practice</title>
		<author>
			<persName><forename type="first">G</forename><surname>Kiryakova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Angelova</surname></persName>
		</author>
		<idno type="DOI">10.3390/educsci13101056</idno>
		<ptr target="https://doi.org/10.3390/educsci13101056" />
	</analytic>
	<monogr>
		<title level="j">Education Sciences</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Large Language Models are Zero-Shot Reasoners</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kojima</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">(</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">)</forename><surname>Shane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Iwasawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="22199" to="22213" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Tailoring university assessment in the age of ChatGPT</title>
		<author>
			<persName><forename type="first">J</forename><surname>Koplin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sparrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hatherley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rivers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Williams</surname></persName>
		</author>
		<ptr target="https://lens.monash.edu/@politics-society/2023/05/15/1385696?slug=tailoring-university-assessment-in-the-age-of-chatgpt" />
		<imprint>
			<date type="published" when="2023-05-15">2023. May 15</date>
			<pubPlace>Monash Lens</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<author>
			<persName><forename type="first">G</forename><surname>Kurtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Amzalag</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zaguri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kohen-Vacs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zailer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barak-Medina</surname></persName>
		</author>
		<idno type="DOI">10.3390/educsci14050503</idno>
		<ptr target="https://doi.org/10.3390/educsci14050503" />
	</analytic>
	<monogr>
		<title level="m">Strategies for Integrating Generative AI into Higher Education: Navigating Challenges and Leveraging Opportunities</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">14</biblScope>
		</imprint>
	</monogr>
	<note>Article 5</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<idno type="DOI">10.1017/S0140525X16001837</idno>
		<ptr target="https://doi.org/10.1017/S0140525X16001837" />
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="page" from="40" to="e253" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A shift towards oration: Teaching philosophy in the age of large language models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lemasters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hurshman</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-024-00455-0</idno>
		<ptr target="https://doi.org/10.1007/s43681-024-00455-0" />
	</analytic>
	<monogr>
		<title level="j">AI and Ethics</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Large Language Models Understand and Can be Enhanced by Emotional Stimuli</title>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2307.11760</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2307.11760" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>In arXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<author>
			<persName><forename type="first">W</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vodrahalli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcfarland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2310.01783</idno>
		<idno type="arXiv">arXiv:2310.01783</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2310.01783" />
		<title level="m">Can large language models provide useful feedback on research papers? A large-scale empirical analysis</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">How to write effective prompts for large language models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-024-01847-2</idno>
		<ptr target="https://doi.org/10.1038/s41562-024-01847-2" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behavior</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="611" to="615" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">What Is the Impact of ChatGPT on Education? A Rapid Review of the Literature</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Lo</surname></persName>
		</author>
		<idno type="DOI">10.3390/educsci13040410</idno>
		<ptr target="https://doi.org/10.3390/educsci13040410" />
	</analytic>
	<monogr>
		<title level="j">Education Sciences</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">(Ir)rationality and cognitive biases in large language models</title>
		<author>
			<persName><forename type="first">O</forename><surname>Macmillan-Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Musolesi</surname></persName>
		</author>
		<idno type="DOI">10.1098/rsos.240255</idno>
		<ptr target="https://doi.org/10.1098/rsos.240255" />
	</analytic>
	<monogr>
		<title level="j">Royal Society Open Science</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">240255</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Artificial intelligence and illusions of understanding in scientific research</title>
		<author>
			<persName><forename type="first">L</forename><surname>Messeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Crockett</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41586-024-07146-0</idno>
		<ptr target="https://doi.org/10.1038/s41586-024-07146-0" />
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">627</biblScope>
			<biblScope unit="issue">8002</biblScope>
			<biblScope unit="page" from="49" to="58" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">ChatGPT and large language models in academia: Opportunities and challenges</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Urbanowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C N</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>O'connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Bright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Tatonetti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gonzalez-Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Moore</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13040-023-00339-9</idno>
		<ptr target="https://doi.org/10.1186/s13040-023-00339-9" />
	</analytic>
	<monogr>
		<title level="j">BioData Mining</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">20</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Large language models are able to downplay their cognitive abilities to fit the persona they simulate</title>
		<author>
			<persName><forename type="first">J</forename><surname>Milička</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marklová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vanslambrouck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pospíšilová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Šimsová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Harvan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Drobil</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0298522</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0298522" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">298522</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schoenegger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhu</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2302.07267</idno>
		<idno type="arXiv">arXiv:2302.07267</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2302.07267" />
		<title level="m">Diminished Diversity-of-Thought in a Standard Large Language Model</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><surname>Plevris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Papazafeiropoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Rios</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.18618</idno>
		<idno type="arXiv">arXiv:2305.18618</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.18618" />
		<title level="m">Chatbots put to the test in math and logic problems: A preliminary comparison and assessment of ChatGPT-3.5, ChatGPT-4, and Google Bard</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Can artificial intelligence help for scientific writing?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Salvagno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">S</forename><surname>Taccone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Gerli</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13054-023-04380-2</idno>
		<ptr target="https://doi.org/10.1186/s13054-023-04380-2" />
	</analytic>
	<monogr>
		<title level="j">Critical Care</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">75</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Computational Psychiatry for Computers. iScience</title>
		<author>
			<persName><forename type="first">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.isci.2020.101772</idno>
		<ptr target="https://doi.org/10.1016/j.isci.2020.101772" />
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">101772</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">AI language models in human reproduction research: Exploring ChatGPT&apos;s potential to assist academic writing</title>
		<author>
			<persName><forename type="first">N</forename><surname>Semrl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Feigl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Taumberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bracic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Fluhr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Blockeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kollmann</surname></persName>
		</author>
		<idno type="DOI">10.1093/humrep/dead207</idno>
		<ptr target="https://doi.org/10.1093/humrep/dead207" />
	</analytic>
	<monogr>
		<title level="j">Human Reproduction</title>
		<imprint>
			<biblScope unit="page">207</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Informing the treatment of social anxiety disorder with computational and neuroimaging data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Sohail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1093/psyrad/kkae010</idno>
		<ptr target="https://doi.org/10.1093/psyrad/kkae010" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>Psychoradiology, 4, kkae010</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Testing theory of mind in large language models and humans</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W A</forename><surname>Strachan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Albergo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Borghini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Pansardi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Scaliti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rufo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Panzeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Manzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S A</forename><surname>Graziano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Becchio</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-024-01882-z</idno>
		<ptr target="https://doi.org/10.1038/s41562-024-01882-z" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behavior</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Do large language models show decision heuristics similar to humans? A case study using GPT-3.5</title>
		<author>
			<persName><forename type="first">G</forename><surname>Suri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Slater</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ziaee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nguyen</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0001547</idno>
		<ptr target="https://doi.org/10.1037/xge0001547" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1066" to="1075" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Susnjak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Reyes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L C</forename><surname>Barczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Mcintosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ranathunga</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2404.08680</idno>
		<idno type="arXiv">arXiv:2404.08680</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2404.08680" />
		<title level="m">Automating Research Synthesis with Domain-Specific Large Language Model Fine-Tuning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Tanay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Arinze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Davis</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2403.18679</idno>
		<idno type="arXiv">arXiv:2403.18679</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2403.18679" />
		<title level="m">An Exploratory Study on Upper-Level Computing Students&apos; Use of Large Language Models as Tools in a Semester-Long Project</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-C</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Bissyandé</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2304.11938</idno>
		<ptr target="http://arxiv.org/abs/2304.11938" />
		<title level="m">Is ChatGPT the Ultimate Programming Assistant-How far is it?</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Large Language Models in Psychology: Application in the Context of a Systematic Literature Review</title>
		<author>
			<persName><forename type="first">K</forename><surname>Uittenhove</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Martinelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Roquet</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/nq4d2</idno>
		<ptr target="https://doi.org/10.31234/osf.io/nq4d2" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">ChatGPT in programming education: ChatGPT as a programming assistant. InspirED Teachers&apos; Voice</title>
		<author>
			<persName><forename type="first">M</forename><surname>Vukojičić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Krstić</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">2023</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Thought and Language, revised and expanded edition</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Vygotsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Dickerson</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2402.01908</idno>
		<idno type="arXiv">arXiv:2402.01908</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2402.01908" />
		<title level="m">Large language models cannot replace human participants because they cannot portray identity groups</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2405.02814</idno>
		<idno type="arXiv">arXiv:2405.02814</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2405.02814" />
		<title level="m">NegativePrompt: Leveraging Psychology for Large Language Models Enhancement via Negative Emotional Stimuli</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Linghu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Grazian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Razzak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hoex</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2308.13565</idno>
		<idno type="arXiv">arXiv:2308.13565</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2308.13565" />
		<title level="m">DARWIN Series: Domain Specific Large Language Models for Natural Science</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Practical and Ethical Challenges of Large Language Models in Education: A Systematic Scoping Review</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Sha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Martinez-Maldonado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gašević</surname></persName>
		</author>
		<idno type="DOI">10.1111/bjet.13370</idno>
		<idno>bjet.13370</idno>
		<ptr target="https://doi.org/10.1111/bjet.13370" />
	</analytic>
	<monogr>
		<title level="j">British Journal of Educational Technology</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Studying and improving reasoning in humans and machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Yax</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Anlló</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.1038/s44271-024-00091-8</idno>
		<ptr target="https://doi.org/10.1038/s44271-024-00091-8" />
	</analytic>
	<monogr>
		<title level="j">Communications Psychology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">A Hybrid Semi-Automated Workflow for Systematic and Literature Review Processes with Large Language Model Analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Maiti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Pedersen</surname></persName>
		</author>
		<idno type="DOI">10.3390/fi16050167</idno>
		<ptr target="https://doi.org/10.3390/fi16050167" />
	</analytic>
	<monogr>
		<title level="j">Future Internet</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>Article 5</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Leveraging Large Language Models for Literature Review Tasks-A Case Study Using ChatGPT</title>
		<author>
			<persName><forename type="first">R</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Staab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Nasseri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Brandtner</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-48858-0_25</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-48858-0_25" />
	</analytic>
	<monogr>
		<title level="m">Advanced Research in Technologies, Information, Innovation and Sustainability</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Guarda</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Portela</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Diaz-Nafria</surname></persName>
		</editor>
		<meeting><address><addrLine>Nature Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Merrill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.13534</idno>
		<idno type="arXiv">arXiv:2305.13534</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.13534" />
		<title level="m">How Language Model Hallucinations Can Snowball</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kilhoffer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Sanfilippo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Underwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gumusel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Choudhry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2401.12453</idno>
		<idno type="arXiv">arXiv:2401.12453</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2401.12453" />
		<title level="m">The teachers are confused as well&apos;: A Multiple-Stakeholder Ethics Discussion on Large Language Models in Computing Education</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
