<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Running head: RANKING VERSUS BEST-WORST SCALING</title>
				<funder ref="#_j2gtbTf">
					<orgName type="full">Australian Research Council</orgName>
				</funder>
				<funder>
					<orgName type="full">joint</orgName>
				</funder>
				<funder>
					<orgName type="full">MURI-AUSMURI in Cybersecurity Assurance for Teams of Computers and Humans</orgName>
					<orgName type="abbreviated">CATCH</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Garston</forename><surname>Liang</surname></persName>
							<email>garston.liang@gmail.com</email>
						</author>
						<author>
							<persName><forename type="first">Mackenzie</forename><surname>Glover</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Guy</forename><forename type="middle">E</forename><surname>Hawkins</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Psychological Sciences</orgName>
								<orgName type="institution">University of Newcastle</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Psychological Science</orgName>
								<orgName type="institution">University of Newcastle</orgName>
								<address>
									<addrLine>Callaghan</addrLine>
									<postCode>2308.</postCode>
									<settlement>Newcastle</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Running head: RANKING VERSUS BEST-WORST SCALING</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5B477EFF7EC198CBA7564DA756AE70C0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-22T20:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ranking</term>
					<term>best-worst scaling</term>
					<term>preference elicitation</term>
					<term>reliability</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Two popular methods of preference elicitation are rankings and Best-Worst Scaling (BWS).</p><p>Rankings, while simple and widely adopted, can be burdensome with larger item sets and fail to capture indifference between options that are neither loved nor hated. Best-Worst Scaling is a survey method that sidesteps the set size problem by capitalising on people's natural capacity to identify preferences at the extremes. Across three experiments, our primary finding is that elicited preferences for ranking and BWS methods align, and that BWS methods provide additional resolution to resolve the indifference between middling options where rankings can struggle as well as the relative importance of each option.</p><p>Moreover, we show that BWS methods exhibit greater test-retest reliability compared to rankings, even over time frames as short as minutes. Taken together, our results privilege BWS as a reliable and readily accessible alternative to ranking methods for preference elicitation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>If Christmas dinner conversation ever needed more spice, arguing over the best era of music might just do it. All of a sudden, an ordinarily quiet uncle rambles on about The Beatles, music of someone's good-old-days is clearly the best, and modern pop music is unquestionably the worst. This might not be the most agreeable conversation between generations (Van Dam, 2024) but, perhaps, it is a familiar one where the range of preferences is immediately clear and how one asks about these preferences matters. Beyond the dinner table, eliciting preferences is a foundational component to understanding a range of complex decisions including health care choices, consumer preferences, and political polling <ref type="bibr" target="#b0">(Cooper &amp; Hawkins, 2019;</ref><ref type="bibr" target="#b15">Ryan, 2004;</ref><ref type="bibr" target="#b20">Viney et al., 2002)</ref>.</p><p>Preference elicitation has a rich history in the psychological and behavioural economics literature <ref type="bibr" target="#b1">(Edwards, 1954;</ref><ref type="bibr" target="#b21">Von Neumann &amp; Morgenstern, 2007)</ref>. A common theoretical framework is to assume that individuals have stable internal representations of their preferences and variability arises from the measurement. Therefore, the choice of elicitation method is centrally important as it provides a window into people's underlying representations, albeit with varying degrees of opacity. Given the many ways to elicit preferences, a critical question is to what extent do common methods agree with one another?</p><p>This paper compares two popular methods of preference elicitation, namely ranking and Best-worst Scaling. Ranking tasks are ubiquitous and favoured for their relative simplicity (M. D. <ref type="bibr" target="#b7">Lee et al., 2012;</ref><ref type="bibr" target="#b13">Montgomery et al., 2024)</ref>. Individuals order a list of items according to some criteria (e.g., most preferred to least preferred music genre, or vice versa). For smaller items sets, e.g., ranking 3 genres, rankings can be easily obtained from relatively few comparisons between the items. However, rankings can be muddied by indifference between options and, particularly for larger sets, the number of comparisons drastically increases, e.g., a top 10 list demands 45 pairwise comparisons <ref type="bibr" target="#b5">(Isaac &amp; Schindler, 2014)</ref>.</p><p>Best-Worst Scaling, henceforth BWS, is a survey method that sidesteps this set size problem by capitalising on people's natural capacity to identify extreme preferences <ref type="bibr" target="#b9">(Louviere et al., 2013)</ref>. Briefly, BWS methods involve individuals indicating their most favoured (i.e., best) and least favoured option (i.e., worst) over multiple sets of options, where each set is composed of different options. Despite its simplicity, elicited preferences from BWS are generally consistent and respondents benefit from the cognitive ease of selecting between options at the extremes from relatively small sets of options <ref type="bibr" target="#b12">(Marley &amp; Louviere, 2005)</ref>.</p><p>In this paper, we directly compare ranking and BWS across three experiments that asked participants about preferences between 10 life values (e.g., rank the importance of benevolence, stimulation, etc., <ref type="bibr" target="#b17">Schwartz, 1994)</ref>. To preface the results, our primary finding is that elicited preferences for ranking and BWS methods are congruent though BWS methods provide the additional resolution to discern indifferences between options where rankings cannot. Additionally, we show that BWS methods exhibit greater test-retest reliability compared to rankings, even within time frames as short as minutes. Taken together, our results privilege BWS as a reliable and readily accessible alternative to ranking methods<ref type="foot" target="#foot_0">foot_0</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preference elicitation</head><p>Best-Worst Scaling is a preference elicitation method that capitalises on the cognitive ease of identifying preferences at the extremes <ref type="bibr" target="#b8">(Louviere et al., 2015)</ref>. In this paper, we consider case 1 'object' BWS methods. Typically, individuals are presented with a set of items and asked to indicate their most preferred and least preferred item within a set (example in Figure <ref type="figure" target="#fig_0">1</ref>). Each item is independent, like a genre of music, and each set contains at least 3 possible alternatives. Repeating these 'best' and 'worst' choices across carefully balanced  <ref type="table" target="#tab_0">1</ref> for full list. In the BWS experiments, participants completed 11 choice sets of best &amp; worst choices, like the screenshot example, across changing subsets of life values. Across subsets, each life value is presented six times in total and each pair of values co-appeared three times. This value-presentation design was imported from the BWS adaptation of Schwartz's Values Theory used in J. A. <ref type="bibr" target="#b6">Lee et al. (2008)</ref>.</p><p>sets reveals for which items decision-makers have clear preferences and for which they entertain trade-offs.</p><p>Beyond ordinal preferences, a core advantage of BWS is that it compares apples with apples. Even when many important but qualitatively different factors are considered, each is placed along a common latent continuum and can be quantitatively weighed against one another. For example in health settings, <ref type="bibr" target="#b2">Ejaz et al. (2014)</ref> asked oncology patients what information helped determine their choice of surgeon. While 'surgeon training' was centrally important to patient decisions, BWS methods provided the added resolution to identify that it was twice as important as 'surgeon experience' and over 3 times more important than the 'hospital's reputation'. Taken together, BWS provide rich data from relatively simple responses to understand the breadth of trade-offs in decision-maker preferences.</p><p>In this domain, ranking tasks are a natural comparison. Ranking is quick, and, for respondents, the goal is immediately apparent even if the exact individual ranks are not.</p><p>These advantages make ranking inherently appealing as a simple, ubiquitous, and relatively inexpensive manner to elicit ordinal preferences.</p><p>A common assumption in the preference elicitation literature is that any method provides imperfect access to the same underlying internal state of preferences. While the internal state remains consistent, expressed preferences might carry perturbations that can arise due to idiosyncratic response styles, such as when some people avoid the extremes of a rating scale <ref type="bibr">(Grimmond et al., in press)</ref>, or idiosyncrasies of the elicitation method itself, such as a ranking task that prevents expressions of equivalent preferences between options. This added randomness to expressed preferences means our comparison of ranking to BWS methods cannot inherently privilege either as closer to the 'true' state of individual's beliefs. Furthermore, like with music taste, there is often no 'ground truth' by which to compare subjective elicited preferences.</p><p>To remedy these complications, we incorporate three features into our experimental design. First, our investigations centered on preferences between life values. We chose this domain because values are personally relevant with natural diversity in preferences across people. Our experiments utilised a previously validated set of 10 life values based on a condensed BWS version of Schwartz' Value Theory (J. A. <ref type="bibr" target="#b6">Lee et al., 2008;</ref><ref type="bibr" target="#b17">Schwartz, 1994)</ref>.</p><p>The main benefit for our investigation is that people's life values are typically stable and fundamental changes take place on the timescales of years dwarfing our experimental demands of mere minutes <ref type="bibr" target="#b14">(Rokeach, 1973;</ref><ref type="bibr" target="#b16">Schwartz, 1992)</ref>. We therefore expect strong test-retest reliability for both the ranking and BWS elicitation tools.</p><p>Second, our experiments investigate whether elicited preferences can be preserved when their descriptions are altered. Returning to our music analogy, consider that when describing the Beatles, one could define a broad genre (e.g., rock or pop) or their characteristic qualities (e.g., iconic counter-melodies, chord progressions, vocal harmonies).</p><p>The particular choice of description highlights distinct features across a common broader concept. Along a similar vein, our experiments describe the set of life values along broad dimensions, such as 'benevolence', as compared to example qualities henceforth called items, such as 'helpful, honest, &amp; forgiving' (see Table <ref type="table" target="#tab_0">1</ref>). We anticipate that dimensionand item-descriptors will evoke different interpretations across individuals. Over and above these interpretations, however, we seek to understand whether rankings or BWS better preserves the elicited preferences across changes in description when both levels of description ostensibly target the same latent psychological concept.</p><p>Third, in all three experiments we elicit preferences from individuals twice. From a random utility perspective, preference stability over time is one indicator of validity in the absence of ground truth. To control for changes over time, we begin by experimentally determining the test-retest reliability of a) rankings in Exp. 1a, b) BWS responses in Exp.</p><p>1b, before c) comparing elicited preferences across methods in Experiment 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>To highlight the consistency across experiments, we describe all three experiments together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Participants were recruited from the online platform Prolific Academic with the constraints that a) English was their first language, and b) had an approval rating greater than 80%, and c) participants did not participate in multiple experiments. Exp. 1a recruited 110 participants (M age = 41.7, SD = 12.9, N f emale = 57, N male = 52, N optout = 1), Exp. 1b recruited 101 participants (M age = 41.3, SD = 15.1, N f emale = 55, N male = 44, N optout = 2), and Exp. 2 recruited 161 participants (M age = 36.1, SD = 11.8, N f emale = 66, N male = 95).</p><p>From these, we removed 9, 1, &amp; 13 participants respectively, where the experiment was only partially completed, where data did not save, or where participants took longer than the maximum allowable time to complete the study.</p><p>Participants were paid at a rate commensurate with £9.00 per hour (Med time = 6.75 minutes). In total, these criteria left respective N 's of Exp. 1a = 101, Exp. 1b = 100, and Exp. 2 = 148.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Design</head><p>All experiments followed a two-task structure where preferences for 10 life values were elicited twice. The experiments used a within-subjects (measurement occasion: first vs. second measurement) by between-subjects design (task labels: items vs. dimensions).</p><p>In Exp. 1a, preferences were twice elicited using the ranking task. In Exp. 1b, preferences were twice elicited using the BWS task. In Exp. 2, participants completed both ranking and BWS tasks, where the order of the tasks was randomised (i.e., ranking-first or BWS-first).</p><p>We manipulated the labels of the life values across both elicitation methods and measurement occasion. Values were labelled either as dimensions (e.g., hedonism) or example value-items (e.g., "Pleasure, enjoying life, self-indulgent", see Table <ref type="table" target="#tab_0">1</ref> for full list of labels). These label sets were drawn from the Schwartz Value Survey <ref type="bibr" target="#b17">(Schwartz, 1994)</ref> where previous work validated the items as representative examples of the 10 life values <ref type="bibr" target="#b16">(Schwartz, 1992;</ref><ref type="bibr" target="#b18">Spini, 2003)</ref>.</p><p>Label set (item vs. dimension) was randomised between-subjects. In Exp. 1a (ranking) and Exp. 1b (BWS), value labels were randomised such that 1 3 participants completed both tasks with dimension-labels, 1 3 with item-labels, and the remaining 1 3 with label-changes across tasks; that is, we assume the order of completing the dimension-vs item-labels measure is inconsequential. In Exp. 2, we randomised labels across both task types and measurement occasions. That is, participants might see dimension labels or item labels at both measurement occasions, or they might see one of each label type across the two measurement occasions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials</head><p>All 3 experiments elicited value preferences using two methods; a ranking task and a BWS task. Both tasks were conducted through the online survey platform QuestionPro and participants inputted their responses using a mouse.</p><p>Ranking task. In the ranking task, participants were presented with a randomised list of ten values labelled as either dimensions or items (see Table <ref type="table" target="#tab_0">1</ref>). To order the list, participants were instructed to drag individual life values into a separate field that automatically ordered the list from most (1) to least (10) important. Once all items were transferred to the ordered list, participants could proceed onto the next page.</p><p>BWS task. We adopted a 'case 1' object-type BWS task used by J. A. <ref type="bibr" target="#b6">Lee et al. (2008)</ref> to examine responses about life values, using an exact replication of their stimulus set structure (see their Table <ref type="table">2</ref>). This stimulus set consisted of 11 subsets of Schwartz's life values, such as 'hedonism' and 'power', and asked participants to indicate the most-and least important life values within each subset (for example, see Figure <ref type="figure" target="#fig_0">1</ref>). Subsets consisted of lists of either 5 or 6 life values and, in total across the subsets, each life value was presented 6 times. The complete list of life values is presented in Table <ref type="table" target="#tab_0">1</ref>. Subsets were balanced such that pairs of values co-appeared on only three occasions.</p><p>For example, 'hedonism' and 'power' appeared in the same subset on three occasions where the remaining values in each subset differed on each occasion. This randomisation is to ensure that each best-worst selection is weighed evenly against all remaining items shown in other subsets.</p><p>Participants were instructed to select the most-and least-important value within each subset before progressing to the next subset of values. Values were presented as a list with a 'most' indicator on the left of the list and a 'least' indicator on the right. There was no order restriction as to which preference was selected first. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data processing &amp; Outcomes</head><p>For the ranking task, we preserved the raw ranks of life values in data analysis. For the BWS task, best and worst choices were converted to Best-Worst scores <ref type="bibr" target="#b8">(Louviere et al., 2015;</ref><ref type="bibr" target="#b10">Marley et al., 2016)</ref>. Scores are generated by a count of each life value according to</p><formula xml:id="formula_0">N (most selections) -N (least selections) N (appearances) . (<label>1</label></formula><formula xml:id="formula_1">)</formula><p>The calculated scores are bounded between -1 &amp; 1 where values towards 1 indicate consistent 'most' important selections and values towards -1 indicate consistent 'least' important selections. For each participant, we calculated these normalised BWS scores for all 10 life values and produced an ordered list of values comparable to a rank ordered list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants began the online experiment by clicking a link to the experiment web page. At first, they were told the experiment was investigating life values and shown a table of values with both dimension and item labels, similar to Table <ref type="table" target="#tab_0">1</ref>. Participants were then randomly allocated into label conditions where value labels remained identical across both measurements (e.g., item-item or dimension-dimension) or value labels alternated (item-dimension or dimension-item).</p><p>Participants completed their first response task that was either a ranking task in Exp. 1a, a BWS task in Exp. 1b, or a random selection between the two tasks in Exp. 2.</p><p>Once complete, participants proceeded onto the second task with the same task constraints.</p><p>For Exp. 1a and 1b, this was the same task they completed in their first repsonse task, though dimension vs item labels may change. In Exp. 2, the second task was the task not completed first (i.e., if the ranking task was completed first then BWS was second, and if BWS was first then ranking was second). Participants were reimbursed upon completion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>As an initial overview of the data, we first present an overall summary of participant preferences for the 10 Schwartz life values. Figure <ref type="figure" target="#fig_2">2</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1a (ranking) &amp; 1b (BWS)</head><p>We first examine the preferences across repeated-measurement occasions within the same task (Exp. 1a &amp; 1b) and then across elicitation tasks (Exp. 2), shown in Figure <ref type="figure" target="#fig_3">3</ref>. Note ordering of labels is shown on the x-axis. See Table <ref type="table" target="#tab_0">1</ref> for complete list of life-value labels.</p><p>that in the following sections, agreement between measurements is indexed by Kendall's Tau (τ ) which is shown at the individual participant-level within the Figure, and reported in the aggregate in-text.</p><p>Beginning with Exp. 1a &amp; 1b, the agreement across first and second measurements was higher, on average, for the BWS task compared to ranking task (i.e., the average of individual participant Kendall's Tau values shown in the left-most vs. centre panel Figure <ref type="figure" target="#fig_3">3</ref>, M rank = 0.47 vs. M BW S = 0.69, SE's= 0.03, BF &gt; 1000). This advantage for BWS tasks likely emerges from the relative ease of selecting preferences at the extremes. In line with this interpretation, the most common rank to change across measurement occasion in Exp. 1a was 6, one of the middle ranks (81% of rank 6 responses changed) and the consistency of ranked values across measurement occasions only increased for each rank-step toward either extreme. That is, by comparison, rank 1 changed for only 54% of responses, rank 10 responses changed for 62%, and other rank-changes monotonically increased with each rank-step before peaking at rank 6.</p><p>Across both Exp. 1a &amp; 1b, agreement was stronger with consistent life-value labels than inconsistent labels (blue vs. red points, Figure <ref type="figure" target="#fig_3">3</ref>, M 1a = 0.55 vs. 0.31, M 1b = 0.82 vs.</p><p>0.41, BF &gt; 1000). That is, changing the label of the life values between measurement occasions decreased the agreement between surveys (e.g., benevolence ↔ helpful, honest, forgiving).</p><p>Notionally, agreement should differ if the new label evokes qualitatively different definitions of a particular life value. This divergence in people's interpretations of item and dimension labels appears in the aggregate preference, shown in Figure <ref type="figure" target="#fig_2">2</ref>. Despite the divergence, however, one interesting consistency is that across both ranking and BWS tasks, the relative preference for an item or dimension label for any individual life value was the same (red vs. blue points across panels in Figure <ref type="figure" target="#fig_2">2</ref>). From a construct validity perspective, this consistency is reassuring as it indicates that despite changing elicitation method we indexed the same underlying preferences for each label set, at least in the aggregate. We return to this point in the General Discussion.</p><p>One point worth noting is that the BWS task allows for ties in preference where ranks do not. These ties indicate equivalent (non-)preferences between life values and so for 10 life values, there may be fewer than 10 bins of BWS scores. In Exp. 1b, where individuals completed the BWS task twice, the mean number of BWS-score bins were similar across the first measurement occasion and the second measurement (M = 7.06 vs.</p><p>6.89, BF 01 = 2.82). Notably, both occasions exhibited fewer than 10 bins indicating the presence of ties in preferences where ranks in Exp. 1A may have forced discrimination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2 (crossed-tasks)</head><p>In Experiment 2, we directly compared preference elicitation methods such that participants completed both BWS and ranking tasks. Overall, preferences elicited by BWS methods largely agreed with preferences elicited by ranking (right-most panel, Figure <ref type="figure" target="#fig_3">3</ref>, M τ = 0.60, SE = 0.02). However, similar to Exp. 1a and 1b, consistent labeling led to greater agreement across ranking and BWS methods (blue vs. red points, M τ = 0.75 vs.</p><p>0.36, BF = 9.19). To understand better where rankings and BWS specifically diverged, we now turn to examine raw BWS scores from Experiment 2.</p><p>Figure <ref type="figure" target="#fig_4">4</ref> shows the mean BWS scores for each rank position as a function of label consistency. Although both measures largely agree on ordinal terms, the relative distances between ranks may guide where disagreement is likely to emerge. For conditions with consistent labeling, one immediate observation is that BWS scores for the first and last rank are more distant from their neighbouring ranks compared to any other rank positions (∆ 1-2 = 0.40, ∆ 9-10 = 0.38 vs. M ∆ = 0.11, se = 0.01). This discrepancy suggests that preferences for first and last ranked values are generally stable. By comparison, average BWS scores for middle ranks, such as the fourth, fifth and sixth ranks, are more tightly clustered suggesting that preferences for options in these rank positions are less discernible from one another. The conflation of similar BWS scores is particularly exaggerated for conditions where the labels switched between tasks (right-most x-axis points, Figure <ref type="figure" target="#fig_4">4</ref>).</p><p>Broadly, the distribution of ranks is more centrally concentrated and within each rank position, each mean BWS score is more variable compared to conditions with the same labels. Considered together, mean BWS scores across rank positions provide a tentative guide as to where disagreement between ranks and BWS arises. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>In this paper, we contrasted two popular methods of preference elicitation. We compared rankings, which extract ordinal preferences, to BWS methods that additionally provide relative information about the strength of those preferences. Across three experiments, we examined the agreement between elicited preferences over time in Exp. 1a and 1b, across elicitation methods in Exp. 2, and over changes in item labels. Together, we draw two main conclusions.</p><p>First, preferences elicited from BWS and ranking agree with one another. Despite the differences in response methods and task demand on individuals, we find that elicited preferences were largely consistent indicating that both methods captured a common underlying representation of individual's preferences about their life values. For survey-designers, our findings provide an empirical validation to support using BWS in contexts where ranking methods are currently employed. The primary benefit is that not only are ordinal preferences between methods preserved but BWS also provides valuable relative information between preferences and detects ties in preference where rankings cannot.</p><p>Second, BWS has greater test-retest reliability compared to rankings. A core methodological consideration is whether one's measurements are stable over time. From Experiment 1a, we find that while acquiring a set of rankings is relatively inexpensive in time-costs, not all ranks are valued equally. Specifically, test-retest reliability across sets of rankings is harmed by interchanging middle ranks that are generally less discernible compared to preferences at the extremes. BWS capitalises on this exact psychological feature. We found that the cognitive ease of identifying the best and worst options in BWS produces higher test-retest reliability across measurement occasions.</p><p>Taken together, our results privilege BWS over rankings as it provides a richer characterisation of preferences alongside the reassurance of test-retest reliability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Different labels, same interpretations?</head><p>Our work leaned on the conceptual similarities between items and dimensions. Across experiments, we labelled each life value using either a dimension label (e.g., benevolence)</p><p>or an item label (e.g., helpful, honest, forgiving). These labels were drawn from labels sets within Schwartz' Value Survey <ref type="bibr" target="#b17">(Schwartz, 1994)</ref> where previous work conducted across 21 countries had validated the set of items as representative examples of the 10 life values <ref type="bibr" target="#b16">(Schwartz, 1992;</ref><ref type="bibr" target="#b18">Spini, 2003)</ref>.</p><p>When thinking about life values, however, context provides many cues to guide interpretation. For instance, the personal importance of the life value 'power' is likely to differ if one individual defines power as social influence while another individual defines power as a proxy for wealth. Alongside individual differences, however, one important consideration is whether the elicitation method itself led to divergent definitions. Should one method inherently guide individuals towards a particular definition, then agreement between the methods would be systematically compromised by the item set rather than the method. We addressed this possibility by incorporating two sets of item labels and comparing the preferences extracted from each.</p><p>Across experiments, item and dimension label sets led to different interpretations of the life values. Where this is most apparent is that in all three experiments, agreement was lower for conditions where label sets alternated. Notably, this disparity held for twice-attempted ranking tasks in Exp. 1a and BWS in Exp. 1b suggesting that different interpretations were present independent of the elicitation method.</p><p>Despite the differences between the label sets, one interesting consistency is that their definitions appear to have been shared across elicitation methods. This concurrence is evident in the relative preference data. In Figure <ref type="figure" target="#fig_2">2</ref>, the order of preference for either item or dimension labels is consistent across ranks and BWS scores. For example, in both ranking and BWS methods, 'benevolence' was more preferred when labelled as items 'helpful, honest, forgiving' compared to as a dimension. Similarly, 'security' was more preferred when labelled as a dimension rather as items 'clean, national security, social order'. This likely emerged because without the context to imply a societal definition of security, many individuals may have converged on a common alternative definition such as personal security. In addition to these discrete label preferences, the relative magnitude of preference changes between item-labelled and dimension-labelled is also similar across elicitation methods. Considered together, two patterns are consistent with the idea that individuals converged on distinct definitions for items and dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Considering set size</head><p>Broadly, the consistency in preferences across elicitation method speak strongly against set-size context effects. Although BWS methods only present a subset of the 10 life values, the similarity in elicited preferences in the aggregate (Exp. 1a &amp; 1b, Figure <ref type="figure" target="#fig_2">2</ref>) and at the individual-level (Exp. 2, Figure <ref type="figure" target="#fig_3">3</ref>) suggests that choosing from a smaller subset is not a diminished compromise of choosing from a complete list.</p><p>Compared to rankings, a core strength of BWS is that preferences across larger sets are as easily obtained as preferences for smaller sets. BWS sidesteps this set size problem due to its iterative piecemeal design. The main mechanism that permits this is that for any set size, BWS methods require only two choices from a subset of all items. For example, our experiments presented subsets of 5 or 6 life values, from which only the best and worst is chosen. This feature means larger set sizes only increase the number of choice 'rounds' an individual completes while maintaining the same cognitive load demand across each round.</p><p>Naturally, this advantage is not free. Increasing the number of rounds means that for the respondent, BWS surveys can take longer to complete as compared to equivalent set-size ranking surveys, as was borne out in our completion time data (Exp. 1a vs. 1b, M rank = 4.60 vs. M BW S = 8.60 minutes). However, our findings suggest that the added RANKING VERSUS BEST-WORST SCALING 20 reliability afforded by the time-cost is worthwhile considering.</p><p>Taking a broader lens, our work dovetails with the long-standing tradition of examining preferences in the absence of ground truth. Like with music taste or choosing between medical treatment options, understanding the subjectivity is the objective. One notable and recent exception is that of <ref type="bibr" target="#b4">Gronau et al. (2023)</ref> whereby classic likert elicitation methods and choice tasks are compared in settings where a 'truth' was engineered, albeit modifying the standard preference elicitation use case. Akin to their efforts, the goal of this work was to evaluate two popular elicitation methods but by standards of consistency, preserving their core task qualities -subjective warts and all. By these standards, we arrive at the conclusion that the BWS method is more reliable than ranking.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1 . Example of a single Best-Worst Scaling choice set involving five life values with item labels, seeTable 1 for full list. In the BWS experiments, participants completed 11</figDesc><graphic coords="5,118.80,75.19,374.41,201.43" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>panel A presents mean life value ranks from Exp. 1a and panel B presents mean BWS scores from Exp. 1b. Almost entirely, ranks and BWS scores were in agreement. For both tasks, the most important value was benevolence (M rank = 3.62, SE = 0.18, M BW S = 0.375, se = 0.03) and the least important value was power (M rank = 7.88, SE = 0.17, M BW S = -0.46, se = 0.03). Notably, the top five most important life values were identically ordered between ranking and BWS tasks as were the two least important life values. Only a single pair of values, tradition &amp; hedonism, ranked 6th or 8th, traded ordinal positions between the preference elicitation methods.As a reminder, across all three experiments, participants completed two preference elicitation tasks. In the next section, we present the agreement between both measurement occasions using Kendall's Tau (τ ). Kendall's Tau is a non-parametric statistic of rank correlation for ordinal data that provides a metric of similarity for lists of life-values generated by BWS as compared to ranking. Tau values are bounded between 1 &amp; -1, where τ values of 1 indicate complete agreement across both lists, and τ values of -1 indicate exact reversals. For clarity, we use the τ b variant of Kendall's Tau that explicitly accounts for ties between lists. Using the overview data from Figure 2 as an illustration, the order of mean ranks strongly agreed with mean BWS scores (items: τ = 0.96, BF 10 = 221.4, dimensions: τ = 0.82, BF 10 = 43.0, Figure 2).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2 . Overview of life value responses separated by task. Panel A shows mean ranks from Exp. 1A of each life value ordered from most important (1) to least important (10). Panel B shows mean BWS scores from Exp. 1B of each life value in the same order from most important (1) to least important (-1). Value label is shown in colour and error bars represent standard error of the mean.</figDesc><graphic coords="12,83.70,270.04,444.61,222.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3 . Agreement across measurement occasions as a function of life value labels (x-axis) and experiment (panels). Gray dots show individual-level participant data and larger coloured dots show means and standard error. Colour indicates life value label consistency. Blue coloured dots indicate conditions where life value labels were the same on both measurement occasions, and red colour dots indicate when labels differed. Exact</figDesc><graphic coords="13,83.70,75.19,444.61,257.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4 . Experiment 2 aggregate-level data showing mean BWS scores (y-axis) as a function of ranks (x-axis). For each rank position, the mean BWS score across individuals is shown in the coloured points. Error bars represent standard error of the mean and text indicates corresponding rank positions. Between-subject label conditions are separated on the x-axis. As a reminder, different labels indicate dimension-item labels switched with ranking and BWS tasks whereas same labels indicate consistent labeling across tasks.</figDesc><graphic coords="16,149.22,75.19,313.56,313.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><figDesc>For only 10 life values, our experiments found that rankings in the middle order were more likely to change across measurement occasion. Hypothetically, one might expect that increasing the set size would only exaggerate the paucity of information from middle ranked values while adding greater cognitive effort of comparing each item against a larger set of alternatives. When one considers the large number of possible influences on surgeon choice (N = 16 in<ref type="bibr" target="#b2">Ejaz et al. (2014)</ref>) or the responses in personality surveys (N = 57 in<ref type="bibr" target="#b17">Schwartz (1994)</ref>) it becomes clear how ranking each option relative to a full set is problematic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Dimension &amp; item labels for all 10 life values ordered by averaged task scores in Figure2.Participants were shown this table of definitions with both dimension &amp; item labels at theoutset of the experiment before completing the ranking or BWS choice task with only a single set of labels at any one time.</figDesc><table><row><cell></cell><cell cols="2">Dimension labels Item labels</cell></row><row><cell>1</cell><cell>Benevolence</cell><cell>Helpful, honest, forgiving</cell></row><row><cell>2</cell><cell>Self-direction</cell><cell>Creativity, curious, freedom</cell></row><row><cell>3</cell><cell>Achievement</cell><cell>Successful, capable, ambitious</cell></row><row><cell>4</cell><cell>Security</cell><cell>Clean, national security, social order</cell></row><row><cell>5</cell><cell>Universalism</cell><cell>Protecting the environment, a world of beauty, unity with nature</cell></row><row><cell>6</cell><cell>Hedonism</cell><cell>Pleasure, enjoying life, self-indulgent</cell></row><row><cell>7</cell><cell>Stimulation</cell><cell>Daring, a varied life, an exciting life</cell></row><row><cell>8</cell><cell>Tradition</cell><cell>Devout, accepting portion in life, humble</cell></row><row><cell>9</cell><cell>Conformity</cell><cell>Politeness, obedient, honouring parents &amp; elders</cell></row><row><cell cols="2">10 Power</cell><cell>Social power, authority, wealth</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>For the reader interested in using BWS themselves, we refer to<ref type="bibr" target="#b9">Louviere et al. (2013)</ref> for an applied demonstration of BWS and<ref type="bibr" target="#b8">Louviere et al. (2015)</ref> for a comprehensive guide.</p></note>
		</body>
		<back>

			<div type="funding">
<div><head>Funding</head><p>This work was supported by the <rs type="funder">joint</rs> <rs type="funder">MURI-AUSMURI in Cybersecurity Assurance for Teams of Computers and Humans (CATCH)</rs> and funding from the <rs type="funder">Australian Research Council</rs> (<rs type="grantNumber">DP210100313</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_j2gtbTf">
					<idno type="grant-number">DP210100313</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability of data and materials</head><p>Survey materials were collected on the QuestionPro platform and can be shared on request.</p><p>Raw and preprocessed data are available on OSF. <ref type="url" target="https://osf.io/ct8ae/?view_only=5dfea3dcf2e14bc3a6f360562883cab0">https://osf.io/ct8ae/?view_only=5dfea3dcf2e14bc3a6f360562883cab0</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code availability</head><p>Analysis &amp; data preparation code are available at the above OSF repository.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declarations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of interest</head><p>The authors have no conflicts of interest to declare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics approval</head><p>This research was approved by the Human Research Ethics Committee at the University of Newcastle, Australia under protocol number H-2019-0321.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent to participate</head><p>All participants consented to participate in the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent to publish</head><p>All authors consent to publishing this manuscript.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Investigating consumer decision strategies with systems factorial technology</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hawkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">102258</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The theory of decision making</title>
		<author>
			<persName><forename type="first">W</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">380</biblScope>
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Choosing a cancer surgeon: Analyzing factors in patient decision making using a best-worst scaling methodology</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ejaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Spolverato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Bridges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Pawlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of surgical oncology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="3732" to="3738" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A solution to the pervasive problem of response bias in self reports</title>
		<author>
			<persName><forename type="first">J</forename><surname>Grimmond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hawkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint/>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Do choice tasks and rating scales elicit the same judgments</title>
		<author>
			<persName><forename type="first">Q</forename><forename type="middle">F</forename><surname>Gronau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Eidels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of choice modelling</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page">100437</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The top-ten effect: Consumers&apos; subjective categorization of ranked lists</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Isaac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Schindler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1181" to="1202" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The best-worst scaling approach: An alternative to schwartz&apos;s values survey</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Soutar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louviere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality assessment</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="335" to="347" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Inferring expertise in knowledge and prediction ranking tasks</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>De Young</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in cognitive science</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="151" to="163" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Best-worst scaling: Theory, methods and applications</title>
		<author>
			<persName><forename type="first">J</forename><surname>Louviere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">N</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A J</forename><surname>Marley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An introduction to the application of (case 1) best-worst scaling in marketing research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Louviere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Lings</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gudergan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Flynn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of research in marketing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="292" to="303" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A formal and empirical comparison of two score measures for best-worst scaling</title>
		<author>
			<persName><forename type="first">A</forename><surname>Marley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Hawkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Choice Modelling</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="15" to="24" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Ranking</forename><surname>Versus</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Best-Worst</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SCALING</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Some probabilistic models of best, worst, and best-worst choices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Marley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louviere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of mathematical psychology</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="464" to="480" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The wisdom of the crowd with partial rankings: A bayesian approach implementing the thurstone model in jags</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Montgomery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bradford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="8091" to="8104" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Rokeach</surname></persName>
		</author>
		<title level="m">The nature of human values</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>The Free Press</publisher>
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discrete choice experiments in health care</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ryan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bmj</title>
		<imprint>
			<biblScope unit="volume">328</biblScope>
			<biblScope unit="issue">7436</biblScope>
			<biblScope unit="page" from="360" to="361" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in experimental social psychology</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Are there universal aspects in the structure and contents of human values</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of social issues</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="19" to="45" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Measurement equivalence of 10 value types from the schwartz value survey across 21 countries</title>
		<author>
			<persName><forename type="first">D</forename><surname>Spini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of cross-cultural psychology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="23" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Van Dam</surname></persName>
		</author>
		<ptr target="https://www.washingtonpost.com/business/2024/05/24/when-america-was-great-according-data/" />
		<title level="m">America&apos;s best decade, according to data</title>
		<imprint>
			<date type="published" when="2024-05">2024, May</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Discrete choice experiments to measure consumer preferences for health and healthcare</title>
		<author>
			<persName><forename type="first">R</forename><surname>Viney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lancsar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Louviere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Expert review of pharmacoeconomics &amp; outcomes research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="319" to="326" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Theory of games and economic behavior: 60th anniversary commemorative edition</title>
		<author>
			<persName><forename type="first">J</forename><surname>Von Neumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Morgenstern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Theory of games and economic behavior</title>
		<imprint>
			<publisher>Princeton university press</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
