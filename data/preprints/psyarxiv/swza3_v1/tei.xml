<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Elsevier BV</publisher>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2023-06">2023-06</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Hung-Yue</forename><surname>Suen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Technology Application and Human Resource Development</orgName>
								<orgName type="institution">National Taiwan Normal University</orgName>
								<address>
									<settlement>Taipei City</settlement>
									<country>Taiwan. R.O.C</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Kuo-En</forename><surname>Hung</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Technology Application and Human Resource Development</orgName>
								<orgName type="institution">National Taiwan Normal University</orgName>
								<address>
									<settlement>Taipei City</settlement>
									<country>Taiwan. R.O.C</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Computers in Human Behavior</title>
						<title level="j" type="abbrev">Computers in Human Behavior</title>
						<idno type="ISSN">0747-5632</idno>
						<imprint>
							<publisher>Elsevier BV</publisher>
							<biblScope unit="volume">143</biblScope>
							<biblScope unit="page">107713</biblScope>
							<date type="published" when="2023-06" />
						</imprint>
					</monogr>
					<idno type="MD5">5DF73B7EE5999233AEBB3B37AF953405</idno>
					<idno type="DOI">10.1016/j.chb.2023.107713</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-22T20:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Asynchronous Video Interview (AVI)</term>
					<term>Human-Computer Interaction (HCI)</term>
					<term>Trustworthy AI</term>
					<term>User Interface (UI)</term>
					<term>User Experience (UX)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As the demand for automatic video interviews powered by artificial intelligence (AI) increases among employers in the postpandemic era, so do concerns over job applicants' trust in the technology. There are various forms of AI-based video interviews with and without the features of tangibility, immediacy, and transparency used for preemployment screening, and these features may distinctively influence applicants' trust in the technology and whether they engage in or disengage from the hiring process accordingly. This field study involved designing a test of the effect of various forms of AI-based video interviews on interviewees' cognitive and affective trust based on the self-reporting of 152 real job applicants. The study found that AI used in asynchronous video interviews (AI-AVI) increased applicants' cognitive trust from that in the non-AI condition. Moreover, when the AI-AVI had features of tangibility and transparency, the applicants' cognitive and affective trust increased. However, the feature of immediacy did not have a statistically significant impact. Contrary to concern over the potential negative effects caused by AI and its features, no statistically significant impacts were found in this study.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref><p>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human <ref type="bibr">Behavior, 143, 107713.</ref> <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Nine out of 10 employers now use artificial intelligence (AI) in employment interviews, according to Harvard Business Review <ref type="bibr" target="#b32">(Jaser et al., 2022)</ref>. The rapid adoption of asynchronous video interviews (AVIs) involving AI for personnel selection has been studied in academic research (e.g., <ref type="bibr" target="#b20">Gonzalez et al., 2022;</ref><ref type="bibr" target="#b31">Hunkenschroer &amp; Luetge, 2022)</ref>. AVIs are one-way interviews in which interviewees answer questions in front of their webcam and interviewers review the video at a later time <ref type="bibr" target="#b48">(Mejia &amp; Torres, 2018)</ref>. AI applications use a visual-audio recognition technique in tandem with deep learning to match job applicants with job vacancies by automatically assessing the applicants' verbal (e.g., content), paraverbal (e.g., prosody), and nonverbal (e.g., head twist) signals, which helps employers screen their applicants <ref type="bibr" target="#b27">(Hickman et al., 2022)</ref>. However, a lack of humanity and transparency can be fatal flaws of AI video interviews, which raises concerns about applicants' trust in such automated systems <ref type="bibr" target="#b32">(Jaser et al., 2022)</ref>. Therefore, many AI service providers have tried to add interfaces that meet human norms to increase trust in AI <ref type="bibr" target="#b11">(Chi et al., 2021)</ref>. Trust is defined in this study as "trustworthiness perceptions toward the characteristics of an automated systems support decisions that affect individuals' fates" <ref type="bibr" target="#b61">(Langer et al., 2022)</ref>.</p><p>There are a variety of interfaces that simulate human interaction and promote trustworthiness through the use of tangibility, immediacy, or transparency <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>. For example, job applicants talk to a void in the AI-based AVI platform HireVue.com (no tangibility, immediacy, or transparency). Robot Vera (ai.robotvera.com) is an AI-based avatar used to interview and interact with job applicants (tangibility). HRDA.pro has a chatbot option by which applicants are aware that they can communicate with the AI in the AVI (immediacy). <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human <ref type="bibr">Behavior, 143, 107713. https://doi.org/10.1016</ref><ref type="bibr">Behavior, 143, 107713. https://doi.org/10. /j.chb.2023.107713 .107713</ref> Pymetrics.ai adopts game-based AI agents to evaluate job applicants' capabilities and explains the "science" behind the game to applicants (transparency). Studies of human-computer interactions have found that user trust in AI is a critical factor in how humans interact with AI; therefore, trust in AI is an important factor that affects AI interface design <ref type="bibr" target="#b11">(Chi et al., 2021)</ref>.</p><p>On the one hand, AI interview technologies empower the personnel selection process <ref type="bibr" target="#b75">(Woods et al., 2020)</ref>; on the other hand, various AI interview interfaces may influence job applicants' feelings, including both cognitive and affective trust <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>, differently and may accordingly affect their withdrawal from the recruitment process <ref type="bibr" target="#b4">(Basch et al., 2020)</ref>. Therefore, it is essential for both scholars and practitioners to examine whether job applicants respond with trust when interacting with various AI interview interfaces since applicants' trust in AI interviewing affects their application willingness and thereby alters employers' recruitment effectiveness <ref type="bibr" target="#b4">(Basch et al., 2020)</ref>.</p><p>Although various AI interfaces have been widely adopted for personnel selection, our understanding of how real job applicants interact with various AI interview interfaces and their trust in the interfaces remain insufficient <ref type="bibr" target="#b29">(Hu et al., 2021)</ref>. <ref type="bibr">Hu and colleagues (2021)</ref> have urged more studies to examine the consequences of applicant-AI interactions. As a result, we adopt a unique context for employment video interviews to explore how job applicants develop trust when interacting with various AI interfaces.</p><p>As mentioned, AI interfaces may have various features, including tangibility, immediacy, and transparency. To examine the effects of different AI interview interfaces on job applicants' trustworthiness, this study aims to explore 1) whether job applicants have different cognitive and affective trust perceptions toward AVI with and without AI and 2) whether job applicants' <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: <ref type="bibr">Tangibility, immediacy, and</ref><ref type="bibr">transparency. Computers in Human Behavior, 143, 107713. https://doi.org/10.1016/j.chb.2023.107713</ref> cognitive/affective trust varies across AI interfaces with and without tangibility, immediacy, and transparency in the condition of AI-AVI. Prior to answering these research questions, the authors developed AI interfaces to embody tangibility with a 2-D affinitive avatar according the principles of anthropomorphism <ref type="bibr" target="#b74">(Waytz et al., 2014)</ref> and uncanny valley theory <ref type="bibr" target="#b51">(Mori, 1970)</ref> to convey immediacy with a chatbot based on a standard script <ref type="bibr" target="#b2">(Adamopoulou &amp; Moussiades, 2020)</ref> and to realize transparency with a text description to explain how AI assesses an interviewee (see <ref type="bibr" target="#b5">Bedué &amp; Fritzsche, 2022)</ref>. Afterward, this study used a series of experimental conditions in a real hiring situation with two layers: in the first layer, job applicants' trust perceptions were examined with and without AI in the AVI condition; in the second layer, job applicants' trust perceptions were examined across individual AI interfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background and hypotheses</head><p>Since AI-based AVIs have been incorporated into employment interviews to screen job applicants <ref type="bibr" target="#b23">(Gupta et al., 2018;</ref><ref type="bibr" target="#b33">Jatobá et al., 2019)</ref>, it is essential to examine how applicants react differently toward those new digital selection tools, such as by investigating their trust in AI interviews <ref type="bibr" target="#b75">(Woods et al., 2020)</ref>. Humans' trust in AI influences how they interact with machines, and the properties of AI interfaces shape human trust, which influences how job applicants engage in the AI selection process <ref type="bibr">(van Esch &amp; Black, 2019)</ref>. Trust has become a critical challenge in implementing AI-based AVIs (see <ref type="bibr" target="#b67">Tambe et al., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Job applicants' trust in AI-and non-AI-based AVIs</head><p>In addition to perceived usefulness and ease of use based on the technology acceptance model <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: <ref type="bibr">Tangibility, immediacy, and</ref><ref type="bibr">transparency. Computers in Human Behavior, 143, 107713. https://doi.org/10.1016/j.chb.2023.107713</ref> (TAM; <ref type="bibr" target="#b12">Davis, 1989)</ref>, many studies have found that users' trust is the other critical factor in determining user acceptance of new technology <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>. Theoretical models of trust in automation <ref type="bibr" target="#b42">(Lee &amp; See, 2004)</ref> show that users' perception of the trustworthiness of an automated system arise from perceived characteristics of the system as well as the system performance, which can help achieve an individual's goals in a context of uncertainty and vulnerability <ref type="bibr" target="#b36">(Kohn et al., 2021)</ref>. In this study, context, this means that job applicants assess trustworthiness in relation to their goals for gaining a better interview rating and a job offer. The trustworthiness of automated systems can be conceptualized through multiple facets <ref type="bibr" target="#b42">(Lee &amp; See, 2004)</ref>, and we examined two facets of trustworthiness that job applicants may consider for an AIbased AVI: cognitive trust and affective trust <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref> for this study context.</p><p>Cognitive trust is determined by rational thinking, whereas affective trust is determined by feelings <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>. Both cognitive and affective trust affect human willingness to rely on automated systems in uncertain situations <ref type="bibr" target="#b28">(Hoff &amp; Bashir, 2015)</ref>, such as in technology-mediated employment interviews <ref type="bibr" target="#b4">(Basch et al., 2020)</ref>. Job applicants who have less trust in an interview technology may perceive the interview process to be unfair, and those with greater trust may perceive greater fairness <ref type="bibr" target="#b4">(Basch et al., 2020)</ref>. As a result, the former may withdraw from the recruitment process or decline job offers <ref type="bibr" target="#b8">(Blacksmith et al., 2016)</ref>.</p><p>Recent studies have found that interviewees develop disfavor toward automatic interview interfaces due to irrational feelings, such as creepiness <ref type="bibr">(Langer et al., 2017;</ref><ref type="bibr">Suen et al., 2019a)</ref>, which may diminish their affective trust. If job applicants believe that their performance will be evaluated fairly, they develop more cognitive trust toward the automatic interview process <ref type="bibr">(Suen et al., 2019a)</ref> according to <ref type="bibr" target="#b18">Gilliland's (1993)</ref> fairness model. <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> Some AVI service providers (e.g., hirevue.com, retorio.com) use AI that can automatically predict interviewees' personality traits <ref type="bibr" target="#b65">(Suen et al., 2019b</ref><ref type="bibr" target="#b66">(Suen et al., , 2020))</ref>, interview performance, interviewability <ref type="bibr" target="#b52">(Naim et al., 2018)</ref>, or interpersonal communication skills <ref type="bibr" target="#b59">(Rao et al., 2017)</ref> according to the interviewees' audio-visual expressions on video (see <ref type="bibr" target="#b9">Celiktutan &amp; Gunes, 2017)</ref>. AI can also make hiring recommendations in real employment interviews by extracting verbal, paraverbal, or nonverbal cues from both the interviewee and interviewer <ref type="bibr" target="#b27">(Hickman et al., 2022;</ref><ref type="bibr" target="#b53">Nguyen et al., 2014)</ref>.</p><p>Job applicants in AI-based AVIs are fully or partially evaluated by AI algorithms, whereas job applicants in non-AI-based AVIs are evaluated by human raters <ref type="bibr">(Suen et al., 2019a)</ref>. Since human raters have personal biases in evaluating job applicants, AI algorithms offer more objective solutions <ref type="bibr">(van Esch et al., 2019)</ref>. In rational, signaling theory states that job applicants understand employers based on incomplete information from their perceptions of the interviewers <ref type="bibr" target="#b62">(Rynes &amp; Miller, 1983)</ref>. AI-based interviewers or raters may provide a consistent and objective hiring process without personal biases <ref type="bibr">(Black &amp; van Esch, 2020)</ref>, which signals to job applicants that employers value equality and novelty (i.e., <ref type="bibr" target="#b1">Acikgoz et al., 2020;</ref><ref type="bibr">van Esch et al., 2020)</ref>, thereby boosting job applicants' cognitive trust. From an emotional perspective, AIbased interviewers or raters may engender anxiety because job applicants do not know what the AI algorithms are assessing <ref type="bibr">(Langer et al., 2020;</ref><ref type="bibr" target="#b69">van Esch et al., 2020)</ref>, which is especially related to the explainability concerns of the AI black box <ref type="bibr" target="#b67">(Tambe et al., 2019)</ref>. Additionally, evidence from past studies shows that using new technology provokes people's anxiety because of its unfamiliarity <ref type="bibr" target="#b49">(Meuter et al., 2003)</ref>. Therefore, AI-based AVIs may decrease job applicants' affective trust due to their uncertainty and unfamiliarity than non-AI-based AVIs. We propose the</p><p>Suen, H. Y., &amp; Hung, K. E. (2023). Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> following hypotheses: Hypothesis 1a: Interviewees perceive a higher level of cognitive trust in AI-based AVIs than in non-AI-based AVIs after automated interviewing. Hypothesis 1b: Interviewees perceive a lower level of affective trust in AI-based AVIs than in non-AI-based AVIs after automated interviewing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Job applicants' trust in AI-based AVIs with and without tangibility</head><p>According to <ref type="bibr" target="#b45">Long's (2001)</ref> social interface theory, people interact with computer interfaces as well as they do with other humans; computer interfaces can arouse responses from users that are similar to those in interpersonal interactions based on whether the computer interface has humanizing cues. Therefore, interviewees tend to treat computer interfaces the same as they treat humans in video interviews if the interfaces have humanizing features <ref type="bibr" target="#b17">(Gerich, 2012)</ref>, and their responses are similar to socially desirable responses in face-to-face interviews <ref type="bibr" target="#b24">(Haan et al., 2017)</ref>. When AVIs use AI with humanizing features, interviewees may respond to the AI-enabled AVIs as they would to human interviewers <ref type="bibr">(Suen et al., 2019a)</ref>, including by developing affective and cognitive trust.</p><p>According to <ref type="bibr" target="#b19">Glikson and Woolley (2020)</ref>, there are various embodiments of AI: AIenabled robots, AI-enabled virtual agents, and embedded AI. AI-enabled robots have a physical presence and human-like features; AI-enabled virtual agents have some distinguished identifiers (e.g., an avatar or a chatbot) and may possess a face, body, or voice or the ability to text without physical presence; embedded AI applications, such computer vision or voice recognition, have neither a physical presence nor distinguished identifiers, preventing users from being aware of <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> their existence. In the context of AVIs, virtual agents (e.g., Vera.ai) and embedded AI (e.g., HireVue.com) are commonly used in AVIs in commercial solutions to evaluate job applicants and make hiring recommendations <ref type="bibr">(Suen et al., 2019a)</ref>.</p><p>Virtual agents and embedded AI can have human-like interface features, such as tangibility, immediacy, and transparency (see <ref type="bibr" target="#b19">Glikson &amp; Woolley, 2020)</ref>. Tangibility is the ability of AI to be physically perceived or touched by human individuals <ref type="bibr" target="#b43">(Liu &amp; London, 2016)</ref>.</p><p>Immediacy is the interpersonal closeness perceived by audiences through AI's verbal and nonverbal responsiveness and human-like interactions <ref type="bibr">(Kreps &amp; Neuhauser, 2013)</ref>. Transparency is the degree to which individuals can understand why and how AI assesses and decides something and follows human rules and logic <ref type="bibr" target="#b28">(Hoff &amp; Bashir, 2015)</ref>.</p><p>Although there are a variety of AI embodiments, virtual agents and embedded AI are used as AI interfaces in AI-based AVIs. According to the literature on social psychology, when users feel they can predict an object's behavior or use and have confidence in it, they have more cognitive trust in the object <ref type="bibr" target="#b34">(Johnson &amp; Grayson, 2005)</ref>. AI interfaces also support this notion <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>. When AI has a tangible interface such as a virtual agent that can be visually perceived by users, users feel that the interface is more predictable and reliable than when the interface uses invisible embedded AI that has no tangibility <ref type="bibr">(Krämer et al., 2017)</ref>. One study also found that an avatar picture on a commercial website increased visitors' cognitive trust and intention to revisit the website <ref type="bibr" target="#b10">(Chattaraman et al., 2014)</ref>.</p><p>With regard to affective trust in AI, researchers have found that AI interfaces with a human-like social presence conveyed by a "persona" increase users' affective trust <ref type="bibr" target="#b13">(de Visser et al., 2017)</ref>. In contrast, when users encounter no AI representation, AI-based applications may <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> decrease affective trust and evoke anger because nontangibility makes users feel unsafe and unsupported <ref type="bibr" target="#b26">(Hengstler et al., 2016)</ref>. <ref type="bibr" target="#b14">Eslami et al. (2015)</ref> found that more than 60% of users were unaware of intangible embedded AI managing their information on many social media sites, which may cause users to feel uncomfortable or even angry about not being informed of the use of AI. A study also showed that the presence of a "persona", such as an avatar, in virtual interactions can significantly reduce users' anxiety and increase their perceived social support <ref type="bibr" target="#b10">(Chattaraman et al., 2014)</ref>. Therefore, if an avatar appears in AI-based AVIs, the tangibility of the AI increases both users' cognitive trust and their affective trust. As discussed above, the following hypotheses are proposed:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hypothesis 2a: Interviewees perceive a higher level of cognitive trust in AI-based</head><p>AVIs with tangibility than in AI-based AVIs without tangibility after automated interviewing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hypothesis 2b: Interviewees perceive a higher level of affective trust in AI-based</head><p>AVIs with tangibility than in AI-based AVIs without tangibility after automated interviewing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Job applicants' trust in AI-based AVIs with and without immediacy</head><p>In addition to tangibility, immediacy can be more easily created in a virtual agent, such as a chatbot, and it can facilitate cognitive trust <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref> because immediacy, including social responsiveness and personalization, gives users more confidence and willingness to rely on an object <ref type="bibr" target="#b34">(Johnson &amp; Grayson, 2005)</ref>, including AI. AI can also foster immediacy in various ways; for example, Uber's algorithm provides</p><p>Suen, H. Y., &amp; Hung, K. E. (2023). Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> immediate tracking signals plus active responses to drivers through the constant monitoring of drivers' actions <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>. On the one hand, tracking signals can help drivers make better decisions and thereby increase their cognitive trust; on the other hand, this immediacy can be perceived as surveillance, which may violate drivers' autonomy (although they can ignore or game the system) and consequently decrease their affective trust (see <ref type="bibr" target="#b50">Möhlmann &amp; Zalmanson, 2017)</ref>. In the context of AI-based AVIs, a constant voice tracker plus a verbal response shown on the screen may create the perception of immediacy by interviewees during automatic interviews (e.g., hrda.pro). Therefore, an AI interface that exhibits immediacy behaviors may increase cognitive trust but decrease affective trust. We thus propose the following:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hypothesis 3a: Interviewees perceive a higher level of cognitive trust in AI-based</head><p>AVIs with immediacy than in AI-based AVIs without immediacy after automated interviewing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hypothesis 3b: Interviewees perceive a lower level of affective trust in AI-based</head><p>AVIs with immediacy than in AI-based AVIs without immediacy after automated interviewing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Job applicants' trust in AI-based AVIs with and without transparency</head><p>Some scholars have argued that AI virtual agents' transparency has a greater impact on cognitive trust than tangibility <ref type="bibr" target="#b73">(Wang et al., 2016)</ref> and immediacy <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>. According to explanation-for-trust theory <ref type="bibr" target="#b58">(Pieters, 2011)</ref>, users have more cognitive trust in technology when they can compare alternatives by explaining how the inner system works in detail, which is <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> the system's transparency <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>. Accordingly, when AI can explain how its algorithm makes decisions, users have more cognitive trust in its competence and benevolence <ref type="bibr" target="#b71">(Wang &amp; Benbasat, 2007)</ref>.</p><p>Although the full transparency of AI algorithms is hard to achieve in AI with a deeplearning black box <ref type="bibr" target="#b3">(Ananny &amp; Crawford, 2018</ref>), an explanation of the rationale behind the AI's recommendations or decisions that can be understood by users without technical knowledge would increase users' expectations for the AI's performance and thereby increase users' cognitive trust <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>. In the case of AI-AVIs, explaining how the AI evaluates the interviewees before the interview would allow the interviewees to have more cognitive trust in the AI-AVIs than when no explanation is provided. Because this transparency affects users' rational thinking but not emotional feelings <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>, explaining how the AI evaluates interviewees in AI-based AVIs will not influence the interviewees' affective trust. Thus, the last hypothesis is proposed:</p><p>Hypothesis 4: Interviewees perceive a higher level of cognitive trust in <ref type="bibr">AI-based</ref> AVIs with transparency than in AI-based AVIs without transparency after automated interviewing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Participants and procedure</head><p>To test the effects of AI-based AVIs on job applicants' cognitive and affective trust in AI and the AI interface used in the AVI condition, the study was conducted in a real hiring situation to explore self-reported cognitive and affective trust in four experimental conditions: 1) AI-AVI vs. non-AI AVI (H1a and H1b), 2) AI-AVI with tangibility vs. AI-AVI without tangibility (H2a and</p><p>Suen, H. Y., &amp; Hung, K. E. (2023). Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> </p><p>H2b), 3) AI-AVI with immediacy vs. AI-AVI without immediacy (H3a and H3b), and 4) AI-AVI with transparency vs. AI-AVI without transparency (H4). To achieve the required sampling size, we used G * Power <ref type="bibr" target="#b16">(Faul et al., 2009)</ref> to effectively solicit 68 interviewees for each condition based on the following assumption in multivariate analysis of variance (MANOVA): effect size f 2 = 0.15, α error probability = 0.05, power of 1-β = 0.8, number of groups = 2, response variables = 2. Finally, valid data were collected from 152 participants for the first condition and 130 participants each for the second, third, and fourth conditions.</p><p>The interviewees were solicited through a professional employer organization (PEO) based on an academic-industry cooperation agreement with the authors. The PEO helps their clients recruit, select, and hire employees to fulfill various job functions, and the PEO adopted an AVI as a screening tool in the initial stage of the selection process. Questions in a prerecorded one-way format are posed to the applicants, and then the recruiters can select appropriately qualified candidates faster to arrange face-to-face interviews. As the PEO hiring process, AVI screening has normally been used by employers and staffing agencies to watch the recording afterward and assesses whether an applicant will proceed to the next stage <ref type="bibr" target="#b61">(Roulin et al., 2022)</ref>.</p><p>The interviewees were solicited after they completed an AVI screening in the first round of personnel selection conducted by the PEO in exchange for a gift card worth USD 18. The AVI enabled with AI (with an option to turn it on/off) was codeveloped by the authors' project team.</p><p>Prior to conducting the formal experiments, 30 participants who had full-time jobs were invited through the authors' connections to join the pilot testing to review and revise the study process, measurement scale, and treatments. Afterward, we invited another 152 real interviewees to participate and randomly assigned them to our experimental groups. Every interviewee was To test the effect of AI used in AVIs on trust, the interviewees in the AI groups were told, "Your interview performances will be analyzed by an AI algorithm", whereas the interviewees in the non-AI video group were told, "Your interview performances will be evaluated by a human rater". These texts were shown in the testing period before starting the formal recorded interviews. As in normal personnel interview practices, we did not explain or disclose what criteria would be assessed by the AI or human rater (see <ref type="bibr">König et al., 2007)</ref>.</p><p>To test the effect of AI-AVI tangibility on trust, a 2-D avatar with medium human likeness and affinity was displayed, as shown in Fig. <ref type="figure">1</ref>, in the top right corner of the screen in the AVI. The avatar can blink, nod, and smile automatically based on a fixed frequency according to the principles of anthropomorphism <ref type="bibr" target="#b74">(Waytz et al., 2014)</ref> and uncanny valley theory <ref type="bibr" target="#b51">(Mori, 1970)</ref> to realize tangibility in the AI-AVI. The invisible embedded AI-AVI was nontangible <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>.</p><p>Suen, H. Y., &amp; Hung, K. E. (2023). Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. Illustration of an AI-AVI avatar</head><p>To test the effect of AI-AVI immediacy on trust, a voice-tracking function plus an automatic text response as a chatbot script <ref type="bibr" target="#b2">(Adamopoulou &amp; Moussiades, 2020)</ref> was built into the AI-AVI to convey immediacy vs. nonimmediacy, as shown on the left and right sides of Fig. <ref type="figure">2</ref>, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2. Illustration of immediacy vs. nonimmediacy in the AI-AVI</head><p>To test the effect of AI-AVI transparency on trust, a text description was displayed on the screen for the interviewees before they entered the AI-AVI: "An AI algorithm will be used in the entire interview process to infer your personality traits according to your facial expressions and head movements". This description explained the AI's functionality to the interviewees and increased the interviewees' post hoc interpretation of the AI's assessment (see <ref type="bibr" target="#b5">Bedué &amp; Fritzsche, 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Manipulation check</head><p>To check the manipulation of perceived AI in the AVI, all interviewees in both the AI-AVI and non-AI-AVI groups responded to the prompt "I received information that my interview would be evaluated by □ AI algorithm/□ Human raters" at the beginning of the survey that followed</p><p>Suen, H. Y., &amp; Hung, K. E. (2023). Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> </p><p>the interview.</p><p>To check the manipulation of the perceived tangibility in the AI-AVI, all interviewees in AI-AVI groups responded to the prompt "A virtual AI interviewer appeared on the screen during the interview": □ YES/□ NO" at the beginning of the survey that followed the interview.</p><p>To check the manipulation of perceived immediacy in the AI-AVI, all interviewees in AI-AVI groups responded to the prompt "I felt that the interview application interacted with and responded to me: □ YES/□ NO" at the beginning of the survey that followed the interview.</p><p>To check the manipulation of the perceived transparency in the AI-AVI, all interviewees in AI-AVI groups responded to the prompt "I received information about what and how the AI would evaluate my performance: □ YES/□ NO" at the beginning of the survey that followed the interview.</p><p>All participants in this study completed four items that checked the manipulation as described above, and the participants who failed to pass the manipulation checks were removed from our data. Thus, 2 were excluded for the treatment of AI, 2 for tangibility, 3 for immediacy, and 1 for transparency, making a total of 8 excluded participants, which was approximately 5.26% of the valid AVI sample (152) and 4.62% of the valid AI-AVI sample (130).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Measures and analysis</head><p>Although the trust scales used to study AI vary, researchers have not made a clear distinction between cognitive and affective trust <ref type="bibr" target="#b19">(Glikson &amp; Woolley, 2020)</ref>. We follow <ref type="bibr" target="#b19">Glikson and Woolley's (2020)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>categorization to develop cognitive and affective trust measures based on Lee</head><p>Suen, H. Y., &amp; Hung, K. E. ( <ref type="formula">2023</ref>). Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human <ref type="bibr">Behavior, 143, 107713. https://doi.org/10.1016</ref><ref type="bibr">Behavior, 143, 107713. https://doi.org/10. /j.chb.2023</ref><ref type="bibr">Behavior, 143, 107713. https://doi.org/10. .107713 et al.'s (2015) )</ref> five-point scale (1=strongly disagree to 5=strongly agree), which includes 6 items.</p><p>An exploratory factor analysis (EFA) also proved that all items could be categorized as cognitive trust based on rationality and as affective trust based on emotional feelings, as shown in Table <ref type="table">1</ref>.</p><p>Additionally, the content validity was reviewed and confirmed by 3 experts in human-computer interaction through the authors' connections.</p><p>One-way MANOVA was used to analyze the hypotheses for each experimental condition between the independent groups established by our manipulation (AI-AVI vs. non-AI-AVI, tangible vs. intangible AI-AVI, immediate vs. nonimmediate AI-AVI, transparent vs.</p><p>nontransparent AI-AVI) on both cognitive and affective trust perceptions from the AVI interviewees.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Scale reliability</head><p>Following <ref type="bibr" target="#b41">Lee et al.'s (2015)</ref> procedure, a principal component analysis with varimax rotation was executed, and two major components were generated, accounting for 55.87% of the total variance in accordance with <ref type="bibr" target="#b19">Glikson and Woolley's (2020)</ref> classification for users' trust in AI based on affective and cognitive components. A Kaiser-Meyer-Olkin (KMO) statistic of 0.850 was achieved and was beyond the cutoff level of 0.5, which indicates that our sample size is adequate. Bartlett's test of sphericity was statistically significant (χ 2 (45) = 536.222, p &lt; 0.001), which indicates that the correlation within our dataset is significant and unlikely to be due to chance. The component structure and reliability are shown in Table <ref type="table">1</ref>, which indicates that all the <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human <ref type="bibr">Behavior, 143, 107713. https://doi.org/10.1016</ref><ref type="bibr">Behavior, 143, 107713. https://doi.org/10. /j.chb.2023.107713 .107713</ref> factor loadings were above the cutoff value of 0.4, and all Cronbach's alpha (ɑ) values were more than the generally acceptable level of 0.7 <ref type="bibr" target="#b25">(Hair et al., 2019)</ref>. .705 .780 2. This automatic interviewer had strong expertise in assessment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. Trust Scale Components and Reliability</head><p>.801 3. This automatic interviewer could identify my responses and answers.</p><p>.687 4. I felt secure about the automatic interviewer assessing my performance.</p><p>.791 .756 5. I felt comfortable interacting with the automatic interviewer.</p><p>.691 6. I felt content with the automatic interviewer as an interviewer.</p><p>.677</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Demographics analysis</head><p>A chi-square analysis and analysis of variance (ANOVA) were conducted to determine whether the experimental groups differed in the interviewees' demographics, such as the participants' age (mean 27.6, standard deviation (SD) 8.2), sex (female 67.8%, male 32.2%), education (master's degree 15.1%, bachelor's degree 74.7%, high school diploma 10.2%), work experience (mean 5.1, SD 5.7), applied job function (human resources 32.2%, financial 25.3%, information technology 31.5%, operations 11%), and number of times participating in an AVI (Mean 1.1, SD 1.3). The analysis did not find any statistically significant factors (p&lt;.05) across the experimental conditions or groups; therefore, those demographics were not treated as covariates in the analysis of the hypotheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Correlation analysis</head><p>To understand the patterns of interaction and linear relationships among the variables in this study, we conducted Pearson correlation analysis and eliminated non-AI-AVI data to compute the</p><p>Suen, H. Y., &amp; Hung, K. E. (2023). Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref>  Table <ref type="table" target="#tab_5">2</ref> shows that cognitive trust (mean 3.509, SD 0.746) and affective trust (mean 3.524, SD 0.701) were moderately intercorrelated, while the various treatments were also slightly intercorrelated because the AI interfaces were under the same experimental conditions as the AI-AVIs. Regarding the treatments correlating with cognitive and affective trust, AI and transparency were positively associated with cognitive trust, whereas tangibility was positively associated with affective trust. Contrary to our expectations, tangibility and immediacy were not significantly associated with cognitive trust, and AI and its immediacy did not influence affective trust. The matrix also shows that the demographics of the interviewees varied with their job <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. <ref type="url" target="https://doi.org/10.1016/j.chb.2023.107713">https://doi.org/10.1016/j.chb.2023.107713</ref> 20 functions, with the older participants having more work experience, but their demographics were not correlated with the study treatments or dependent variables. Additionally, the interviewees' previous AVI experience in employment interviews did not influence their cognitive or affective trust in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis of hypotheses</head><p>Table <ref type="table" target="#tab_6">3</ref> displays descriptive statistics by experimental group, and the mean of each treatment group was more than that of the control group, except for the mean of immediacy for affective trust.</p><p>MANOVA showed a statistically significant difference in cognitive trust between the AIbased AVI and non-AI-based AVI (F (1, 150) = 8.221; p &lt;.01; partial η2 =.052); thus, H1a was supported. However, there was no statistically significant difference (p=.232) in affective trust between the two groups. This means that the AI-supported screening did not negatively influence the interviewees' affective responses, which is similar to the results of <ref type="bibr">Köchling et al.'s (2022)</ref> empirical study; therefore, H1b was not supported. The reason for this could be the greater popularity of using AI interviews and reports in public media, which accordingly leads job applicants to accept the new normal even though they do not know how the black box works (see <ref type="bibr" target="#b56">O'Brien, 2021;</ref><ref type="bibr" target="#b57">O'Connor, 2021)</ref>.</p><p>MANOVA showed a statistically significant difference in affective trust between the tangible AI-AVI and intangible AI-AVI, F (1, 128) = 4.083, p &lt;.05; partial η 2 =.031, but there was no significant difference in cognitive trust (p=.790). Therefore, H2b was supported, but H2a was not. This unexpected result may be explained by <ref type="bibr" target="#b41">Lee et al.'s (2015)</ref> study, which revealed <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: <ref type="bibr">Tangibility, immediacy, and</ref><ref type="bibr">transparency. Computers in Human Behavior, 143, 107713. https://doi.org/10.1016/j.chb.2023.107713</ref> that online consumers have more affective trust than cognitive trust toward attractive avatars but not expert avatars because cognitive trust is grounded in strongly rational reasons, whereas affective trust is built on feelings and not reason. Since the participants in this treatment in both the tangible and intangible groups were told they would be evaluated by AI, they may have had a good reason to trust both types of AI-AVI from a cognitive perspective. The tangibility value of the AI may have increased its attractiveness and thus affective trust.</p><p>Inconsistent with H3a and H3b, neither cognitive (p=.949) nor affective trust (p=.607) was significantly different across groups with the immediacy treatment according to MANOVA.</p><p>Regarding cognitive trust, <ref type="bibr" target="#b54">Nordheim et al. (2019)</ref> found that whether a chatbot can correctly and appropriately interpret users' responses or queries influences the latter's trust that the former has sufficient expertise and responsiveness. However, while the chatbot representing immediacy followed a standard script to respond to the interviewees' voice patterns, it could not interpret or answer interviewees' various responses or queries as an intelligent chatbot (e.g., Amazon Alexa, Apple Siri, ChatGPT, or Paradox.ai). Therefore, the treatment did not elevate users' cognitive trust, and H3a was not supported. As mentioned above, the immediacy was conveyed by a predefined standard script without human-likeness or computer intelligence in which the interviewees might not perceive that they were monitored or threatened, and thus, the treatment might not have decreased their affective trust toward the AI-AVI, as proposed by H3b. Supporting H4, transparency positively affected cognitive trust by MANOVA (F (1, 128) = 4.457, p &lt;.05; partial η 2 =.034), while affective trust was not significantly affected by the treatment (p=.152).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Although AI-based AVI has been used as a replacement for conferencing interviews, phone interviews, and face-to-face interviews in initial employment screening <ref type="bibr" target="#b21">(Gorman et al., 2018)</ref>, whether job applicants trust this approach is unknown, and this issue is critical to recruitment effectiveness (e.g., applicant withdrawal) <ref type="bibr" target="#b69">(van Esch et al., 2020)</ref>. This project answers Glikson and Woolley's (2020) call for research on both cognitive and affective trust in various AI embodiments and interface features, especially in the context of employee selection <ref type="bibr" target="#b1">(Acikgoz et al., 2020)</ref>. The study investigated applicants' cognitive and affective trust in various AI-AVI interfaces in real employee selection, and the results showed that AI per se can activate applicants' cognitive trust. Moreover, if an AI-AVI is equipped with tangibility, applicants' affective trust can be increased; if transparency is embedded, applicants' cognitive trust can be increased. Contrary to our assumptions, the applicants' affective trust was not decreased by the AI and its immediacy in this study, and their cognitive trust was not increased by tangibility or immediacy.</p><p>Building on the literature on social psychology and human-computer interaction, this field study is the first to probe job applicants' trust in AI-based video interviews from both cognitive and affective perspectives and to examine the effects of various AI-AVI interfaces.</p><p>Consistent with the argument for AI's objectivity (e.g., <ref type="bibr">van Esch et al., 2019)</ref>, signaling <ref type="bibr" target="#b1">(Acikgoz et al., 2020)</ref>, and selection fairness <ref type="bibr" target="#b18">(Gilliland, 1993)</ref>, job applicants trust AI more than human raters from a rational perspective. In contrast to concerns about AI's explainability (e.g., <ref type="bibr" target="#b40">Langer et al., 2021)</ref>, job applicants' emotional trust in the AI used in video interviews may not be so low if they are told about the use of AI (see <ref type="bibr" target="#b37">Köchling et al., 2022)</ref> because AI use has become a new normal <ref type="bibr" target="#b35">(Kim &amp; Heo, 2022)</ref>. Moreover, AI-AVI with transparency conveys more rational explanations to job applicants, allowing them to understand what AI is being used and how AI evaluates their interviews in accordance with explanation-for-trust theory <ref type="bibr" target="#b58">(Pieters, 2011)</ref>.</p><p>In line with social interface theory <ref type="bibr" target="#b45">(Long, 2001)</ref>, humanizing cues in an AI interface can elicit responses from interviewees during human-to-AI interviewer interaction similar to those produced by human-to-human interviewer interaction. This study conferred humanizing cues on the AI interfaces with tangibility and immediacy, and the study results show how social interface theory needs to be elaborated to become applicable to the AI context to better understand job applicants' trust in the AI used for automatic video interviews (i.e., AI-AVI) <ref type="bibr" target="#b27">(Hickman et al., 2022</ref>). An AI-AVI reveals tangibility by being embodied by an avatar, which can increase job applicants' affective trust because of the increased social presence and interaction perceived by the applicants <ref type="bibr" target="#b10">(Chattaraman et al., 2014)</ref>, and avatar may arouse more affective trust than cognitive trust when applicants perceive more attractiveness than expertise from the avatar (see <ref type="bibr" target="#b41">Lee et al., 2015)</ref>. However, an AI-AVI supplied with immediacy by being embodied by a chatbot that has a voice tracking signal with standard text-based responsiveness may not increase job applicants' cognitive trust or decrease their affective trust. Whether more intelligent chatbots that convey immediacy influence job applicants' trust should be explored in future studies (see <ref type="bibr" target="#b54">Nordheim et al., 2019)</ref>.</p><p>Accordingly, the study results provide some recommendations for designing AI-AVI and choosing optimal interfaces for AI-AVI to increase job applicants' trust in the initial preemployment selection process. First, job applicants should be informed in writing that their interview performance will be assessed by AI algorithms when true to activate their cognitive <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human <ref type="bibr">Behavior, 143, 107713. https://doi.org/10.1016</ref><ref type="bibr">Behavior, 143, 107713. https://doi.org/10. /j.chb.2023.107713 .107713</ref> trust by conveying objectivity. Second, what AI will be used and how the AI will assess the interviewees should be conveyed with simple words through text to increase cognitive trust by conveying transparency. Finally, an attractive virtual agent or avatar should be displayed on the screen to increase affective trust by simulating a social presence and human interaction in conferencing interviews.</p><p>Although this study tested and determined how to increase job applicants' trust in AI-AVIs using various interface features, some notable limitations of this study should be addressed by future research. First, because of the wide adoption and media reports of AI-AVIs being used for personnel selection, the participants may have been familiar with and accepted the technology without restrictions on the use of AI video interviews (e.g., Illinois' Artificial Intelligence Video Interview Act). Additionally, cultural differences might have some impact on their evaluation of trust in the AI video interview system. Future studies should repeat our experiment in other states or countries with different digital maturities, legal requirements, and cultural contexts to examine whether negative trust responses can occur. Second, this study involved only 152 participants, who had an average age of 27.6 years old, had a bachelor's degree or higher (90%) came from a single PEO, and applied for only four types of job functions, which may have influenced the study's generalizability because the demographics may mediate or moderate the resulting dependent variables. Future studies should solicit more diverse job applicants to test our research hypotheses. Third, the participants' prior perception toward AI itself may have influenced their trust in AI <ref type="bibr" target="#b61">(Langer et al., 2022)</ref>. Future studies should measure and control the prior perception toward AI. Finally, the three AI interfaces and their impacts on the results were limited to our interface designs. However, different AI interface designs may <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human <ref type="bibr">Behavior, 143, 107713. https://doi.org/10.1016</ref><ref type="bibr">Behavior, 143, 107713. https://doi.org/10. /j.chb.2023.107713 .107713</ref> have different impacts on users' trust in AI, according to <ref type="bibr" target="#b5">Bedué and Fritzsche's (2022)</ref> qualitative study. Future studies should use a male avatar to display tangibility (see <ref type="bibr" target="#b46">Machneva et al., 2022)</ref>, apply machine learning and natural language processing (NLP) to develop an intelligent chatbot to convey immediacy (see <ref type="bibr" target="#b29">Hu al., 2021)</ref> or use different interpretable messages to demonstrate transparency (see <ref type="bibr" target="#b44">Liu &amp; Wei, 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>As the demand for AI-AVIs increases in the postpandemic era, so do concerns about their lack of humanity and transparency impairing users' trust <ref type="bibr" target="#b32">(Jaser et al., 2022)</ref>. This study tested various modalities of AI-AVI, and we found that trust concerns were not present among the actual job applicants. Moreover, the findings show that AI-AVIs equipped with various interface designs can increase applicants' cognitive and/or affective trust. We believe that this study can benefit future academic research through this important finding and can help vendors and users develop and adopt the most trustworthy approaches to using AI-AVIs for personnel selection. <ref type="bibr">Suen, H. Y., &amp; Hung, K. E. (2023)</ref>. Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human <ref type="bibr">Behavior, 143, 107713. https://doi.org/10.1016</ref><ref type="bibr">Behavior, 143, 107713. https://doi.org/10. /j.chb.2023.107713 .107713</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>Suen, H. Y., &amp; Hung, K. E. (2023). Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. https://doi.org/10.1016/j.chb.2023.107713 asked five behavioral-based structured interview questions to assess their interpersonal communication skills that would be essential for various job functions. The five interview questions took approximately 15-20 minutes to complete. A sample question is as follows:"Describe a time you had to share bad news with your team or have a difficult conversation with a coworker."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><figDesc>automatic interviewer was like a real expert in assessing my performance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><figDesc>Moreover, we examined the difference in the treatments between each of the four experimental groups and a control group -AI-AVI without any AI-interface features (n=40) by MANOVA, and we obtained results similar to those above. Cognitive trust was significantly different between the AI-AVI and control groups (mean 3.425, SD 0.687, N=40), F (1, 60) = 4.072, p &lt;.05; partial η 2 =.064), but affective trust was not (p=.785). Affective trust was significantly different between the tangible AI-AVI and control groups (mean 3.317, SD 0.594), F (1, 65) = 9.151, p &lt;.01; partial η 2 =.123), but cognitive trust was not (p=.303). Neither cognitive trust (p=.398) nor affective trust (p=.354) was significantly different between the immediate AI-AVI and control groups. Cognitive trust was significantly different between the transparent AI-AVI and the control groups, F (1, 70) = 6.450, p &lt;.05; partial η 2 =.084, but affective trust was not (p=.143).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 .</head><label>2</label><figDesc>Suen, H. Y., &amp; Hung, K. E. (2023). Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in Human Behavior, 143, 107713. https://doi.org/10.1016/j.chb.2023.107713 correlations among tangibility, immediacy, transparency and other variables, as shown in Table2.Correlation Matrix</figDesc><table><row><cell>Variables</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell><cell>11</cell></row><row><cell>1. Cognitive trust</cell><cell>--</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2. Affective trust</cell><cell cols="2">.559** --</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3. AI a</cell><cell cols="3">.225** .104 --</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4. Tangibility a</cell><cell cols="4">.060 .188* .167* --</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5. Immediacy a</cell><cell cols="5">.045 .025 -.045 .142 --</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>6. Transparency a</cell><cell cols="6">.238** .133 .186* .152 -.069 --</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>7. Sex b</cell><cell cols="7">-.003 -.153 .179 -.102 -.060 .102 --</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>8. Age</cell><cell cols="7">-.022 -.020 .040 .052 .055 -.013 -.098</cell><cell>--</cell><cell></cell><cell></cell><cell></cell></row><row><cell>9. Education c</cell><cell cols="8">-.001 .151 -.105 .069 -.089 .119 -.111 .074</cell><cell>--</cell><cell></cell><cell></cell></row><row><cell>10. Work experience</cell><cell cols="9">-.014 -.021 .016 .017 .119 .050 -.098 .894** -.151</cell><cell>--</cell><cell></cell></row><row><cell>11. AVI experience</cell><cell cols="10">.081 .003 .008 .150 -.077 -.116 -.102 -.008 .028 -.030</cell><cell>--</cell></row><row><cell>12. Applied job function a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Human Resources</cell><cell cols="11">-.018 -.066 .142 .078 -.035 -.065 -.098 -.348** .307** -.367** .127</cell></row><row><cell>Financial</cell><cell cols="11">-.015 -.068 .102 .106 -.029 -.109 -.031 .149 -.084 .143 .046</cell></row><row><cell>Information Technology</cell><cell cols="11">.062 .036 .109 -.117 .039 .143 .232** -.176* -.187* -.140 -.107</cell></row><row><cell>Operation</cell><cell cols="11">.040 .019 .123 -.107 .069 -.116 .148 .390** -.307** .328** .000</cell></row><row><cell>*p&lt;.05; **p&lt;.01</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>a. Dummy coding</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>b. Male=1; Female=0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>c. Master's degree=2; Bachelor's</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>degree=1; High School diploma=0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 .</head><label>3</label><figDesc>Descriptive StatisticsSuen, H. Y., &amp; Hung, K. E.(2023). Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency. Computers in HumanBehavior, 143, 107713.  https://doi.org/10.1016Behavior, 143, 107713.  https://doi.org/10. /j.chb.2023.107713   .107713    </figDesc><table><row><cell>22</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713References" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Justice perceptions of artificial intelligence in selection</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Acikgoz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Compagnone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Laske</surname></persName>
		</author>
		<idno type="DOI">10.1111/ijsa.12306</idno>
		<ptr target="https://doi.org/10.1111/ijsa.12306" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Selection and Assessment</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="399" to="416" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Chatbots: History, technology, and applications</title>
		<author>
			<persName><forename type="first">E</forename><surname>Adamopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Moussiades</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.mlwa.2020.100006</idno>
		<ptr target="https://doi.org/10.1016/j.mlwa.2020.100006" />
	</analytic>
	<monogr>
		<title level="j">Machine Learning with Applications</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">100006</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ananny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Crawford</surname></persName>
		</author>
		<idno type="DOI">10.1177/1461444816676645</idno>
		<ptr target="https://doi.org/10.1177/1461444816676645" />
	</analytic>
	<monogr>
		<title level="j">New Media &amp; Society</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="973" to="989" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">It takes more than a good camera: Which factors contribute to differences between face-to-face interviews and videoconference interviews regarding performance ratings and interviewee perceptions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Basch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Melchers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kurz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10869-020-09714-3</idno>
		<ptr target="https://doi.org/10.1007/s10869-020-09714-3" />
	</analytic>
	<monogr>
		<title level="j">Journal of business and psychology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="921" to="940" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Can we trust AI? An empirical investigation of trust requirements and guide to successful AI adoption</title>
		<author>
			<persName><forename type="first">P</forename><surname>Bedué</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Fritzsche</surname></persName>
		</author>
		<idno type="DOI">10.1108/jeim-06-2020-0233</idno>
		<ptr target="https://doi.org/10.1108/jeim-06-2020-0233" />
	</analytic>
	<monogr>
		<title level="j">Journal of Enterprise Information Management</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="530" to="549" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">AI-enabled recruiting: What is it and how should a manager use it</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Van Esch</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bushor.2019.12.001</idno>
		<ptr target="https://doi.org/10.1016/j.bushor.2019.12.001" />
	</analytic>
	<monogr>
		<title level="j">Business Horizons</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="215" to="226" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Technology in the employment interview: A meta-analysis and future research agenda</title>
		<author>
			<persName><forename type="first">N</forename><surname>Blacksmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Willford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Behrend</surname></persName>
		</author>
		<idno type="DOI">10.25035/pad.2016.002</idno>
		<ptr target="https://doi.org/10.25035/pad.2016.002" />
	</analytic>
	<monogr>
		<title level="j">Personnel Assessment and Decisions</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="12" to="20" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Automatic prediction of impressions in time and across varying context: Personality, attractiveness and likeability</title>
		<author>
			<persName><forename type="first">O</forename><surname>Celiktutan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Gunes</surname></persName>
		</author>
		<idno type="DOI">10.1109/taffc.2015.2513401</idno>
		<ptr target="https://doi.org/10.1109/taffc.2015.2513401" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="42" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Virtual shopping agents</title>
		<author>
			<persName><forename type="first">V</forename><surname>Chattaraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W.-S</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename></persName>
		</author>
		<idno type="DOI">10.1108/jrim-08-2013-0054</idno>
		<ptr target="https://doi.org/10.1108/jrim-08-2013-0054" />
	</analytic>
	<monogr>
		<title level="j">Journal of Research in Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="144" to="162" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Developing a formative scale to measure consumers&apos; trust toward interaction with artificially intelligent (AI) social robots in service delivery</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">H</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gursoy</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2021.106700</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2021.106700" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page">106700</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Perceived usefulness, perceived ease of use, and user acceptance of information technology</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">D</forename><surname>Davis</surname></persName>
		</author>
		<idno type="DOI">10.2307/249008</idno>
		<ptr target="https://doi.org/10.2307/249008" />
	</analytic>
	<monogr>
		<title level="j">MIS Quarterly</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="319" to="340" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A little anthropomorphism goes a long way: Effects of oxytocin on trust, compliance, and team performance with automated agents</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>De Visser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Goodyear</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>O'hara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Parasuraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Krueger</surname></persName>
		</author>
		<idno type="DOI">10.1177/0018720816687205</idno>
		<ptr target="https://doi.org/10.1177/0018720816687205" />
	</analytic>
	<monogr>
		<title level="j">Human factors</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="133" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">I always assumed that I wasn&apos;t really that close to [her]&quot;: Reasoning about Invisible Algorithms in News Feeds</title>
		<author>
			<persName><forename type="first">M</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Vaccaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Aleyasen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vuong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Karahalios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sandvig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd annual</title>
		<meeting>the 33rd annual</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.10771329" />
	</analytic>
	<monogr>
		<title level="m">ACM conference on human factors in computing systems</title>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Statistical power analyses using G*Power 3.1: Tests for correlation and regression analyses</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-G</forename><surname>Lang</surname></persName>
		</author>
		<idno type="DOI">10.3758/brm.41.4.1149</idno>
		<ptr target="https://doi.org/10.3758/brm.41.4.1149" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1149" to="1160" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Video-enhanced self-administered computer interviews: Design and outcomes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Gerich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Online research methods in urban and planning studies: Design and outcomes</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">N S</forename><surname>Hershey</surname></persName>
		</editor>
		<imprint>
			<publisher>IGI Global</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="99" to="119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The perceived fairness of selection systems: An organizational justice perspective</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Gilliland</surname></persName>
		</author>
		<idno type="DOI">10.5465/amr.1993.9402210155</idno>
		<ptr target="https://doi.org/10.5465/amr.1993.9402210155" />
	</analytic>
	<monogr>
		<title level="j">Academy of Management Review</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="694" to="734" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Human trust in artificial intelligence: Review of empirical research</title>
		<author>
			<persName><forename type="first">E</forename><surname>Glikson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Woolley</surname></persName>
		</author>
		<idno type="DOI">10.5465/annals.2018.0057</idno>
		<ptr target="https://doi.org/10.5465/annals.2018.0057" />
	</analytic>
	<monogr>
		<title level="j">Academy of Management Annals</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="627" to="660" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Allying with AI? Reactions toward human-based, AI/ML-based, and augmented hiring processes</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shirase</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Tomczak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Lobbe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Justenhoven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Martin</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2022.107179</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2022.107179" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="page">107179</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An investigation into the validity of asynchronous web-based video employment-interview ratings</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Gamble</surname></persName>
		</author>
		<idno type="DOI">10.1037/cpb0000102</idno>
		<ptr target="https://doi.org/10.1037/cpb0000102" />
	</analytic>
	<monogr>
		<title level="j">Consulting Psychology Journal: Practice and Research</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Automation in recruitment: A new frontier</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">F</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jain</surname></persName>
		</author>
		<idno type="DOI">10.1057/s41266-018-0042-x</idno>
		<ptr target="https://doi.org/10.1057/s41266-018-0042-x" />
	</analytic>
	<monogr>
		<title level="j">Journal of Information Technology Teaching Cases</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="118" to="125" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Response behavior in a video-web survey: A mode comparison study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Haan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">P</forename><surname>Ongena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T A</forename><surname>Vannieuwenhuyze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>De Glopper</surname></persName>
		</author>
		<idno type="DOI">10.1093/jssam/smw023</idno>
		<ptr target="https://doi.org/10.1093/jssam/smw023" />
	</analytic>
	<monogr>
		<title level="j">Journal of Survey Statistics and Methodology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="69" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Multivariate data analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Hair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">C</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Babin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Anderson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>Prentice-Hall</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Applied artificial intelligence and trust-The case of autonomous vehicles and medical assistance devices</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hengstler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Enkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Duelli</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.techfore.2015.12.014</idno>
		<ptr target="https://doi.org/10.1016/j.techfore.2015.12.014" />
	</analytic>
	<monogr>
		<title level="j">Technological Forecasting and Social Change</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="page" from="105" to="120" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automated video interview personality assessments: Reliability, validity, and generalizability investigations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Hickman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Saef</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Woo</surname></persName>
		</author>
		<idno type="DOI">10.1037/apl0000695</idno>
		<ptr target="https://doi.org/10.1037/apl0000695" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Psychology</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1323" to="1351" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Trust in automation: Integrating empirical evidence on factors that influence trust</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Hoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bashir</surname></persName>
		</author>
		<idno type="DOI">10.1177/0018720814547570</idno>
		<ptr target="https://doi.org/10.1177/0018720814547570" />
	</analytic>
	<monogr>
		<title level="j">Human Factors: The Journal of the Human Factors and Ergonomics Society</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="407" to="434" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dual humanness and trust in conversational AI: A person-centered approach</title>
		<author>
			<persName><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">(</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">)</forename><surname>Yale</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2021.106727</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2021.106727" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">106727</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Ethics of AI-enabled recruiting and selection: A review and research agenda</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Hunkenschroer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Luetge</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10551-022-05049-6</idno>
		<ptr target="https://doi.org/10.1007/s10551-022-05049-6" />
	</analytic>
	<monogr>
		<title level="j">Journal of Business Ethics</title>
		<imprint>
			<biblScope unit="volume">178</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="977" to="1007" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Where automated job interviews fall short</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Jaser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Petrakaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Starr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Oyarbide-Magaña</surname></persName>
		</author>
		<ptr target="https://hbr.org/2022/01/where-automated-job-interviews-fall-short" />
	</analytic>
	<monogr>
		<title level="j">Harvard Business Review</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Evolution of artificial intelligence research in human resources</title>
		<author>
			<persName><forename type="first">M</forename><surname>Jatobá</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Gutierriz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moscon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">O</forename><surname>Fernandes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Teixeira</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.procs.2019.12.165</idno>
		<ptr target="https://doi.org/10.1016/j.procs.2019.12.165" />
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="page" from="137" to="142" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cognitive and affective trust in service relationships</title>
		<author>
			<persName><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grayson</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0148-2963(03)00140-1</idno>
		<ptr target="https://doi.org/10.1016/s0148-2963(03)00140-1" />
	</analytic>
	<monogr>
		<title level="j">Journal of Business Research</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="500" to="507" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Artificial intelligence video interviewing for employment: Perspectives from applicants, companies, developer and academicians</title>
		<author>
			<persName><forename type="first">J.-Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Heo</surname></persName>
		</author>
		<idno type="DOI">10.1108/itp-04-2019-0173</idno>
		<ptr target="https://doi.org/10.1108/itp-04-2019-0173" />
	</analytic>
	<monogr>
		<title level="j">Information Technology &amp; People</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="861" to="878" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Measurement of Trust in Automation: A Narrative Review and Reference Guide</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Visser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wiese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Shaw</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2021.604977</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2021.604977" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">604977</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Can I show my skills? Affective responses to artificial intelligence in the recruitment process</title>
		<author>
			<persName><forename type="first">A</forename><surname>Köchling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Wehner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Warkocz</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11846-021-00514-4</idno>
		<ptr target="https://doi.org/10.1007/s11846-021-00514-4" />
	</analytic>
	<monogr>
		<title level="j">Review of Managerial Science</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">What do we want from explainable artificial intelligence (XAI)? -A stakeholder perspective on XAI and a conceptual model guiding interdisciplinary XAI research</title>
		<author>
			<persName><forename type="first">M</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Speith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hermanns</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kä Stner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sesing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Baum</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2021.103473</idno>
		<ptr target="https://doi.org/10.1016/j.artint.2021.103473" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">296</biblScope>
			<biblScope unit="page">103473</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The effects of avatar on trust and purchase intention of female online consumer: Consumer knowledge as a moderator</title>
		<author>
			<persName><forename type="first">H.-S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P.-C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y.-J</forename><surname>Jhu</surname></persName>
		</author>
		<idno type="DOI">10.7903/ijecs.1395</idno>
		<ptr target="https://doi.org/10.7903/ijecs.1395" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Electronic Commerce Studies</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="118" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Trust in automation: Designing for appropriate reliance</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>See</surname></persName>
		</author>
		<idno type="DOI">10.1518/hfes.46.1.50.30392</idno>
		<ptr target="https://doi.org/10.1518/hfes.46.1.50.30392" />
	</analytic>
	<monogr>
		<title level="j">Human Factors</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="80" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">I: A tangible AI interface to enhance human-artificial intelligence (AI) communication beyond the screen</title>
		<author>
			<persName><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>London</surname></persName>
		</author>
		<author>
			<persName><forename type="first">)</forename><forename type="middle">T A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 ACM conference on designing interactive systems</title>
		<meeting>the 2016 ACM conference on designing interactive systems</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="281" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Machine gaze in online behavioral targeting: The effects of algorithmic human likeness on social presence and social influence</title>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2021.106926</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2021.106926" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">106926</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Development sociology: Actor perspectives</title>
		<author>
			<persName><forename type="first">N</forename><surname>Long</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>Routledge</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Consensus and (lack of) accuracy in perceptions of avatar trustworthiness</title>
		<author>
			<persName><forename type="first">M</forename><surname>Machneva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Stavrova</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2021.107017</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2021.107017" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page">107017</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Implementation and normalization process of asynchronous video interviewing practices in the hospitality industry</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mejia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">N</forename><surname>Torres</surname></persName>
		</author>
		<idno type="DOI">10.1108/ijchm-07-2016-0402</idno>
		<ptr target="https://doi.org/10.1108/ijchm-07-2016-0402" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Contemporary Hospitality Management</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="685" to="701" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">The influence of technology anxiety on consumer use and experiences with self-service technologies</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Meuter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Ostrom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Bitner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Roundtree</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0148-2963(01)00276-4</idno>
		<ptr target="https://doi.org/10.1016/S0148-2963(01)00276-4" />
	</analytic>
	<monogr>
		<title level="j">Journal of Business Research</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="899" to="906" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Hands on the wheel: Navigating algorithmic management and Uber drivers</title>
		<author>
			<persName><forename type="first">M</forename><surname>Möhlmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zalmanson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the international conference on information systems (ICIS)</title>
		<meeting>the international conference on information systems (ICIS)</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="10" to="13" />
		</imprint>
	</monogr>
	<note>Autonomy</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Bukimi no tani [The uncanny valley</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Energy</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="33" to="35" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Automated analysis and prediction of job interview performance</title>
		<author>
			<persName><forename type="first">I</forename><surname>Naim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Tanveer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Hoque</surname></persName>
		</author>
		<idno type="DOI">10.1109/taffc.2016.2614299</idno>
		<ptr target="https://doi.org/10.1109/taffc.2016.2614299" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Affective Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="191" to="204" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Hire me: Computational inference of hirability in employment interviews based on nonverbal behavior</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">S</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Frauendorfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Mast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Gatica-Perez</surname></persName>
		</author>
		<idno type="DOI">10.1109/tmm.2014.2307169</idno>
		<ptr target="https://doi.org/10.1109/tmm.2014.2307169" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1018" to="1031" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">An initial model of trust in chatbots for customer service-Findings from a questionnaire study</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Nordheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Følstad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Bjørkli</surname></persName>
		</author>
		<idno type="DOI">10.1093/iwc/iwz022</idno>
		<ptr target="https://doi.org/10.1093/iwc/iwz022" />
	</analytic>
	<monogr>
		<title level="j">Interacting with Computers</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="317" to="335" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Want a job? Employers say: Talk to the computer</title>
		<author>
			<persName><forename type="first">M</forename><surname>O'brien</surname></persName>
		</author>
		<ptr target="https://fortune.com/2021/06/18/job-interview-artificial-intelligence-remote-online/" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">Fortune</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">AI is making applying for jobs even more miserable</title>
		<author>
			<persName><forename type="first">S</forename><surname>O'connor</surname></persName>
		</author>
		<ptr target="https://www.ft.com/content/a81245ee-9916-47e2-81b9-846e9403be00" />
	</analytic>
	<monogr>
		<title level="j">Financial Times</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Explanation and trust: What to tell the user in security and AI?</title>
		<author>
			<persName><forename type="first">W</forename><surname>Pieters</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10676-010-9253-3</idno>
		<ptr target="https://doi.org/10.1007/s10676-010-9253-3" />
	</analytic>
	<monogr>
		<title level="j">Ethics and Information Technology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="64" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Automatic assessment of communication skill in non-conventional interview settings: a comparative study</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B P</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rasipuram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Jayagopi</surname></persName>
		</author>
		<editor>E.</editor>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m">Proceedings of the 19th ACM international conference on multimodal interaction</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Lank</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">H S</forename><surname>Vinciarelli</surname></persName>
		</editor>
		<editor>
			<persName><surname>Subramanian</surname></persName>
		</editor>
		<meeting>the 19th ACM international conference on multimodal interaction</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page" from="221" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Is more always better? How preparation time and re-recording opportunities impact fairness, anxiety, impression management, and performance in asynchronous video interviews</title>
		<author>
			<persName><forename type="first">N</forename><surname>Roulin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Langer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Bourdage</surname></persName>
		</author>
		<idno type="DOI">10.1080/1359432X.2022.2156862</idno>
		<ptr target="https://doi.org/10.1080/1359432X.2022.2156862" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Work and Organizational Psychology</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Recruiter and job influences on *s for employment</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Rynes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Miller</surname></persName>
		</author>
		<idno type="DOI">10.1037/0021-9010.68.1.147</idno>
		<ptr target="https://doi.org/10.1037/0021-9010.68.1.147" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Psychology</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="154" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Does the use of synchrony and artificial intelligence in video interviews affect interview ratings and applicant attitudes?</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-C</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S.-H</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2019.04.012</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2019.04.012" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="93" to="101" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">TensorFlow-based automatic personality recognition used in asynchronous video interviews</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-E</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1109/access.2019.2902863</idno>
		<ptr target="https://doi.org/10.1109/access.2019.2902863" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="61018" to="61023" />
			<date type="published" when="2019">2019b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Intelligent video interview agent used to predict communication skill and perceived personality traits</title>
		<author>
			<persName><forename type="first">H.-Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K.-E</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-L</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13673-020-0208-3</idno>
		<ptr target="https://doi.org/10.1186/s13673-020-0208-3" />
	</analytic>
	<monogr>
		<title level="j">Human-centric Computing and Information Sciences</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Artificial intelligence in human resources management: Challenges and a path forward</title>
		<author>
			<persName><forename type="first">P</forename><surname>Tambe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Cappelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Yakubovich</surname></persName>
		</author>
		<idno type="DOI">10.1177/0008125619867910</idno>
		<ptr target="https://doi.org/10.1177/0008125619867910" />
	</analytic>
	<monogr>
		<title level="j">California Management Review</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="15" to="42" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Factors that influence new generation candidates to engage with and complete digital, AI-enabled recruiting</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Esch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Black</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bushor.2019.07.004</idno>
		<ptr target="https://doi.org/10.1016/j.bushor.2019.07.004" />
	</analytic>
	<monogr>
		<title level="j">Business Horizons</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="729" to="739" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Job candidates&apos; reactions to AI-Enabled job application processes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Esch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Arli</surname></persName>
		</author>
		<idno type="DOI">10.1007/s43681-020-00025-0</idno>
		<ptr target="https://doi.org/10.1007/s43681-020-00025-0" />
	</analytic>
	<monogr>
		<title level="j">AI and Ethics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="130" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Marketing AI recruitment: The next phase in job application and selection</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Esch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ferolie</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2018.09.009</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2018.09.009" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="215" to="222" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Recommendation agents for electronic commerce: Effects of explanation facilities on trusting beliefs</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Benbasat</surname></persName>
		</author>
		<idno type="DOI">10.2753/mis0742-1222230410</idno>
		<ptr target="https://doi.org/10.2753/mis0742-1222230410" />
	</analytic>
	<monogr>
		<title level="j">Journal of Management Information Systems</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="217" to="246" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Building trust in automatic video interviews using various AI interfaces: Tangibility, immediacy, and transparency</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Hung</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.chb.2023.107713</idno>
		<ptr target="https://doi.org/10.1016/j.chb.2023.107713" />
	</analytic>
	<monogr>
		<title level="j">Computers in Human Behavior</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page">107713</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Effects of rational and social appeals of online recommendation agents on cognition-and affect-based trust</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Benbasat</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dss.2016.03.007</idno>
		<ptr target="https://doi.org/10.1016/j.dss.2016.03.007" />
	</analytic>
	<monogr>
		<title level="j">Decision Support Systems</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="48" to="60" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">The mind in the machine: Anthropomorphism increases trust in an autonomous vehicle</title>
		<author>
			<persName><forename type="first">A</forename><surname>Waytz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heafner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Epley</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jesp.2014.01.005</idno>
		<ptr target="https://doi.org/10.1016/j.jesp.2014.01.005" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="113" to="117" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Personnel selection in the digital age: A review of validity and applicant reactions, and future research challenges</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Woods</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nikolaou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<idno type="DOI">10.1080/1359432x.2019.1681401</idno>
		<ptr target="https://doi.org/10.1080/1359432x.2019.1681401" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Work and Organizational Psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="77" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
