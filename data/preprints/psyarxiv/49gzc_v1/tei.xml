<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ChatGPT exhibits bias towards developed countries over developing ones, as indicated by a sentiment analysis approach</title>
				<funder>
					<orgName type="full">Phonetic Lab of the University of Nicosia</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Georgios</forename><forename type="middle">P</forename><surname>Georgiou</surname></persName>
							<email>georgiou.georg@unic.ac.cy</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Languages and Literature</orgName>
								<orgName type="institution">University of Nicosia</orgName>
								<address>
									<settlement>Nicosia</settlement>
									<country key="CY">Cyprus</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Director of the Phonetic Lab</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ChatGPT exhibits bias towards developed countries over developing ones, as indicated by a sentiment analysis approach</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">75E325F32FD5027312FFD0754EAE72CB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ChatGPT</term>
					<term>developing countries</term>
					<term>developed countries</term>
					<term>sentiment analysis</term>
				</keywords>
			</textClass>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Large Language Models (LLMs) have transformed the landscape of Natural Language Processing (NLP). The capability of LLMs like ChatGPT in producing high-quality text closely mimicking human language is welldocumented <ref type="bibr" target="#b1">(Adeshola &amp; Adepoju, 2023;</ref><ref type="bibr" target="#b6">Chukwuere 2024</ref>). Nevertheless, LLMs inadvertently mirror and perpetuate biases present in their training data <ref type="bibr" target="#b4">(Caliskan, 2017)</ref>. While content filtering techniques have been employed to mitigate harmful outputs <ref type="bibr" target="#b13">(Markov et al., 2023)</ref>, biases can persist within the model itself <ref type="bibr">(Ray, 2023)</ref>. Deploying biased models in real-world applications can have detrimental consequences, as demonstrated by incidents such as those involving Artificial Intelligence (AI) healthcare predictions <ref type="bibr" target="#b14">(Obermeyer et al., 2019)</ref>.</p><p>LLMs demonstrate various biases associated with gender <ref type="bibr" target="#b11">(Gross, 2023)</ref>, language <ref type="bibr">(Georgiou, 2024)</ref>, religion <ref type="bibr" target="#b0">(Abid et al., 2021)</ref>, politics <ref type="bibr" target="#b17">(Rozado, 2023)</ref>, and nationality <ref type="bibr" target="#b19">(Venkit et al., 2023)</ref> among others. <ref type="bibr">Zhou et al. (2024)</ref> investigated the nationality bias of ChatGPT using a sample of 195 countries, with descriptions provided in both English and Chinese. The authors evaluated the output using vocabulary richness, sentiment, and offensiveness metrics. Evaluations of language have also been conducted by humans and ChatGPT. The findings indicated that although the generated content was largely positive, ChatGPT produced negative content when given prompts with negative connotations. Although the model viewed its output as neutral, it consistently demonstrated selfawareness of nationality bias when evaluated using the same pair-wise comparison</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>This study analyzes how ChatGPT characterizes developed and developing countries using a sentiment analysis framework. We selected 10 countries with the highest Human Development Index (HDI) and 10 countries with the lowest. The sentiment analysis provided scores indicating the degree of positivity in the descriptions of these countries provided by ChatGPT. The results revealed that ChatGPT generally expressed positive sentiments about all countries. However, strong evidence emerged showing that countries with high HDI received more positive sentiments compared to those with low HDI. These findings highlight the bias of the model in describing developed versus developing countries. Ultimately, the study highlights the importance of adjusting large language models to ensure fairer representations of countries. annotation method employed by human annotators.</p><p>The examination of country bias in AIgenerated language has received minimal scientific attention. In a relevant study, <ref type="bibr">Boussidan et al. (2023)</ref> explored the biases of ChatGPT regarding various countries around the globe. The authors followed a sentiment analysis approach, prompting the model to assign a positivity score to each country. Prompts were provided in four different languages, namely French, English, Russian and Arabic. The findings revealed that North American and European countries received higher scores, whereas African countries received the lowest. South American and Asian countries typically fell in the middle range. The results also denoted variations across languages. When prompted in French, African countries, particularly those colonized by France, tended to receive more negative scores. In contrast, when prompted in English, the model assigned positive scores to Commonwealth nations like India and Australia. However, the sentiment analysis in the above study relied on the scores assigned to these countries by ChatGPT, using a scale developed by the authors. The conclusion drawn is that ChatGPT is biased towards specific countries. For instance, <ref type="bibr" target="#b18">Salinas et al. (2023)</ref> reported that when prompted to select 20 nationalities, the model chose exclusively from Western countries, omitting African nations.</p><p>This study aims to fill a research gap by investigating the sentiments found in ChatGPT-generated language regarding developed versus developing countries. We uniquely employ a sentiment analysis framework, which indicates the sentiment scores of the generated texts about the countries under investigation. These scores were derived from an embedded online dictionary, which assessed the positivity of each word in the generated language. The comparison between developed and developing countries is performed through statistical modeling. Since the LLM is sensitive to biases based on previous research, we hypothesize that developed countries will exhibit higher sentiment scores than developing countries. By analyzing sentiment scores in AI-generated texts, the study aims to reveal potential biases, promoting fairer and more accurate representations. This effort supports ethical AI development, enhances trustworthiness in AI systems, and ensures informed decisionmaking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Procedure</head><p>We used ChatGPT-3.5 to generate the texts. We employed a prompt designed to elicit unbiased thoughts about specific countries. Specifically, we presented the following prompt to ChatGPT: "Please provide us with any thoughts about [name of the country] within 10 sentences". The sample consisted of 20 countries selected according to their Human Development Index (HDI). HDI is a composite statistic that combines life expectancy, education (measured by both the average years of schooling completed and the expected years of schooling at the start of education), and per capita income. This index categorizes countries into four levels of human development. Higher HDI scores correspond to longer lifespans, higher education levels, and greater gross national income per capita adjusted for purchasing power parity. HDI is employed by the United Nations Development Program's Human Development Report Office to assess and compare the development progress of countries (World Health Organization, 2024).</p><p>The selected countries were retrieved from the latest Human Development Report 2023-24 and include data from 2022 <ref type="bibr" target="#b8">(Conceição, 2024)</ref>. These countries were Switzerland, Norway, Iceland, Hong Kong, Denmark, Sweden, Ireland, Germany, Singapore, and Netherlands as well as Sierra Leone, Burkina Faso, Yemen, Burundi, Mali, Niger, Chad, Central African Republic, South Sudan, and Somalia. The first 10 countries had the highest HDI in the report (0.946 -0.967, Standard Deviation (SD) = 0.007), while the other 10 countries had the lowest HDI (0.38 -0.424, SD = 0.02).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Analysis</head><p>The sentiment analysis was conducted with the use of the SentimentAnalysis package in R (R Core Team, 2024). Sentiments were extracted utilizing the QDAP dictionary from the qdapDictionaries package <ref type="bibr" target="#b16">(Rinker, 2021)</ref>. The value of particular words ranges from -1 (highly negative) to 1 (highly positive). Scores close to zero indicate neutral sentiment.</p><p>We used a Bayesian regression model via the brms package <ref type="bibr">(Bürkner et al., 2023)</ref> in R to analyze our data. This is because of its potential to handle small sample data <ref type="bibr" target="#b7">(Georgiou, 2023)</ref>. The dependent variable included the sentiment SCORE measured between -1 and 1. HDI (low/high) was modeled as the fixed factor, while COUNTRY was treated as a random factor. Weakly informative priors were used, given the lack of predefined assumptions about the data parameters <ref type="bibr" target="#b9">(Georgiou &amp; Giannakou, 2024)</ref>. These priors followed a student's tdistribution with 3 degrees of freedom, a mean of 0, and an SD of 2.5 <ref type="bibr" target="#b10">(Georgiou &amp; Kaskampa, 2024)</ref>. The Evidence Ratio (ER) was used to assess the likelihood of the test hypotheses compared to their alternatives. We adhered to <ref type="bibr" target="#b12">Jeffreys's (1961)</ref> approach, considering an Evidence Ratio (ER) of 10 or higher as strong evidence in favor of a hypothesis, and an ER of 0.1 or lower as strong evidence against a hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>The sentiment analysis indicated positive average sentiment scores (i.e., &gt; 0) for all countries under investigation. However, according to the descriptive statistics, the language related to the high HDI group had more positive sentiments compared to the low HDI group. Figure <ref type="figure" target="#fig_0">1</ref> shows the sentiment scores of both high and low HDI countries together with their SDs. The scores ranged between -0.29 -0.57 for high HDI and -0.5 -0.5 for low HDI. Figure <ref type="figure">2</ref> illustrates the sentiment scores and the SDs for each country with the high and low HDI. We utilized a Bayesian regression model to assess whether ChatGPT exhibited sentiment differences between countries with high HDI and those with low HDI. According to the analysis, the Credible Interval (CI) for high HDI suggests that there is a 95% probability that the true value of the sentiment score lies between 0.13 and 0.20. As the values do not cross zero, there is strong evidence that the true value of high HDI was greater than zero, indicating in this case positive sentiments for these countries. Similarly, the CI for low HDI indicates a 95% probability that the true value of the parameter lies between 0.04 and 0.10. This provides strong evidence that the low HDI is significantly greater than zero, implying that these countries are associated with positive sentiments. Subsequent hypothesis testing exhibited strong evidence (ER = 3900, PP = 1.00) that the high HDI countries exhibited higher sentiment scores than the low HDI countries. Table <ref type="table" target="#tab_0">1</ref> shows the results of the Bayesian analysis and hypothesis testing. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion</head><p>The study examined the language used by ChatGPT to describe developed and developing countries by employing a sentiment analysis framework. We utilized prompts to direct ChatGPT in generating discourses pertaining to selected developed and developing countries; these countries were divided based on their HDI scores. We subsequently elicited the sentiment scores for these texts using sentiment analysis in R.</p><p>Comparisons between high HDI and low HDI countries were conducted using a Bayesian regression model.</p><p>The results demonstrated positive sentiments on average for both high and low HDI countries and each of the 20 countries added to the analysis. This is consistent with the findings of <ref type="bibr">Zhou et al. (2024)</ref>, who reported the generation of positive content by ChatGPT for various nationalities around the world. Thus, the model avoids using negative language for the description of these countries. However, the Bayesian regression analysis confirmed our initial hypothesis, since the language used by ChatGPT for the description of each country encompassed more positive sentiments for countries with high HDI than countries with low HDI. The former group included mostly European nations, while the latter group mainly included African countries. These results corroborate earlier findings. For instance, <ref type="bibr">Boussidan et al. (2023)</ref> found that ChatGPT attributed higher positivity ratings to North American and European countries, while African countries received lower ratings.</p><p>Overall, ChatGPT presents with biases by distinguishing between developed and developing countries as seen in the sentiment analysis. This can significantly amplify racial and ethnic biases and stereotypes <ref type="bibr" target="#b5">(Choudhary, 2024)</ref>. By consistently using more positive language to describe developed countries and less positive language to describe developing ones, ChatGPT may perpetuate perceptions of superiority or inferiority based on national economic status. This could lead to the reinforcement of existing inequalities between more developed and less developed countries, influencing societal attitudes and potentially impacting policy decisions and resource allocation.</p><p>This research is essential because it identifies biases within AI-generated content, calling for impartial and just representations of all countries. It underscores the need for the development of ethically responsible AI systems; this would strengthen their credibility and reliability, which are vital for gaining widespread trust and acceptance. Additionally, the findings aid in fostering fair decisionmaking by preventing AI from perpetuating stereotypes or inequalities. Furthermore, the research contributes to global understanding by encouraging the cultivation of accurate perceptions of various countries, which will reduce misinformation and enhance international relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>A significant differentiation between developed and developing countries was observed in the language of ChatGPT on the basis of a sentiment analysis. These tentative findings could be important for AI developers who may consider adjusting the algorithm accordingly to reduce socially biased language in LLMs like ChatGPT. Future research can include a larger pool of countries and use additional metrics to investigate the language of the model. Furthermore, future work can examine the socio-cultural impacts of biased AI-generated content on global perceptions and interactions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Sentiment scores for countries with high and low HDI</figDesc><graphic coords="4,210.00,72.00,191.55,227.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Results of the Bayesian analysis and hypothesis testing</figDesc><table><row><cell>Main analysis</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Estimate Est. Error l-95% CI</cell><cell cols="2">u-95% CI Rhat</cell><cell>Bulk ESS</cell></row><row><cell>sd(Intercept)</cell><cell>0.02</cell><cell>0.01</cell><cell>0.00</cell><cell>0.04</cell><cell>1.00</cell><cell>2286</cell></row><row><cell>HDIhigh</cell><cell>0.16</cell><cell>0.02</cell><cell>0.13</cell><cell>0.20</cell><cell>1.00</cell><cell>5268</cell></row><row><cell>HDIlow</cell><cell>0.07</cell><cell>0.02</cell><cell>0.04</cell><cell>0.10</cell><cell>1.00</cell><cell>5056</cell></row><row><cell>sigma</cell><cell>0.16</cell><cell>0.01</cell><cell>0.14</cell><cell>0.17</cell><cell>1.00</cell><cell>5652</cell></row><row><cell>Hypothesis testing</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Hypothesis</cell><cell cols="3">Estimate Est. Error l-95% CI</cell><cell cols="2">u-95% CI ER</cell><cell>PP</cell></row><row><cell cols="2">HDIhigh &gt; HDIlow 0.10</cell><cell>0.02</cell><cell>0.06</cell><cell>0.13</cell><cell>3999</cell><cell>1.00</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This study is supported by the <rs type="funder">Phonetic Lab of the University of Nicosia</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflicts of interest</head><p>There are no conflicts of interest to disclose.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Persistent anti-muslim bias in large language models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Abid</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Farooqi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society</title>
		<meeting>the 2021 AAAI/ACM Conference on AI, Ethics, and Society</meeting>
		<imprint>
			<date type="published" when="2021-07">2021, July</date>
			<biblScope unit="page" from="298" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The opportunities and challenges of ChatGPT in education</title>
		<author>
			<persName><forename type="first">I</forename><surname>Adeshola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Adepoju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interactive Learning Environments</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">What ChatGPT tells us about ourselves</title>
		<author>
			<persName><forename type="first">A</forename><surname>Boussidan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ducel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Fort</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journée d&apos;étude Éthique et TAL 2024</title>
		<imprint>
			<date type="published" when="2024-04">2024, April</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Bürkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Modrak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Badr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Ben-Shachar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Rabel</surname></persName>
		</author>
		<title level="m">brms: Bayesian Regression Models Using &apos;Stan</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>R package</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Semantics derived automatically from language corpora contain human-like biases</title>
		<author>
			<persName><forename type="first">A</forename><surname>Caliskan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">356</biblScope>
			<biblScope unit="issue">6334</biblScope>
			<biblScope unit="page" from="183" to="186" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Choudhary</surname></persName>
		</author>
		<title level="m">Reducing Racial and Ethnic Bias in AI Models: A Comparative Analysis of ChatGPT and Google Bard. Preprints 2024</title>
		<imprint>
			<date type="published" when="2024">2024. 2024062016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Today&apos;s academic research: The role of ChatGPT writing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Chukwuere</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information Systems and Informatics</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="30" to="46" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Bayesian models are better than frequentist models in identifying differences in small datasets comprising phonetic data</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Georgiou</surname></persName>
		</author>
		<idno>arxiv.2312.01146</idno>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Human Development Report 2023-24: Breaking the gridlock: Reimagining cooperation in a polarized world</title>
		<author>
			<persName><forename type="first">P</forename><surname>Conceição</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">United Nations Development Programme</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discrimination of second language vowel contrasts and the role of phonological short-term memory and nonverbal intelligence</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Georgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Giannakou</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10936-024-10038-z</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Psycholinguistic Research</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Differences in voice quality measures among monolingual and bilingual speakers</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Georgiou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kaskampa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">100175</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">What ChatGPT tells us about gender: a cautionary tale about performativity and gender biases in AI</title>
		<author>
			<persName><forename type="first">N</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Sciences</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">435</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">The Theory of Probability</title>
		<author>
			<persName><forename type="first">H</forename><surname>Jeffreys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961">1961</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A holistic approach to undesired content detection in the real world</title>
		<author>
			<persName><forename type="first">T</forename><surname>Markov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">E</forename><surname>Nekoul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2023-06">2023. June</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="15009" to="15018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dissecting racial bias in an algorithm used to manage the health of populations</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Vogeli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="issue">6464</biblScope>
			<biblScope unit="page" from="447" to="453" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/Ray" />
	</analytic>
	<monogr>
		<title level="m">R Foundation for Statistical Computing</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2023">2024. 2023</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="121" to="154" />
		</imprint>
	</monogr>
	<note>P. P.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">QdapDictionaries: dictionaries and word lists for the &apos;Qdap&apos;Package. R package version 1</title>
		<author>
			<persName><forename type="first">T</forename><surname>Rinker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="0" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The political biases of ChatGPT</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rozado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Sciences</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">148</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The unequal opportunities of large language models: Examining demographic biases in job recommendations by chatgpt and llama</title>
		<author>
			<persName><forename type="first">A</forename><surname>Salinas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mccormack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Morstatter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization</title>
		<meeting>the 3rd ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization</meeting>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Human development index</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">N</forename><surname>Venkit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gautam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Panchanadikar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2302.02463</idno>
		<ptr target="https://www.who.int/data/nutrition/nlis/info/human-development-index" />
	</analytic>
	<monogr>
		<title level="m">Nationality bias in text generation</title>
		<imprint>
			<publisher>World Health Organization</publisher>
			<date type="published" when="2023">2023. 2024. July 7, 2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2405.06996</idno>
		<title level="m">Quite Good, but Not Enough: Nationality Bias in Large Language Models--A Case Study of ChatGPT</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
