<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Bears Don&apos;t Always Mess With Beers: Limits on Generalization of Statistical Learning in Speech</title>
				<funder ref="#_YgrF2vM #_cZ9SJhQ">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder ref="#_rDvKgdQ">
					<orgName type="full">Predoctoral Training Program in Behavioral Brain Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Timothy</forename><forename type="middle">K</forename><surname>Murphy</surname></persName>
							<email>tmurphy37@wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Waisman Center</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Communication Sciences and Disorders</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<settlement>Madison</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nazbanou</forename><surname>Nozari</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychological and Brain Sciences</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<settlement>Bloomington</settlement>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lori</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">The University of Texas at Austin</orgName>
								<address>
									<settlement>Austin</settlement>
									<region>TX</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Bears Don&apos;t Always Mess With Beers: Limits on Generalization of Statistical Learning in Speech</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E393EBE6DAE9C43C2F0E2AC9531E5B24</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Perception changes rapidly and implicitly as a function of passive exposure to speech that samples different acoustic distributions. Past research has shown that this statistical learning generalizes across talkers and, to some extent, new items but these studies involved listeners' active engagement in processing statistics-bearing stimuli. In this study, we manipulated the relationship between voice onset time (VOT) and fundamental frequency (F0) to establish distributional regularities either aligned with American English or reversed the regularity to create a subtle foreign accent. We then tested whether statistical learning across passive exposure to these distributions generalized to new items not experienced in the exposure stimuli. Experiment 1 showed statistical learning across passive exposure but no generalization of learning when exposure and test items shared the same phoneme (bear/pear  beer/pier) or when they differed in phoneme but shared distributional regularities across VOT and F0 dimensions (deer/tear  beer/pier). Experiment 2 showed generalization to stimuli that shared the statistic-bearing phoneme (bear/pear  beer/pier), but only when the response set included tokens from the exposure and test stimuli. Moreover, statistical learning transferred to influence the subtle acoustics of listeners' own speech productions but did not generalize to new stimuli. These findings reveal that passive exposure is sufficient to support statistical learning in perception and its generalization, but task demands modulate this dynamic. Moreover, generalization in perception is not always accompanied by generalization in production, demonstrating that production is not simply a mirror of the perceptual system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Encountering a talker with an idiosyncratic speaking style or a non-native accent can diminish speech comprehension (e.g., <ref type="bibr" target="#b6">Bradlow &amp; Bent, 2008)</ref>. But experience often leads to improvements that generalize to other speakers (e.g., <ref type="bibr">Xie &amp; Myers 2017)</ref>. Sometimes, such encounters even impact subtle characteristics of one's own speech (e.g., <ref type="bibr" target="#b30">Pardo et al., 2017)</ref>. Although instances of such adaptation and convergence are well documented, many questions regarding their bases remain unanswered.</p><p>A literature examining dimension-based statistical learning provides a means with which to fill these gaps (e.g., <ref type="bibr" target="#b12">Idemaru &amp; Holt, 2011;</ref><ref type="bibr" target="#b22">Liu &amp; Holt, 2015;</ref><ref type="bibr" target="#b33">Schertz, Cho, Lotto, &amp; Warner, 2016;</ref><ref type="bibr" target="#b38">Wu &amp; Holt, 2022)</ref>. This work posits that subtle differences across talkers can be characterized as shifts in the underlying acoustic regularities -the statistical distributions -of speech. The somewhat different speech patterns of American English compared to Scottish English <ref type="bibr" target="#b8">(Escudero, 2001)</ref>, for example, can be modeled as distribution shifts across multidimensional acoustic space, and the impact of listening across these distributions on perception (as well as production) can be tracked.</p><p>Such distributional shifts can be studied experimentally. For example, <ref type="bibr" target="#b12">Idemaru and Holt (2011)</ref> selectively sampled beer-pier utterances across an acoustic space defined by voice onset time (VOT, the timing of articulators' release versus voicing onset) and fundamental frequency (F0, related to pitch).</p><p>A Canonical sampling mirrored the typical American English F0xVOT correlation whereas a Reverse sampling created a subtle accent with an opposing correlation. In a passive exposure version of the paradigm <ref type="bibr" target="#b10">(Hodson et al., 2023;</ref><ref type="bibr" target="#b25">Murphy et al. 2023)</ref>, listeners hear a sequence of beer and pier utterances conveying one of these distributional regularities followed by one of two F0-differentiated test stimuli with ambiguous VOT. With only F0 available to convey category identity, test stimulus categorization indexes listeners' reliance on F0 in speech categorization. In a pattern now wellreplicated across many studies, F0 robustly signals beer versus pier when distributions mirror American English norms but F0 reliance is markedly reduced in the context of the accent. This points to implicit learning of statistical speech regularities that has an immediate influence on the nature of the mapping of acoustics to speech, thus informing how listeners adapt to idiosyncratic or accented speech.</p><p>Generalization has been a valuable tool in examining the representations across which this statistical learning operates. Experience with an accent in one context can generalize to affect perception in new contexts, including new talkers <ref type="bibr" target="#b22">(Liu &amp; Holt, 2015)</ref> and new words/nonwords <ref type="bibr" target="#b20">(Lehet &amp; Holt, 2020;</ref><ref type="bibr" target="#b22">Liu &amp; Holt, 2015)</ref>. Restriction of statistical learning to specific lexical items was ruled out by <ref type="bibr" target="#b14">Idemaru and Holt (2020)</ref> who observed generalization across word contexts that share a common initial consonant (beer-pier → bear-pear, and vice versa), although effects were weaker across, compared to within, word pairs (see also <ref type="bibr" target="#b22">Liu &amp; Holt, 2015;</ref><ref type="bibr" target="#b20">Lehet &amp; Holt, 2020;</ref><ref type="bibr" target="#b42">Zhang, Wu &amp; Holt, 2021)</ref>.</p><p>Notably, <ref type="bibr" target="#b13">Idemaru and Holt (2014)</ref> found no evidence of generalization across distributions sampling the same acoustic dimensions; beer-pier learning did not generalize to deer-tear even when each sampled a similar acoustic space.</p><p>Collectively, these studies suggest learning that is sensitive to both phonemes and the coarticulated vowel. However, in contrast to the passive exposure paradigm described above, generalization studies have relied exclusively on active tasks with overt, trial-by-trial categorization of both statistics-bearing speech stimuli and the test stimuli that measure statistical learning.</p><p>Correspondingly, the response set includes responses that match the statistics-bearing speech (e.g., bear-pear), and also responses to test generalization (beer-pier). The differences across paradigms bring up the question, is active engagement of the learner necessary for generalization? This paper tackles this question.</p><p>Experiment 1 examines generalization of statistical learning across passive exposure with a single response set (beer-pier) across all conditions. Listeners hear a sequence of utterances conveying canonical or reverse distributions, then categorize sequence-final, F0-differentiated beerpier test stimuli across three conditions: No Generalization (beer-pier→beer-pier), Phoneme Generalization (bear-pear→beer-pier, for which active categorization paradigms observe generalization), and Dimension Generalization (deer-tear→beer-pier, for which no generalization is observed in active tasks). To anticipate the results, we replicate the null effect in the Dimension Generalization condition. But, unlike past studies, we do not observe generalization in the Phoneme Generalization condition. In Experiment 2 we examine whether this difference arises from learning across passive listening, or emerges due to the lack of an active response to the statistics-bearing stimuli. We focus our investigation on exposure and test stimuli that share the onset phoneme and introduce a mixed response set (beer-pier + bear-pear) in the critical condition. The mixed response set restores generalization, despite the passive exposure.</p><p>As a secondary measure in each experiment, we elicit speech productions to attempt to replicate recently reported transfer of statistical learning from perception to production <ref type="bibr" target="#b25">(Murphy et al., 2023)</ref> and to examine generalization in production.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1 Methods</head><p>Experiment 1 examined statistical learning across passive exposure to speech regularities and its generalization. Participants listened to a sequence of speech tokens possessing a (Canonical, Reverse) short-term distributional regularity and reported whether a final test stimulus was beer or pier.</p><p>They then heard the same test stimulus again and repeated it aloud (Figure <ref type="figure" target="#fig_0">1</ref>). Test stimuli were always beer-pier, differentiated only by F0. Across conditions experienced by all listeners, the stimuli that conveyed distributional regularities across passive exposure varied: beer-pier (requiring No Generalization), bear-pear (Phoneme Generalization), deer-tear (Dimension Generalization). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>In keeping with past studies, we assumed a small effect size of d=0.3 for generalization in speech perception <ref type="bibr" target="#b22">(Liu and Holt 2015;</ref><ref type="bibr" target="#b14">Idemaru and Holt, 2020)</ref>. A power analysis performed using the program PANGEA <ref type="bibr" target="#b37">(Westfall, 2015)</ref> indicated that a sample size of 90 participants would provide power &gt; 0.8 to detect a three-way interaction between Test Stimulus F0, Canonical/Reverse statistical regularity and the three-level generalization factor, at α = 0.05. As a provision against data loss in online studies, we collected online data from 110 adult (55 females) native-English participants located in the United States. Eighteen participants' data did not enter into analyses due to silent or highly noisy production recordings that precluded acoustic analysis of speech productions (N=17) or perceptual responses indicating task noncompliance (N=1). Data from 92 participants (49 females, mean age 28.1 years, SD = 4.8 years) entered the analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimuli</head><p>Figure <ref type="figure" target="#fig_0">1A</ref> illustrates the speech stimuli. Fundamental frequency (F0) and voice onset time (VOT) varied, with other acoustic dimensions held constant, to create perceptual spaces corresponding to beer-pier, bear-pear, and deer-tear. Each of the six target words was spoken by an adult female native American English speaker, with specific tokens chosen to have similar duration (400 ms for beer-pier and deer/tear, 500 ms for bear-pear) and F0 contour. Beginning with these natural speech exemplars, we edited in the time domain to create 5-ms VOT steps <ref type="bibr" target="#b23">(McMurray &amp; Aslin, 2005)</ref>. Next, we manipulated the F0 onset of each of these stimuli using a custom Praat script (Praat 6.1, <ref type="bibr">Boersma &amp; Weenink, 2023)</ref> such that onset F0 varied from 220 to 320 Hz in 10 Hz steps, with F0 contour interpolated smoothly across voicing to word offset. Amplitude normalization assured each stimulus possessed the same root mean-squared amplitude.</p><p>Exposure stimuli (blue, Figure <ref type="figure" target="#fig_0">1A</ref>) sub-sampled these acoustic spaces to create a distinct shortterm speech regularities. The Canonical English sampling (Figure <ref type="figure" target="#fig_0">1A</ref>, left) followed acoustic speech regularities typical of American English: stimuli with shorter VOT (&lt;25 ms) tend to have lower F0 and be labeled as /b/ or /d/ (light blue) whereas those with longer VOT (&gt;25 ms) tend to have higher F0 and be labeled as /p/ or /t/ (dark blue). A statistically defined 'accent' reversed this distributional relationship from American English norms (Figure <ref type="figure" target="#fig_0">1A</ref>, right). Here, for the Reverse condition, shorter VOTs signal /b/ or /d/ but F0 is higher frequency. Longer VOTs signal /p/ or /t/ but F0 is lower frequency. Beer-pier and bear-pear tokens (blue, no line) shared identical F0xVOT values whereas deer-tear tokens (blue, aqua line) sampled distributions shifted +5 ms in VOT to account for natural English VOT patterns <ref type="bibr" target="#b7">(Cho &amp; Ladefoged, 1999)</ref>.</p><p>Additionally, two test stimuli possessed a perceptually ambiguous, 25-ms VOT and varied only in F0 (230 or 310 Hz; Figure <ref type="figure" target="#fig_0">1A</ref>, red symbols). Test stimulus categorization measured listeners' reliance on F0 in category decisions and test stimuli also served to elicit speech productions in the auditory repetition task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Online participants recruited via Prolific.co were automatically directed to an experiment hosted on <ref type="bibr">Gorilla (www.gorilla.sc, Anwyl-Irvine et al., 2021)</ref>. Using the Chrome browser on a computer (no mobile devices), participants provided consent, completed a demographics survey, and underwent both a brief check of headphone compliance test <ref type="bibr">(Milne et al., 2020)</ref> and a check that the computer microphone was recording utterances.</p><p>Figure <ref type="figure" target="#fig_0">1B</ref> shows the trial structure. Participants listened passively to a sequence of 8 perceptually unambiguous exposure stimuli that conveyed either a Canonical or a Reverse short-term regularity. Each sequence included 4 tokens from each of the two distributions (Figure <ref type="figure" target="#fig_0">1A</ref>, dark and light blue symbols), randomly selected and concatenated with 300-ms silent intervals separating utterances. Clipart images corresponding to the word expected from the perceptually unambiguous VOT appeared at the onset of each sound. Next, after 600 ms, participants heard one of the two test stimuli (High or Low F0; Figure <ref type="figure" target="#fig_0">1A</ref>, red symbols) and categorized it as beer or pier via a keyboard response with onscreen text to guide the mapping. Then, 300 ms later, the same test stimulus played again, and an image of a microphone prompted participants to repeat the word aloud. Participants had 2500 ms to repeat the test stimulus and utterances were saved digitally for subsequent acoustic analysis of F0.</p><p>As summarized in Figure <ref type="figure" target="#fig_0">1C</ref>, beer-pier test stimuli elicited perceptual categorization responses and speech productions across each of three conditions. The statistics-bearing exposure stimuli of the No Generalization condition matched the beer-pier test stimuli, thereby measuring statistical learning without requiring generalization. In contrast, bear-pear exposure sequences in the Phoneme Generalization condition necessitated generalization of statistical learning to beer-pier test stimuli sharing a common initial phoneme. Finally, in the Dimension Generalization condition, the deer-tear regularities differed in initial phoneme from the beer-pier test stimuli but overlapped across F0xVOT acoustic dimensions.</p><p>For each condition, participants experienced 30 Canonical trials followed by 30 Reverse trials. Among these trials, 6 involved perceptually unambiguous beer-pier test stimuli to measure online participants' task engagement. Responses from these trials were not included in the analysis, resulting in 24 Canonical and 24 Reverse trials for each condition. A Latin square design assured balanced presentation across generalization conditions across participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Analyses</head><p>Perceptual Categorization. We modeled the influence of statistical learning on perceptual categorization of test stimuli using mixed effects models (lme4, <ref type="bibr">Bates, Mochler, Bolker, and Walker, 2015)</ref>  Speech Production. Transfer of statistical learning in listening to speaking was modeled across by-participant z-score normalized utterance F0 (as in <ref type="bibr" target="#b25">Murphy et al., 2023)</ref>. In brief, the F0 (computed across the first 40 ms) was measured for each utterance. F0 values ±3 standard deviations from a participant's mean F0 were removed from analysis. Next, we normalized F0 on a by-individual basis to account for F0 variability arising across talkers <ref type="bibr">(Titze, 1989)</ref>. Therefore, for production analyses, a zscore of 0 indicates the mean F0 for a participant across all productions. Positive and negative z-scores correspond to continuous standard deviation units above and below the mean, respectively, that we submitted to standard linear effects models. Fixed and random effect structures, and the approach to post-hoc tests, were identical to perceptual statistical learning analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Perceptual Categorization. Figure <ref type="figure" target="#fig_2">2</ref> presents perceptual categorization of F0-differentiated beer-pier test stimuli as a function in Canonical and Reverse conditions. Table <ref type="table" target="#tab_0">1</ref> displays results of a logistic mixed effects model fit to these data. Across all conditions, there were more pier responses for High F0, as is typical in American English <ref type="bibr" target="#b21">(Lisker, 1986)</ref>, reflected in a main effect of Test Stimulus F0 (z=17.52, p&lt;.001). A main effect of Statistical Regularity was also found (z=17.53, p&lt;.001). Importantly, there was a significant Test Stimulus F0 and Statistical Regularity interaction (z=15.43, p&lt;.001), indicating that statistical learning across passive listening impacted reliance on F0 in categorization. Based on these two significant three-way interactions, we tested statistical learning in each condition with separate, post-hoc logistic mixed effect models. The two-way interaction between Test Stimulus F0 and Statistical Regularity was significant only in the No Generalization model (z=23.72, p&lt;.001), but not the Phoneme (z=0.57, p=.567) or Dimension (z=0.94, p=.348) Generalization models.</p><p>Thus, Experiment 1 reveals evidence of statistical learning but not of generalization of the learning. The results are clear: perceptual statistical learning across passive exposure failed to generalize in perception. While this replicates the finding of no generalization in the Dimension Generalization (deer-tearbeer-pier) condition <ref type="bibr" target="#b13">(Idemaru &amp; Holt, 2014)</ref>, it contrasts with Phoneme Generalization (bear-pearbeer-pier) observed in active tasks that involve trial-by-trial overt speech categorization <ref type="bibr" target="#b14">(Idemaru &amp; Holt, 2020)</ref>. Naturally, since no generalization was uncovered in perception, transfer of generalization was not seen in production. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2 Methods</head><p>Experiment 1 replicated the null effect of dimension generalization <ref type="bibr" target="#b13">(Idemaru &amp; Holt, 2014)</ref> but failed to find evidence of phoneme generalization, contrary to prior reports <ref type="bibr" target="#b14">(Idemaru &amp; Holt, 2020)</ref>. One interpretation of these results is that statistical learning across passive listening is not sufficient to support generalization. But before this conclusion is drawn, we must rule out the influence of another factor. Recall that in <ref type="bibr" target="#b14">Idemaru and Holt's (2020)</ref> task, participants responded to all tokens, meaning that both the statistic-bearing stimuli and the generalization stimuli were part of the response set. If overlap between exposure and test stimuli is critical for extracting statistics or applying statistics to new stimuli, then a mixed response set should restore phoneme generalization, even with passive exposure.</p><p>Experiment 2 tested this possibility. First, we aimed to replicate the main findings of statistical learning and its transfer to production, observed in Experiment 1, in a different pair, bear-pear. We used this pair as exposure stimuli to test phoneme generalization to a different pair, beer-pier, presented in a mixed response set comprised of both bear-pear and beer-pier tokens with equal frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Based on the power analysis of Experiment 1, we tested 95 participants (48 female) with 87 participants (45 female, Mage = 31.3, SD = 6.0 years) entering analyses after application of the Experiment 1 exclusion criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stimuli</head><p>Experiment 2 relied on the beer-pier and bear-pear stimuli from Experiment 1 (Figure <ref type="figure" target="#fig_0">1A</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Experiment 2 consisted of 6 blocks (30 trials each) of trials alternating with Canonical and Reverse regularities. The first two blocks reproduced the No Generalization (beer-pierbeer-pier) condition of Experiment 1 (Replication: No Generalization). The remaining four blocks conveyed statistics across bear-pear utterances and involved both bear-pear (Mixed Response: No Generalization) and beer-pier (Mixed Response: Phoneme Generalization) test trials, randomly intermixed such that there was uncertainty about the target of categorization on each trial and the mixed response set involved beer, pier, bear, and pear. In each block, six trials measured online participants' task engagement by swapping ambiguous test stimuli for unambiguous beer-pier or bear-pear tokens.</p><p>Responses from these trials did not enter analyses, resulting in a total 24 Canonical and 24 Reverse trials for each condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Analyses</head><p>Perceptual Categorization. The statistical approach was similar to Experiment 1. Our first goal was to replicate statistical learning and its transfer to production in the No Generalization condition, observed in Exp 1. This model included the subset of data from the beer-pierbeer-pier blocks. The model included Test Stimulus F0 (High F0, Low F0), Statistical Regularity (Canonical, Reverse) and their interaction, as well as a maximal random effects structure consisting of by-subject random intercept, random slopes for Test Stimulus F0, Statistical Regularity, and the interaction between Test Stimulus F0 and Statistical Regularity over subjects.</p><p>Next, we examined generalization using blocks with Mixed Response conditions. The model's dependent variable was coded as voiced (beer, bear) or voiceless (pier, pear). Three fixed effects, Test Stimulus F0 (High F0, Low F0), Statistical Regularity (Canonical, Reverse) and Condition (Mixed Response: No Generalization; Mixed Response: Phoneme Generalization), were included alongside their 2-way and 3-way interactions. The random effects structure was similar to the structure used in the Replication task analysis with the addition of a random slope for Condition. All fixed effects were centered coded (-0.5, or 0.5).</p><p>Speech Production. Acoustic speech analysis followed the Experiment 1 approach with byparticipant z-score normalized production F0s as a continuous dependent variable analyzed with linear mixed effects models. As with the perceptual categorization analysis, separate models assessed production changes in the Replication and the Mixed Response tasks. Fixed effects and their interactions were identical to those included in the corresponding perceptual categorization models.</p><p>Both models included by-participant random intercept and random slopes for Test Stimulus F0 and Statistical Regularity. The Mixed Response model also included a random slope for Condition. Neither model tolerated the addition of random slopes for the interaction terms. All fixed effects were center coded (-0.5 or 0.5). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Perceptual Categorization. As in Experiment 1, we analyzed perceptual responses for evidence of statistical learning and its generalization to novel tokens (Figure <ref type="figure" target="#fig_3">3</ref>, top row). Analysis of perceptual responses from the Replication task revealed a significant main effect of Test Stimulus F0 (z=8.18, p&lt;.001), a significant main effect of Statistical Regularity (z=2.00, p=.045) and, importantly, an interaction between the two (z=13.87, p&lt;.001), showing statistical learning in perception.</p><p>Table <ref type="table" target="#tab_2">3</ref> reports the results from the analysis of perceptual response from the Mixed Response blocks. A significant main effect of Test Stimulus F0 indicated that, overall, participants tended to perceive High F0 test stimuli as pier or pear and Low F0 as beer or bear (z=18.58, p&lt;.001). The main effect of Condition was also significant, indicating a difference in voiced and voiceless response rates in the Mixed Response: No Generalization and the Mixed Response: Phoneme Generalization conditions <ref type="bibr">(z= -5.70, p&lt;.001)</ref>. This difference appears to be driven by a bias towards pier responses in the Mixed Response: Phoneme Generalization condition, a finding also reported by <ref type="bibr" target="#b14">Idemaru &amp; Holt (2020)</ref>. A significant two-way interaction between Statistical Regularity and Test Stimulus F0 indicated statistical learning in perception in the Mixed Response blocks (z= 12.50, p&lt;.001).</p><p>We also found a significant three-way interaction between Statistical Regularity, Test Stimulus F0, and Condition (z=10.20, p&lt;.001). To unpack this interaction, we fit separate post-hoc models to each of the two Conditions, separately. In the Mixed Response blocks, there is evidence of statistical learning in the form of a significant two-way interaction between Statistical Regularity and Test Stimulus  Speech Production. We next examined transfer of statistical learning to production using zscore normalized F0 measured from beer-pier and bear-pear productions (Figure <ref type="figure" target="#fig_3">3</ref>, bottom row). First examining the Replication condition, the model reveals the expected main effect of Test Stimulus F0 (t=9.55, p&lt;.001), as well as a significant two-way interaction between Test Stimulus F0 and Statistical Regularity indicating the transfer of statistical learning to production (t=14.55, p&lt;.001), thereby replicating the transfer observed in Experiment 1.</p><p>Table <ref type="table" target="#tab_3">4</ref> reports the transfer of speech production results from the Mixed Response blocks.</p><p>Mirroring the perceptual results, the analysis revealed a main of Test Stimulus F0 (t = 13.64, p &lt;.001), as well as a main effect of Condition on production F0s (t=-14.81, p&lt;.001). The latter finding is in line with previous research on intrinsic F0, a tendency for high vowels like the /i/ in beer to have higher F0s than low vowels like the /e/ in bear <ref type="bibr">(Chen et al. 2021;</ref><ref type="bibr" target="#b36">Whalen &amp; Levitt, 1995)</ref>. Transfer of statistical learning was evident in the significant two-way interaction between Statistical Regularity and Test Stimulus F0 (t=6.64, p&lt;.001). There were significant interactions between Statistical Regularity and Condition (t=3.01, p=.003) as well as Test Stimulus F0 and Condition (t=-6.41, p&lt;.001).</p><p>Critical for our determining whether generalization transfers to influence speech production, we found a significant three-way interaction between Statistical Regularity, Test Stimulus F0, and Condition (t=4.63, p&lt;.001). Post hoc analyses revealed that the two-way interaction between Test Stimulus F0 and Statistical Regularity was significant in the Mixed Response: No Generalization model (t=8.18, p&lt;.001) but the perceptual generalization observed for the Mixed Response: Phoneme-Generalization condition did not transfer to production (t=1.44, p=.151).</p><p>To summarize, Experiment 2 replicates statistical learning across passive exposure to beer-pier and its transfer to speech production. It extends this finding to bear-pear, when no generalization is required. Importantly, inclusion of a mixed response set rescued phoneme-level generalization of perceptual statistical learning, although with a smaller magnitude of influence on the generalization pair than the pair experienced across the regularity. This generalization of learning did not transfer to influence speech production. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>Does generalization of statistical learning emerge only with learning in an active task? Potentially consistent with this possibility, <ref type="bibr" target="#b38">Wu and Holt (2022)</ref> have argued that when speech conveys sufficient perceptual information to activate a phonetic category (e.g., via VOT) it may generate predictions of the typical mapping of other acoustic dimensions, like F0, to the category representation. In the Reverse condition, these expectations are not met and the mismatch may power error-driven learning that downweights F0 to minimize future mismatches. Inasmuch as active categorization tasks might boost category activation, it may promote learning and its successful generalization. Yet, <ref type="bibr" target="#b10">Hodson et al. (2023)</ref> report statistically equivalent outcomes for learning across passive exposure versus active tasks, arguing against this account, suggesting that learning across passive learning can be just as potent as learning in an active task. Experiment 2 confirms that passive listening is sufficient for both statistical learning as well as its generalization. When the response set included both statistics-bearing and new stimuli, generalization to new words with the same initial phoneme was restored for statistical learning across passive exposure. But why should response set matter? Although speculative, the most reasonable explanation for the influence of response set on generalization may relate to attention and goal-setting, in line with recent findings that show the importance of explicit attentional goals in implicit statistical learning <ref type="bibr" target="#b40">(Zhang &amp; Carlisle, 2023)</ref>. If participants detect no relationship between exposure and test stimuli, they may tune out exposure stimuli. Under this view, attention is important for learning not because it forces the learner to actively process every statistic-bearing stimulus, but rather because it sets a higher-level behavioral goal in the cognitive-perceptual system. Our results demonstrate the importance of task demands and goals in the context of statistical learning, even when implicit and across passive exposure.</p><p>The present study also lays groundwork for understanding the currency of representation shared between speech perception and production. We replicated the transfer of statistical learning from perception to production reported in <ref type="bibr" target="#b25">Murphy et al. (2023)</ref> twice (Experiment 1 and 2, beer-pierbeerpier). Additionally, the present work extends evidence of transfer to a novel context and word pair (Experiment 2, bear-pearbear-pear). These results demonstrate that there are rapid and implicit changes to the production system as a result of statistical learning across the patterns of other talkers' speech. They are interesting, particularly, in light of the finding that most instances of auditory repetition entail the retrieval of existing lexical representations and their segmental encoding in the speaker's production system <ref type="bibr">(Nozari et al., 2010;</ref><ref type="bibr">Nozari &amp; Dell, 2013)</ref>. As such, the present data build from <ref type="bibr" target="#b25">Murphy et al. (2023)</ref> to provide new insights into phonetic convergence <ref type="bibr">(Pardo, 2022)</ref> and to extend how other talkers' speech affects one's own productions (e.g. <ref type="bibr" target="#b4">Bourguignon et al., 2014;</ref><ref type="bibr">2016;</ref><ref type="bibr" target="#b18">Lametti et al., 2014</ref>).</p><p>Yet, even when bears affected beers in perception, they did not influence production. In Experiment 2, exposure to bear-pear distributional regularities led to statistical learning that generalized to beer-pier (with a mixed response set). But this learning did not exert an influence on production. The magnitude of generalization (bear-pearbeer-pier) was smaller than the magnitude of statistical learning across matched trials (bear-pearbear-pear) so it is possible that generalization was not robust enough to drive transfer to production. Alternatively, the currency of representation supporting generalization in perception may differ from that in production. Future studies of transfer in dimensionbased statistical learning are well-poised to address this intriguing possibility because the approach makes it possible to quantify listeners' and speakers' detailed reliance on subtle acoustic dimensions, and to manipulate exposure to distributions across them in both passive and active tasks. At this stage, observance of generalization of statistical learning in the absence of transfer to production is important in establishing that production is not simply a mirror of perceptual experience, according with other studies of statistical learning across speech production and perception (e.g., <ref type="bibr" target="#b16">Kittredge &amp; Dell, 2016;</ref><ref type="bibr" target="#b34">Schwartz et al. 2012)</ref>. Learning-related adjustments to the representations within the production system appear to be necessary.</p><p>In conclusion, passive exposure is sufficient to produce generalization of statistical learning in perception, but subtle task demands affect such generalization. Inasmuch as the utility of implicit statistical learning over passive exposure is its ability to impact behavior, this highlights how important it will be to direct research toward better understanding how statistical learning statistical learning supports, and is influenced by, task goals and demands.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Experiment Protocol. A. Stimuli. An acoustic space defined by voice onset time (VOT) and fundamental frequency (F0) conveyed beer-pier and bear-pear (solid blue, no line) and deer-tear (solid blue, aqua line) tokens sampled in a manner Canonical of American English or Reversed to convey an accent. B. Trial Structure. A representative trial from the Experiment 1 Control condition illustrates the trial structure across each experiment, and all groups. C. Experiment Conditions. The speech tokens that convey the short-term speech regularity (Exposure, blue) and the test stimuli that elicit perception (Perception, red) and production (Production, gray) are depicted for each condition of each experiment.</figDesc><graphic coords="6,121.20,50.40,369.36,367.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>in R (version 4.1.3, R Core Development Team, 2022) with the binary (beer, pier) categorization response as the dependent variable. The full statistical model involved fixed effects across Statistical Regularity (Canonical, Reverse), Test Stimulus F0 (Low F0, High F0) and Condition (No Generalization, beer-pier; Phoneme Generalization, bear-pear; Dimension Generalization, deer-tear) as well as 2-and 3-way interactions. Random effects included by-subject random intercepts and random slopes for Statistical Regularity and Test Stimulus F0 over subjects. Statistical Regularity and Test Stimulus F0 fixed effects were center coded (-0.5 or 0.5). A simple effects coding scheme was applied to the 3-level Condition effect whereby the No Generalization condition served as the reference level to which the Phoneme Generalization and Dimension Generalization conditions were compared. Three-way interactions among Statistical Regularity, Test Stimulus F0, and Condition were examined with posthoc tests of the Statistical Regularity by Test Stimulus F0 interaction for each Condition. Satterthwaite approximates using the LmerTest package (version 3.1-3, Kuznetsova, Brockhoff, &amp; Christensen, 2016) provided p values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Experiment 1 Perception and Production Results. The top row depicts percent pier categorization responses to High and Low F0 beer-pier test stimuli in the context of Canonical and Reverse short-term regularities. The bottom row shows z-score normalized fundamental frequency (F0) of beer-pier speech productions elicited in repetition of High and Low F0 test stimuli in the context of Canonical and Reverse short-term regularities. A. No Generalization (beer-pier exposure, beer-pier test) B. Phoneme Generalization (bear-pear exposure, beer-pier test). C. Dimension Generalization (deer-tear exposure, beer-pier test). Larger symbols and thick lines represent sample mean and standard error. Smaller symbols and transparent lines indicate individual participants' behavior.</figDesc><graphic coords="11,35.76,85.92,540.48,360.00" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Experiment 2 Perception and Production Results. The top row depicts percent pier/pear categorization responses to High and Low F0 beer-pier (A, C) or bear-pear (B) test stimuli in the context of Canonical and Reverse shortterm regularities. The bottom row shows z-score normalized fundamental frequency (F0) speech productions elicited in repetition of these same test stimuli. A. Replication: No Generalization (beer-pier exposure, beer-pier test) is a replication of Experiment 1. B. Mixed Response Condition trials with No Generalization (bear-pear exposure, bear-pear test). C. Mixed Response Condition trials requiring Phoneme Generalization (bear-pear exposure, beer-pier test).</figDesc><graphic coords="17,35.76,62.88,540.48,371.76" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>F0</head><label></label><figDesc>in both the No Generalization model (z=11.47, p&lt;.001) as well as the Phoneme-Generalization model (z=3.49, p&lt;.001).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Experiment 1 Perceptual Categorization of Test Stimuli across Conditions</figDesc><table><row><cell>β</cell><cell>SE</cell><cell>z</cell><cell>p</cell></row></table><note><p>Overall, speech productions elicited by the High (compared to the Low) F0 beer-pier test stimuli had higher F0 (t=15.35, p&lt;.001). A significant two-way interaction between Test Stimulus F0 and p=.383) or Dimension Generalization (t=-0.82, p=.410) condition.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Experiment 1 Speech Production F0 across Conditions Phoneme Generalization and Dimension Generalization result from simple effects coding comparing the respective conditions to the No Generalization condition.</figDesc><table><row><cell>β</cell><cell>SE</cell><cell>t</cell><cell>p</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Perceptual Categorization of Voiced/Voiceless Test Stimuli in Mixed Response Task</figDesc><table><row><cell>β</cell><cell>SE</cell><cell>z</cell><cell>p</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Mixed Response Task Productions by Test Stimulus F0 and Condition</figDesc><table><row><cell>β</cell><cell>SE</cell><cell>t</cell><cell>p</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>Funding This work was supported by funding from the <rs type="funder">National Science Foundation</rs> <rs type="grantNumber">BCS-1941357</rs> to LH and <rs type="grantNumber">BCS-2217415</rs> to NN and LH. TM was supported by the <rs type="funder">Predoctoral Training Program in Behavioral Brain Research</rs> (<rs type="grantNumber">T32GM081760</rs>, awarded institutionally to LH and <rs type="person">Dr. Julie Fiez</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_YgrF2vM">
					<idno type="grant-number">BCS-1941357</idno>
				</org>
				<org type="funding" xml:id="_cZ9SJhQ">
					<idno type="grant-number">BCS-2217415</idno>
				</org>
				<org type="funding" xml:id="_rDvKgdQ">
					<idno type="grant-number">T32GM081760</idno>
				</org>
			</listOrg>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability of data and materials</head><p>The data and tables of the results are available on OSF (https://osf.io/5uqx8/) Code Availability R scripts used for statistical analyses are available on OSF (https://osf.io/5uqx8/)</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declarations Conflicts of interest/Competing interests</head><p>The authors have no relevant financial or non-financial interests to disclose</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Approval</head><p>Approval was obtained by Institutional Review Board at Carnegie Mellon University.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent to Participate</head><p>Informed consent was obtained from all individual participants in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent for publication</head><p>Not applicable</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Realistic precision and accuracy of online experiment platforms, web browsers, and devices</title>
		<author>
			<persName><forename type="first">A</forename><surname>Anwyl-Irvine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Dalmaijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Evershed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1407" to="1425" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Dialect convergence and divergence in New</title>
		<author>
			<persName><forename type="first">M</forename><surname>Babel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Zealand English. Language in Society</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="437" to="456" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Praat: doing phonetics by computer [Computer program]. Version 6.1</title>
		<author>
			<persName><forename type="first">P</forename><surname>Boersma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Weenink</surname></persName>
		</author>
		<ptr target="http://www.praat.org/" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mächler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Bolker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.5823</idno>
		<title level="m">Fitting linear mixed-effects models using lme4</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Lexical-perceptual integration influences sensorimotor adaptation in speech</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Bourguignon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Shiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">208</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Please say what this word is-Vowel-extrinsic normalization in the sensorimotor control of speech</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Bourguignon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Baum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Shiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">1039</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Perceptual adaptation to non-native speech</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Whalen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Tiede</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">K</forename></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">101063</biblScope>
			<date type="published" when="2008">2008. 2021</date>
		</imprint>
	</monogr>
	<note>Cognition</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Variation and universals in VOT: evidence from 18 languages</title>
		<author>
			<persName><forename type="first">T</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ladefoged</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="207" to="229" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The role of the input in the development of L1 and L2 sound contrasts: Languagespecific cue weighting for vowels</title>
		<author>
			<persName><forename type="first">Paola</forename><surname>Escudero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th annual Boston University conference on language development</title>
		<meeting>the 25th annual Boston University conference on language development<address><addrLine>Somerville, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Cascadilla Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Accommodation theory: Communication, context, and consequence</title>
		<author>
			<persName><forename type="first">H</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Coupland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Coupland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Contexts of accommodation: Developments in applied sociolinguistics</title>
		<imprint>
			<date type="published" when="1991">1991</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Statistical learning across passive listening adjusts perceptual weights of speech input dimensions</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Hodson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Shinn-Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">238</biblScope>
			<biblScope unit="page">105473</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Hyman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phonology</title>
		<editor>
			<persName><forename type="first">Reinhart</forename><surname>Holt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Winston</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="1975">1975</date>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Word recognition reflects dimension-based statistical learning</title>
		<author>
			<persName><forename type="first">K</forename><surname>Idemaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1939</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Specificity of dimension-based statistical learning in word recognition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Idemaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1009</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Generalization of dimension-based statistical learning. Attention, Perception, &amp; Psychophysics</title>
		<author>
			<persName><forename type="first">K</forename><surname>Idemaru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="1744" to="1762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Phonetic knowledge</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kingston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Diehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="419" to="454" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to speak by listening: Transfer of phonotactics from perception to production</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Kittredge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Dell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Memory and Language</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="8" to="22" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">lmerTest package: tests in linear mixed effects models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Kuznetsova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Brockhoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Christensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Brief periods of auditory perceptual training can determine the sensory targets of speech motor learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lametti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Krol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Shiller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Ostry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1325" to="1336" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dimension-based statistical learning affects both speech perception and production</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lehet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="885" to="912" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Nevertheless, it persists: Perceptual recalibration and normalization of speech impact different levels of representation</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lehet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">202</biblScope>
			<biblScope unit="page">104328</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Voicing&quot; in English: A catalogue of acoustic features signaling/b/versus/p/in trochees</title>
		<author>
			<persName><forename type="first">L</forename><surname>Lisker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language and Speech</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="11" />
			<date type="published" when="1986">1986</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dimension-based statistical learning of vowels</title>
		<author>
			<persName><forename type="first">R</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1783</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Infants are sensitive to within-category variation in speech perception</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mcmurray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Aslin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="15" to="B26" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An online headphone screening test based on dichotic pitch</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bianco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">C</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Oxenham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Billig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1551" to="1562" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Transfer of statistical learning from passive speech perception to speech production</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Nozari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-023-02399-8</idno>
		<ptr target="https://doi.org/10.3758/s13423-023-02399-8" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Gender differences in vocal accommodation: The role of perception</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Namy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Nygaard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sauerteig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Language and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="432" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On phonetic convergence during conversational interaction</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2382" to="2393" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Conversational role influences speech imitation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Jay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Krauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2254" to="2264" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Phonetic convergence in college roommates</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gibbons</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Suppes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Krauss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="190" to="197" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Phonetic convergence across multiple measures and model talkers</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Urmanche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wilman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wiener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="637" to="659" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Talker-listener accent interactions in speech-in-noise recognition: Effects of prosodic manipulation as a function of language experience</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pinet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Iverson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1357" to="1365" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Gestural drift in a bilingual speaker of Brazilian Portuguese and English</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Sancier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Fowler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="421" to="436" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Individual differences in perceptual adaptability of foreign sound categories</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schertz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Warner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="355" to="367" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Attention</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Perception-for-Action-Control Theory (PACT): A perceptuo-motor theory of speech perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Basirat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Ménard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neurolinguistics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="336" to="354" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Foreign accented speech: Adaptation and generalization (Master&apos;s thesis</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Weil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Ohio State University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The universality of intrinsic F0 of vowels</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Whalen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Levitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Phonetics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="366" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">PANGEA: Power analysis for general ANOVA designs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Westfall</surname></persName>
		</author>
		<ptr target="http://jakewestfall.org/publications/pangea.pdf,4" />
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Phonetic category activation predicts the direction and magnitude of perceptual adaptation to accented speech</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Rapid adaptation to foreign-accented speech and its transfer to an unfamiliar talker</title>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weatherholtz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bainton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Burchill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">F</forename><surname>Jaeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2013" to="2031" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Explicit attentional goals unlock implicit spatial statistical learning</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Carlisle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">2125</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Simultaneous tracking of coevolving distributional regularities in speech</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1760</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The learning signal in perceptual tuning of speech: Bottom up versus top-down information</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Holt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">12947</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
