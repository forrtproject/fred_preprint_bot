<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PUPIL AND REGULARITY VIOLATIONS 1</title>
				<funder ref="#_Q2mDvkc">
					<orgName type="full">Machine Learning Cluster of Excellence</orgName>
				</funder>
				<funder>
					<orgName type="full">Max Planck Society and Humboldt Foundation (Peter Dayan)</orgName>
				</funder>
				<funder ref="#_V3e5DHq">
					<orgName type="full">German Research Foundation (DFG)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Hamit</forename><surname>Basgol</surname></persName>
							<email>hamit.basgoel@uni-tuebingen.de.</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Experimental Cognitive Science</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">The Graduate Training Centre of Neuroscience</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Florian</forename><surname>Raab</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">The Graduate Training Centre of Neuroscience</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Dayan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Max Planck Institute for Biological Cybernetics</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Volker</forename><forename type="middle">H</forename><surname>Franz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Experimental Cognitive Science</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Experimental Cognitive Science</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<addrLine>Sand 6</addrLine>
									<postCode>72074</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">PUPIL AND REGULARITY VIOLATIONS 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2DCE54D5E88482F808CE240943FBE97C</idno>
					<note type="submission">poster at the SVS Summer School 2023,</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-22T20:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pupil size</term>
					<term>arousal</term>
					<term>uncertainty</term>
					<term>visual regularities</term>
					<term>auditory regularities</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Pupil dilation responses are reliable physiological markers of arousal in reaction to unexpected events across sensory modalities. However, a direct comparison across modalities</p><p>has not yet been conducted. In this study, we address this gap by examining pupil responses to regular and random sequences of visual dots and auditory tones, as well as transitions between these sequences. In Experiment 1, we showed dilation responses when a regular sequence of visual dots changed to a random sequence, but not to the reverse transition. A transition between two different regular sequences led to less dilation on average. In Experiment 2, we replicated these findings, confirming the reliability of the observed dilation patterns. In Experiment 3, we compared the pupil responses when sequences and transitions were presented in visual versus auditory modalities. We observed strong cross-modal similarity in pupil sizes, particularly for transitions between regular and random sequences.</p><p>Notably, these similarities persisted even during baseline trials, when no explicit transition occurred. We also decomposed the time-series pupil size to approximate phasic pupil dilation events. The patterns of dilation events aligned with the overall dilation, with modality-specific dilation event size differences primarily in the context of transitions between different regular sequences. Overall, our findings suggest that pupil-linked arousal reflects imperfect inference of statistical structure and its violations, exhibiting substantial similarity across modalities.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modality-General Sensitivity of Pupil Responses to Regularity Violations</head><p>Sensory input exhibits statistical regularities over multiple temporal and spatial scales.</p><p>A wide range of studies has demonstrated that human observers track these statistical regularities <ref type="bibr" target="#b5">(Barascud et al., 2016;</ref><ref type="bibr" target="#b12">Canale, 2022;</ref><ref type="bibr" target="#b13">Conway, 2020;</ref><ref type="bibr" target="#b28">Frost et al., 2015;</ref><ref type="bibr" target="#b58">Paavilainen, 2013;</ref><ref type="bibr" target="#b76">Sherman et al., 2020)</ref>. Regularities exhibit a complex structure, leading observers to experience prediction errors in varying degrees across various time scales. In particular, low-probability, salient, and abrupt changes generate strong brain responses and highlight the requirement for learning and adaptation <ref type="bibr" target="#b17">(Dayan and Yu, 2006;</ref><ref type="bibr" target="#b35">Jordan, 2024;</ref><ref type="bibr" target="#b79">Soltani and Izquierdo, 2019)</ref>.</p><p>The brain responds to prediction errors in different ways. In this study, we use pupil dilation responses as a biomarker of such errors, and examine how they unfold in response to unexpected events experienced in visual or auditory modalities. In the following sections, we discuss biomarkers of prediction errors and associated findings that suggest cross-modal similarities across the brain, and then continue our discussion with pupil dilation responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Brain responses to prediction errors</head><p>Several biomarkers have been associated with prediction errors, notably various electroencephalography (EEG) signatures. These include Mismatch Negativity Response (MMN), an early EEG component (100-200 ms) elicited by a deviant stimulus within a regularly structured sequence. Although it is studied primarily in the auditory literature, MMNs are observed across all modalities, and concern the predictability of stimuli independent of modality of interest; and have been taken as reflecting hierarchical inferences across cortices <ref type="bibr" target="#b20">(Duncan et al., 2009;</ref><ref type="bibr" target="#b33">Grundei et al., 2023;</ref><ref type="bibr" target="#b46">Lieder et al., 2013;</ref><ref type="bibr" target="#b65">Prete et al., 2022;</ref><ref type="bibr" target="#b75">Schröger et al., 2015;</ref><ref type="bibr" target="#b84">Sussman, 2005)</ref>. MMNs are seen, for example, in audition <ref type="bibr" target="#b33">(Grundei et al., 2023;</ref><ref type="bibr" target="#b43">Lecaignard et al., 2022)</ref>, somatosensory <ref type="bibr" target="#b33">(Grundei et al., 2023)</ref>, and vision <ref type="bibr" target="#b39">(Kremláček et al., 2016)</ref>. Equally, the P3 component (300-500 ms) responds to prediction errors and has been observed across auditory, visual, and somatosensory modalities <ref type="bibr" target="#b3">(Andersen and Lundqvist, 2019;</ref><ref type="bibr" target="#b20">Duncan et al., 2009;</ref><ref type="bibr" target="#b92">Zhang et al., 2022)</ref> and multi-modal sequences <ref type="bibr" target="#b33">(Grundei et al., 2023)</ref>.</p><p>Critically, the brain's response to violations exemplified by the MMN and P3 is also frequently accompanied by a physiological marker: pupil dilation, a type of pupil response characterised by an increase in pupil size <ref type="bibr" target="#b1">(Alamia et al., 2019;</ref><ref type="bibr">Basgol et al., 2025;</ref><ref type="bibr" target="#b7">Bianco et al., 2020;</ref><ref type="bibr">Liao, Kidani, et al., 2016;</ref><ref type="bibr">Liao, Yoneya, et al., 2016;</ref><ref type="bibr" target="#b64">Planton and Dehaene, 2021;</ref><ref type="bibr" target="#b91">Zekveld et al., 2018;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. Pupil responses, with a focus on dilations, are the main subject of our investigation.</p><p>Pupil dilations are associated with the basal forebrain-ACh activity (the BF-ACh system; <ref type="bibr" target="#b49">Lloyd et al., 2023)</ref> and particularly the the locus coeruleus-norepinephrine system (the LC-NE system; de <ref type="bibr" target="#b18">Gee et al., 2017;</ref><ref type="bibr" target="#b31">Glennon et al., 2019;</ref><ref type="bibr" target="#b36">Joshi and Gold, 2020;</ref><ref type="bibr">Joshi et al., 2016;</ref><ref type="bibr" target="#b41">Larsen and Waters, 2018;</ref><ref type="bibr" target="#b56">Murphy et al., 2014;</ref><ref type="bibr" target="#b68">Reimer et al., 2016;</ref><ref type="bibr" target="#b83">Strauch et al., 2022)</ref>. Such responses have long been investigated as reflecting computational processes in the brain <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b26">Filipowicz et al., 2020;</ref><ref type="bibr" target="#b41">Larsen and Waters, 2018;</ref><ref type="bibr" target="#b57">Nassar et al., 2012;</ref><ref type="bibr" target="#b59">Pajkossy et al., 2023;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>, even when these responses are not directly relevant to task requirements or when the effect of task requirements on pupil size is statistically controlled <ref type="bibr" target="#b1">(Alamia et al., 2019;</ref><ref type="bibr">Basgol et al., 2025;</ref><ref type="bibr">Liao, Yoneya, et al., 2016;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>.</p><p>The pupil dilates, for example, in response to the violation of simple, regularly structured stimuli by a deviant stimulus <ref type="bibr" target="#b1">(Alamia et al., 2019;</ref><ref type="bibr">Liao, Yoneya, et al., 2016;</ref><ref type="bibr" target="#b91">Zekveld et al., 2018)</ref>. Extending these results in the auditory domain, the pupil also dilates in response to unexpected transitions from a regular sequence (structured by repeating a set of 50-ms-long tone pips) either to a random sequence (S. <ref type="bibr" target="#b95">Zhao et al., 2019)</ref> or a different regular sequence <ref type="bibr">(Basgol et al., 2025)</ref>. The magnitude and the number of dilation events are modulated by the extent of violations introduced by these transitions (i.e., the surprise, <ref type="bibr">Basgol et al., 2025)</ref>. These results are consistent with the view that phasic pupil dilation responses reflect state transitions <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b10">Bouret and Sara, 2005;</ref><ref type="bibr" target="#b17">Dayan and Yu, 2006;</ref><ref type="bibr" target="#b18">de Gee et al., 2017;</ref><ref type="bibr" target="#b40">Krishnamurthy et al., 2017;</ref><ref type="bibr" target="#b57">Nassar et al., 2012;</ref><ref type="bibr" target="#b89">Yu, 2012;</ref><ref type="bibr" target="#b90">Yu and Dayan, 2005)</ref>. That is, a sufficiently strong environmental change, indicating a state transition, would elicit the LC-NE system activity associated with arousal, which in turn would reset cortical target circuits to enhance focus on novel information <ref type="bibr" target="#b10">(Bouret and Sara, 2005;</ref><ref type="bibr" target="#b17">Dayan and Yu, 2006)</ref>.</p><p>Previous research on pupil responses to complex sequences has primarily focused on audition. Here, we study the degree of generalisation to vision. We first compare auditory and visual modalities in terms of sequential processing, and then outline the purpose and methodology of the current study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sequential learning in visual and auditory modalities</head><p>Both auditory and visual systems are capable of processing and learning the statistical relationships within sequences <ref type="bibr" target="#b13">(Conway, 2020)</ref>; however, growing evidence suggests that the auditory system is better at sequential patterns across time, whereas the visual system is better at patterns across space <ref type="bibr" target="#b23">(Emberson et al., 2011</ref><ref type="bibr" target="#b13">, Conway, 2020;</ref><ref type="bibr" target="#b13">Conway and</ref><ref type="bibr">Christiansen, 2005, 2009;</ref><ref type="bibr" target="#b25">Ferguson et al., 2018;</ref><ref type="bibr" target="#b28">Frost et al., 2015;</ref><ref type="bibr" target="#b29">Furth and Pufall, 1966;</ref><ref type="bibr" target="#b67">Recanzone, 2009;</ref><ref type="bibr" target="#b71">Robinson and Sloutsky, 2007)</ref>. These differences and many others <ref type="bibr" target="#b13">(Conway, 2020;</ref><ref type="bibr" target="#b28">Frost et al., 2015)</ref> have raised questions about the domain-generality of sequential processing.</p><p>Nonetheless, emerging evidence, including EEG biomarkers <ref type="bibr">(MMN and P3;</ref><ref type="bibr" target="#b33">Grundei et al., 2023)</ref>, and the engagement of overlapping brain networks across sensory modalities <ref type="bibr" target="#b64">(Planton and Dehaene, 2021)</ref>, suggests that domain-general mechanisms may underlie responses to prediction errors, potentially operating in concert with modality-specific processes <ref type="bibr" target="#b13">(Conway, 2020;</ref><ref type="bibr" target="#b28">Frost et al., 2015)</ref>. Furthermore, predictions based on one modality can influence other modalities, pointing to the involvement of a supra-modal predictive system <ref type="bibr" target="#b74">(Sabio-Albert et al., 2025)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Purpose of the study</head><p>Bringing together these threads, we sought to investigate pupil dynamics, as a proxy of computational processes in the brain, in response to prediction errors in auditory versus visual sequences. We created a visual version of a rapid tone presentation paradigm <ref type="bibr" target="#b5">(Barascud et al., 2016;</ref><ref type="bibr" target="#b81">Southwell and Chait, 2018;</ref><ref type="bibr" target="#b80">Southwell et al., 2017;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref> that we have also previously employed <ref type="bibr">(Basgol et al., 2025)</ref>. In this new visual version, a short-lived white dot appeared on a two-dimensional (2D) screen, moving across predetermined positions in either a regular (repeating trajectory) or random pattern. We employed three types of transitions between these patterns: random to regular, regular to random, or regular to a novel regular pattern. While transitions from random to regular patterns lead to the emergence of regularities (increasing predictability and reduction of surprise), those from regular to random or to novel regular patterns lead to their violations (reducing predictability and increasing surprise either continuously or momentarily <ref type="bibr" target="#b5">Barascud et al., 2016;</ref><ref type="bibr">Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>.</p><p>As for the case of audition, we isolated spontaneous processing of visual regularities and minimised the influence of decision-making and motor responses on pupil size <ref type="bibr" target="#b66">(Privitera et al., 2010;</ref><ref type="bibr" target="#b77">Simpson, 1969)</ref>, by instructing participants to perform the incidental task of detecting a target (e.g., a gap or a shape). This was to ensure that they kept their attention on the sequences.</p><p>First, we conducted two experiments, Experiments 1 and 2, to examine whether observations of pupil size from the auditory modality can be extended to the visual modality, with violations, but not the emergence, of visual regularities eliciting pupil dilation responses <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. The experiments differed in their incidental tasks: detecting a gap (Experiment 1, mirroring previous auditory studies; <ref type="bibr">Basgol et al., 2025;</ref><ref type="bibr" target="#b55">Milne et al., 2021;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref> or detecting a brief shape change (Experiment 2).</p><p>Then, in Experiment 3, we compared pupil responses to visual and auditory regularity violations. Here, we build on previous studies that compared auditory and visual modalities <ref type="bibr" target="#b16">(D'Ascenzo et al., 2018;</ref><ref type="bibr" target="#b38">Klingner et al., 2011;</ref><ref type="bibr">Liao, Yoneya, et al., 2016</ref>) by presenting transitions with varying degrees of statistical change, and explored which aspects of pupil dynamics best capture changes in stimulus statistics, beyond modality-specific differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>In this experiment, we investigated whether we could extend previous auditory results, which demonstrate that regularity violations lead to pupil dilation responses <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>, to the case of vision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>The raw data, processed data, and analysis scripts associated with studies in this manuscript will be made publicly available on the Open Science Framework (the OSF) upon acceptance. Unlike other experiments in this paper, this experiment and associated analyses were not preregistered. However, the analysis plan closely followed our previous study with auditory stimuli <ref type="bibr">(Basgol et al., 2025)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Fifteen participants contributed to the study. We dropped the data of one participant due to a high number of blinks and excessive data loss, resulting in 14 participants (11 female, one diverse, M age : 23.78, SD age : 3.25). The number of participants was comparable to experiments investigating the effect of auditory regularity violations (S. <ref type="bibr" target="#b95">Zhao et al., 2019)</ref>.  Note. Conditions and experiments. (a) An example set of stimuli. The x-axis represents time, and the y-axis represents the possible positions on a visual display of a white dot, as shown in (b, c, d). Note that 2D positions were flattened for a one-dimensional representation on the y-axis. Red vertical lines in (a) and red borders in (b , <ref type="figure">c</ref>, and <ref type="figure">d</ref>) indicate transitions between visual patterns (although the timing of transitions was jittered in the experiment). RAND5: Five positions were randomly chosen from a set of 20 possible positions and shown in random order. REG5: Five positions were also randomly selected from the same position pool (without replacement), but these were presented repeatedly in a fixed, consistent order. Both RAND5 and REG5 served as control conditions, as they did not involve any statistical transition. RAND5-REG5: A sequence began with a RAND5 pattern and then transitioned into a REG5 pattern. REG5-RAND5: A transition occurred from a REG5 pattern to a RAND5 pattern. REG5a-REG5b: The sequence transitioned from one REG5 pattern to a different REG5 pattern. Therefore, REG5-RAND5 and REG5a-REG5b lead to violations of the previous regularity, whereas RAND5-REG5 lead to the emergence of new regularities. Note that we controlled for the introduction of new positions after transitions. Experiment 1 included all conditions; Experiments 2 and 3 included REG5, REG5-RAND5, and REG5a-REG5b. Pattern and trial durations differed across experiments. (b) Experiment 1 used a 2D display (4 rows x 5 columns). In this task, participants were required to detect gaps in the sequences (marked by blue borders). (c) Experiment 2 used a 3 x 3 display, where possible positions of the moving white dot were marked with a grey patch. Instead of a gap, participants were instructed to detect a white diagonal shape (highlighted with blue borders). (d) In Experiment 3, we compared pupil responses to visual and auditory regularity violations, and therefore included the presentation of visual and auditory sequences. Visual sequences were presented as the movement of a dot (without reference locations), similar to Experiments 1 and 2, whereas auditory sequences consisted of tones. Sequences from each modality were presented in separate blocks. Participants first detected gaps, and then they evaluated the items, which consisted of sequences, in terms of similarity and the saliency of transitions between patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials</head><p>Previous studies in the auditory literature generated random (RAND) and regular (REG) patterns by sampling a number (n) of tones from a 20-item frequency pool <ref type="bibr" target="#b5">(Barascud et al., 2016;</ref><ref type="bibr">Basgol et al., 2025;</ref><ref type="bibr" target="#b55">Milne et al., 2021;</ref><ref type="bibr" target="#b81">Southwell and Chait, 2018;</ref><ref type="bibr" target="#b80">Southwell et al., 2017;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. For a RANDn pattern, n tones were randomly chosen from the pool (with replacement), and were then randomly resampled (with replacement) until the desired total sequence length was reached. In contrast, for a REGn pattern, n tones were again randomly chosen from the pool (with replacement), but were then presented repeatedly in the same order.</p><p>RAND and REG patterns shared the same low-level features but differed in their statistical properties. When trials involved a transition from one pattern to another (e.g., RANDn-REGn or REGn-RANDn), the same positions were used for both sequence types to avoid a confound with the novelty of items <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>.</p><p>We sampled REG5 and RAND5 patterns, similar to previous studies, to generate baseline trials. However, in our work, we used sampling without replacement to generate REGn patterns to preserve complexity. Trials involving RAND5-REG5 were used to investigate the effect of the emergence of a regularity on pupil size. Trials involving the transition REG5-RAND5 were used to investigate the effect of regularity violation. We also included a transition between different regularities, REG5a-REG5b (which were different but used the same 5 visual positions; see Figure <ref type="figure" target="#fig_9">1a</ref>).</p><p>Comparing REG5-RAND5 with REG5a-REG5b allowed us to compare the effects of violations that later evolved into regularities. We also analysed the amount of surprise afforded by the various transitions using a variable-order Markov model, called Information Dynamics of Music (IDyOM; <ref type="bibr">Pearce, 2018;</ref><ref type="bibr">Pearce, 2005</ref>, see Figure <ref type="figure" target="#fig_9">S1</ref> and Figure <ref type="figure" target="#fig_2">2</ref>).</p><p>In our visual analogue of this paradigm, we showed these sequences using a 2D display (a grid with 4 rows x 5 columns) that involved 20 possible positions where a short-lived white dot could appear (see Figure <ref type="figure" target="#fig_9">1b</ref>). Thus, regularities were structured by the spatio-temporal trajectory of the dot's position, rather than by its identity (such as its colour or shape, see similar paradigms in the statistical learning literature; <ref type="bibr" target="#b13">Conway and</ref><ref type="bibr">Christiansen, 2005, 2009;</ref><ref type="bibr" target="#b21">Durrant et al., 2016)</ref>. This type of display allowed us to control for two potential sources of noise. That is (a) we minimised luminance-driven effects on pupil, and (b) kept the working memory load low for tracking the statistics across items, helping the regularities pop-out (see <ref type="bibr" target="#b15">Conway and Christiansen, 2009,</ref> showing that participants are better at extracting statistical patterns when stimuli change locations instead of just changing identity at one spot). We used similar displays in the following experiments (see Figures <ref type="figure" target="#fig_9">1b</ref>, <ref type="figure" target="#fig_9">1c</ref> and <ref type="figure" target="#fig_9">1d</ref>).</p><p>Each participant observed 210 trials of randomly generated visual sequences (30 REG5-RAND5, 30 REG5a-REG5b, 60 REG5, 60 RAND5-REG5, and 30 RAND5). The length of trials varied from 6 to 8 s, and transitions occurred between 3.25 and 4 s after the sequence onset with a granularity of 0.25 s. REG5 presentations consisted of 24-32 repetitions of the same visual sequence (120-160 items in total), and the REG5 sequences in REG5-RAND5 and REG5a-REG5b were violated after 13-16 repetitions (65-80 items in total). Visual regularities may require more time to be recognised than auditory regularities.</p><p>Therefore, we increased the trial durations beyond those used in earlier auditory studies <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>.</p><p>A gap detection task was provided to maintain participants' attention to visual sequences without requiring them to search for the transitions between patterns. It required participants to detect possible 0.4 s gaps that could occur on 20% of trials and at any time between 0.5 s post-onset and pre-offset. Note that 0.4 s is approximately three times longer than the gap duration in earlier auditory research (0.15 s for RAND and 0.1 s for REG patterns; <ref type="bibr">Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. We chose this duration based on pilot experiments, in which participants had difficulty detecting visual gaps less than 0.4 s. Each condition involved the same proportion of gaps. Inter-trial intervals were 4 s with a 1-s feedback. All participants attended a brief practice session before the main experiment.</p><p>The main experiment consisted of six blocks, each containing trials from different conditions. After the main experiment, participants completed a short control block. Trials in this control block were REG5 or RAND5, and in 50% of the trials, a single tone pip was also presented (0.5 s, 1000 Hz). This control block was designed to assess whether the visual properties of the experiment alone induced a ceiling effect in pupil size. If such a ceiling effect were present, we would expect no pupil dilation response to the tone pip, and the absence of pupil dilation responses would have been due to the inability of the pupil to dilate further.</p><p>The visual stimuli were presented using a ViewPixx/3D System (screen diagonal: 24 inches, 60.96 cm). Participants were provided a RESPONSEPixx connected to the monitor and could respond by choosing one of the five buttons. Their right eyes (unless specified) were tracked using an EyeLink 1000 system (SR Research) at a sampling rate of 1000 Hz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants sat in a luminance-controlled, dimly lit room (5 cd/m 2 ). They were instructed to place their chin on a chin-rest to maintain a fixed distance between the eye and the monitor (50 cm), and the eye tracker was positioned below the monitor. Participants were shown an example of a trial that included a gap and then attended a brief practice session. They were instructed to monitor the sequences for gaps and respond with a button press. To minimise the influence of gaze position and retinal luminance changes (due to shifts in the white dot's position) on pupil, participants were instructed to fixate on the cross at the centre of the screen (or the centre of the screen if the cross was absent).</p><p>The main experiment consisted of six blocks, each separated by an optional 3-minute break. Before each block, a calibration phase was conducted to align gaze location data recorded by the eye tracker. Following the main experiment, participants completed the control experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of behavioural performance</head><p>We transformed participants' hit and false alarm rates using an arcsine function for subsequent parametric and Bayesian statistical analyses <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of pupil responses</head><p>Pupil area in the right eye was recorded at a sampling rate of 1000 Hz. Trials with a gap or a button press were excluded from analysis to eliminate potential effects of the gap or motor responses on pupil <ref type="bibr" target="#b66">(Privitera et al., 2010;</ref><ref type="bibr" target="#b77">Simpson, 1969)</ref>. For RAND5-REG5, REG5-RAND5, and REG5a-REG5b conditions, pupil data were segmented from 1 second before to 3 seconds after transitions. For REG5 and RAND5 conditions, dummy transitions corresponding to the times of real transitions were randomly picked.</p><p>Pupil size was reconstructed by piecewise cubic interpolation when there were complete or partial blinks. Trials with 20% missing data due to blinking, and those involving missing data after interpolation, were excluded from the analyses. Due to excessive trial loss (70%), one participant was excluded. We controlled the effect of gaze on pupil size by analysing participants' gaze direction: none of the participants' mean gaze locations exceeded the group mean by more than three standard deviations.</p><p>After smoothing the data with a 150 ms Hanning window, pupil size was z-scored by computing the mean and standard deviation separately for each participant and block.</p><p>Baseline correction was performed by subtracting the average pupil size from the 1 s interval before each real or dummy transition, allowing us to assess the impact of transitions on pupil size. A similar analysis pipeline was used to evaluate the effect of the tone pip on pupil size, with data segmented from 1 s before to 3 s after its onset. Pupil size in the no-transition control conditions (REG5 and RAND5) was also analysed over the whole trial (see Figure <ref type="figure" target="#fig_10">S2</ref>).</p><p>Upon aggregating the data, we compared transition conditions with corresponding no-transition control conditions using a non-parametric permutation procedure (generating a null distribution by sign flipping participants' mean; 5000 iterations with a threshold of p &lt; .05, using the MNE package in Python; <ref type="bibr" target="#b32">Gramfort et al., 2013;</ref><ref type="bibr" target="#b42">Larson et al., 2022;</ref><ref type="bibr" target="#b50">Maris and Oostenveld, 2007)</ref> to control the family-wise error rate. We transformed t-values to Bayes factors (BF 10 or BF 01 for estimating the evidence of the null hypothesis) with Jeffreys, Zellner, and Siow (JZS) prior using a Cauchy scale factor of 0.707 (Pingouin package in Python, <ref type="bibr" target="#b85">Vallat, 2018)</ref>. p values were corrected using the Holm-Bonferroni method, and corrections were noted where applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of pupil events and their magnitudes</head><p>The standard analysis in pupillometry involves averaging event-related pupil responses across trials. However, this approach may distort peak amplitudes and response latencies <ref type="bibr">(Fink et al., 2024)</ref>, similar to challenges observed in other biological signals such as functional magnetic resonance imaging (fMRI) and EEG <ref type="bibr">(Guy et al., 2021;</ref><ref type="bibr">Wang et al., 2021)</ref>. In our experience, two key issues can contribute to this distortion: (a) variability in pupil response times across trials and (b) reductions in pupil size as an orientation response to an event.</p><p>One solution to these issues is to extract small pupil events, such as micro-dilations and constrictions, from continuous measurements of pupil size. These events are relevant because, as a proxy of phasic pupil response, they are associated with the activity of the LC-NE system <ref type="bibr">(Joshi et al., 2016)</ref>, especially when their magnitudes are high <ref type="bibr" target="#b54">(Megemont et al., 2022)</ref>.</p><p>We identified these events by detecting the moments when the pupil size increased or decreased, analysing the slopes of pupil size (computed using the np.gradient function from numpy in Python, <ref type="bibr">Basgol et al., 2025;</ref><ref type="bibr">Joshi et al., 2016;</ref><ref type="bibr" target="#b54">Megemont et al., 2022;</ref><ref type="bibr" target="#b55">Milne et al., 2021;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>.</p><p>Note that transitions between patterns can elicit saccadic eye movements, which may, in turn, influence pupil size <ref type="bibr" target="#b88">(Winn et al., 2018)</ref> and lead to an overestimation of event rates in visual processing. We addressed this potential confound in several ways: Participants were instructed not to follow the dots with their gaze, and a previously described control analysis was applied to exclude trials showing gaze-related deviations. Furthermore, to minimise overestimation, we restricted our analysis to pupil events lasting longer than 300 ms, a threshold that was also adopted in previous studies (see <ref type="bibr">Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. These measures helped reduce the risk of overestimation of pupil events.</p><p>To assess how these events evolve after transitions, we applied a 500-ms sliding window (based on each participant's mean across trials) to the event data, separately for each participant and condition. Events were encoded as one at the time point at which they occurred, and their magnitude was defined as the magnitude difference from the preceding zero crossing, which served as the baseline. Depending on whether event size was taken into account, this analysis produced two distinct time series: one reflecting the count of events, and the other also reflecting the size of these events. Baseline correction was applied in the same manner as for the time-series pupil size data. We conducted this analysis for all experiments, but discuss them in Experiment 3 (see Figure <ref type="figure">S6</ref> for details).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioural performance</head><p>Participants performed similarly on gap detection across conditions (see Figure <ref type="figure" target="#fig_10">2a</ref>).</p><p>We analysed potential outliers by examining hit and false alarm rates that were more than three standard deviations above or below the group mean. The final analysis was conducted on data from 14 participants.</p><p>Paired two-sided t-tests revealed no significant difference in hit rates between REG5 and RAND5 (REG5 = 95.2, RAND5 = 90.5, BF 10 = 0.374, p = .399, 95% CI = [-0.140, 0.320], d z = 0.327) nor false alarm rates (REG5 = 0.146, RAND5 = 0, BF 10 = 0.413, p = .336, 95% CI = [-0.0017, 0.0046], d z = 0.277), indicating that the task was similarly challenging across conditions. Note that statistical tests were calculated after arcsine transformation. Note. Results of Experiment 1. (a) Hit and false alarm rates, Hit and FA, respectively, for the gap detection performance. (b) Baseline corrected pupil size. Time 0 s marks real or dummy transitions to the next pattern. Regularity violations (REG5-RAND5, REG5a-REG5b) evoked pupil dilation responses, but the emergence of regular patterns (RAND5-REG5) did not. (c) The difference between regularity violation conditions and corresponding no-transition conditions. The REG5-RAND5 condition was associated with greater pupil dilation than REG5a-REG5b. (d) Results of surprise analyses. Surprise values were estimated using a variable-order Markov model, known as Information Dynamics of Music (Pearce, 2018; Pearce, 2005), based on trials observed by a participant during an experimental session. The average surprise from the 1-second interval preceding the transition (from -1 to 0 s) was calculated and subtracted from each trial to correct for baseline.(e) Pupil dilation responses to tone pips. Coloured horizontal lines indicate regions where cluster-level statistics p &lt; .05 compared to no-transition control conditions. Shaded areas indicate the between-participants' standard error of the means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupil responses</head><p>The emergence of visual regularities (RAND5-REG5) did not elicit significant pupil dilation (see Figure <ref type="figure" target="#fig_10">2b</ref>). By contrast, violations of visual regularities in REG5-RAND5 and REG5a-REG5b conditions did lead to transient pupil dilation (Figure <ref type="figure" target="#fig_10">2b</ref>). These results are consistent with previous findings in the auditory domain <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>.</p><p>To isolate the effect of transitions, we subtracted pupil size in the REG5 condition from pupil size in REG5-RAND5 and REG5a-REG5b conditions (see Figure <ref type="figure" target="#fig_10">2c</ref>). The increase in pupil size in REG5a-REG5b (approximately 0.15) was smaller than in REG5-RAND5 (approximately 0.25) after the transitions.</p><p>Pupil size has been shown to scale with the amount of surprise after auditory transitions <ref type="bibr">(Basgol et al., 2025)</ref>. We estimated surprise profiles of visual transitions using IDyOM <ref type="bibr">(Pearce, 2018;</ref><ref type="bibr">Pearce, 2005</ref>, see Figure <ref type="figure" target="#fig_10">2d</ref> and Section S 1) for comparability with the previous work. The model suggests that the surprise for the REG5-RAND5 condition upon transition was transient and sustained (see dark blue line in Figure <ref type="figure" target="#fig_10">2d</ref>); in contrast, the surprise for REG5a-REG5b was transient (see orange line in Figure <ref type="figure" target="#fig_10">2d</ref>). The surprise for RAND5a-REG5b was gradually reducing after the transition (see red line in Figure <ref type="figure" target="#fig_10">2d</ref>). We compared these values with a modality-agnostic model <ref type="bibr">Éltetho et al., 2022</ref>, yielding similar results (see Figure <ref type="figure" target="#fig_9">S1</ref>).</p><p>In the control block, participants were presented with a short tone pip, which also elicited pupil dilation responses (see Figure <ref type="figure" target="#fig_10">2e</ref>), indicating that performing a visual task does not prevent the pupil from responding to an arousing stimulus, consistent with previous findings <ref type="bibr" target="#b51">(Marois and Vachon, 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Visual regularity violations in the REG5-RAND5 and REG5a-REG5b conditions resulted in pupil dilations; in contrast, the emergence of visual regularities (RAND5-REG5) did not lead to a considerable increase in pupil size. These results generalised previous findings in the auditory domain <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. The REG5-RAND5 condition elicited a greater increase in pupil size compared to the REG5a-REG5b condition, corresponding to information-theoretic profiles (see Figure <ref type="figure" target="#fig_10">2d</ref>).</p><p>The lack of a pupil dilation response to the emergence of visual regularities (Experiment 1; see Figure <ref type="figure" target="#fig_10">2b</ref>) is notable, specifically for vision, given that temporal regularities at a spatial location have been shown to guide attention of participants, even when such regularities do not provide any information about the task (J. <ref type="bibr" target="#b94">Zhao and Luo, 2017;</ref><ref type="bibr">J. Zhao et al., 2013, but see Alamia and</ref><ref type="bibr" target="#b2">Zénon, 2016)</ref>. This has been interpreted as a task-irrelevant attentional bias towards visual regularities (which was not observed for auditory regularities, <ref type="bibr" target="#b80">Southwell et al., 2017)</ref>. Previous work suggests that pupil responses reflect the activity of attentional networks <ref type="bibr" target="#b83">(Strauch et al., 2022)</ref>; therefore, it needs to be examined whether and how regularities influence attention, and whether pupil responses (including constrictions) are sensitive to such regularities and how (see a recent study in this direction, <ref type="bibr" target="#b9">Binda et al., 2025)</ref>.</p><p>A control block confirmed, moreover, that pupils were not at ceiling during the visual task: short tone pips still produced robust dilations, demonstrating that engagement in a visual sequence task does not preclude arousal-driven pupil responses <ref type="bibr" target="#b51">(Marois and Vachon, 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>We next administered a pre-registered version of Experiment 1. This was intended to ensure that the difference between the two conditions (REG5-RAND5 vs. REG5a-REG5b) arises from transitions between patterns rather than the experimental structure.</p><p>We therefore adjusted both the task and the stimulus display: (a) we used a 3 x 3 grid, limiting the display to nine locations. We expected that this would enable participants to monitor dot positions more effectively. Following this change, the dot size was set to 1°of the visual angle. (b) To support the same goal, we marked the locations (i.e., locations on the reference grid) where the white dot could appear. (c) Finally, participants were instructed to detect brief changes in the shape of the white dot rather than to detect a gap in the sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>We preregistered this study using AsPredicted (<ref type="url" target="https://aspredicted.org/db33-5vg8.pdf">https://aspredicted.org/db33-5vg8.pdf</ref>). We highlight deviations from the preregistration and indicate exploratory analyses where applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We estimated the effect size based on Experiment 1 to determine the number of participants for the current experiment; we first identified peak pupil dilation responses in the grand average for REG5-RAND5 and REG5a-REG5b. Then, using this information, we calculated the difference in amplitude between the REG5-RAND5 and REG5a-REG5b conditions and the corresponding control condition, REG5, for each participant. Note that calculating the effect size this way is more conservative than calculating the effect size based on time-series pupil size, as the grand average does not consider the shape of individual differences in pupil responses.</p><p>The effect size of Experiment 1 was d z = 0.75 and d z = 1 for REG5a-REG5b and REG5-RAND5, respectively (based on a one-tailed student t-test). Using G*Power <ref type="bibr" target="#b24">(Faul et al., 2007)</ref>, with d z = 0.75, we found that N = 18 is enough for an adequately powered study with 1β = 0.92 and α = 0.05.</p><p>To improve upon Experiment 1, we measured participants' visual acuity using the Freiburg Vision Test (the FrACT) and included only those with a visual acuity smaller than and equal to 0.3 logMAR (i.e., within the normal vision range; <ref type="bibr" target="#b4">Bach, 2006)</ref>. We excluded two participants due to eye tracker calibration problems, as inaccurate gaze measurements could affect pupil size estimation. Including their data did not alter the overall pupil response pattern. We included the data of 19 participants in our analyses (14 female, M age = 22.7, SD age = 4.21, mean M logMAR = -0.14, SD logMAR = 0.13). Note that this number is one more than specified in the preregistration; however, we retained this participant, as its inclusion did not change the overall pattern of statistical results. The experiment lasted 1.5 hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials</head><p>Each participant observed 120 trials of randomly generated visual sequences (30 REG5-RAND5, 30 REG5a-REG5b, and 60 REG5 as a baseline). The length of trials was 8 s, and transitions occurred between 3.5 s and 4 s after the sequence onset with a granularity of 0.25 s. Specifically, REG5s consisted of 32 repetitions (160 tones) of the same sequence, and REG5s in REG5-RAND5 and REG5a-REG5b were violated after 14-16 repetitions (70-80 tones). Participants were instructed to perform a shape detection task, which required them to detect a brief change of the white dot into a diamond lasting 0.1 s (see Figure <ref type="figure" target="#fig_9">1c</ref>). All other aspects of this experiment were identical to Experiment 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>The procedure for Experiment 2 was similar to that of Experiment 1, with a few key differences. This time, we assessed participants' visual acuity using the FrACT <ref type="bibr" target="#b4">(Bach, 2006)</ref>.</p><p>Participants were required to achieve an 85% hit rate during the practice session. After completing the main experiment, they filled out a short questionnaire.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of behavioural performance</head><p>We followed the analysis procedure described in Experiment 1. 36 trials were dropped (≈ 2%) as a result of preprocessing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioural performance</head><p>Participants performed similarly across conditions, with hit rates around 96% and false alarm rates between 0-2% (see Figure <ref type="figure" target="#fig_11">3a</ref>). We conducted repeated measures ANOVA to examine the effect of conditions on hit and false alarm rates. The analysis did not reveal a significant effect for hit rates, F (2, 36) = 0.13, p = .870, η 2 p = 0.007. In contrast, the numerically small difference, ≈ 1.5%, in the REG5-RAND5 condition led to a statistical difference across conditions, F (2, 36) = 6.84, p = .003, η 2 p = 0.28. The REG5-RAND5 condition received more false alarm responses than the REG5a-REG5b condition (p = .015, BF 10 = 9.26, d z = 1.04), but not more than the REG5 condition (p = .126, BF 10 = 1.61, d z = 0.68).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupil responses</head><p>The REG5-RAND5 and REG5a-REG5b conditions evoked pupil dilation responses (see Figure <ref type="figure" target="#fig_11">3b</ref>). To isolate the effect of transitions, we subtracted pupil size in the REG5 condition from pupil size observed in REG5-RAND5 and REG5a-REG5b conditions (see Figure <ref type="figure" target="#fig_11">3c</ref>). Although average pupil size in REG5a-REG5b was smaller than in REG5-RAND5, the test did not provide sufficient evidence for a difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Pupil responses show a similar pattern across visual and auditory modalities <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. The emergence of regularities (RAND5-REG5) does not lead to pupil dilation responses (Experiment 1), whereas violations of regularities by random patterns (REG5-RAND5) evoke pupil dilation responses (Experiments 1 and 2). Violations of regularities by novel regular patterns (REG5a-REG5b) elicit pupil dilation responses (Experiments 1 and 2). The relative magnitude of REG5-RAND5 and REG5a-REG5b Note. Results of Experiment 2. (a) Hit and false alarm rates, Hit and FA respectively, for the shape detection performance. (b) Baseline corrected pupil size. In line with Experiment 1, pupil dilation responses were induced by regularity violations (REG5-RAND5, REG5a-REG5b). (c) The difference between regularity violation conditions and the corresponding no-transition condition. Shaded areas and error bars indicate the betweenparticipant standard error of the means. Coloured horizontal lines indicate regions where cluster-level statistics p &lt; .05.</p><p>appears to be influenced by the structure of the experiment.</p><p>The similarity in pupil response across modalities (see Figure <ref type="figure" target="#fig_6">S5</ref> for comparisons of all experiments) provides compelling evidence for domain-general responses to prediction errors in the brain <ref type="bibr" target="#b13">(Conway, 2020;</ref><ref type="bibr" target="#b33">Grundei et al., 2023;</ref><ref type="bibr" target="#b64">Planton and Dehaene, 2021;</ref><ref type="bibr" target="#b74">Sabio-Albert et al., 2025)</ref>. One contributor may be the LC-NE system (or the ascending arousal system more broadly) that also modulates pupil dilation responses, which are sensitive to unexpected events in the environment that violate predictions <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b17">Dayan and Yu, 2006;</ref><ref type="bibr" target="#b19">de Gee et al., 2014</ref><ref type="bibr" target="#b18">de Gee et al., , 2017;;</ref><ref type="bibr">Joshi et al., 2016;</ref><ref type="bibr" target="#b83">Strauch et al., 2022;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. Similar pupil dilations across modalities, possibly mediated by the LC-NE system activity, would support the existence of a shared computational principle for detecting unexpected events <ref type="bibr" target="#b33">(Grundei et al., 2023;</ref><ref type="bibr" target="#b64">Planton and Dehaene, 2021;</ref><ref type="bibr" target="#b74">Sabio-Albert et al., 2025)</ref>.</p><p>Note, however, that in Experiments 1 and 2, we examined pupil responses to visual regularity violations and compared resulting pupil responses to those observed in the literature <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. These comparisons were, therefore, limited to qualitative comparisons that do not allow for investigating the effect of prediction errors on pupil responses at high resolution, nor do they reveal whether this effect varies or remains consistent across visual and auditory modalities. In the following experiment, Experiment 3, we made quantitative comparisons across modalities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>Previous studies observed similar patterns of pupil responses across modalities, but they compared pupil responses by only varying cognitive efforts <ref type="bibr" target="#b16">(D'Ascenzo et al., 2018;</ref><ref type="bibr" target="#b38">Klingner et al., 2011;</ref><ref type="bibr" target="#b47">Lisi et al., 2015)</ref>. For unexpected events that violate predictions, modalities have mainly been studied in isolation <ref type="bibr">(Liao, Yoneya, et al., 2016;</ref><ref type="bibr" target="#b91">Zekveld et al., 2018)</ref> with a limited, simple set of stimuli that lack variance. Perhaps because of this, correlations across modalities were not estimated <ref type="bibr" target="#b16">(D'Ascenzo et al., 2018;</ref><ref type="bibr" target="#b38">Klingner et al., 2011;</ref><ref type="bibr">Liao, Yoneya, et al., 2016;</ref><ref type="bibr" target="#b47">Lisi et al., 2015)</ref>. Fortunately, the sequential and rapid nature of the current paradigm allows various statistical changes to be presented in a single experimental session.</p><p>In Experiment 3, participants were presented with sequences from different modalities.</p><p>These sequences shared the same conditional relationships across items in time, but they differed in presentation format (i.e., the sequential presentation of tones for auditory stimuli and dot locations for visual stimuli, a standard method used in the statistical learning literature; see <ref type="bibr">Conway and Christiansen, 2005)</ref>. Therefore, they were isomorphic.</p><p>Isomorphic transitions involved varying degrees of violations of the previous pattern.</p><p>This design enables the examination of similarities and correlations in the resulting pupil responses based on these violations, thereby yielding variance to compare pupil responses across modalities. Importantly, this approach does not depend on participant-level variability, which can influence overall pupil size similarly across modalities without necessarily reflecting differences in how prediction errors are processed across modalities.</p><p>Differences in pupil response dynamics may arise from modality-specific characteristics, for example, the relative insensitivity of the visual modality and the heightened sensitivity of the auditory modality to this type of stimulus presentation. Prior work has shown a linear relationship between subjective judgements of saliency and pupil dilation <ref type="bibr">(Liao, Kidani, et al., 2016)</ref>. Therefore, to further investigate cross-modal effects, we compared pupil responses based on participants' subjective ratings of saliency (see Figure <ref type="figure" target="#fig_19">S10</ref> for details).</p><p>We hypothesised that violations of regularities would increase pupil size in both modalities. Additionally, we expected isomorphic transitions to evoke similar pupil responses after transitions, as reflected in both time-series and scalar pupil measures. We also hypothesised that pupil responses across modalities would present similar relationships with participants' saliency judgements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>This experiment was preregistered on AsPredicted (<ref type="url" target="https://aspredicted.org/v3wq-bszn.pdf">https://aspredicted.org/v3wq-bszn.pdf</ref>). We highlight any deviations or exploratory analyses, when applicable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We used the effect size from Experiment 1 (d z = 0.75, other details were similar to the previous experiment) to determine the required number of participants for comparing pupil size in regularity violation conditions to the no-transition baseline, as the current experiment resembles Experiment 1 (in terms of visual display and task). Using G*Power <ref type="bibr" target="#b24">(Faul et al., 2007)</ref>, we found that a sample size of N = 20 would result in a power of 1-β = 0.94 with α = 0.05.</p><p>We sought to test correlations of pupil responses across modalities. For this test, we planned to compute a Pearson correlation coefficient for each participant, and compare coefficients to zero using a one-tailed t-test. We therefore conducted another power analysis.</p><p>Assuming that correlations of participants (Fisher's z-transformed) across modalities would be normally distributed (r z = 0.21 and SD z = 0.22, approximately corresponding to r = 0.2 and SD = 0.2, respectively), we ran the simulation 500 times. We found that, with N = 20, 24 trials (for a transition condition after excluding trials with gaps) would be enough for 1-β = 0.89, and 48 trials (for two transition conditions after excluding trials with gaps) and for 1-β = 0.96 (with α = 0.05).</p><p>Twenty participants attended the experiment (13 female, M age : 24.4, SD age : 7.51, mean M logMAR : -0.1, SD logMAR : 0.15). Participants were mostly university students and compensated with either course credit or 12.5 EUR per hour. The experiment took approximately 2 hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials</head><p>Participants observed a set of 120 trials (30 REG5-RAND5, 30 REG5a-REG5b, and 60 REG5) for each modality. In contrast to our earlier experiments (Experiments 1 and 2) and previous studies <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>, in which participants were presented with randomly generated, different sets of trials, all participants in this experiment received the same set of trials that were generated before the data collection (but in individually-randomised orders). Moreover, unbeknownst to the participants, the visual and auditory sequences shown in trials were the same in terms of conditional relationships between items; thus, the visual and auditory sequences (and transitions within them) formed isomorphic pairs.</p><p>To create a set, we sampled sequences based on nine elements corresponding to the indices of pools (e.g., indices of frequency and position pools), a standard method used in the statistical learning literature <ref type="bibr">(Conway and Christiansen, 2005)</ref>. The frequency pool included nine pre-selected tones: three base frequencies <ref type="bibr">(222,</ref><ref type="bibr">292,</ref><ref type="bibr">and 384 Hz)</ref> and their two successive octaves <ref type="bibr">(444, 584, 768 Hz and</ref><ref type="bibr">888, 1168, 1536 Hz)</ref>. On the other hand, the position pool included the positions created by a 3 x 3 grid (without grey-coloured reference locations to keep modalities conceptually similar; see Figure <ref type="figure" target="#fig_9">1d</ref>).</p><p>Also, unbeknownst to the participants, items in frequency and position pools were mapped (certain frequencies and dot positions were associated with the same state) according to the findings from the cross-modal association literature (see the spatial-musical association of response codes, the SMARC effect in short, <ref type="bibr" target="#b73">Rusconi et al., 2006)</ref>. High tones (low tones)</p><p>were associated with higher (lower) locations in the grid to arrange for the visual and auditory patterns to be represented as similarly as possible (see Figure <ref type="figure" target="#fig_9">1d</ref>).</p><p>To ensure sufficient variability for cross-modal correlations within conditions, transitions involving 3, 4, and 5 unique indices following a pattern change were equally represented. Trials with zero circular Hamming distance (i.e., identical patterns differing only by a phase shift) were excluded, as such transitions could be imperceptible under rapid and continuous presentation.</p><p>Participants began the experiment with a block from one modality (e.g., auditory).</p><p>Then they continued with a block from the other modality (e.g., visual), with the trial order randomised across participants. Notably, each pair of successive blocks, namely 1-2, 3-4, 5-6, included the identical sequences presented in different modalities in the same order. We kept blocks close in time given that pupil response systematically varies as a function of time <ref type="bibr" target="#b53">(McLaughlin et al., 2023)</ref>.</p><p>Due to the long block duration (approximately 7 minutes), participants were unlikely to discover these associations; indeed, none of the participants reported awareness of the association. The order of sequences was randomised for each participant to prevent time-varying factors (such as fatigue and warm-up effects) from being associated with specific trials <ref type="bibr" target="#b53">(McLaughlin et al., 2023;</ref><ref type="bibr" target="#b78">Sirois and Brisson, 2014;</ref><ref type="bibr" target="#b88">Winn et al., 2018)</ref>.</p><p>The length of trials was 7.5 s, and transitions occurred between 2.5 and 3.5 s after the sequence onset with a granularity of 0.25 s. Specifically, REG5 sequences consisted of 30 repetitions (150 items) of the same auditory sequence, and REG5s in REG5-RAND5 and REG5-REG5b were violated after 10-14 repetitions (50-70 items). We shortened the trial duration relative to Experiments 1 and 2 to keep the experiment below 2 hours and reduce the risk of pupil fatigue <ref type="bibr" target="#b53">(McLaughlin et al., 2023;</ref><ref type="bibr" target="#b88">Winn et al., 2018)</ref>.</p><p>Participants were instructed to detect gaps occurring between 0.5 s after sequence onset and 1 second before sequence offset, which occurred with a probability of 20%. Gaps in auditory sequences were set to 0.2 s, whereas in visual sequences, they were set to 0.4 s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants were shown examples of auditory and visual sequences (with gaps) and began the practice session with their assigned modality (for example, auditory); then, they continued the practice block for the other modality (for example, visual). Similar to the practice session, they began the main experiment with their assigned modality (e.g., auditory)</p><p>and then continued with the alternate modality (e.g., visual). They completed a brief questionnaire, which now included a question about their perceived mental effort for the visual and auditory gap detection tasks.</p><p>After completing the questionnaire, participants first rated the similarity between items and then assessed the saliency of transitions. Analyses and discussions associated with these measurements are presented in the supplementary materials (Section S9).</p><p>Auditory stimuli were presented through headphones (diotically using Beyerdynamic DT-770 M 80 Ohm) connected to the display. All remaining procedural aspects were consistent with previous experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupil responses</head><p>Compared with Experiments 1 and 2, we made a minor, preregistered adjustment to the pipeline of pupil size analysis. The analysis now focuses on the four-second (previously three-second) window following the transition, as 80% of pupil peaks occurred within this time frame in Experiments 1 and 2. Dummy transition times used for REG5 were kept consistent across modalities (based on isomorphic trials) to ensure comparability. During preprocessing, 32 trials (approximately 1%) were excluded due to missing data. Due to issues with the experimental setup, measurements of the left pupil were taken for two participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time-series pupil size</head><p>We compared time-series pupil size (REG5-RAND5 vs. REG5a-REG5b) using BF 01 that estimates the degree of evidence supporting the null hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correlations of pupil responses</head><p>We calculated scalar values for isomorphic trial pairs (stimuli identical in statistical properties but differing in presentation format), thus ensuring that the observed correlations reflect pupil responses to statistical changes following transitions. Measurements include peak pupil size, the time of peak pupil response, mean pupil size and the minimum pupil size after transitions. We then computed correlations between these scalar values at the level of individuals and groups as follows:</p><p>(a) As outlined in our preregistration, we first examined whether participants showed comparable scalar pupil measures for isomorphic pairs. We calculated a Pearson correlation coefficient for each participant separately and tested if these correlations significantly differed from zero using a one-tailed t-test (following Fisher's z-transformation).</p><p>(b) In an exploratory analysis, we examined whether scalar pupil measures were similar across modalities at the group level. To do this, we computed the average scalar value for each isomorphic transition across participants (calculating the group's response as a scalar value) and then assessed correlations between averages. This reduced measurement noise, yielding more stable estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioural performance</head><p>Hit and false alarm rates were slightly different across modalities.  Note. Gap detection performances for REG5 in Experiment 3. Error bars indicate between-participant standard error of the means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Time-series pupil size</head><p>The REG5-RAND5 condition evoked remarkably similar pupil dilations across modalities (see Figures <ref type="figure" target="#fig_6">5a</ref> and <ref type="figure" target="#fig_6">5b</ref>, and, for a comparison, see Figure <ref type="figure" target="#fig_6">5c</ref>). However, unlike</p><p>Experiments 1 and 2, the REG5a-REG5b condition did not evoke strong pupil dilations (see Figures <ref type="figure" target="#fig_6">5a</ref> and <ref type="figure" target="#fig_6">5b</ref>). Although in this condition, a slight increase in pupil size was observed in the auditory modality compared to the visual modality, the difference was not statistically strong (see Figure <ref type="figure" target="#fig_6">5d</ref>).</p><p>We therefore compared pupil responses in visual and auditory conditions.</p><p>Cluster-based permutation statistics did not reveal a reliable difference. We then calculated BF 10 for each time step, with none exceeding the threshold of 3. We then assessed the evidence for the null hypothesis using BF 01 (see Figures <ref type="figure" target="#fig_6">5c</ref>, <ref type="figure" target="#fig_6">5d</ref>, and 5e). Overall, pupil Note. Pupil responses in Experiment 3. Baseline-corrected pupil size for (a) visual and (b) auditory modalities. Similar to previous experiments, the REG5-RAND5 condition evoked pupil dilation responses. In contrast, the REG5a-REG5b condition did not trigger substantial pupil dilation. (c) The REG5-RAND5 condition led to similar pupil responses across modalities. (d) However, in the REG5a-REG5b condition, the auditory modality showed a slight increase compared to the visual modality, but this difference was not statistically significant. (e) The main pupil trend for the REG5 condition was similar across modalities, with the auditory modality slightly increasing. Shaded areas indicate the between-participant standard error of the means. Coloured horizontal lines indicate regions where cluster-level statistics p &lt; .05 in (a) and (b); and they indicate BF01 for (c), (d), and (e) to estimate the amount of evidence for the null hypothesis (suggesting no difference between the distributions). The thin line corresponds to BF01 &gt; 1, and the thick line corresponds to BF01 &gt; 3. We also calculated clusterlevel statistics for (c), (d), and (e), which did not suggest a statistical difference (p &lt; .05).</p><p>responses after transitions were similar across modalities with momentary deviations in REG5a-REG5b and REG5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6</head><p>Pupil dilation events and their size across experiments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupil events and their magnitudes</head><p>We conducted an exploratory analysis based on pupil events. We first present pupil events across experiments (Experiment 3 and the combined data of Experiments 1 and 2), and compare modalities in Experiment 3 (see Figure <ref type="figure">6</ref>). For both REG5-RAND5 and REG5a-REG5b, dilation event rates and amplitudes were consistent (see Figures <ref type="figure">6a</ref> and <ref type="figure">6b</ref>)</p><p>across experiments with visual sequences. However, the effect of the REG5a-REG5b condition on pupil size was weaker, even when combining Experiments 1 and 2, than in Experiment 3</p><p>(compare Figures <ref type="figure">6c</ref> and <ref type="figure">6d</ref>).</p><p>In Experiment 3, for both modalities, pupil events showed a similar pattern of results</p><p>for the REG5-RAND5 condition, suggesting that violations of regularities by random patterns led to similar dilation and constriction events in terms of size and rate (see Figure <ref type="figure">6b</ref> for dilations and Figure <ref type="figure">6d</ref> for constrictions). However, although visual and auditory REG5-REG5b conditions were highly similar in terms of the number of dilation events, they were different in the size of those events. Namely, the auditory REG5a-REG5b condition resulted in larger dilation events than the visual REG5a-REG5b condition (Figure <ref type="figure">6d</ref>).</p><p>Overall, this analysis provides a complementary perspective to pupil size averaging. It suggests that the increase in missing pupil size for the REG5-REG5b condition may not indicate that the pupil is unaffected, and that pupil responses across modalities may not be entirely identical (compare Figure <ref type="figure" target="#fig_6">5d</ref> and Figure <ref type="figure">6d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correlations of pupil responses</head><p>In the following section, we compare scalar values extracted from pupil traces across modalities. This analysis addresses two questions: (a) how similar are pupil responses across modalities, and (b) among the pupil-derived metrics, which provides the most reliable measure when conditional properties across items are matched.</p><p>To this end, we conducted two analyses focusing on cross-modal correlations and one analysis targeting cross-modal differences. We first estimated correlations across modalities based on isomorphic transitions for each participant (see Figure <ref type="figure" target="#fig_16">7a</ref> and Table <ref type="table" target="#tab_1">1</ref>). This analysis tests whether scalar pupil measures are correlated within individuals. Second, we examined correlations at the group level by averaging scalar values across isomorphic transitions (see Figure <ref type="figure" target="#fig_16">7b</ref>; Table <ref type="table" target="#tab_2">2</ref>). Because this approach involves computing group-level responses for each transition, it is more robust to individual variability. Finally, we compared scalar pupil measures across modalities as a complementary analysis to the time-series comparison (see Figure <ref type="figure" target="#fig_6">5</ref>). p-values reported in Tables <ref type="table" target="#tab_4">1</ref>, <ref type="table" target="#tab_2">2</ref>, and 3 were corrected on a per-table basis (using the Holm-Bonferroni method). Note. Individual correlations based on isomorphic pairs of visual and auditory sequences were calculated for each participant. The correlations were then compared to 0 using a one-tailed t-test. Mr corresponds to the mean of individual correlations; 95% CI denotes the one=sided confidence interval. The statistical metrics BF10, pcorr, and dz refer, respectively, to the Bayes factor, the corrected p-values of these correlations, and effect sizes.</p><p>Peak and mean pupil size: Peak pupil size was correlated (see Table <ref type="table" target="#tab_1">1</ref>, one-tailed t-tests were used as specified in the preregistration) for the majority of participants (see Figure <ref type="figure" target="#fig_16">7a</ref>). Note, however, that the REG5a-REG5b condition showed a weaker correlation (M r = 0.12) than the REG5-RAND5 condition (M r = 0.28; difference: t = 2.658, BF 10 = 3.556, p = 0.016, d z = 0.763, 95% CI = [0.030, 0.280]). Group responses calculated for isomorphic transitions agreed with this observation (see Figure <ref type="figure" target="#fig_16">7b</ref> and Table <ref type="table" target="#tab_2">2</ref>), again the correlation for REG5a-REG5b was numerically weaker (r = 0.64) than REG5-RAND5 (r = 0.86; however, the difference was not statistically strong, z = 1.734, p = 0.083, 95% CI = [-0.070, 1.140]). Mean pupil size was consistent with peak pupil size (see Tables <ref type="table" target="#tab_4">1</ref> and <ref type="table" target="#tab_2">2</ref>;</p><p>difference: z = 2.376, p = 0.018, 95% CI = [0.128, 1.338] with a statistically strong estimate).</p><p>The REG5a-REG5b condition did not lead to consistent correlations compared to the REG5-RAND5 condition, following peak pupil size (t = 2.3, BF 10 = 2.2, p = 0.028, d z = 0.75, 95% CI = [0.020, 0.280]).</p><p>The REG5-RAND5 condition led to the same peak pupil magnitudes (see Figure <ref type="figure" target="#fig_16">7c</ref> and Table <ref type="table" target="#tab_3">3</ref>); This measure was slightly different for the REG5a-REG5b and REG5 conditions (see Table <ref type="table" target="#tab_3">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Peak time:</head><p>The time of pupil peaks was not consistently correlated within participants (see Figure <ref type="figure" target="#fig_16">7d</ref> and Table <ref type="table" target="#tab_1">1</ref>); it became correlated when all transitions together were considered (see Figure <ref type="figure" target="#fig_16">7e</ref> and Table <ref type="table" target="#tab_2">2</ref>). The reason for the missing correlation in REG5-RAND5 is possibly because transitions of this condition induce sustained violations that the pupil can continue responding to.</p><p>The time of peak pupil size was similar across conditions (note that t-tests were conducted after log transformation). Only the REG5a-REG5b condition appeared different, but this effect did not survive the multiple comparison correction (see Table <ref type="table" target="#tab_3">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Minimum pupil size:</head><p>As an exploratory analysis, we examined minimum pupil size across conditions, as it may reflect a decrease in uncertainty after transitions <ref type="bibr" target="#b55">(Milne et al., 2021)</ref>. The REG5-RAND5 condition seemed to be correlated (see Table <ref type="table" target="#tab_1">1</ref> for a weak correlation that could not survive the correction procedure and Table <ref type="table" target="#tab_2">2</ref> for a stronger correlation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Control analysis:</head><p>Correlations reflect structural similarities between isomorphic transitions in visual and auditory modalities. Still, it is reasonable to question if these correlations may have been modulated by other experimental factors rather than by statistical properties (despite our randomisation attempts). We re-ran these analyses to address this possible concern, determining "fake" isomorphic pairs. These fake pairs were determined as the closest trials (in terms of time) to the original pair within the same condition (and block); thereby, to assess, if correlations are due to statistical structures rather than other variables that could be associated with the dynamics of the experiment (i.e., trial pairs occur in the same order within the block). Out of 32 tests estimating correlations, only one test yielded a BF 10 greater than 3, which is the correlation of modalities for REG5 in terms of peak size (M r = 0.09, BF 10 = 12.59, p corr = 0.063). No other comparison yielded a BF 10 &gt; 3 (with all other corrected p-values &gt; .476).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correlations of pupil events:</head><p>We conducted similar analyses based on pupil dilation events and associated scalar measures (the number of dilation events and their total Note. Comparisons of scalar values extracted from pupil traces in Experiment 3. The first row corresponds to peak pupil size, and the second corresponds to their time. Columns correspond to different types of comparisons: participants' correlations, group correlations based on averages of isomorphic transitions, and differences of scalar values. Shaded areas and error bars indicate between-participant standard error of the means. Asterisks denote where pcorr &lt; 0.05. magnitude after the transition and within the epoch). While the number of dilation events did not correlate across modalities, the total magnitude showed strong correlations in transitions (but not in REG5a-REG5b) and baseline conditions (see Figure <ref type="figure" target="#fig_6">S5</ref>). Notably, although dilation events exhibited similar patterns across conditions (see Figure <ref type="figure">6</ref>), the lack of cross-modal correlation may be attributable to the range in the dataset (the maximum number of events in a trial was only 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Having observed consistent results in Experiments 1 and 2, we proceeded with Experiment 3 to compare pupil responses to visual and auditory sequences, as well as their violations of regularities within these sequences.</p><p>Similar to Experiments 1 and 2, in Experiment 3, we observed that regularity violations led to pupil dilation responses. Pupil size increased in response to the violations of regularities by random patterns (REG5-RAND5). In contrast with previous experiments, pupil size did not increase significantly when violations of regularities by regular patterns (REG5a-REG5b) were presented. This pupil event analyses showed a complementary picture: the number of dilation events and associated magnitudes increased after transitions in both visual and auditory REG5-RAND5 conditions (see Figure <ref type="figure">6</ref>). On the other hand, the auditory and visual REG5a-REG5b conditions resulted in an increase in the number of dilation events. In contrast, the visual REG5a-REG5b condition produced smaller pupil events compared to the auditory REG5a-REG5b condition (see Figure <ref type="figure">6d</ref>).</p><p>We calculated correlations of scalar values of pupil size based on isomorphic trials.</p><p>Overall, pupil responses across modalities were highly correlated. This correlation was strongest for REG5-RAND5 and slightly weaker for REG5a-REG5b; Figures <ref type="figure" target="#fig_9">1</ref> and <ref type="figure" target="#fig_2">2</ref>). Even during unchanging sequences (REG5), pupil dynamics remained correlated across modalities (except RTs of pupil), suggesting that tonic adjustments in arousal can drive convergent pupil behaviour. Among the various pupil metrics examined, peak dilation emerged as the most robust indicator of pupil sensitivity to statistical structure. It demonstrated greater stability and stronger cross-modal correlations (as evidenced by high BF 10 s and correlations).</p><p>After the main experiment, we presented the same transitions to participants at the end of the session to estimate their subjective saliency <ref type="bibr">(Liao, Kidani, et al., 2016)</ref>; this helped us find a perceptual basis for transitions based on self-reports. Participants' rating of saliency judgements were positively correlated with their pupil dilations, reinforcing the notion that both objective and subjective measures of transition strength are closely tied to phasic pupil responses (see Figure <ref type="figure" target="#fig_18">S9</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>Given the sensitivity of pupil responses to prediction errors <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>, and building on prior evidence indicating cross-modal similarities in the processing of deviant stimuli <ref type="bibr" target="#b33">(Grundei et al., 2023;</ref><ref type="bibr" target="#b64">Planton and Dehaene, 2021;</ref><ref type="bibr" target="#b74">Sabio-Albert et al., 2025)</ref>, we adapted to vision the rapid tone presentation paradigm used in audition <ref type="bibr" target="#b5">(Barascud et al., 2016;</ref><ref type="bibr">Basgol et al., 2025;</ref><ref type="bibr" target="#b81">Southwell and Chait, 2018;</ref><ref type="bibr" target="#b80">Southwell et al., 2017;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref> and investigated and compared pupil dynamics in response to changes within visual and auditory sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regularity violations lead to pupil dilation responses</head><p>Our main results were consistent with previous auditory observations <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. The emergence of regularities (RAND5-REG5) does not lead to pupil dilation responses, whereas violations of regularities by random patterns (REG5-RAND5) evoke pupil dilation responses (Experiments 1, 2, and 3, see Figure <ref type="figure" target="#fig_6">S5</ref>).</p><p>However, the magnitude of pupil dilation in response to regularity violations by 5 item regular patterns (REG5a-REG5b) was smaller than that observed for regularity violations by random patterns (REG5-RAND5; see Figures <ref type="figure" target="#fig_10">2c</ref> and <ref type="figure" target="#fig_11">3b</ref>). This differed from our earlier study, which used 10-item regular auditory sequences <ref type="bibr">(Basgol et al., 2025)</ref>. One consideration is that REG5b only violates expectations to the extent permitted by the new conditional relationships.</p><p>In our experiments, we observed changing pupil dynamics, possibly as a result of changing task demands (gap vs. shape detection, compare Experiments 1 and 2 in Figure <ref type="figure" target="#fig_12">S4</ref>), display (with vs. without reference locations, compare Experiments 1 and 2), and introducing an additional task (compare Experiments 1 and 3). Despite these differences, the REG5-RAND5 condition resulted in a consistent increase above baseline; however, REG5a-REG5b did not exhibit a consistent effect (Experiments 1 and 2 led to an increase; whereas Experiment 3 did not lead to an increase, see Figure <ref type="figure" target="#fig_12">S4</ref>).</p><p>We conducted exploratory analyses to identify the factors that may contribute to the missing effect. One factor we considered was pupil baseline, as it is known that baseline measurements can obscure increases in pupil size (refer to Relaño-Iborra et al., 2022 for a detailed discussion). Our analysis, however, revealed that the pupil baseline in Experiment 3 was similar to the pupil baseline observed in Experiment 1 (see Figure <ref type="figure" target="#fig_12">S4</ref>). Furthermore, pupil size increased in the REG5-RAND5 condition, which rules out the potential influence of pupil baseline.</p><p>Another factor is experiment duration, which is associated with a reduction in pupil size increase <ref type="bibr" target="#b53">(McLaughlin et al., 2023)</ref>. We also observed that the duration of the experiment influenced pupil size, with regularity violations in initial blocks causing a slightly larger increase. However, even the earliest trials did not demonstrate effects consistent with previous experiments (see REG5a-REG5b in Figure <ref type="figure" target="#fig_12">S4</ref>).</p><p>Participants may also have implicitly learned when the transition occurred <ref type="bibr" target="#b0">(Akdoğan et al., 2016)</ref>, allowing them to modulate their effort in response to changing task demands.</p><p>This modulation could have produced a gradual increase in pupil size around the time of transitions, followed by a reduction (see Figure <ref type="figure" target="#fig_17">S8</ref>) in REG5. It may also explain the reduction in pupil size observed in REG5a-REG5b, resulting from more efficient effort regulation.</p><p>It is important to note that the absence of time-series pupil size increase does not imply that REG5a-REG5b did not affect pupil size; in fact, pupil dilation events have increased due to these transitions (compare Figure <ref type="figure" target="#fig_6">5d</ref> and Figure <ref type="figure">6d</ref>). We return to this point later in the discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupil size: cross-modal similarities and differences</head><p>Beyond comparing time-series pupil size across experiments, we compared modalities in a single experiment, in Experiment 3. The REG5-RAND5 condition resulted in remarkably similar pupil dilations (see Figure <ref type="figure" target="#fig_6">5c</ref>), suggesting that modalities led to converging pupil responses. This similarity is visible not only in scalar measures but also in overall pupil dynamics (i.e., time-series pupil size, events and associated magnitudes).</p><p>However, the REG5a-REG5b condition did not elicit consistent pupil dilation responses across modalities (see Figure <ref type="figure" target="#fig_6">5d</ref>). The auditory REG5a-REG5b condition evoked numerically higher pupil responses than the visual REG5a-REG5b condition (agreeing with previous research, <ref type="bibr" target="#b38">Klingner et al., 2011)</ref>. However, neither permutation-based clustering nor BF 10 suggested a consistent difference across modalities (see Figure <ref type="figure" target="#fig_6">5d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-modal correlations of scalar pupil measures</head><p>Pupil responses across modalities have been investigated using a limited number of simple stimuli with low variability <ref type="bibr">(Liao, Yoneya, et al., 2016)</ref>. Consequently, correlations across modalities have been underexplored.</p><p>Overall, we observed that pupil responses to statistical changes following visual and auditory transitions are strongly correlated, suggesting that both modalities are similarly sensitive to changes in statistical structure. The modalities tend to converge when regularities are violated by a random pattern (i.e., REG5-RAND5), whereas when they are violated by a regular pattern (i.e., REG5a-REG5b). These results suggest that transition-evoked (i.e., phasic) pupil responses reflect (inference of) statistical changes upon transitions. Correlations of dilation event magnitudes agree with this interpretation (see Section S7).</p><p>As an exploratory analysis, we compared pupil responses across modalities without transitions (i.e., REG5). Interestingly, pupil responses are still correlated across modalities and show stable correlations (see peak size, mean size, and minimum size in Figure <ref type="figure" target="#fig_1">1</ref> and mean size in Figure <ref type="figure" target="#fig_2">2</ref>). This suggests that pupil size reflects not only changes due to transitions (e.g., REG5a-REG5b and REG5-RAND5), but also imperfect inferences by participants in response to REG5 sequences that could be interpreted as the general level of uncertainty <ref type="bibr" target="#b55">(Milne et al., 2021)</ref>, which has been shown to lead to tonic increases in pupil size, reflected in baseline pupil size levels <ref type="bibr" target="#b26">(Filipowicz et al., 2020;</ref><ref type="bibr" target="#b30">Gesztesi and Pajkossy, 2025;</ref><ref type="bibr" target="#b55">Milne et al., 2021;</ref><ref type="bibr" target="#b57">Nassar et al., 2012;</ref><ref type="bibr" target="#b59">Pajkossy et al., 2023)</ref>.</p><p>Another possibility is that the correlated pupil responses reflect phasic reactions to change points within the pattern itself. For example, a REG5 sequence consists of repeated chunks that contain items (abcde-abcde-abcde, where letters correspond to frequencies or dots). The transition between two chunks might elicit a pupil response that could drive the correlations across modalities in REG5.</p><p>We further observed that the variable that is most sensitive to changes in statistical structure is peak pupil size. This is despite the recent observation that the slope, delay and curvature of pupil traces, along with peak pupil size, but not mean pupil size, are affected by pupil baseline <ref type="bibr" target="#b69">(Relaño-Iborra et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pupil events: cross-modal similarities and differences</head><p>Despite the similarities between modalities in pupil responses, differences also appeared across experiments (see Figure <ref type="figure" target="#fig_11">S3</ref>) and between modalities (see Figure <ref type="figure" target="#fig_6">5d</ref>), particularly in REG5a-REG5b. We suspect that the absence of dilation responses in REG5a-REG5b may be due to the averaging operation. We therefore extracted pupil events from pupil traces.</p><p>We observed a consistent increase in dilation events in REG5-RAND5 across experiments (see Figures <ref type="figure">6a</ref> and <ref type="figure">6b</ref>, in line with previous studies <ref type="bibr">(Basgol et al., 2025)</ref>.</p><p>However, the effect for REG5a-REG5b was weak and short-lived in Experiments 1 and 2 (6c)</p><p>but not in <ref type="bibr">Experiment 3 (6d)</ref>, where sequences were identical across participants, thereby reducing pupil-response variability.</p><p>Suggesting a difference across modalities, the event analysis revealed a more fine-grained picture: the number of dilation events and their associated magnitudes increased after transitions in both visual and auditory REG5-RAND5 conditions (see Figure <ref type="figure">6</ref>), with a remarkably similar degree across modalities. In contrast, the auditory and visual REG5a-REG5b conditions differed. There was a similar increase in the number of dilation events (see Figure <ref type="figure">6d</ref>) in both modalities, but visual presentations led to smaller pupil events than the auditory presentations (similar to the previous experiments, see Figure <ref type="figure">6c</ref>).</p><p>From a theoretical perspective, the distinction between modalities might be particularly interesting. Consistent prediction errors associated with state-change signals (i.e., unexpected uncertainty) are proposed to elicit the LC-NE system activity, which in turn gives rise to pupil dilation responses <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b17">Dayan and Yu, 2006;</ref><ref type="bibr" target="#b35">Jordan, 2024;</ref><ref type="bibr" target="#b59">Pajkossy et al., 2023;</ref><ref type="bibr" target="#b89">Yu, 2012;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>. A recent study further suggests that only infrequent but large pupil dilation events reliably track the LC-NE system activity <ref type="bibr" target="#b54">(Megemont et al., 2022)</ref>.</p><p>Following this view, the substantial prediction errors in REG5-RAND5 transitions may signal consistent change signals, resulting in robust and comparable pupil dilation responses across modalities. In contrast, possibly transient prediction errors of REG5a-REG5b transitions may generate weaker change signals, potentially revealing modality-specific sensitivity to statistical structure. This could reflect differences in how visual and auditory systems infer change points under their unique constraints <ref type="bibr" target="#b13">(Conway, 2020;</ref><ref type="bibr">Conway and Christiansen, 2005;</ref><ref type="bibr" target="#b28">Frost et al., 2015)</ref>.</p><p>Inferring change points is harder when the general volatility of predictions (i.e., expected uncertainty) is higher; the visual modality may form worse predictions for temporal sequences than the auditory modality for REG5; and therefore, require stronger signals to determine a change point (compare auditory and visual REG5a-REG5b in Figure <ref type="figure">6d</ref>), leading to model reset <ref type="bibr">(Basgol et al., 2025)</ref>. This interpretation is consistent with previous research, suggesting that the auditory modality has an advantage in processing low-level sequential stimuli <ref type="bibr" target="#b13">(Conway, 2020;</ref><ref type="bibr">Conway and Christiansen, 2005;</ref><ref type="bibr" target="#b28">Frost et al., 2015;</ref><ref type="bibr" target="#b72">Rubinstein and Gruenberg, 1971)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Detection of prediction errors with modality constraints</head><p>Structured learning of patterns occurs across perceptual domains. Yet, the underlying mechanisms vary by modality and the presentation mode, suggesting the presence of modality-specific learning systems <ref type="bibr" target="#b13">(Conway, 2020;</ref><ref type="bibr" target="#b15">Conway and Christiansen, 2009;</ref><ref type="bibr" target="#b28">Frost et al., 2015)</ref>. In our study, we observed similar and strongly correlated pupil responses in the REG5-RAND5 condition across visual and auditory modalities (see Figures <ref type="figure" target="#fig_16">7a</ref> and <ref type="figure" target="#fig_16">7b</ref>), suggesting that specific processes may unfold similarly regardless of modality.</p><p>Strong cross-modal correlations support (but do not definitively prove) the idea of a domain-general response to prediction errors <ref type="bibr" target="#b33">(Grundei et al., 2023;</ref><ref type="bibr" target="#b64">Planton and Dehaene, 2021;</ref><ref type="bibr" target="#b74">Sabio-Albert et al., 2025)</ref> that informs the arousal system. Perceptual saliency reported by participants and its relationship with pupil dilation responses across modalities suggest a similar conclusion (see Section S9). The pupil size divergences in the REG5a-REG5b condition across modalities (albeit correlated responses) suggest modality differences (see Figures <ref type="figure">6d</ref>, <ref type="figure" target="#fig_16">7c</ref>, and <ref type="figure" target="#fig_16">7f</ref>). These differences are reflected in pupil-linked arousal responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations and further research</head><p>In the visual paradigm of our experiment, regularities were formed by spatio-temporal relationships between the positions of the white dot, rather than identity relationships between tones, which helped control noise sources due to luminance changes and reduced the memory demand of keeping individual items in memory. Similar paradigms have been used</p><p>before <ref type="bibr" target="#b13">(Conway and</ref><ref type="bibr">Christiansen, 2005, 2009;</ref><ref type="bibr" target="#b21">Durrant et al., 2016)</ref>, where it has been found that participants extracted visual patterns better when stimuli were presented spatially compared to, for example, when they were presented as successive coloured patches <ref type="bibr" target="#b15">(Conway and Christiansen, 2009;</ref><ref type="bibr" target="#b29">Furth and Pufall, 1966;</ref><ref type="bibr" target="#b71">Robinson and Sloutsky, 2007)</ref>. Therefore, a key question is how current results vary across different modality presentations (for example, by varying durations of items or their complexities) and, if so, where any differences originate.</p><p>For example, in the current paradigm, small changes in dot location after transitions may not significantly affect pupil size, not because of visual limitations, but due to the way the visual system functions. Vision, for example, is scale-and translation-invariant, which may render specific transitions less salient and allow new regularities to be more easily integrated with prior information. This, in turn, could lead to transitions that are not surprising (i.e., carry less information content). One compelling experimental idea is to identify conditions in which the visual modality surpasses the auditory modality, thereby reversing the current pattern of results.</p><p>There is growing evidence that the visual system exhibits anisotropy, and the pupil is no exception to this phenomenon. For instance, the pupillary light reflex is influenced differently by luminance from the top versus the bottom of a display <ref type="bibr" target="#b11">(Cai et al., 2024)</ref>. It is possible that some of the variability in pupil responses to violations of visual regularity could be attributed to this effect.</p><p>Retinal illumination and covert attention to the illuminated portion of the screen lead to pupil constrictions <ref type="bibr" target="#b8">(Binda et al., 2013;</ref><ref type="bibr" target="#b52">Mathôt et al., 2013;</ref><ref type="bibr" target="#b82">Strauch, 2024)</ref>; therefore, white dots that do not appear in a predicted position might lead to small dilations (if the retina is on that spot). These studies used large and wide stimuli (usually occupying half of the screen), remaining on the screen for extended periods (in the order of seconds). In contrast, in our presentations, the size of white dots was small (maximum of 1°of visual angle), the dots were presented in a confined space (5°wide of visual angle) and presented quickly (20 Hz, in the order of ms). A natural extension of our study would be to use a black dot to diminish this possible effect or investigate how dots with different luminance profiles affect pupil responses <ref type="bibr" target="#b60">(Pan et al., 2022</ref><ref type="bibr" target="#b61">(Pan et al., , 2024))</ref>. Given the strong cross-modal consistency across numerous measurements and gaze-related controls, we believe that possible effects, if they exist, would be minimal and unlikely to have a substantial effect on the present results.</p><p>We observed strong cross-modal correlations, but note that individual variabilities were apparent. Participants exhibit differential sensitivities to sequences of different modalities. Given cross-modal sensitivities of pupils to regularity violations, one possibility is to infer their sensitivities to sequences from their pupil size. A similar work was conducted for RTs in an implicit learning task (see <ref type="bibr">Éltetho et al., 2022)</ref>.</p><p>Previous research has investigated the oddball effect on pupil size, for example, by simultaneously presenting auditory and visual stimuli and directing participants' attention <ref type="bibr">(Liao, Yoneya, et al., 2016)</ref>. Pupillometry has begun to investigate the contribution of modalities to pupil size <ref type="bibr" target="#b48">(Liu et al., 2024;</ref><ref type="bibr" target="#b70">Rigato et al., 2016;</ref><ref type="bibr" target="#b86">Van der Stoep et al., 2021)</ref>; further research can explore how pupil size dynamically evolves within sequences when a new modality is introduced and how multimodal predictions are formed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Previous studies point to the possibility that the processing of regularities is constrained by modality <ref type="bibr" target="#b5">(Barascud et al., 2016;</ref><ref type="bibr" target="#b12">Canale, 2022;</ref><ref type="bibr" target="#b13">Conway, 2020;</ref><ref type="bibr" target="#b28">Frost et al., 2015;</ref><ref type="bibr" target="#b58">Paavilainen, 2013;</ref><ref type="bibr" target="#b76">Sherman et al., 2020)</ref>, yet violations of those regularities may be detected through a domain-general mechanism <ref type="bibr" target="#b33">(Grundei et al., 2023;</ref><ref type="bibr" target="#b64">Planton and Dehaene, 2021;</ref><ref type="bibr" target="#b74">Sabio-Albert et al., 2025)</ref>. We observed that pupil dilation responses, often linked to such violations <ref type="bibr">(Basgol et al., 2025;</ref><ref type="bibr" target="#b57">Nassar et al., 2012;</ref><ref type="bibr" target="#b95">S. Zhao et al., 2019)</ref>, exhibit notable similarities across modalities. While these responses are correlated across domains, transitions with random patterns elicit more consistent effects than those with regular patterns, particularly since the latter evoke the weakest phasic pupil responses. These findings highlight pupil dilation responses as a sensitive, modality-general index of the violation of statistical structure, while also revealing modality-specific constraints in their processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open Practices Statement</head><p>We report on how we determined our sample size, all data exclusions, the inclusion/exclusion criteria, whether these criteria were established before data analysis, all manipulations, and all measures used in the study.</p><p>Experiments 2 and 3 were preregistered at AsPredicted (<ref type="url" target="https://aspredicted.org/db33-5vg8.pdf">https://aspredicted.org/db33-5vg8.pdf</ref>) and (<ref type="url" target="https://aspredicted.org/v3wq-bszn.pdf">https://aspredicted.org/v3wq-bszn.pdf</ref>), respectively. Experiment 1 was not preregistered but the analysis plan closely followed our previous study <ref type="bibr">(Basgol et al., 2025)</ref>. The raw data, processed data, and analysis scripts will be made publicly available on the OSF upon acceptance. Note. Surprise analyses. (a) shows baseline-corrected surprise values estimated by Information Dynamics of Music (IDyOM; Pearce, 2018; Pearce, 2005); whereas (b) shows a similar pattern of results with a hierarchical Chinese restaurant process model (HCRP; Éltetho et al., 2022). The average surprise from the 1-second interval preceding the transition (from -1 to 0 s) was calculated and subtracted from each trial to correct for baseline. Models yield a similar pattern of results across conditions. Shaded areas indicate standard error of the means.</p><p>trials. Bayesian analysis supports this evidence, such that the BF 10 exceeds 3 at around 5.48 s, suggesting moderate evidence in favour of a difference. However, this evidence decreases, with the BF 10 dropping below 3 at 5.68 s (see Figure <ref type="figure" target="#fig_10">2a</ref>).</p><p>In Experiment 2, we observed that pupil responses to regular patterns spontaneously increased, possibly as a proxy for the effort participants exerted on the task (see Figure <ref type="figure" target="#fig_10">2b</ref>).</p><p>This observation suggests that the detection task in Experiment 2 was possibly more effortful than the gap detection task in Experiment 1. This aspect of the results was not investigated, as it was beyond the scope of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Experiment 3:</head><p>In Experiment 3, we presented participants with visual and auditory regularities.</p><p>Pupil responses to consistent auditory patterns were greater than those to visual patterns (see Figure <ref type="figure" target="#fig_3">3</ref>). In light of accounts that sustained pupil size is a proxy of effort (Van der Wel and <ref type="bibr" target="#b106">Van Steenbergen, 2018)</ref>, this result may indicate that processing of frequencies (in the scope of the gap detection task) might require more effort.</p><p>Baseline pupil size was calculated by averaging pupil measurements taken during the Note. Sustained pupil responses in Experiments 1 and 2. (a) Experiment 1. Pupil dilation responses to pattern types. Average normalised pupil size over time in no-transition control conditions. These conditions led to similar changes in pupil size. However, there appears to be a gradual decline in pupil size for REG5. (b) Experiment 2. Shaded areas indicate the between-participant standard error of the means. Note. Sustained pupil responses in Experiment 3. Pupil dilation responses to REG5 across modalities. Average normalised pupil size over time in no-transition control conditions. These conditions led to different pupil size changes, such that the auditory regular patterns elicited a heightened pupil response compared to the visual regular patterns. Coloured horizontal lines indicate regions where cluster-level statistics p &lt; 0.05 for the difference between visual and auditory modalities. Shaded areas indicate the between-participant standard error of the means.</p><p>1-second interval before trial onset. This baseline value was then subtracted from the pupil sizes recorded during the trial to analyse the effect of presentation modality on pupil size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Comparisons of Experiments</head><p>We show all experiments and the same conditions on the same figure (see Figure <ref type="figure" target="#fig_5">4</ref>). Note. Pupil baseline and dilations across experiments. (a) shows pupil responses in REG5-RAND5, (b) in REG5a-REG5b and (c) in REG5, (d) shows pupil baselines that are calculated by averaging 1 sec before the transition. Shaded areas and error bars indicate the between-participant standard error of the means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Comparison with the Previous Study</head><p>In our previous work, we investigated pupil dilation responses to complex auditory sequences (complexity of 10); violations of regularities, both by random patterns (REG10-RAND10) and by novel regularities (REG10a-REG10b), led to pupil dilation responses, as shown in Figure <ref type="figure" target="#fig_6">5a</ref>. The emergence of regularities from a random sequence (RAND10-REG10) did not yield an increase relative to the random baseline (RAND10).</p><p>We obtained a similar pattern of results when using sequences of lower complexity (5), as shown in Figure <ref type="figure" target="#fig_6">5b</ref>. While most conditions mirrored the findings from the more complex sequences, the pupil dilation responses observed for the violation of a regularity by a novel regularity (REG5a-REG5b) were notably smaller in magnitude. These observations on pupil response to regularity changes were replicated even when the nature of the task was modified to a more engaging shape detection task (see Figure <ref type="figure" target="#fig_6">5c</ref>).</p><p>We performed a direct comparison of pupil dilation responses to structured stimuli across auditory (frequencies) and visual (changing dot positions) modalities, as in Figures <ref type="figure" target="#fig_6">5d</ref> and <ref type="figure" target="#fig_6">5e</ref>. When a regular pattern was violated by a random one (REG5-RAND5), the pupil responses were similar across modalities and consistent with our previous findings (compare REG5-RAND5 in 5d and 5e with Figure <ref type="figure" target="#fig_6">5a</ref>). In contrast, when a presented regularity was violated by a novel one (REG5a-REG5b), the pupil responses diverged between the auditory and visual modalities (compare REG5a-REG5b in Figures <ref type="figure" target="#fig_6">5d</ref> and <ref type="figure" target="#fig_6">5e</ref> with Figure <ref type="figure" target="#fig_6">5a</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Pupil Event Rate Analysis</head><p>A typical pupillometry analysis involves averaging event-related pupil responses across trials. Still, this method can misrepresent peak amplitudes and response latencies <ref type="bibr">(Fink et al., 2024)</ref>, as is also the case with signals such as functional magnetic resonance imaging (fMRI)</p><p>and EEG <ref type="bibr">(Guy et al., 2021;</ref><ref type="bibr">Wang et al., 2021)</ref>.</p><p>To address these problems, we extracted pupil events (i.e., dilations and constrictions) from continuous pupil data. These were identified by analysing changes in pupil size slopes.</p><p>This method enabled a more detailed analysis of condition and modality differences.</p><p>In Experiments 1 and 2, we observed differences between the transition conditions and the no-transition control condition. However, these differences did not survive the cluster-based permutation test (except for the strong constriction response in the REG5-RAND5 condition of Experiment 1). On the other hand, increasing statistical power by combining Experiments 1 and 2 (though note that differences exist across experiments that could increase variability) revealed a strong response in the REG5-RAND5 condition (in terms of event rates and magnitudes) and a potential difference in the REG5a-REG5b condition (in terms of event rates), which was later confirmed in Experiment 3 (see the main text for the discussion).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Control Analyses for Correlations</head><p>We conducted correlations across modalities based on scalar measures of pupil size, as presented in the main text. We also conducted a control analysis to estimate whether these correlations are based on a common variable that could be associated with the temporal dynamics of the experiment (remember that trial pairs occur in the same order within the block). We conducted control analyses to address the potential impact of isomorphic pairs on our results. To do this, we re-ran the analyses with "fake" isomorphic pairs, which were</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 5</head><p>The comparison with the previous study. (a) Reproduced from the supplementary material of Basgol, H., <ref type="bibr">Dayan, P., &amp; Franz, V. H. (2025)</ref>. Violation of auditory regularities is reflected in pupil dynamics. Cortex, 183, 66-86. CC BY 4.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6</head><p>Pupil event rate analyses for Experiments 1 and 2.</p><p>Note. Pupil event rate analyses for Experiments 1 and 2. Pupil dilation and constriction rates were computed using a running average with a 500-ms window. Overall, dilation rates for REG5-RAND5 and REG5a-REG5b have increased slightly due to transitions across experiments (this increase became significant after combining Experiments 1 and 2, as described in the main text). On the other hand, the transition from RAND5 to REG5 did not result in a considerable change. Coloured horizontal lines indicate regions where cluster-level statistics p &lt; 0.05 between each transition condition (shown as dark green) and the no-transition control (light green). Shaded areas represent between-participant standard error of the means.</p><p>determined as the closest trials in time to the original pair, within the same condition and block.</p><p>Out of 32 tests estimating correlations, only one test yielded a BF 10 greater than 3, which is the correlation of modalities for REG5 (Mr = 0.09, 10 = 12.59, p corr = 0.063, see Tables <ref type="table" target="#tab_4">1</ref> and <ref type="table" target="#tab_2">2</ref>). No other comparison yielded a BF 10 &gt; 3 (with all other corrected p-values &gt; .476).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Correlations of Modalities based on Pupil Events</head><p>We calculated scalar measures of pupil size for isomorphic trial pairs. Similar to this analysis, we calculated the number of dilation events and the sum of event size, and computed correlations between these values across isomorphic trial pairs. Interestingly, the number of dilation events was not correlated; however, the total size of events was correlated in both Note. Individual correlations based on isomorphic pairs of visual and auditory sequences were calculated for each participant (but now after selecting fake pairs for control analyses). The correlations were then compared to 0 using a one-tailed t-test. Mr corresponds to the mean of individual correlations; 95% CI denotes the one=sided confidence interval. The statistical metrics BF10, pcorr, and dz refer, respectively, to the Bayes factor, the corrected p-values of these correlations, and effect sizes.</p><p>transition and baseline conditions across modalities (see Tables <ref type="table" target="#tab_3">3</ref> and <ref type="table" target="#tab_5">4</ref>). Although modalities resulted in similar patterns of results (see the main manuscript), they were not correlated across modalities due to the limited range (the maximum number of events in a trial was only 4, and the minimum was 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Temporal Analyses</head><p>We investigated whether the timing within the experiment influences pupil responses to regularity violations and whether these effects are consistent across modalities. To this end, we divided the experiment into three segments: early (blocks 1-2), mid <ref type="bibr" target="#b67">(3)</ref><ref type="bibr">(4)</ref>, and late (5-6), and averaged the time-series pupil size along with associated scalar measures (i.e., peak and mean pupil sizes).   We also investigated the general progression of pupil responses throughout all experiments (see 8).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Saliency Analyses</head><p>Following <ref type="bibr">Conway and Christiansen (2005)</ref>, we asked participants to judge similarities between items (i.e., tones and dots appearing on a grid) on a continuous scale from 0 to 100 Note. Pupil responses in Experiment 3 across groups of blocks. Panels a-c and f-h show normalised pupil size in the REG5-RAND5 (blue, top row) and REG5a-REG5b (yellow, bottom row) conditions, split by block groups: (1, 2) early, (3, 4) mid, and (5, 6) late. In the REG5-RAND5 condition, pupil dilation remained, though with a gradual reduction in amplitude (a, c). In contrast, REG5a-REG5b transitions evoked smaller pupil dilations overall, especially in the visual modality, and declined more steeply across blocks (f, h). (d-e) and (i, j) summarise peak and mean pupil sizes across block groups for each condition and modality. In REG5-RAND5, pupil size decreased over time for both modalities without a strong divergence (d, e). In REG5a-REG5b, auditory responses remained stable, whereas visual responses declined more over time (i, j), indicating a modality-specific adaptation to transient statistical violations. Asterisks denote p &lt; 0.05 between modalities. Note that p-values are not corrected. Error bars and shaded areas indicate between-participant standard error of the means. Note. Pupil responses across groups of blocks for all experiments. Pupil responses during different experiments and on time. The first column shows pupil responses in the early phase of the experiment (1, 2 blocks); the second column shows the mid phase of the experiment (3, 4 blocks), and the last column shows the late phase of the experiment (5, 6 blocks). There is a gradual reduction in pupil size in transition conditions. Error bars and shaded areas indicate between-participant standard error of the means. Error bars and shaded areas indicate between-participant standard error of the means.</p><p>(i.e., 81 randomly selected, pairwise comparisons of 9 items within a given modality). Each item was displayed for 0.5 s, with an inter-presentation interval of 1 s. In a subsequent experiment, participants were presented with short versions of transitions (1 s before and 1 s after the transition, totalling 2 s). They rated the saliency of these transitions using a continuous scale from 0 to 100 (i.e., 48 judgements for visual items and 48 for auditory items, totalling 96).</p><p>Participants then participated in the item similarity judgment experiment, where they were asked to assess the similarity between pairs of items. Before the experiment, they were shown the most distant (i.e., dissimilar) items from the dataset (auditory: 222 Hz and 1536</p><p>Hz tones; visual: dots in the bottom-left and upper-right corners of the reference grid), and they were asked to scale their similarity judgements accordingly.</p><p>All permutations were presented to participants in a random order. We conducted this experiment to design possible exploratory analyses that could estimate representations of items that participants form; however, given confirmed predictions and the strong correlations across modalities, we did not analyse the results of this measurement.</p><p>Participants then rated transitions based on their saliency. They were presented with three example trials (one from each condition; REG5, REG5a-REG5b, and REG5-RAND5) and instructed to evaluate the degree of subjective detectability (i.e., saliency) of transitions.</p><p>Participants were encouraged to respond consistently, reflecting a consistent and ordered relationship. This procedure provided a shared basis for comparing pupil responses observed across modalities <ref type="bibr">(Liao et al., 2016)</ref>. We first rescaled participants' saliency judgements (in isolation for each modality) to a 0-100 range to minimise the influence of individual scaling biases on overall trends (note that this rescaling was not specified in the preregistration). We then examined correlations of these judgements between modalities at individual and group levels.</p><p>We investigated the relationship between participants' pupil responses following the transition and their saliency judgements by running a linear mixed effects model for each modality and time point (using the statsmodels package in Python; <ref type="bibr" target="#b105">Seabold and Perktold, 2010)</ref> to predict pupil size (without baseline correction). We based our analysis on all trials without splitting the data into transitions, as participants judged transitions in the same session and were instructed to rate salience in an ordered relationship, independent of conditions. For the sake of completeness, we re-ran the analysis for all conditions and modalities.</p><p>We used a linear mixed model to consider the effect of participant-level variables associated with the overall experiment, such as reaction times (RTs), sensitivity (d') and mental effort. We included the following predictors in the models: baseline pupil responses for each trial (averaged over one second before the transition), d', RTs and mental effort reported by participants for gap detection tasks. All variables in the model were normalised to ensure the comparability of coefficients.</p><p>We examined participants' saliency judgements for visual and auditory transitions to find out a common perceptual metric for transitions <ref type="bibr">(Joshi et al., 2016)</ref>. These judgements were correlated (see Figure <ref type="figure" target="#fig_18">9b</ref>; REG5-RAND5: z = 0.13, BF 10 = 5.75, p = .009, 95% CI = [0.04, 0.22], d z = 0.65; REG5a-REG5b: z = 0.08, BF 10 = 2.45, p = .025, 95% CI = [0.01, 0.16], d z = 0.55). However, the average correlations among participants were only around 0.1, which may be attributed to the experimental structure. In the experiment, participants judged and compared all transitions together, independent of conditions. Indeed, the correlation between saliency judgements for sequences increased when transition trials were considered together (z = 0.30, BF 10 &gt; 1000, p &lt; .001, 95% CI = [0.23, 0.37], d z = 1.96).</p><p>We calculated the average saliency per transition and calculated correlations of these averages. These values were highly correlated for the REG5-RAND5 condition (see Figure <ref type="figure" target="#fig_18">9b</ref>, REG5-RAND5: r = .65, BF 10 = 61.93, p &lt; .001, 95% CI = [0.33, 0.83]). However, for REG5a-REG5b, the test was inconclusive (REG5a-REG5b: r = .32, BF 10 = 0.74, p = .132, 95% CI = [-0.10, 0.64]). Correlations increased when all trials were considered (All: r = .75, BF 10 &gt; 1000, p &lt; .001, 95% CI = [0.59, 0.85]).</p><p>Some transitions were rated as more salient than the others (see Figure <ref type="figure" target="#fig_18">9b</ref> and compare conditions REG5-RAND5 and REG5a-REG5b). These judgements coarsely reflected pupil dilation responses (see time-series pupil trace examples for transitions that lead to the lowest and highest total saliency in Figure <ref type="figure" target="#fig_18">9b</ref>).</p><p>Beyond visual descriptions, we examined how saliency judgements relate to pupil responses after transitions. We used linear regression to account for several other variables that could influence pupil size, such as baseline pupil size, transition time, trial order, sensitivity (d ′ ), reaction times, and mental effort. This was necessary to ensure that these Note. The relationship between participants' saliency judgements in Experiment 3. (a) Correlations for participants across modalities, (b) the group. Pupil trace examples for transitions at the lowest and highest total saliency across modalities. Shaded areas and error bars indicate standard error of the means.</p><p>factors did not confound our results. This analysis also helped to reveal the relationships between the experimental variables.</p><p>Our analysis was based on all trials without separating transitions, as participants rated salience in an ordered relationship within the same session, independent of conditions (For completeness, we also reran the analysis for conditions separately in Figure <ref type="figure" target="#fig_9">11</ref>).</p><p>Pupil responses were positively associated with participants' post-experiment saliency judgements across time, in a way that was similar across visual and auditory conditions (see Figure <ref type="figure" target="#fig_19">10a</ref>). Baseline pupil size had a strong early effect just after the transition, which decreased gradually over time (see Figure <ref type="figure" target="#fig_19">10b</ref>). Based on this finding, we divided the data into blocks. We found that pupil size decreased more in the visual than in the auditory REG5a-REG5b condition.</p><p>Among task-related variables, transition time tended to decrease pupil size, especially in the visual modality (Figure <ref type="figure" target="#fig_19">10c</ref>).</p><p>Pupil responses also decreased slightly throughout the experiment as trials progressed, suggesting a possible effect of habituation (Figure <ref type="figure" target="#fig_19">10d</ref>). Upon this observation, we divided the data into three natural groups: early (blocks 1-2), mid (blocks 3-4), and late (blocks 5-6), and averaged the time-series pupil size along with associated scalar measures (i.e., peak and mean pupil sizes). Pupil responses in REG5a-REG5b across visual and auditory modalities diverged after the middle of the experiment, with the visual modality leading to progressively smaller pupil responses than the auditory modality.</p><p>d' was not related to pupil responses in either modality (Figure <ref type="figure" target="#fig_19">10e</ref>). RTs showed weak associations with pupil size, slightly stronger in the visual condition, although these effects were small and short-lived (Figure <ref type="figure" target="#fig_19">10f</ref>). Perceived mental effort did not show a consistent relationship with pupil responses; coefficients stayed close to zero throughout the time window (Figure <ref type="figure" target="#fig_19">10g</ref>).</p><p>Finally, the intercept term increased after the transition in both modalities, indicating that some variability in pupil responses remained unexplained by the included predictors (Figure <ref type="figure" target="#fig_19">10h</ref>).</p><p>Since participants evaluated all transitions together in the same session, this may have influenced their ratings. Our correlation analysis in the main text also supported this notion.</p><p>That is why we examined the relationship between these judgments and pupil size. Here, for the sake of completeness, we conducted the same analyses again, but this time splitting them into conditions.</p><p>Pupil responses were positively associated with participants' explicit reports of saliency, with coefficients rising after the transition (Figure <ref type="figure" target="#fig_9">11a</ref>). However, the coefficients were not statistically significant. Coefficients estimated for the REG5-RAND5 condition seem to reach significance.</p><p>Baseline pupil size was a strong predictor, showing a large positive coefficient at the moment of transition that decayed rapidly over the following 4 seconds (Figure <ref type="figure" target="#fig_9">11b</ref>).</p><p>Transition time showed a small, transient negative association with pupil size after the transition, an effect that was slightly more pronounced in the visual modality of the REG5a-REG5b condition (Figure <ref type="figure" target="#fig_9">11c</ref>). Among the other predictors, trial order had a negative influence on pupil size, particularly in the REG5a-REG5b condition, suggesting an effect of habituation over the course of the experiment (Figure <ref type="figure" target="#fig_9">11d</ref>).</p><p>Performance-related metrics were not strongly associated with pupil responses. d'</p><p>showed only a minor relationship with pupil size, with coefficients remaining at zero after the transition (Figure <ref type="figure" target="#fig_9">11e</ref>). Similarly, RTs and (Figure <ref type="figure" target="#fig_9">11f</ref>) perceived effort for the gap detection task did not explain considerable variance (Figure <ref type="figure" target="#fig_9">11g</ref>). Note. Time-dependent coefficients of the linear model developed for Experiment 3. (a) Relationship between participants' post-experiment saliency judgements and their pupil responses over time, showing similar patterns across visual and auditory modalities. (b) Contribution of baseline pupil size (averaged over the 1 s before transition) to the observed pupil response. (c) Influence of transition time on pupil size, indicating a negative relationship between the time that transition occurs in a trial and pupil size. The effect is particularly evident for the visual modality. (d) Effect of trial order, showing a gradual decline in pupil response with repeated trials. (e) Relationship between sensitivity (d ′ ) and pupil response over time, with no consistent difference across modalities. (f) Effect of reaction times on pupil responses, suggesting slightly stronger associations in the visual condition. However, note that the effect is small. (g) Influence of perceived effort for detecting gaps, showing no strong contribution. (h) Intercept term reflecting general trends in pupil responses after transition, independent of predictors. Shaded regions indicate the 95% confidence intervals received from the model. The grey solid and dashed lines indicate time points where p &lt; .05 for the visual and auditory modalities, respectively. No reliable difference was observed across modalities in terms of experimental variables affecting pupil size.</p><p>We observed that, in line with previous distance measures <ref type="bibr">(Basgol et al., 2025)</ref>, saliency was positively associated with pupil dilation, confirming earlier findings (see Figure <ref type="figure" target="#fig_19">10</ref>). Moreover, the relationship of saliency with pupil size was similar across modalities (see Figure <ref type="figure" target="#fig_19">10</ref>).</p><p>Finally, the intercept term showed a robust increase following the transition in all conditions, peaking around 2 seconds before slowly decaying (Figure <ref type="figure" target="#fig_9">11h</ref>). This indicates a significant portion of the pupillary response to the transition itself remained after accounting for all other predictors in the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 11</head><p>Pupil dilation responses and experimental variables. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><figDesc>Participants were mostly university students and were compensated with either course credit or 10 EUR per hour. The ethics committee of Eberhard Karls University of Tübingen approved all experiments in this study (Date of approval: June 17, 2020). The experiment took approximately 1.5 hours.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1</head><label>1</label><figDesc>Figure 1Conditions and experiments.</figDesc><graphic coords="7,72.00,180.25,451.23,227.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2</head><label>2</label><figDesc>Figure 2Gap detection performance and pupil responses in Experiment 1</figDesc><graphic coords="13,72.00,190.03,451.29,364.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3</head><label>3</label><figDesc>Figure 3Shape detection performance and pupil dilation responses.</figDesc><graphic coords="18,72.00,110.39,451.25,184.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><figDesc>Auditory modality received less hit (REG5: Auditory = 0.967, Visual = 1.00, BF 10 = 3.25, p = .017, 95% CI = [-0.000590, -0.0000645], d z = -0.598; for the average of all conditions: Auditory = 0.927, Visual = 0.988, BF 10 = 9.19, p = .005, 95% CI = [-0.001, -0.000208], d z = -0.728) and more false alarm rates (REG5: Auditory = 0.016, Visual = 0.0014, BF 10 = 3.29, p = .017, 95% CI = [0.0000293, 0.000264], d z = 0.6; for the average of all conditions: Auditory = 0.015, Visual = 0.010, BF 10 = 0.265, p = .592, 95% CI = [-0.000116, 0.000197], d z = 0.125) than visual modality. Note that statistical tests were applied after arcsine transformation We analysed additional performance variables. Participants' reaction times (RTs) did not differ (Auditory = 958 ms, Visual = 884 ms, BF 10 = 0.39, p = .290, 95% CI = [-69.58, 218.12], d z = 0.32) and they did not find the auditory task harder than the visual task (BF 10 = 0.371, p = .316, 95% CI = [-0.31, 0.91], d z = 0.213). Their perception of effort was correlated across the two tasks (r = .590, BF 10 = 9.119, p = .006, 95% CI = [0.2, 0.82]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4</head><label>4</label><figDesc>Figure 4Gap detection performances for REG5.</figDesc><graphic coords="24,184.82,293.00,225.64,165.57" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5</head><label>5</label><figDesc>Figure 5Time-series pupil size across modalities.</figDesc><graphic coords="25,72.00,195.98,451.28,352.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><figDesc>Note. Baseline-corrected rates and sizes of dilation events. Notethat (a, b, c, d) show dilation events; (a, b) for REG5-RAND5 and (c, d) for REG5a-REG5b conditions. (e, f, g, h) show constriction events; (e, f) for REG5-RAND5 and (g, h) for REG5a-REG5b conditions. The upper figures show the size of events, whereas the lower figures show event rates, regardless of the magnitude of the event. (a, b) Pupil dilation event rates and magnitudes are in a similar direction in REG5-RAND5 across experiments, and the results are statistically strong.(c, d) Pupil dilation event rates and magnitudes are also similar in REG5a-REG5b;. However, the results are not strong for the first two experiments compared to Experiment 3. (e, f) Pupil constriction event rates are strong only for Experiment 3, mirroring the dilation rates. Modalities appeared to behave differently across conditions in their effects on pupil size and rates. In Experiment 3, (b) dilation rates and magnitudes are similar for the REG5-RAND5 condition; whereas, (d) they diverge for the REG5a-REG5b condition, where auditory modality did lead to a pupil size increase; whereas visual modality did not. Experiments 1 and 2 agree that visual modality does not lead to a dilation event size increase for REG5a-REG5b but for REG5-RAND5 (a, c). Coloured horizontal lines indicate regions where cluster-level statistics p &lt; .05 for transition and baseline conditions. The grey line indicates the difference between transition conditions across modalities (detected only for the event magnitudes of the REG5a-REG5b condition, as shown in (d)). There was no reliable difference between auditory and visual baseline conditions (REG5). Dots in pupil rate figures correspond to dilation and constriction events in transition conditions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7</head><label>7</label><figDesc>Figure 7Scalar pupil measures across modalities.</figDesc><graphic coords="30,72.00,203.75,451.26,403.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Surprise Analyses.</figDesc><graphic coords="52,72.00,110.38,451.27,231.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 2</head><label>2</label><figDesc>Figure 2Pupil responses to pattern types.</figDesc><graphic coords="53,72.00,117.20,451.27,232.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 3</head><label>3</label><figDesc>Figure 3Pupil responses to REG5 across modalities.</figDesc><graphic coords="53,72.00,468.77,225.58,215.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 4</head><label>4</label><figDesc>Figure 4Pupil baseline and dilations across experiments.</figDesc><graphic coords="54,72.00,208.72,451.26,214.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Note.</head><figDesc>The comparison of the current results of pupil dilation responses with the previous study. (a) In our previous study,Basgol et al., 2025, we investigated pupil dilation responses to regularity violations, but in more complex sequences with a complexity of 10, and items were presented as Violations of regularities with random patterns (REG10-RAND10) and novel regularities (REG10a-REG10b) led to an increase. The emergence of regularities from random patterns (RAND10-REG10) did not result in a significant increase compared to the baseline (RAND10). (b) Similar results were obtained with less complex sequences with a complexity of 5. However, smaller pupil dilation responses were observed for the violation of regularities by novel regularities (REG5a-REG5b). (c) Similar observations were obtained when the task was changed to a more engaging shape detection task. (d, e) We directly compared pupil dilation responses when structured stimuli were presented in auditory, as frequencies, and vision, as changing dot positions. Similar pupil responses were obtained when random patterns violated presented regularities (compare REG5-RAND5 in d, e with a). In contrast, pupil responses diverged when novel regularities violated presented regularities (compare REG5a-REG5b in d, e with a). Baseline pupil responses (i.e., REG5) tend to fluctuate. Shaded areas indicate the between-participant standard error of the means. Coloured horizontal lines indicate regions where cluster-level statistics p &lt; .05.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Figure 7</head><label>7</label><figDesc>Figure 7 illustrates the temporal dynamics of pupil responses to two types of statistical transitions, REG5-RAND5 and REG5a-REG5b, across experimental blocks. Figures 7 a to c and Figures 7 f to h display time-locked, normalised pupil size traces for early (blocks 1-2), mid (3-4), and late (4-6) segments, separately for each condition. Solid and dashed lines</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><figDesc>denote the visual and auditory modalities, respectively. In the REG5-RAND5 condition (Figure7ato c), pupil dilation responses were large and sustained across the session, although a gradual reduction in amplitude was observed over time. By contrast, REG5a-REG5b transitions (Figures7f to h) elicited smaller responses overall, with a more pronounced decline across blocks, particularly in the visual modality. Summary metrics of these responses are shown in Figures7d and e (REG5-RAND5) and Figures7i and j(REG5a-REG5b), plotting peak and mean pupil size as a function of block group. For REG5-RAND5, both modalities exhibited a similar decline in pupil response over time (Figures7d and e), consistent with habituation to continuous violations during the experiment. In contrast, for REG5a-REG5b (Figures7i and j), the auditory modality remained stable across blocks, while the visual modality showed a significant reduction in both peak and mean pupil size. This divergence, indicated by asterisks, reflects a modality-specific sensitivity to transient statistical changes. Note that p-values are not corrected for multiple comparisons. The correction operation (with 12 tests) yielded no test results suggesting a significant difference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 7</head><label>7</label><figDesc>Figure 7Temporal Analyses of Pupil Responses forExperiment 3.    </figDesc><graphic coords="61,72.00,110.39,383.58,559.91" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 8</head><label>8</label><figDesc>Figure 8Temporal Analyses of Pupil Responses.</figDesc><graphic coords="62,72.00,174.00,451.27,451.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 9</head><label>9</label><figDesc>Figure 9Saliency of transitions.</figDesc><graphic coords="65,72.00,110.39,451.22,221.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 10</head><label>10</label><figDesc>Figure 10Pupil dilation responses and experimental variables.</figDesc><graphic coords="67,72.00,193.85,451.26,293.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><figDesc>Note. Time-dependent coefficients of the linear model developed for Experiment 3. This time, we split conditions. (a) Relationship between participants' post-experiment saliency judgements and their pupil responses over time. (b) Contribution of baseline pupil size (averaged over the 1 s before transition) to the observed pupil response. (c) Influence of transition time on pupil size. (d) Effect of trial order, showing a gradual decline in pupil response with repeated trials. (e) Relationship between sensitivity (d ′ ) and pupil response over time. (f) Effect of reaction times on pupil responses. (g) Influence of perceived effort for detecting gaps. (h) Intercept term reflecting general trends in pupil responses after transition, independent of predictors. Shaded regions indicate the 95% confidence intervals received from the model. The grey solid and dashed lines indicate time points where p &lt; .05 for the visual and auditory modalities, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="57,72.00,110.39,451.27,303.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Correlations of Participants</figDesc><table><row><cell></cell><cell>Statistics</cell><cell>t</cell><cell>M r</cell><cell>%95 CI</cell><cell>BF 10</cell><cell>p corr</cell><cell>d</cell></row><row><cell>dv</cell><cell>Conditions</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">Peak pupil size REG5-RAND5 5.06 0.28 [0.19, 1] 768.94 &lt; .001 1.13</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="3">2.69 0.12 [0.04, 1]</cell><cell>7.58</cell><cell>0.065</cell><cell>0.6</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="6">5.73 0.22 [0.16, 1] &gt; 1000 &lt; .001 1.28</cell></row><row><cell></cell><cell>REG5</cell><cell cols="6">5.48 0.25 [0.17, 1] &gt; 1000 &lt; .001 1.22</cell></row><row><cell>Peak time</cell><cell>REG5-RAND5</cell><cell cols="4">-0.13 -0.01 [-0.09, 1] 0.47</cell><cell>0.812</cell><cell>0.03</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="4">0.58 0.03 [-0.06, 1] 0.54</cell><cell>0.812</cell><cell>0.13</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="4">0.62 0.02 [-0.04, 1] 0.55</cell><cell>0.812</cell><cell>0.14</cell></row><row><cell></cell><cell>REG5</cell><cell cols="3">2.55 0.06 [0.02, 1]</cell><cell>5.87</cell><cell>0.069</cell><cell>0.57</cell></row><row><cell>Mean size</cell><cell cols="6">REG5-RAND5 4.34 0.22 [0.13, 1] 183.61 0.002</cell><cell>0.97</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="4">1.48 0.06 [-0.01, 1] 1.19</cell><cell>0.345</cell><cell>0.33</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="5">4.67 0.15 [0.10, 1] 356.18 0.001</cell><cell>1.05</cell></row><row><cell></cell><cell>REG5</cell><cell>4.5</cell><cell cols="4">0.18 [0.11, 1] 248.79 0.001</cell><cell>1.01</cell></row><row><cell>Minimum size</cell><cell>REG5-RAND5</cell><cell>2.4</cell><cell cols="2">0.12 [0.03, 1]</cell><cell>4.54</cell><cell>0.081</cell><cell>0.54</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="4">1.55 0.09 [-0.01, 1] 1.29</cell><cell>0.345</cell><cell>0.35</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="2">2.67 0.1</cell><cell>[0.03, 1]</cell><cell>7.25</cell><cell>0.065</cell><cell>0.6</cell></row><row><cell></cell><cell>REG5</cell><cell cols="4">3.26 0.13 [0.06, 1] 21.8</cell><cell>0.02</cell><cell>0.73</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Correlations across Isomorphic Transitions</figDesc><table><row><cell></cell><cell>Statistics</cell><cell>r</cell><cell>%95 CI</cell><cell>BF 10</cell><cell>p corr</cell></row><row><cell>dv</cell><cell>Conditions</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Peak pupil size REG5-RAND5 0.86 [0.71, 0.94] &gt; 1000 &lt; .001</cell></row><row><cell></cell><cell cols="4">REG5a-REG5b 0.64 [0.32, 0.83] 56.96</cell><cell>0.006</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="4">0.77 [0.62, 0.86] &gt; 1000 &lt; .001</cell></row><row><cell></cell><cell>REG5</cell><cell cols="4">0.71 [0.53, 0.83] &gt; 1000 &lt; .001</cell></row><row><cell>Peak time</cell><cell>REG5-RAND5</cell><cell cols="3">0.31 [-0.11, 0.63] 0.71</cell><cell>0.367</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="2">0.47 [0.09, 0.74]</cell><cell>3.33</cell><cell>0.097</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="3">0.39 [0.12, 0.61] 7.08</cell><cell>0.036</cell></row><row><cell></cell><cell>REG5</cell><cell cols="4">0.54 [0.31, 0.72] 393.55 0.001</cell></row><row><cell>Mean size</cell><cell cols="2">REG5-RAND5 0.8</cell><cell cols="3">[0.58, 0.91] &gt; 1000 &lt; .001</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="3">0.35 [-0.06, 0.66] 0.96</cell><cell>0.367</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="4">0.64 [0.44, 0.79] &gt; 1000 &lt; .001</cell></row><row><cell></cell><cell>REG5</cell><cell cols="2">0.53 [0.3, 0.71]</cell><cell>304.7</cell><cell>0.001</cell></row><row><cell>Minimum size</cell><cell cols="4">REG5-RAND5 0.64 [0.32, 0.83] 53.21</cell><cell>0.006</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell>0.2</cell><cell cols="2">[-0.22, 0.56] 0.39</cell><cell>0.367</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="3">0.46 [0.21, 0.66] 38.16</cell><cell>0.006</cell></row><row><cell></cell><cell>REG5</cell><cell cols="2">0.25 [-0.04, 0.5]</cell><cell>0.72</cell><cell>0.367</cell></row></table><note><p>Note. Correlations were calculated based on the mean of visual and auditory transitions, reflecting group-level responses. r denotes the correlation coefficient; 95% CI denotes the confidence interval. The statistical metrics BF10 and pcorr refer, respectively, to the Bayes factor and the corrected p-values of these correlations.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>Pupil Differences across ModalitiesDifferences of scalar pupil values extracted from pupil traces. t denotes the value of t-test, M A and M V correspond to the mean of scalar pupil values; SEM A and SEM V are corresponding standard error of the means. 95% CI denotes confidence intervals. Statistical metrics, BF10 and pcorr, refer, respectively, to the Bayes factor and the corrected p-values of these correlations. dz corresponds to effect sizes.</figDesc><table><row><cell></cell><cell>Statistics</cell><cell>t</cell><cell>M A</cell><cell cols="2">SEM A M V</cell><cell cols="2">SEM V 95% CI</cell><cell>BF 10</cell><cell>p corr</cell><cell>d z</cell></row><row><cell>dv</cell><cell>Conditions</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Peak pupil size REG5-RAND5</cell><cell cols="2">0.22 0.88</cell><cell>0.05</cell><cell>0.87</cell><cell>0.07</cell><cell cols="2">[-0.09, 0.11] 0.24</cell><cell>1.0</cell><cell>0.04</cell></row><row><cell></cell><cell cols="3">REG5a-REG5b 3.71 0.75</cell><cell>0.04</cell><cell>0.57</cell><cell>0.04</cell><cell cols="3">[0.08, 0.28] 25.76 0.018 0.98</cell></row><row><cell></cell><cell>REG5</cell><cell>3.1</cell><cell>0.75</cell><cell>0.04</cell><cell>0.63</cell><cell>0.04</cell><cell>[0.04, 0.2]</cell><cell>8.05</cell><cell>0.064 0.71</cell></row><row><cell>Peak time</cell><cell>REG5-RAND5</cell><cell cols="3">-1.18 2080.0 78.0</cell><cell cols="2">2191.0 76.0</cell><cell cols="2">[-0.15, 0.04] 0.43</cell><cell>1.0</cell><cell>0.32</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="3">2.98 2025.0 69.0</cell><cell cols="2">1770.0 81.0</cell><cell>[0.04, 0.25]</cell><cell>6.38</cell><cell>0.077 0.82</cell></row><row><cell></cell><cell>REG5</cell><cell cols="3">0.66 2006.0 83.0</cell><cell cols="2">1946.0 59.0</cell><cell cols="2">[-0.05, 0.09] 0.28</cell><cell>1.0</cell><cell>0.13</cell></row><row><cell>Mean size</cell><cell>REG5-RAND5</cell><cell cols="2">-0.73 0.21</cell><cell>0.04</cell><cell>0.24</cell><cell>0.05</cell><cell cols="2">[-0.09, 0.04] 0.3</cell><cell>1.0</cell><cell>0.12</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="2">2.07 0.08</cell><cell>0.04</cell><cell>-0.03</cell><cell>0.04</cell><cell>[-0.0, 0.23]</cell><cell>1.35</cell><cell>0.415 0.62</cell></row><row><cell></cell><cell>REG5</cell><cell cols="2">1.43 0.07</cell><cell>0.04</cell><cell>0.01</cell><cell>0.04</cell><cell cols="2">[-0.02, 0.13] 0.56</cell><cell>1.0</cell><cell>0.3</cell></row><row><cell>Minimum size</cell><cell>REG5-RAND5</cell><cell cols="2">-2.46 -0.58</cell><cell>0.04</cell><cell>-0.47</cell><cell>0.04</cell><cell cols="2">[-0.21, -0.02] 2.51</cell><cell>0.214 0.6</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="2">0.01 -0.67</cell><cell>0.05</cell><cell>-0.67</cell><cell>0.05</cell><cell cols="2">[-0.13, 0.13] 0.23</cell><cell>1.0</cell><cell>0.0</cell></row><row><cell></cell><cell>REG5</cell><cell cols="2">-1.53 -0.67</cell><cell>0.05</cell><cell>-0.6</cell><cell>0.04</cell><cell cols="2">[-0.17, 0.03] 0.63</cell><cell>0.998 0.32</cell></row><row><cell>Note.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1</head><label>1</label><figDesc>Control Analysis: Correlations of Participants</figDesc><table><row><cell></cell><cell>Statistics</cell><cell>t</cell><cell>M r</cell><cell>%95 CI</cell><cell>BF 10</cell><cell>p corr</cell><cell>d</cell></row><row><cell>dv</cell><cell>Conditions</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Peak size</cell><cell cols="3">REG5-RAND5 0.03 0.0</cell><cell cols="2">[-0.07, 1] 0.46</cell><cell>1.0</cell><cell>0.01</cell></row><row><cell></cell><cell cols="3">REG5a-REG5b -0.04 -0.0</cell><cell>[-0.1, 1]</cell><cell>0.46</cell><cell>1.0</cell><cell>0.01</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="4">0.67 0.02 [-0.03, 1] 0.57</cell><cell>1.0</cell><cell>0.15</cell></row><row><cell></cell><cell>REG5</cell><cell cols="6">2.97 0.09 [0.04, 1] 12.59 0.063 0.66</cell></row><row><cell>Peak time</cell><cell cols="5">REG5-RAND5 -0.21 -0.01 [-0.11, 1] 0.47</cell><cell>1.0</cell><cell>0.05</cell></row><row><cell></cell><cell cols="5">REG5a-REG5b 0.25 0.01 [-0.07, 1] 0.48</cell><cell>1.0</cell><cell>0.06</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="4">0.28 0.01 [-0.05, 1] 0.48</cell><cell>1.0</cell><cell>0.06</cell></row><row><cell></cell><cell>REG5</cell><cell cols="4">0.49 0.02 [-0.05, 1] 0.52</cell><cell>1.0</cell><cell>0.11</cell></row><row><cell>Mean size</cell><cell cols="5">REG5-RAND5 1.05 0.04 [-0.03, 1] 0.76</cell><cell>1.0</cell><cell>0.24</cell></row><row><cell></cell><cell cols="4">REG5a-REG5b -0.23 -0.01 [-0.1, 1]</cell><cell>0.48</cell><cell>1.0</cell><cell>0.05</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="4">1.01 0.04 [-0.02, 1] 0.73</cell><cell>1.0</cell><cell>0.23</cell></row><row><cell></cell><cell>REG5</cell><cell cols="3">1.96 0.07 [0.01, 1]</cell><cell>2.26</cell><cell>0.49</cell><cell>0.44</cell></row><row><cell cols="6">Minimum size REG5-RAND5 0.51 0.03 [-0.06, 1] 0.52</cell><cell>1.0</cell><cell>0.12</cell></row><row><cell></cell><cell cols="5">REG5a-REG5b 0.42 0.02 [-0.06, 1] 0.5</cell><cell>1.0</cell><cell>0.09</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="4">0.67 0.02 [-0.04, 1] 0.57</cell><cell>1.0</cell><cell>0.15</cell></row><row><cell></cell><cell>REG5</cell><cell cols="4">1.39 0.06 [-0.01, 1] 1.08</cell><cell>1.0</cell><cell>0.31</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc>Correlations across Isomorphic Transitions for Dilation EventsNote. Correlations were calculated based on the mean of visual and auditory transitions, reflecting group-level responses. r denotes the correlation coefficient; 95% CI denotes the confidence interval. The statistical metrics BF10 and pcorr refer, respectively, to the Bayes factor and the corrected p-values of these correlations.</figDesc><table><row><cell></cell><cell>Statistics</cell><cell>r</cell><cell>%95 CI</cell><cell>BF 10</cell><cell>p corr</cell></row><row><cell>dv</cell><cell>Conditions</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Number of dilation events REG5-RAND5</cell><cell cols="3">0.16 [-0.26, 0.53] 0.33</cell><cell>1.0</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="3">-0.14 [-0.51, 0.28] 0.31</cell><cell>1.0</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="3">0.05 [-0.24, 0.33] 0.19</cell><cell>1.0</cell></row><row><cell></cell><cell>REG5</cell><cell cols="3">-0.24 [-0.49, 0.05] 0.65</cell><cell>0.515</cell></row><row><cell>Sum of event size</cell><cell cols="4">REG5-RAND5 0.51 [0.14, 0.76] 5.65</cell><cell>0.062</cell></row><row><cell></cell><cell>REG5a-REG5b</cell><cell cols="2">0.22 [-0.2, 0.57]</cell><cell>0.42</cell><cell>1.0</cell></row><row><cell></cell><cell>Transitions</cell><cell cols="2">0.52 [0.28, 0.7]</cell><cell cols="2">203.08 0.001</cell></row><row><cell></cell><cell>REG5</cell><cell cols="4">0.66 [0.46, 0.79] &gt; 1000 &lt; .001</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>The study was supported by the <rs type="funder">German Research Foundation (DFG)</rs>: <rs type="programName">SFB 1233</rs>, <rs type="funder">Max Planck Society and Humboldt Foundation (Peter Dayan)</rs>, and <rs type="funder">Machine Learning Cluster of Excellence</rs>, <rs type="grantNumber">EXC 2064/1 No 39072764</rs> (<rs type="person">Volker H. Franz</rs>).</p><p>FR conducted the first and the second experiments; the first experiment was conducted within the scope of his bachelor's thesis. HB conducted the third experiment.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_V3e5DHq">
					<orgName type="program" subtype="full">SFB 1233</orgName>
				</org>
				<org type="funding" xml:id="_Q2mDvkc">
					<idno type="grant-number">EXC 2064/1 No 39072764</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modality-General Sensitivity of Pupil Responses to Regularity Violations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Materials</head><p>Hamit Basgol 1, 2, 3 , Florian Raab 3 , Peter Dayan 1, 4 , and Volker H. Franz 1, 2 1 Department of Computer Science, University of Tübingen, Tübingen, Germany 2 Experimental Cognitive Science, University of Tübingen, Tübingen, Germany 3 The Graduate Training Centre of Neuroscience, University of Tübingen, Tübingen, Germany 4 Max Planck Institute for Biological Cybernetics, Tübingen, Germany</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modality-General Sensitivity of Pupil Responses to Regularity Violations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Materials 1 Surprise Analyses</head><p>We estimated the information content presented by transitions using a variable-order Markov model, called Information Dynamics of Music (IDyOM; <ref type="bibr">Pearce, 2018;</ref><ref type="bibr">Pearce, 2005)</ref>.</p><p>Designed for auditory perception, the IDyOM model learns about a domain through statistical learning and uses this to estimate conditional probabilities for events in a sequence, along with information-theoretic measures, based on the prior context and both short-and long-term training. We used this model for the comparability with our previous work <ref type="bibr">(Basgol et al., 2025)</ref>. (a) RAND5-REG5 involved a transition from RAND5 to REG5 and was used to investigate the emergence of regularity (see Figure <ref type="figure">1</ref>). As noted above, this transition enables a gradual model update, which in turn presents a reduction in information content (i.e., surprise). (b) REG5-RAND5 involved a transition from REG5 to RAND5. (c) REG5a-REG5b involved a shift from one REG5 pattern to another, thereby also constituting a transient violation of regularity and eliciting an initial increase followed by a rapid decrease in information content.</p><p>We validated responses of the IDyOM model for the visual stimuli using a hierarchical Chinese restaurant process model (HCRP; <ref type="bibr">Éltetho et al., 2022)</ref>. This model is modality-agnostic. We used an HCRP model instance with a context length of 5, employing the same strength parameter for all contexts. The strength parameter was in the high learning regime (0.0001; see the details in <ref type="bibr">Éltetho et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Analysis of Sustained Pupil Responses</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Experiments 1 and 2:</head><p>To explore potential differences between REG5 and RAND5, we analysed pupil size data 6 s after the start of each trial. Baseline pupil size was calculated by averaging pupil measurements taken during the first 0.25 s (due to the missing pupil size measurements in the inter-trial interval) after trial onset (i.e., during the first repetition of a possible regularity).</p><p>We then subtracted this baseline value from pupil sizes recorded during the 6 s epoch to assess the influence of the pattern types on pupil size. We compared pupil sizes in REG5 and RAND5. As shown in Figure <ref type="figure">2a</ref>, there is no considerable difference in pupil size between the two conditions. However, there appears to be a gradual decline in pupil size during the REG5  Note. Individual correlations based on isomorphic pairs of visual and auditory sequences were calculated for each participant. The correlations were then compared to 0 using a one-tailed t-test. Mr corresponds to the mean of individual correlations; 95% CI denotes the confidence interval from the t-test. Because of the one-tailed t-test, only one tail of the CI is given. The statistical metrics BF10, pcorr, and dz refer, respectively, to the Bayes factor, the corrected p-values of these correlations, and effect sizes.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Temporal expectation indexed by pupillary response</title>
		<author>
			<persName><forename type="first">B</forename><surname>Akdoğan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Balcı</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Rijn</surname></persName>
		</author>
		<idno type="DOI">10.1163/22134468-00002075</idno>
		<ptr target="https://doi.org/10.1163/22134468-00002075" />
	</analytic>
	<monogr>
		<title level="j">Timing &amp; Time Perception</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="354" to="370" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pupil-linked arousal responds to unconscious surprisal</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alamia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vanrullen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pasqualotto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mouraux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zenon</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.3010-18.2019</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.3010-18.2019" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">27</biblScope>
			<biblScope unit="page" from="5369" to="5376" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Statistical regularities attract attention when task-relevant</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alamia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zénon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Human Neuroscience</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">42</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Somatosensory responses to nothing: An MEG study of expectations during omission of tactile stimulations</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Lundqvist</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2018.09.014</idno>
		<ptr target="https://doi.org/10.1016/j.neuroimage.2018.09.014" />
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">184</biblScope>
			<biblScope unit="page" from="78" to="89" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The Freiburg Visual Acuity Test-variability unchanged by post-hoc re-analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graefe&apos;s Archive for Clinical and Experimental Ophthalmology</title>
		<imprint>
			<biblScope unit="volume">245</biblScope>
			<biblScope unit="page" from="965" to="971" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Brain responses in humans reveal ideal observer-like sensitivity to complex acoustic patterns</title>
		<author>
			<persName><forename type="first">N</forename><surname>Barascud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Pearce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chait</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1508523113</idno>
		<ptr target="https://doi.org/10.1073/pnas.1508523113" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Violation of auditory regularities is reflected in pupil dynamics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Basgol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H</forename><surname>Franz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="66" to="86" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Pupil responses to pitch deviants reflect predictability of melodic sequences</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bianco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">E</forename><surname>Ptasczynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Omigie</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bandc.2019.103621</idno>
		<ptr target="https://doi.org/10.1016/j.bandc.2019.103621" />
	</analytic>
	<monogr>
		<title level="j">Brain and Cognition</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="page">103621</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Attention to bright surfaces enhances the pupillary light reflex</title>
		<author>
			<persName><forename type="first">P</forename><surname>Binda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pereverzeva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">O</forename><surname>Murray</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.3440-12.2013</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.3440-12.2013" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="2199" to="2204" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pupillometric signature of implicit learning of statistical regularities</title>
		<author>
			<persName><forename type="first">P</forename><surname>Binda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Terzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Turi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Burr</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cub.2025.02.011</idno>
		<ptr target="https://doi.org/10.1016/j.cub.2025.02.011" />
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1431" to="1435" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Network reset: A simplified overarching theory of locus coeruleus noradrenaline function</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bouret</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Sara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Neurosciences</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="574" to="582" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Open-DPSM: An open-source toolkit for modeling pupil size changes to dynamic visual inputs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Strauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Der Stigchel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naber</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13428-023-02292-1</idno>
		<ptr target="https://doi.org/10.3758/s13428-023-02292-1" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="5605" to="5621" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The importance of statistical learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Canale</surname></persName>
		</author>
		<idno type="DOI">10.1038/s44159-021-00010-2</idno>
		<ptr target="https://doi.org/10.1038/s44159-021-00010-2" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Psychology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="68" to="68" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">How does the brain learn environmental structure? ten core principles for understanding the neurocognitive mechanisms of statistical learning</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Conway</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neubiorev.2020.01.032</idno>
		<ptr target="https://doi.org/10.1016/j.neubiorev.2020.01.032" />
	</analytic>
	<monogr>
		<title level="j">Neuroscience &amp; Biobehavioral Reviews</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="279" to="299" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Modality-constrained statistical learning of tactile, visual, and auditory sequences</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Christiansen</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.31.1.24</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.31.1.24" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="39" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Seeing and hearing in space and time: Effects of modality and presentation rate on implicit statistical learning</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Christiansen</surname></persName>
		</author>
		<idno type="DOI">10.1080/09541440802097951</idno>
		<ptr target="https://doi.org/10.1080/09541440802097951" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="561" to="580" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Visual versus auditory Simon effect: A behavioural and physiological investigation</title>
		<author>
			<persName><forename type="first">S</forename><surname>D'ascenzo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lugli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guidotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rubichi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Iani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nicoletti</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470218.2017.1307429</idno>
		<ptr target="https://doi.org/10.1080/17470218.2017.1307429" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="917" to="930" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Phasic norepinephrine: A neural interrupt signal for unexpected events</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1080/09548980601004024</idno>
		<ptr target="https://doi.org/10.1080/09548980601004024" />
	</analytic>
	<monogr>
		<title level="j">Network: Computation in Neural Systems</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="335" to="350" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dynamic modulation of decision biases by brainstem arousal systems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>De Gee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Colizoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Kloosterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Knapen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nieuwenhuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Donner</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.23232</idno>
		<ptr target="https://doi.org/10.7554/eLife.23232" />
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">23232</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Decision-related pupil dilation reflects upcoming choice and individual bias</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>De Gee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Knapen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Donner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Event-related potentials in clinical research: Guidelines for eliciting, recording, and quantifying mismatch negativity, P300, and N400</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Connolly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">T</forename><surname>Michie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Näätänen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Polich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Reinvang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Van Petten</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.clinph.2009.07.045</idno>
		<ptr target="https://doi.org/10.1016/j.clinph.2009.07.045" />
	</analytic>
	<monogr>
		<title level="j">Clinical Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1883" to="1908" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cross-modal transfer of statistical information benefits from sleep</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Durrant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Cairney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2016.02.011</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2016.02.011" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="85" to="99" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tracking human skill learning with a hierarchical bayesian sequence model</title>
		<author>
			<persName><forename type="first">N</forename><surname>Éltetho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nemeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Janacsek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1009866</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Timing is everything: Changes in presentation rate have opposite effects on auditory and visual implicit statistical learning</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Emberson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Christiansen</surname></persName>
		</author>
		<idno type="DOI">10.1080/17470218.2010.538972</idno>
		<ptr target="https://doi.org/10.1080/17470218.2010.538972" />
	</analytic>
	<monogr>
		<title level="j">Quarterly Journal of Experimental Psychology</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1021" to="1040" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">G*power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences</title>
		<author>
			<persName><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A.-G</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="191" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Very young infants learn abstract rules in the visual modality</title>
		<author>
			<persName><forename type="first">B</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Franconeri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Waxman</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0190185</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0190185" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pupil diameter encodes the idiosyncratic, cognitive complexity of belief updating</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Filipowicz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Glaze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kable</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.57872</idno>
		<ptr target="https://doi.org/10.7554/eLife.57872" />
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">57872</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">From pre-processing to advanced dynamic modeling of pupil data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Simola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tavano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wallot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Laeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1376" to="1412" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Domain generality versus modality specificity: The paradox of statistical learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Frost</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Siegelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Christiansen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2014.12.010</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2014.12.010" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="117" to="125" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visual and auditory sequence learning in hearing-impaired children</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">G</forename><surname>Furth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Pufall</surname></persName>
		</author>
		<idno type="DOI">10.1044/jshr.0903.441</idno>
		<ptr target="https://doi.org/10.1044/jshr.0903.441" />
	</analytic>
	<monogr>
		<title level="j">Journal of Speech and Hearing Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="441" to="449" />
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Wink or blush? Pupil-linked phasic arousal signals both change and uncertainty during assessment of changing environmental regularities</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gesztesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pajkossy</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2025.106256</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2025.106256" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">264</biblScope>
			<biblScope unit="page">106256</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Locus coeruleus activation accelerates perceptual learning</title>
		<author>
			<persName><forename type="first">E</forename><surname>Glennon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Carcea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R O</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Multani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shehu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Svirsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Froemke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brain Research</title>
		<imprint>
			<biblScope unit="volume">1709</biblScope>
			<biblScope unit="page" from="39" to="49" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">MEG and EEG data analysis with MNE-python</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Luessi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Engemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Strohmeier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brodbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Goj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Parkkonen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">267</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">EEG mismatch responses in a multimodal roving stimulus paradigm provide evidence for probabilistic inference across audition, somatosensation, and vision</title>
		<author>
			<persName><forename type="first">M</forename><surname>Grundei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schröder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gijsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Blankenburg</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.26303</idno>
		<ptr target="https://doi.org/10.1002/hbm.26303" />
	</analytic>
	<monogr>
		<title level="j">Human Brain Mapping</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3644" to="3668" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Peak selection and latency jitter correction in developmental event-related potentials</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bursalıoğlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Richards</surname></persName>
		</author>
		<idno type="DOI">10.1002/dev.22193</idno>
		<ptr target="https://doi.org/10.1002/dev.22193" />
	</analytic>
	<monogr>
		<title level="j">Developmental Psychobiology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">22193</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The locus coeruleus as a global model failure system</title>
		<author>
			<persName><forename type="first">R</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Neurosciences</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="92" to="105" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pupil size as a window on neural substrates of cognition</title>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2020.03.005</idno>
		<ptr target="https://doi.org/10.1016/j.tics.2020.03.005" />
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="466" to="480" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Relationships between pupil diameter and neuronal activity in the locus coeruleus, colliculi, and cingulate cortex</title>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Kalwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2015.11.028</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2015.11.028" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="221" to="234" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Effects of visual and verbal presentation on cognitive load in vigilance, memory, and arithmetic tasks</title>
		<author>
			<persName><forename type="first">J</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Hanrahan</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1469-8986.2010.01069.x</idno>
		<ptr target="https://doi.org/10.1111/j.1469-8986.2010.01069.x" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="323" to="332" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Visual mismatch negativity (vMMN): A review and meta-analysis of studies in psychiatric and neurological disorders</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kremláček</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kreegipuu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tales</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Astikainen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Põldver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Näätänen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Stefanics</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2016.03.017</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2016.03.017" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="76" to="112" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Arousal-related adjustments of perceptual biases optimize perception in dynamic environments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Krishnamurthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sarode</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-017-0107</idno>
		<ptr target="https://doi.org/10.1038/s41562-017-0107" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">6</biblScope>
			<date type="published" when="2017">2017. 0107</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neuromodulatory correlates of pupil dilation</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Waters</surname></persName>
		</author>
		<idno type="DOI">10.3389/fncir.2018.00021</idno>
		<ptr target="https://doi.org/10.3389/fncir.2018.00021" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neural Circuits</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">E</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Engemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Leppakangas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Brodbeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MNE-Python</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>1.2. 3 computer software</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Neurocomputational underpinnings of expected surprise</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lecaignard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bertrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Caclin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mattout</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0601-21.2021</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.0601-21.2021" />
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="474" to="486" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Correspondences among pupillary dilation response, subjective salience of sounds, and loudness</title>
		<author>
			<persName><forename type="first">H.-I</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kidani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yoneya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kashino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Furukawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="412" to="425" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Human pupillary dilation response to deviant auditory stimuli: Effects of stimulus properties and voluntary attention</title>
		<author>
			<persName><forename type="first">H.-I</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yoneya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kidani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kashino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Furukawa</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2016.00043</idno>
		<ptr target="https://doi.org/10.3389/fnins.2016.00043" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Modelling trial-by-trial changes in the mismatch negativity</title>
		<author>
			<persName><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1002911</idno>
		<ptr target="https://doi.org/10.1371/journal.pcbi.1002911" />
	</analytic>
	<monogr>
		<title level="j">PLOS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">1002911</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Pupil dilation reveals top-down attentional load during spatial monitoring</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lisi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bonato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zorzi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.biopsycho.2015.10.002</idno>
		<ptr target="https://doi.org/10.1016/j.biopsycho.2015.10.002" />
	</analytic>
	<monogr>
		<title level="j">Biological Psychology</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="39" to="45" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Linear integration of multisensory signals in the pupil</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1111/psyp.14453</idno>
		<ptr target="https://doi.org/10.1111/psyp.14453" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">14453</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Pupil size reflects activation of subcortical ascending arousal system nuclei during rest</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lloyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D</forename><surname>De Voogd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Mäki-Marttunen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nieuwenhuis</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.84822</idno>
		<ptr target="https://doi.org/10.7554/eLife.84822" />
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">84822</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Nonparametric statistical testing of EEG and MEG data</title>
		<author>
			<persName><forename type="first">E</forename><surname>Maris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Oostenveld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience Methods</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="177" to="190" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Can pupillometry index auditory attentional capture in contexts of active visual processing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Marois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vachon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="484" to="502" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The pupillary light response reveals the focus of covert visual attention</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mathôt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">V D</forename><surname>Linden</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Grainger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Vitu</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0078168</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0078168" />
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">78168</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Give me a break! Unavoidable fatigue effects in cognitive pupillometry</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Mclaughlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Zink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Gaunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Sommers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Van Engen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Peelle</surname></persName>
		</author>
		<idno type="DOI">10.1111/psyp.14256</idno>
		<ptr target="https://doi.org/10.1111/psyp.14256" />
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">14256</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Pupil diameter is not an accurate real-time readout of locus coeruleus activity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Megemont</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcburney-Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.70510</idno>
		<ptr target="https://doi.org/10.7554/eLife.70510" />
	</analytic>
	<monogr>
		<title level="j">eLife</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">70510</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Sustained pupil responses are modulated by predictability of auditory sequences</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tampakaki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chait</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.2879-20.2021</idno>
		<ptr target="https://doi.org/10.1523/JNEUROSCI.2879-20.2021" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">28</biblScope>
			<biblScope unit="page" from="6116" to="6127" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Pupil diameter covaries with BOLD activity in human locus coeruleus</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>O'connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>O'sullivan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">H</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Balsters</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.22466</idno>
		<ptr target="https://doi.org/10.1002/hbm.22466" />
	</analytic>
	<monogr>
		<title level="j">Human Brain Mapping</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="4140" to="4154" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Rational regulation of learning dynamics by pupil-linked arousal systems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Rumsey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Heasly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.3130</idno>
		<ptr target="https://doi.org/10.1038/nn.3130" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1040" to="1046" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">The mismatch-negativity (MMN) component of the auditory event-related potential to violations of abstract regularities: A review</title>
		<author>
			<persName><forename type="first">P</forename><surname>Paavilainen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijpsycho.2013.03.015</idno>
		<ptr target="https://doi.org/10.1016/j.ijpsycho.2013.03.015" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="123" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">How uncertain are you? disentangling expected and unexpected uncertainty in pupil-linked brain arousal during reversal learning</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pajkossy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gesztesi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Racsmány</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13415-023-01072-w</idno>
		<ptr target="https://doi.org/10.3758/s13415-023-01072-w" />
	</analytic>
	<monogr>
		<title level="j">Cognitive, Affective, &amp; Behavioral Neuroscience</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="578" to="599" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Arousal-based pupil modulation is dictated by luminance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Klímová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Mcguire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ling</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-022-05280-1</idno>
		<ptr target="https://doi.org/10.1038/s41598-022-05280-1" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1390</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The effects of emotional arousal on pupil size depend on luminance</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Klimova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Mcguire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ling</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-024-70895-5</idno>
		<ptr target="https://doi.org/10.1038/s41598-024-70895-5" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">21895</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Statistical learning and probabilistic prediction in music cognition: Mechanisms of stylistic enculturation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1423</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="378" to="395" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">The construction and evaluation of statistical models of melodic structure in music perception and composition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Pearce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>City University London</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Doctoral dissertation</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Cerebral representation of sequence patterns across multiple presentation formats</title>
		<author>
			<persName><forename type="first">S</forename><surname>Planton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dehaene</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2021.09.003</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2021.09.003" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="13" to="36" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">The sound of silence: Predictive error responses to unexpected sound omission in adults</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Prete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heikoop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mcgillivray</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Reilly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Trainor</surname></persName>
		</author>
		<idno type="DOI">10.1111/ejn.15660</idno>
		<ptr target="https://doi.org/10.1111/ejn.15660" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1972" to="1985" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Pupil dilation during visual target detection</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Privitera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Renninger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aguilar</surname></persName>
		</author>
		<idno type="DOI">10.1167/10.10.3</idno>
		<ptr target="https://doi.org/10.1167/10.10" />
	</analytic>
	<monogr>
		<title level="j">Journal of Vision</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Interactions of auditory and visual stimuli in space and time</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Recanzone</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.heares.2009.04.009</idno>
		<ptr target="https://doi.org/10.1016/j.heares.2009.04.009" />
	</analytic>
	<monogr>
		<title level="j">Hearing Research</title>
		<imprint>
			<biblScope unit="volume">258</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="99" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex</title>
		<author>
			<persName><forename type="first">J</forename><surname>Reimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcginley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rodenkirch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Tolias</surname></persName>
		</author>
		<idno type="DOI">10.1038/ncomms13289</idno>
		<ptr target="https://doi.org/10.1038/ncomms13289" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">13289</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Baseline pupil size encodes task-related information and modulates the task-evoked response in a speech-in-noise task</title>
		<author>
			<persName><forename type="first">H</forename><surname>Relaño-Iborra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wendt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Neagu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Kressner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Baekgaard</surname></persName>
		</author>
		<idno type="DOI">10.1177/23312165221134003</idno>
		<ptr target="https://doi.org/10.1177/23312165221134003" />
	</analytic>
	<monogr>
		<title level="j">Trends in Hearing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Multisensory signalling enhances pupil dilation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Rigato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Rieger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Romei</surname></persName>
		</author>
		<idno type="DOI">10.1038/srep26188</idno>
		<ptr target="https://doi.org/10.1038/srep26188" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">26188</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Visual statistical learning: Getting some help from the auditory modality</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Sloutsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Intramodal and crossmodal sensory transfer of visual and auditory temporal patterns</title>
		<author>
			<persName><forename type="first">L</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Gruenberg</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03210235</idno>
		<ptr target="https://doi.org/10.3758/BF03210235" />
	</analytic>
	<monogr>
		<title level="j">Perception &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="385" to="390" />
			<date type="published" when="1971">1971</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Spatial representation of pitch height: The SMARC effect</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rusconi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Kwan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Giordano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Umilta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Butterworth</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2005.01.004</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2005.01.004" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="129" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Anticipating multisensory environments: Evidence for a supra-modal predictive system</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sabio-Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Fuentemilla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pérez-Bellido</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">254</biblScope>
			<biblScope unit="page">105970</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Attention and prediction in human audition: A lesson from cognitive psychophysiology</title>
		<author>
			<persName><forename type="first">E</forename><surname>Schröger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marzecová</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sanmiguel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">The prevalence and importance of statistical learning in human cognition and behavior</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Sherman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Turk-Browne</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cobeha.2020.01.015</idno>
		<ptr target="https://doi.org/10.1016/j.cobeha.2020.01.015" />
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="15" to="20" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Effects of a task-relevant response on pupil size</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Simpson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Pupillometry</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sirois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Brisson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wiley Interdisciplinary Reviews: Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="679" to="692" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Adaptive learning under expected and unexpected uncertainty</title>
		<author>
			<persName><forename type="first">A</forename><surname>Soltani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Izquierdo</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41583-019-0180-y</idno>
		<ptr target="https://doi.org/10.1038/s41583-019-0180-y" />
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Neuroscience</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="635" to="644" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Is predictability salient? A study of attentional capture by auditory patterns</title>
		<author>
			<persName><forename type="first">R</forename><surname>Southwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Baumann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Barascud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chait</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2016.0105</idno>
		<ptr target="https://doi.org/10.1098/rstb.2016.0105" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<biblScope unit="issue">1714</biblScope>
			<biblScope unit="page">20160105</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Enhanced deviant responses in patterned relative to random sound sequences</title>
		<author>
			<persName><forename type="first">R</forename><surname>Southwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chait</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2018.08.032</idno>
		<ptr target="https://doi.org/10.1016/j.cortex.2018.08.032" />
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="92" to="103" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">The forgotten wave of early pupillometry research</title>
		<author>
			<persName><forename type="first">C</forename><surname>Strauch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Neurosciences</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="571" to="572" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Pupillometry as an integrated readout of distinct attentional networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Strauch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Einhäuser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Van Der Stigchel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naber</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tins.2022.05.003</idno>
		<ptr target="https://doi.org/10.1016/j.tins.2022.05.003" />
	</analytic>
	<monogr>
		<title level="j">Trends in Neurosciences</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="635" to="647" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Integration and segregation in auditory scene analysis</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Sussman</surname></persName>
		</author>
		<idno type="DOI">10.1121/1.1854312</idno>
		<ptr target="https://doi.org/10.1121/1.1854312" />
	</analytic>
	<monogr>
		<title level="j">The Journal of the Acoustical Society of America</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1285" to="1298" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Pingouin: Statistics in python</title>
		<author>
			<persName><forename type="first">R</forename><surname>Vallat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">31</biblScope>
			<biblScope unit="page">1026</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">The additive nature of the human multisensory evoked pupil response</title>
		<author>
			<persName><forename type="first">N</forename><surname>Van Der Stoep</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Van Der Smagt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Notaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Spock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Naber</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-020-80286-1</idno>
		<ptr target="https://doi.org/10.1038/s41598-020-80286-1" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">707</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Hemodynamic response varies across tactile stimuli with different temporal structures</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.25243</idno>
		<ptr target="https://doi.org/10.1002/hbm.25243" />
	</analytic>
	<monogr>
		<title level="j">Human Brain Mapping</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="587" to="597" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Best practices and advice for using pupillometry to measure listening effort: An introduction for those who want to get started</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Wendt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koelewijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Kuchinsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Hearing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Change is in the eye of the beholder</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn.3150</idno>
		<ptr target="https://doi.org/10.1038/nn.3150" />
	</analytic>
	<monogr>
		<title level="j">Nature Neuroscience</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="933" to="935" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Uncertainty, neuromodulation, and attention</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2005.04.026</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2005.04.026" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="681" to="692" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">The pupil dilation response to auditory stimuli: Current state of knowledge</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Zekveld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Koelewijn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Kramer</surname></persName>
		</author>
		<idno type="DOI">10.1177/2331216518777174</idno>
		<ptr target="https://doi.org/10.1177/2331216518777174" />
	</analytic>
	<monogr>
		<title level="j">Trends in Hearing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Visual selective attention P300 source in frontal-parietal lobe: ERP and fMRI study</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ngetich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10548-022-00916-x</idno>
		<ptr target="https://doi.org/10.1007/s10548-022-00916-x" />
	</analytic>
	<monogr>
		<title level="j">Brain Topography</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="636" to="650" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Attention is spontaneously biased toward regularities</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Al-Aidroos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">B</forename><surname>Turk-Browne</surname></persName>
		</author>
		<idno type="DOI">10.1177/0956797612460407</idno>
		<ptr target="https://doi.org/10.1177/0956797612460407" />
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="667" to="677" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Statistical regularities guide the spatial scale of attention</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13414-016-1233-1</idno>
		<ptr target="https://doi.org/10.3758/s13414-016-1233-1" />
	</analytic>
	<monogr>
		<title level="j">Attention, Perception, &amp; Psychophysics</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="30" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Pupil-linked phasic arousal evoked by violation but not emergence of regularity within rapid sound sequences</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Dick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Furukawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H.-I</forename><surname>Liao</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-019-12048-1</idno>
		<ptr target="https://doi.org/10.1038/s41467-019-12048-1References" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4030</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">Violation of auditory regularities is reflected in pupil dynamics</title>
		<author>
			<persName><forename type="first">H</forename><surname>Basgol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">H</forename><surname>Franz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="page" from="66" to="86" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Modality-constrained statistical learning of tactile, visual, and auditory sequences</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Conway</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Christiansen</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.31.1.24</idno>
		<ptr target="https://doi.org/10.1037/0278-7393.31.1.24" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="39" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Tracking human skill learning with a hierarchical bayesian sequence model</title>
		<author>
			<persName><forename type="first">N</forename><surname>Éltetho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nemeth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Janacsek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Computational Biology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">1009866</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">From pre-processing to advanced dynamic modeling of pupil data</title>
		<author>
			<persName><forename type="first">L</forename><surname>Fink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Simola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tavano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wallot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Laeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1376" to="1412" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Peak selection and latency jitter correction in developmental event-related potentials</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Conte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bursalıoğlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Richards</surname></persName>
		</author>
		<idno type="DOI">10.1002/dev.22193</idno>
		<ptr target="https://doi.org/10.1002/dev.22193" />
	</analytic>
	<monogr>
		<title level="j">Developmental Psychobiology</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">22193</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Relationships between pupil diameter and neuronal activity in the locus coeruleus, colliculi, and cingulate cortex</title>
		<author>
			<persName><forename type="first">S</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Kalwani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2015.11.028</idno>
		<ptr target="https://doi.org/10.1016/j.neuron.2015.11.028" />
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="221" to="234" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Correspondences among pupillary dilation response, subjective salience of sounds, and loudness</title>
		<author>
			<persName><forename type="first">H.-I</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kidani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Yoneya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kashino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Furukawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="412" to="425" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Statistical learning and probabilistic prediction in music cognition: Mechanisms of stylistic enculturation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the New York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1423</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="378" to="395" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">The construction and evaluation of statistical models of melodic structure in music perception and composition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Pearce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>City University London</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Doctoral dissertation</note>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title level="m" type="main">Statsmodels: Econometric and statistical modeling with Python</title>
		<author>
			<persName><forename type="first">S</forename><surname>Seabold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Perktold</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="92" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Pupil dilation as an index of effort in cognitive control tasks: A review</title>
		<author>
			<persName><forename type="first">P</forename><surname>Van Der Wel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Van Steenbergen</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-018-1432-y</idno>
		<ptr target="https://doi.org/10.3758/s13423-018-1432-y" />
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2005" to="2015" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Hemodynamic response varies across tactile stimuli with different temporal structures</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Go</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yan</surname></persName>
		</author>
		<idno type="DOI">10.1002/hbm.25243</idno>
		<ptr target="https://doi.org/10.1002/hbm.25243" />
	</analytic>
	<monogr>
		<title level="j">Human Brain Mapping</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="587" to="597" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
