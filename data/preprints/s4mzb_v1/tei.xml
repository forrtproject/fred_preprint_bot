<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Technocultural Hegemony: What Role Does Natural Language Processing Play in the Reinforcement of Dominant Cultural Narratives?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Daria</forename><surname>Markava</surname></persName>
							<email>daria.markava@bist.ge</email>
						</author>
						<title level="a" type="main">Technocultural Hegemony: What Role Does Natural Language Processing Play in the Reinforcement of Dominant Cultural Narratives?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F13317466080B006AC2F3C8875CE13C8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-19T16:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>While Natural Language Processing (NLP) tools keep gaining popularity among users from around the globe, their vast majority is developed in the west, mainly the US. Although plenty of studies have shown that NLP tools don't perform equally well in different languages and cultural contexts, little research has been conducted on the broader consequences of such performance disparities. By using the evidence from previous research, this study aims to bridge this gap and explore how NLP and the existing cultural hierarchies can be mutually constitutive. This paper first reviews existing literature on the NLP tools' performance in relation to underrepresented languages and non-western cultures. It then takes a critical theory approach to examining the broader cultural implications of the shortcomings identified during the review. More specifically, this work uses the concept of technoculture proposed by Leila Green, to connect the technological and cultural aspects of NLP, and refers to Gramsci's theory of cultural hegemony to explore how the bias in NLP tools reinforces dominant cultural narratives overrepresented in the training data. This study argues that NLP applications play a role in reinforcing the dominant norms, ideals, and ways of expression as universal, thus marginalizing alternative worldviews and imposing normative standards of communication onto the users of different backgrounds. The analysis concludes that, as the popularity of NLP tools keeps growing worldwide, their influence on what is perceived as "common sense" will increase too. This study emphasizes the importance of ensuring equitable representation of the user base throughout the whole NLP development pipeline.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. Introduction</head><p>Although Natural Language Processing (NLP) has been around since the middle of the 20th century, it started gaining mass popularity outside the AI industry around 2017, sparked by Google's introduction of the Transformer architecture <ref type="bibr" target="#b20">(Vaswani et al., 2017)</ref>, and later by OpenAI's creation of GPT-1 <ref type="bibr" target="#b15">(Radford et al., 2018)</ref>. Increasingly, users from across the globe are using Large Language Models (LLMs) for various purposes on a regular basis, and the integration of these tools into everyday life is only expected to continue.</p><p>In contrast to the diversity of their user base, the vast majority of NLP tools (as well as other applications of artificial intelligence) are developed in the West -predominantly the United States -with China close behind. While a lot of those tools are nominally supported in many different countries and languages, there are barriers preventing people of different cultures from benefiting from the technology equally. These barriers, which will be discussed below in more detail, effectively disadvantage users with cultural backgrounds different from those of the developers, and perpetuate existing inequalities.</p><p>LLMs are unlike any other type of communication tools, as they don't enable interactions between people directly. Nevertheless, the text produced by LLMs is influenced by the real-world training data, meaning that although the final output is machine-generated, human influence is not eliminated from the pipeline, but rather takes a new form. In order to characterize the unique ways in which AI developers' cultural narratives are passed onto the users through NLP, this paper looks into the concepts of technoculture and cultural hegemony, and how they intertwine in NLP applications.</p><p>The purpose of this study is to take an interdisciplinary approach to identifying and understanding the implications of NLP tools, like LLMs, for users of diverse cultural backgrounds. While previous research on cultural aspects of NLP mentions the negative effects of its performance disparities across different languages and cultures, these effects are rarely discussed in depth, and the majority of studies focus solely on the technical aspects. There is currently little research on how the increased global use of NLP tools is going to reshape the culture worldwide, and this paper aims to address this gap by placing the effects of natural language processing on cultures around the world in a broader context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research Questions</head><p>The key question this research aims to answer is how NLP reinforcing dominant cultural narratives contributes to cultural hegemony, epistemic injustice, and perpetuates existing inequalities. To evaluate the cultural impact of NLP, this study will answer the following questions:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RQ1.</head><p>To what extent can NLP be considered an emerging form of technoculture according to Green's definition? RQ2. How do existing cultural hierarchies influence the performance of NLP tools?</p><p>RQ3. What could be the consequences of discrepancies of NLP applications' capabilities across different languages and cultural contexts?</p><p>Answering these questions will allow for a comprehensive understanding of how NLP can influence cultures, languages, and the relationships between them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Literature Collection</head><p>The search for relevant literature was conducted across three databases: IEEE Xplore, ACM Digital Library, and Google Scholar. IEEE Xplore and ACM DL were chosen for their renown in the disciplines of technology and computer science; Google Scholar was used primarily due to its scope. Furthermore, these databases include literature produced by authors from different cultures around the world. This was a factor when choosing databases, since incorporating diverse perspectives is essential to reflecting and upholding the values that motivated this study in the first place.</p><p>To collect relevant literature, keywords "NLP" and "LLMs" were searched in combination with terms such as "culture", "narrative", "hegemony", "westernization", "dominance", "bias", etc., as well as boolean operators AND and OR. In all three databases, the advanced search option was used to search for keywords in either the title of an article or the full text. In the case of Xplore, publication topic filters were used as well. For terms like "culture", "dominance" and "epistemology", an asterisk was used to allow for relevant derived forms of the words to be included. While searching ACM Digital Library and IEEE Xplore, more general keyword combinations were used. The scope of Google Scholar, on the other hand, allowed for more precise queries, such as 'NLP AND "anglocentrism"', whereas similar queries on the other two databases returned no results. For all queries, the time range was specified as 2020-2025 to ensure the relevance of the articles, with the exception of the query 'NLP AND "epistemic injustice"', where the time range was set as 2024-2025, to limit the number of search results to a manageable amount. In ACM and Xplore, only articles labeled as "Open Access" or "Free" were selected; since Google Scholar doesn't provide such an option, 7 out of initially selected articles could not be accessed and were therefore excluded from screening. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inclusion/exclusion criteria</head><p>To collect literature that would comprehensively represent the current state of NLP capabilities in relation to culture, the following inclusion and exclusion criteria were implemented. Included were studies that examined the performance of NLP tools in the context of language and/or culture. As expected, the majority of studies focused on LLMs; however, a few studies of Sentiment Analysis tools were also included. For a study to be included in the review, it had to discuss the question of culture, identity, fairness, or inclusivity raised by the study's results. Therefore, studies that were solely focused on the technical aspects of NLP applications were excluded. Works that proposed domain-specific applications of NLP (e.g. in healthcare, e-commerce, etc.) and review articles were excluded. Recognizing the rapid pace of development in the AI field, relevant preprints from arXiv found during the search of Google Scholar were included as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Critical theory analysis</head><p>Drawing from the evidence from literature, this work explores the cultural implications of NLP through the lens of two theories, technoculture and cultural hegemony.</p><p>Technoculture is a neologism that can be vaguely defined as the interaction between technology and culture. However, this definition lacks specificity, as it allows for any overlap between technology and culture to be considered technoculture <ref type="bibr" target="#b6">(Green, 2001)</ref>. To avoid using the term loosely, this study uses the definition of technoculture suggested by Green. Her paper defines technoculture as "communication of cultural material in technological contexts" that "can influence perceptions and experiences of time, place and space" (p. 16).</p><p>This research assesses to what extent NLP technologies fit Green's definition of technoculture. However, it is essential to keep in mind that the framework was developed in 2001, long before the NLP in its modern form was created, let alone widely employed by the general public. Still, Green acknowledged that new forms of technoculture would appear with time, which opens the opportunity for investigating the role artificial intelligence, namely NLP, plays in the construction of culture.</p><p>The second concept this paper explores is cultural hegemony. Similarly to technoculture, there is no universally agreed-upon definition of the term, and its exact meaning depends on the sociocultural context to which it is applied. The theory of cultural hegemony was coined by an Italian Marxist philosopher Antonio Gramsci. It refers to the way the ruling class reinforces its dominance in society by positioning its values and beliefs as the norm via cultural institutions <ref type="bibr" target="#b9">(Lears, 1985)</ref>. Although the term was originally used to explain how the ruling elites maintain their power over the working class in capitalist societies, it has become more widely used in other contexts. The ones most relevant to this work are the linguistic hegemony of the English language worldwide, and the cultural aspects of Western hegemony, i.e. the positioning of Western ideals as universal. This article aims to determine to what extent these two forms of cultural hegemony manifest in modern NLP applications, with a focus on large language models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. NLP as a Technocultural Phenomenon</head><p>Green ( <ref type="formula">2001</ref>) suggests that an ideal example of technoculture "would necessarily be in the high-tech domain", which modern NLP applications undoubtedly are, given that they utilize state-of-the-art deep learning techniques. Green also argues that such an instance of technoculture would "be imbued with communication and culture", and enable the creation and circulation of cultural material "using technologically mediated communication" (p. 16).</p><p>Creation and circulation of cultural material is inherent to NLP for the following reasons.</p><p>First, these models are trained on enormous corpora of human-produced texts, such as books, web pages, online publications, social media posts, etc. These sources of text data are not neutral representations of language, but direct products of culture, permeated with human values, biases, and worldviews. Using them as training data results in the same epistemes being woven into NLP models. Consequently, the output of such tools is heavily influenced by the narratives present in the corpora, enabling the circulation of cultural material. An example of this can be seen in <ref type="bibr" target="#b1">Das et al. (2024)</ref>, who conducted an audit of Bengali sentiment analysis tools and found that most of the tools tested were biased towards particular genders, nationalities, and religions. This illustrates how post-colonial prejudices embedded in the training data are communicated through an NLP tool (in this case, by assigning more positive or negative sentiment scores to sentences expressing some or other identities).</p><p>Second, some types of NLP like natural language generation or machine translation produce language-based output, which in itself can be seen as a form of creation of cultural material since language, according to Green, is a technoculture as well. Additionally, by producing text output, generative language models create a body of text that is informed by, and builds on, human knowledge and culture. For example, when prompted to write an email to a professor, an LLM would produce a formal and professional-sounding message, even if not explicitly asked to make it formal<ref type="foot" target="#foot_0">1</ref> . Such an output is influenced by the norms of communication in settings such as academia and workplace; in its turn, the output may reinforce the user's understanding of these norms. Machine translation tools facilitate communication of culture more directly, by enabling the exchange of ideas between languages; however, they sometimes fail to communicate some linguistic nuances successfully <ref type="bibr">(Helm et al. 2023)</ref>.</p><p>Another characteristic of a technoculture, according to Green, is its ability to negate space or time (p. 12). In NLP, this ability manifests in quite an interesting way. As <ref type="bibr" target="#b8">Johnson et al. (2022)</ref> point out, the training data for language models only represents the current moment in time.</p><p>Contrary to the human culture, which evolves continuously, an individual NLP tool's model of reality is static, and doesn't take into account the changes that have taken place over time.</p><p>Although modern NLP applications haven't been around long enough for this effect to be substantially visible, it is likely that a model released in 2025 has been trained on a different representation of reality than a model released in 2018.</p><p>As of June 2025, language models do not learn continuously in real time; once they have been trained, they reflect the cultural narratives of the time of their training for as long as they are used. A suitable analogy is a book (which Green also uses as an example of technoculture); a book written in the 19th century will continue to reflect the 19th century's values regardless of when it is being read. It is worth noting, however, that the time-negating properties of NLP might not be similarly obvious. New models are developed and fine-tuned at a rapid pace, replacing older versions; the "lifetime" of any language model, therefore, is incomparable to the period of time it would take for a significant shift of values to take place in society.</p><p>Overall, the above analysis suggests that NLP can indeed be considered an emerging form of technoculture, as it is simultaneously technological and rooted in human culture, with these two aspects being inseparable from each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. Cultural Hegemony in NLP</head><p>Building on Gramsci's theory of cultural hegemony <ref type="bibr" target="#b9">(Lears, 1985)</ref>, this section examines how the technocultural occurrence of NLP serves to reinforce dominant cultural narratives, particularly the westernization of cultural defaults globally and the supremacy of the English language as the universal lingua franca.</p><p>Cultural competence of NLP tools, mainly LLMs, has been widely studied <ref type="bibr" target="#b0">(Aksoy, 2024;</ref><ref type="bibr" target="#b3">Dusi et al., 2024;</ref><ref type="bibr" target="#b10">Li et al., 2024;</ref><ref type="bibr" target="#b11">Naous et al., 2024;</ref><ref type="bibr" target="#b13">Pawar et al., 2025;</ref><ref type="bibr" target="#b14">Plaza-del-Arco et al., 2024;</ref><ref type="bibr" target="#b18">Shen et al., 2024;</ref><ref type="bibr" target="#b19">Tao et al., 2024;</ref><ref type="bibr" target="#b22">Wang et al., 2025)</ref>, proving that the tools tested display some sort of bias based on factors such as gender, religion, nationality, race and other identity dimensions.</p><p>NLP tools can be applied in various cases, such as content moderation, customer feedback analysis, social media monitoring, etc. <ref type="bibr" target="#b17">(Shehu et al., 2024)</ref>. When the tools used for such purposes exhibit bias based on demographic factors, it increases the risk of discrimination against the users whose cultural values, ways of expression, and linguistic backgrounds differ from those most prevalent in the training corpora.</p><p>Perhaps the largest cause of the unequal cultural representation in NLP tools is the training data imbalance. While there are massive English-language corpora available, the majority of the world's languages are underrepresented in the training datasets. For instance, on Common Crawl -a popular source of training data for NLP models -about 45% of the data is in English, as shown in Figure 1 <ref type="bibr" target="#b2">(Dawson et al., 2024)</ref>. Consequently, there are more opportunities for the development of English NLP than most other languages. The availability of pre-trained models is also an issue for underrepresented languages. While training a language model from scratch requires a lot of resources, fine-tuning a pre-trained model is much less costly -and since these only exist for a few languages, the speakers of the remaining languages are further excluded from participation <ref type="bibr" target="#b21">(Wali et al. 2020</ref>).</p><p>As a result, innovations in NLP are almost always centered around the English language. As Wali et al. observe, new tools are first introduced for English, only later adding support for other languages. This gives the English-speaking world a significant advantage, as they are often the first to get access to latest NLP technologies, and exacerbates the digital divide. Those who do not speak English or some other high-resource language are essentially excluded from the newest developments in NLP, and hence the benefits that the technology brings.</p><p>Furthermore, even when multiple languages are nominally supported by an NLP tool, it doesn't always mean that the speakers of those languages receive equally high quality services. <ref type="bibr">Wali et al.</ref> emphasize that when low-resource languages are supported by a multilingual model, the model's performance in these languages tends to be significantly worse. While it is technically possible for the speakers of such languages to use NLP tools, they are still disadvantaged by this disparity.</p><p>This argument is also strongly supported by <ref type="bibr">Helm et al. (2023)</ref>, who define language modelling bias, a form of linguistic bias, as a situation when "[T]he technology, by design, represents, interprets, or processes content less accurately in certain languages than in others, thereby forcing speakers of the disadvantaged language to simplify or adapt their communication, (self-)representation, and expression when using that technology to fit the default incorporated in the privileged language." (p. 6)</p><p>This stems from the oversimplified idea of diversity in the field of technology, the study argues, and the work on expanding NLP to support more languages being usually done by the western developers, rather than the native speakers -a "top-down" approach that is ultimately harms the native communities by forcing them to fit into the Anglocentric standards of communication in order to use the technology.</p><p>Such an approach creates an illusion of representation while in reality, it perpetuates marginalization of expression that doesn't meet western standards, while positioning the latter as universal. Helm et al. uses Fricker's concept of epistemic injustice to examine the harms caused by language technologies when they fail to adequately represent the voices of certain communities. Hermeneutical injustice, a type of epistemic injustice, refers to the way someone's experience is not adequately understood or represented since the means of expressing it don't exist <ref type="bibr" target="#b5">(Fricker, 2007)</ref>. This is true for NLP tools, especially LLMs, where worldviews and narratives alternative to the ones of the western world are hardly acknowledged. <ref type="bibr" target="#b9">Lears (1985)</ref>, quoting Gramsci, states that "every language contains the elements of a conception of the world" (p. 569). Thus unable to communicate the realities of their world when interacting with language models, speakers of underrepresented languages are forced to adapt to the privileged epistemes, reinforcing the notion that the dominant narratives are the only legitimate ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. Conclusion</head><p>This study has shown how NLP possesses the key characteristics of a technoculture, particularly by synthesizing and enabling the circulation of cultural material, and negating the effects of time.</p><p>A deeper analysis would be desirable; however, it would be beyond the scope of this paper. This work has also looked into the hegemonic elements of NLP, including how structural inequalities simultaneously influence and are held up by the technology; its tendency to misrepresent, stereotype and discriminate against many identities and demographic groups; and its positioning of western standards as the default. NLP, acting as a technoculture, perpetuates existing imbalances and reinforces dominant cultural narratives. As NLP tools' usage increases in various applications, their hegemonic effects will manifest at a bigger scale, amplifying the voices of some at the expense of others' exclusion.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: AI training data on Common Crawl across language groups<ref type="bibr" target="#b2">(Dawson et al., 2024)</ref> </figDesc><graphic coords="7,171.15,254.54,268.89,161.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>provides a summary of the search, selection and inclusion results.</figDesc><table><row><cell>N=</cell><cell>IEEE Xplore</cell><cell>ACM DL</cell><cell>Google Scholar</cell><cell>Total</cell></row><row><cell cols="2">Search results 163</cell><cell>116</cell><cell>468</cell><cell>747</cell></row><row><cell>Selected</cell><cell>23</cell><cell>8</cell><cell>54</cell><cell>85</cell></row><row><cell>Screened</cell><cell>23</cell><cell>8</cell><cell>47</cell><cell>78</cell></row><row><cell>Included</cell><cell>3</cell><cell>2</cell><cell>15</cell><cell>20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Number of articles (N) yielded, selected, screened and included in the review.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>An example of the prompt and output can be found here: https://chatgpt.com/share/680de0ff-8e6c-8013-861b-2cf3385bfb4e</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Aksoy</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2412.18863</idno>
		<idno type="arXiv">arXiv:2412.18863</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2412.18863" />
		<title level="m">Whose Morality Do They Speak? Unraveling Cultural Bias in Multilingual Language Models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Brubaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Semaan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3613904.3642669</idno>
		<ptr target="https://doi.org/10.1145/3613904.3642669" />
		<title level="m">The ``Colonial Impulse&quot; of Natural Language Processing: An Audit of Bengali Sentiment Analysis Tools and Their Identity-based Biases. Proceedings of the CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="1" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><surname>Dawson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Mosunmola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pocker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Dandekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dandekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Panat</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2410.01811</idno>
		<idno type="arXiv">arXiv:2410.01811</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2410.01811" />
		<title level="m">Evaluating Cultural Awareness of LLMs for Yoruba, Malayalam, and English</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Discrimination Bias Detection Through Categorical Association in Pre-Trained Language Models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Dusi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Arici</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Emilio Gerevini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Putelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Serina</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2024.3482010</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2024.3482010" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="162651" to="162667" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">BERTAQA: How Much Do Language Models Know About Local Culture?</title>
		<author>
			<persName><forename type="first">J</forename><surname>Etxaniz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Azkune</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Soroa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">L</forename><surname>De Lacalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Epistemic Injustice</title>
		<author>
			<persName><forename type="first">M</forename><surname>Fricker</surname></persName>
		</author>
		<idno type="DOI">10.1093/acprof:oso/9780198237907.001.0001</idno>
		<ptr target="https://doi.org/10.1093/acprof:oso/9780198237907.001.0001" />
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Green</surname></persName>
		</author>
		<idno type="DOI">10.1177/1329878X0109800105</idno>
		<ptr target="https://doi.org/10.1177/1329878X0109800105" />
		<title level="m">Technoculture: Another Term That Means Nothing and Gets Us Nowhere? Media International Australia</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="11" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Diversity and language technology: How language modeling bias causes epistemic injustice</title>
		<author>
			<persName><forename type="first">P</forename><surname>Helm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Bella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Giunchiglia</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10676-023-09742-6</idno>
		<ptr target="https://doi.org/10.1007/s10676-023-09742-6" />
	</analytic>
	<monogr>
		<title level="j">Ethics and Information Technology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pistilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Menédez-González</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">D D</forename><surname>Duran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Panai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kalpokiene</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Bertulfo</surname></persName>
		</author>
		<title level="m">The Ghost in the Machine has an American accent: Value conflict in GPT-3</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Concept of Cultural Hegemony: Problems and Possibilities</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J J</forename><surname>Lears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">The American Historical Review</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="567" to="593" />
			<date type="published" when="1985-06">1985. Jun., 1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">CULTURE-GEN: Revealing Global Cultural Perception in Language Models through Natural Language Prompting</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Santy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Sorensen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Dziri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2404.10199</idno>
		<idno type="arXiv">arXiv:2404.10199</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2404.10199" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Naous</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.14456</idno>
		<idno type="arXiv">arXiv:2305.14456</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.14456" />
		<title level="m">Having Beer after Prayer? Measuring Cultural Bias in Large Language Models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ChatGPT Label: Comparing the Quality of Human-Generated and LLM-Generated Annotations in Low-Resource Language NLP Tasks</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Nasution</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Onan</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2024.3402809</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2024.3402809" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="71876" to="71900" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Pawar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L.-A</forename><surname>Kaffee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Augenstein</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2502.11995</idno>
		<idno type="arXiv">arXiv:2502.11995</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2502.11995" />
		<title level="m">Presumed Cultural Identity: How Names Shape LLM Responses</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Plaza-Del-Arco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Paoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2407.06908</idno>
		<idno type="arXiv">arXiv:2407.06908</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2407.06908" />
		<title level="m">Divine LLaMAs: Bias, Stereotypes, Stigmatization, and Emotion Representation of Religion in Large Language Models</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Improving Language Understanding by Generative Pre-Training</title>
		<author>
			<persName><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ChatGPT and World History Essays: An Assignment and its Insights into the Coloniality of Generative AI</title>
		<author>
			<persName><forename type="first">K</forename><surname>Rice</surname></persName>
		</author>
		<idno type="DOI">10.33043/67bdga4z9</idno>
		<ptr target="https://doi.org/10.33043/67bdga4z9" />
	</analytic>
	<monogr>
		<title level="j">Teaching History: A Journal of Methods</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="55" />
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Unveiling Sentiments: A Deep Dive Into Sentiment Analysis for Low-Resource Languages-A Case Study on Hausa Texts</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Shehu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Usman Majikumna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bashir Suleiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Luka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Md</forename><forename type="middle">H</forename><surname>Sharif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Ramadan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kusetogullari</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2024.3427416</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2024.3427416" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="98900" to="98916" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Understanding the Capabilities and Limitations of Large Language Models for Cultural Commonsense</title>
		<author>
			<persName><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2405.04655</idno>
		<idno type="arXiv">arXiv:2405.04655</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2405.04655" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cultural bias and cultural alignment of large language models</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Viberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Kizilcec</surname></persName>
		</author>
		<idno type="DOI">10.1093/pnasnexus/pgae346</idno>
		<ptr target="https://doi.org/10.1093/pnasnexus/pgae346" />
	</analytic>
	<monogr>
		<title level="j">PNAS Nexus</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">346</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>Attention is All you Need</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><surname>Wali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Mahoney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Middleton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Babaeianjelodar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Matthews</surname></persName>
		</author>
		<title level="m">Is Machine Learning Speaking my Language? A Critical Look at the NLP-Pipeline Across 8 Human Languages</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Large language models that replace human participants can harmfully misportray and flatten identity groups</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Dickerson</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2402.01908</idno>
		<idno type="arXiv">arXiv:2402.01908</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2402.01908" />
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Can LLMs Translate Cultural Nuance in Dialects? A Case Study on Lebanese Arabic</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yakhni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Chehab</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Censorship of Online Encyclopedias: Implications for NLP Models</title>
		<author>
			<persName><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Roberts</surname></persName>
		</author>
		<idno type="DOI">10.1145/3442188.3445916</idno>
		<ptr target="https://doi.org/10.1145/3442188.3445916" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="537" to="548" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
