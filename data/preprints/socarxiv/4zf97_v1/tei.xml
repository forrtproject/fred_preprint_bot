<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">From &apos;AI to Law&apos; in Healthcare: The Proliferation of Global Guidelines in a Void of Legal Uncertainty</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Barry</forename><surname>Solaiman</surname></persName>
						</author>
						<title level="a" type="main">From &apos;AI to Law&apos; in Healthcare: The Proliferation of Global Guidelines in a Void of Legal Uncertainty</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D2CA282B2C105DD7A58F5C00DB5EEAAC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-23T06:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Artificial Intelligence</term>
					<term>Healthcare</term>
					<term>Guidelines</term>
					<term>Soft Law</term>
					<term>Artificial Intelligence Act</term>
					<term>AIA</term>
					<term>AI Act</term>
					<term>Technology</term>
					<term>Medicine</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Artificial intelligence (AI) in healthcare raises significant legal and ethical concerns. AI has been deployed rapidly in healthcare systems despite a lack of legal oversight, leaving policymakers and lawmakers scrambling to catch up. This article develops a four-stage framework for multidisciplinary audiences to understand more clearly the path that has emerged from 'AI to law' using healthcare as a case study. First, AI is introduced into the healthcare system, posing unique legal challenges surrounding algorithmic autonomy, explainability and data biases. Second, legal research interprets current regulations and mainly tort law to determine whether the law can be adapted to these unique challenges, but the law can only be adapted to a point which will then require new legislation. Third, from the absence of legal oversight, policies and guidelines are created as a stopgap measure from governments and bodies such as the World Health Organization (WHO), the Food and Drug Administration (FDA), and the National Health Service (NHS). The policies and guidelines form part of a growing body of research that considers what new laws should be created -research that informs highlevel governmental and intergovernmental consultations on developing such new laws. Fourth, following consultations, new laws are devised to address the unique challenges posed by AI, such as the European Union's Artificial Intelligence Act (AIA). While this process is slow, multifaceted, and highly complex, it is argued that it is necessary owing to the unique challenge posed by AI technology.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The age of COVID can be characterised as an age of technological proliferation in healthcare. Faced with the spread of the virus, healthcare providers cancelled in-person appointments, closed wards, and postponed routine tests. Technology was designated as the necessary tool for surmounting the hurdles posed by such restrictions. Telemedicine became an immediate mainstay in many countries.</p><p>Following COVID-19, there was an increase from 43% to 95% of healthcare facilities able to provide telemedicine services in the United States (US). <ref type="bibr" target="#b21">1</ref> The United Kingdom (UK) saw 10 years' worth of advancements in telemedicine in a few weeks. <ref type="bibr" target="#b22">2</ref> This increase was to be expected in the initial stages of the pandemic, but the ramifications continue. After the initial surge, telemedicine utilisation stabilised at levels 38X higher than before the pandemic, with utilisation fluctuating between 13-17% across specialities. <ref type="bibr" target="#b23">3</ref> Behind that push has been a concurrent drive towards the sophistication of virtual care powered by artificial intelligence (AI).</p><p>Telemedicine will no longer be a video conversation between a doctor and patient but will encompass an interconnected system of virtual care. Wearable devices are being deployed to constantly monitor patients, analyse that information using AI and provide recommendations for care. <ref type="bibr" target="#b24">4</ref> AI is being combined with telemedicine to advise doctors. <ref type="bibr" target="#b26">5</ref> Virtual spaces are being created in the 'metaverse' to provide immersive care using virtual reality (VR) and augmented reality (AR). <ref type="bibr" target="#b27">6</ref> Care robots for the elderly, advanced prostheses, diagnostic systems and surgical robots form part of a broad network of AI technological advancements impacting medicine. In the UK, the National Health Service (NHS) has already deployed AI for various uses, and dozens of new technologies are set for large-scale deployment. <ref type="bibr" target="#b28">7</ref> In the US, hospitals have new dedicated AI departments. <ref type="bibr" target="#b29">8</ref> These advancements signal an increasing emphasis on preventing illnesses rather than reacting to them once they arise.</p><p>Patients will be required to take more responsibility for their own care. The investment is significant. $20bn USD was invested in healthcare AI start-ups in three quarters of 2021 alone. <ref type="bibr" target="#b30">9</ref> These developments have occurred rapidly within a void of legal uncertainty. AI raises significant ethical and legal concerns about the standard of care, informed consent, data discrimination, data privacy, cybersecurity, medical device regulation and more. However, there are no laws on AI. Policymakers and lawmakers are scrambling to catch up, resulting in a unique paradigm that this article seeks to chart. From the legal void, guidelines and codes of conduct have emerged since 2019. Those guidelines and codes have sought to recommend broad principles for the development of AI. The broad principles have laid a foundation for the growth of the first major proposed law on AI -the Artificial Intelligence Act (AIA), a regulation in the European Union (EU), which represents the culmination of a development process.</p><p>These developments in AI elucidate a four-stage process that has emerged on the path towards law (a process that can be well illustrated in the healthcare space). First, technology (AI) has made significant inroads into healthcare. While its use has many potential benefits, experts flag ethical and legal concerns about its use that are wholly unique. Second, researchers and entities seek to answer those concerns by interpreting current laws to determine whether they can be adapted to these unique challenges. From that analysis, it is determined that current laws can be adapted, but only up to a certain point. Consequently, entirely new laws will be required, or alternatively we should wait until these specific legal questions are tested in court (a potentially indefinite period of uncertainty). Third, in the meantime, soft law is pursued as a stopgap. Policies and guidelines are formed from so many sources that they are practically meaningless, but they are helpful for policymakers seeking to narrow down what is legally important. The guidelines form part of a growing body of research that considers what new laws should be created -research that informs high-level governmental and intergovernmental consultations on developing such new laws. Fourth, from those consultations, proposed law is created that devises specific legal provisions which are designed to deal with the unique challenges posed by the new technology. The proposals will be subject to lobbying from interested parties in the following months and years until a final version is agreed upon and enacted. This process is summarised below. Ultimately, this process is slow, multifaceted, and highly complex, but it is argued that it is necessary owing to the unique challenge that the technology poses. <ref type="bibr" target="#b31">10</ref> Additionally, the intention of this paper is to act as a reference point across disciplines for how AI laws and guidelines have arisen in the healthcare space and why they arose in the order in which they did. Concluding remarks emphasise the importance of interdisciplinarity in the field owing to the specific challenges posed by AI. The sections below provide an analytical account of the four-stage process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">New Technology: New Problems</head><p>AI can be defined as a range of algorithm-based technologies that solve complex tasks by carrying out functions that previously required human thinking. <ref type="bibr" target="#b32">11</ref> The technology is not new, having existed in rudimentary forms since the 1940s.<ref type="foot" target="#foot_4">foot_4</ref> Its use in healthcare dates back to the 1970s in limited ways, but in recent years, complex forms of AI have started to be trialled and deployed on a larger scale in hospital settings. These complex systems have the potential to intersect with a doctor's responsibility by making diagnoses and treatment recommendations in a manner that did not exist in prior decades. At present, clinicians retain responsibility for the decisions made, but a shift in that paradigm may occur owing to autonomy, explainability and data concerns. These concerns make AI complicated to regulate. AI systems are autonomous, unlike other forms of medical devices. A heart rate monitor, an x-ray or other monitoring and diagnostic systems are static, providing a range of results based on their pre-programming. Once they go to market, they will function in the same manner every time they are used. However, AI algorithms can evolve based on the data they receive. They continuously recalibrate their internal equations without human input and become more accurate over time based on those recalibrations. Consequently, their results may change over time as they 'learn'. Existing laws are not equipped to deal with this challenge. The</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>New technolog y</head><p>Current laws inadequa te Soft law stopgap New law original device that was legally approved may no longer reflect the device that has subsequently evolved.</p><p>Another complication is 'explainability'. When a doctor makes a recommendation to a patient, they can give precise and reasoned explanations for their recommendation. A back-and-forth conversation can be undertaken to explore those reasons in more detail. If a doctor relies on information from a diagnostic device, they can reliably indicate why that information is correct. For example, a positive result for a disease determined by a kit approved by regulators. AI systems suffer from the 'black-box' problem. In many cases, no one truly knows why the system made a recommendation or a decision because the algorithms are so complex that they are undecipherable -even to the scientists who developed them. This has implications for informed consent and liability.</p><p>There are also data concerns. AI has the potential to exacerbate existing discrimination. AI systems are initially trained on real-world data. However, if that data underrepresents certain groups or reflects biases in real-world scenarios, then its recommendations may be influenced by that information. This could have implications for the recommendations given to patients. There are also data privacy and security concerns arising from the plethora of data processed by AI from multiple sources, databases, and jurisdictions. <ref type="bibr" target="#b34">13</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Inadequacy of Current Laws</head><p>One of the early responses of researchers has been to explore how current laws may apply or be adapted to these challenges posed by AI. Such research is helpful because it may resolve some pending concerns or provide an interim solution until specific laws are devised (or current laws are tested in court). This process has been alluded to by Cohen, who notes that as new technologies arise, it is not unusual to struggle to determine whether that technology 'can be assimilated into existing doctrines or whether it requires something new'. <ref type="bibr" target="#b35">14</ref> He notes how the common law (the doctrinal analogical approach) is a familiar approach to this recurring phenomenon in that it 'mirrors the way common law judges have for centuries dealt with new issues' by drawing examples with similar previous cases or hypothetical examples. <ref type="bibr" target="#b36">15</ref> Cohen makes this point in his research on informed consent, exploring how US jurisprudence may apply to AI in health. <ref type="bibr" target="#b37">16</ref> He divides his analysis into a doctrinal examination of existing law followed by empirical and <ref type="bibr" target="#b34">13</ref> For a more detailed overview of the challenges in healthcare see, Sara</p><p>Gerke, Timo Minssen and Glenn Cohen, 'Ethical and Legal Challenges of Artificial Intelligence-Driven Healthcare' in Adam Bohr and Memarzadeh (eds), Artificial Intelligence in Healthcare (Academic Press 2020) 295-336. These scholars are among a group of legal academics who have published widely on the law of AI in healthcare since circa 2018, publishing in leading journals and books with colleagues in several disciplines. 14 I Glenn Cohen, 'Informed Consent and Medical Artificial Intelligence: What to Tell the Patient?' (2020) 108 The Georgetown Law Journal 1425, 1441. 15 ibid. 16 ibid 1245.</p><p>normative considerations of AI/ML (machine learning) in medicine. Thus, on the doctrinal examination, he examines the development of case law on the physician-based versus patient-based standards of disclosure. <ref type="bibr" target="#b38">17</ref> Answers from such case law are not clear-cut, and Cohen highlights the need to consider more 'penumbral' cases to think more clearly about how AI fits into the informed consent picture. <ref type="bibr" target="#b39">18</ref> However, while those penumbral cases 'provide some useful analogies', he notes that 'it may be hard to ground legal obligations of informed consent for medical AI/ML in the current doctrine'. <ref type="bibr" target="#b40">19</ref> Nevertheless, Cohen attempts (as far as possible) to provide an answer based on the doctrine of what a patient should be told when AI is used in decision-making relating to their care. He finds that the 'doctrinal-analogical path' leads to 'competing possible analogies', but the general answer is that there will be no liability where patients have not been informed about the use of AI to formulate their treatment recommendations. <ref type="bibr" target="#b41">20</ref> On the empirical front, one could derive an answer on informed consent by measuring what physicians who use AI (or other non-AI decisionsupport systems) actually do in terms of disclosure to patients. One can also examine what doctors who do not use such systems believe the standard ought to be or what the patients view as material. <ref type="bibr" target="#b42">21</ref> The problem with empirical approaches is that they may conflate the law's objective reasonable person standard with a study representing a cohort of subjective views. Translating information gathered from patients and doctors may be a value-laden process. <ref type="bibr" target="#b43">22</ref> On the normative approach, there are questions about what informed consent is for, and Cohen finds that 'the best we can do is identify a few cases where overlap between normative theories of informed consent makes stronger the case for disclosure'. <ref type="bibr" target="#b44">23</ref> Similar challenges arise in the medical liability context. From the US perspective, Price, Gerke and Cohen examine physician, institutional, and developer liability under existing legal doctrine, concluding that there is 'substantial uncertainty' about how the relevant factors will fall into place once cases come to court. <ref type="bibr" target="#b45">24</ref> For physician liability, the authors consider the interplay between AI and the standard of care under malpractice law. They find that doctors are incentivised to use AI only for confirmatory advice. Doctors can only be sure of avoiding liability if they make decisions under the existing standard of care, even where AI <ref type="bibr" target="#b38">17</ref> ibid 1433. <ref type="bibr" target="#b39">18</ref> ibid 1434. <ref type="bibr" target="#b40">19</ref> ibid. <ref type="bibr" target="#b41">20</ref> ibid 1428 &amp; 1448. <ref type="bibr" target="#b42">21</ref> ibid 1449-1452. <ref type="bibr" target="#b43">22</ref> ibid. <ref type="bibr" target="#b44">23</ref> ibid 1461. <ref type="bibr" target="#b45">24</ref> W. Nicholson Price, Sara Gerke and I Glenn Cohen, 'Liability for Use of Artificial Intelligence in Medicine' in Barry Solaiman and I Glenn Cohen, Research Handbook on Health, AI and the Law (Edward Elgar Publishing 2024) p.20. Available at SSRN, <ref type="url" target="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4115538">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4115538</ref> accessed 10 May 2023.</p><p>systems make novel and correct recommendations that do not comport with the existing standard. <ref type="bibr" target="#b46">25</ref> However, the courts will make the 'ultimate determination' on such issues when liability and AI matters arise in a case. <ref type="bibr" target="#b47">26</ref> On institutional liability, the authors examine the well-trodden path of derivative or vicarious liability whereby the medical institution is liable for the actions of a negligent doctor. <ref type="bibr" target="#b48">27</ref> Matters become more complicated when there is consideration of AI as an autonomous tortfeasor, but possibilities remain speculative. <ref type="bibr" target="#b49">28</ref> The limits of current legal doctrine are also highlighted under direct liability for a hospital's use of AI, with the authors noting the problems of specifying the scope of a theory of negligent evaluation of medical AI. <ref type="bibr" target="#b50">29</ref> On developer liability, courts have been reluctant to hold developers liable under product liability law. <ref type="bibr" target="#b51">30</ref> Further, gaining approval from the FDA for medical devices (an existing legal pathway) may offer some protection against liability (although not definitively). <ref type="bibr" target="#b52">31</ref> Several other articles have also examined similar avenues of liability under existing doctrine. Griffin explores medical liability and product liability, among others. <ref type="bibr" target="#b53">32</ref> Concerns about data biases, bad data and discrimination are all placed within existing theories of 'design defects' under product liability. <ref type="bibr" target="#b54">33</ref> There are examinations of the limitations of data protection and privacy laws in the US and EU in the context of big data used in AI. <ref type="bibr" target="#b55">34</ref> Froomkin et al. also consider possible changes to torts rules, such as reviving previously established torts rules, creating exceptions to current rules or adjusting the definition of the standard of care. <ref type="bibr" target="#b56">35</ref> Price queries how torts liability may apply to black-box medicine. <ref type="bibr" target="#b57">36</ref> Schweikart explores how AI will shape medical tort law. <ref type="bibr" target="#b58">37</ref> He explores the interaction of AI with medical malpractice, product liability, vicarious liability and <ref type="bibr" target="#b46">25</ref> ibid 4. 26 ibid 6. 27 ibid 8. 28 ibid 9-10. 29 ibid 12. 30 ibid 14. 31 ibid 15; see also, Barbara J Evans and Frank Pasquale, 'Product Liability Suits for FDA-Regulated AI/ML Software' in I Glenn Cohen et al, The Future of Medical Device Regulation: Innovation and Protection (CUP 2022) 22-35. 32 Frank Griffin, 'Artificial Intelligence and Liability in Healthcare' (2021) 31 Health Matrix 65. 33 ibid 78-88. 34 I Glenn Cohen and Michelle M Mello, 'Big Data, Big Tech, and Protecting Patient Privacy' (2019) 322(12) JAMA 1141-1142; Solaiman (n 12) 1117-1129. 35 A Michael Froomkin, Ian Kerr and Joelle Pineau, 'When AIs Outperform Doctors: Confronting the Challenges of a Tort-Induced Over-Reliance on Machine learning' (2019) 61(33) Arizona Law Review 33, 94-98. 36 W. Nicholson Price II, 'Medical Malpractice and Black-Box Medicine' in I Glenn Cohen et al, Big Data, Health Law, and Bioethics (CUP 2018) 295, 296. 37 Scott J Schweikart, 'Who Will Be Liable for Medical Malpractice in the Future? How the Use of Artificial Intelligence in Medicine Will Shape Medical Tort Law' (2021) 22(2) Minnesota Journal of Law, Science &amp; Technology 1.</p><p>informed consent and considers possible legal evolutions like AI personhood, common enterprise liability, and a new standard of care. <ref type="bibr" target="#b59">38</ref> On the regulatory front, Price et al. consider how AI innovations interact less with legal regimes that scholars traditionally conceive as shaping medical innovation in the US. <ref type="bibr">39</ref> There is a 'relative weakness' of legal regimes for AI technologies spanning FDA regulation, patent law and insurance reimbursement. <ref type="bibr" target="#b61">40</ref> Indeed, Gerke argues for a new regulatory framework for AI-based medical devices, finding that the FDA incompletely regulates health AI-based products. <ref type="bibr">41</ref> In Europe, Solaiman and Bloom have highlighted the inadequacies of existing regulations for dealing with the lack of explainability in wearable AI medical devices. <ref type="bibr">42</ref> They argue that regulations should move towards a more sciencefocussed model premised on minimum standards of explainability that ought to be determined. <ref type="bibr">43</ref> It is beyond the scope of this paper to highlight all research in the field, but this small sample of articles reflect a pattern that can be seen in medical AI research around the world. They consider how current laws may be adapted but conclude that such exercises only take us so far. Consequently, they identify gaps where new laws will be required or note that we should wait until those specific legal questions are tested in court (a potentially indefinite period of uncertainty).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">A Soft Law Stopgap</head><p>While that research process has occurred, attempts have been made to formulate policies and guidelines that act largely as a stopgap measure until legislation is created. More than 100 guidelines were developed around the world between 2015-2020 by private companies, governmental and intergovernmental agencies, researchers, and professional organisations. <ref type="bibr" target="#b66">44</ref> Those guidelines have helped inform policies on AI, which can now be found in more than 60 countries. <ref type="bibr">45</ref> Guidelines may espouse high-level principles premised on autonomy, non-maleficence, beneficence, and justice that developers should consider as they develop AI systems. They may also provide specific recommendations for gaining regulatory approval. The policies and guidelines are not limited to medicine, but the figures illustrate the scale at which they have proliferated. Here, some significant policies and guidelines are highlighted to underscore their influence on the legal pathway that may be (or may not be) ultimately pursued.</p><p>Thus, in the US, the Trump administration signalled a light-touch approach regulating AI following a White House summit in which a 'free market' approach to AI was championed that would involve removing regulatory barriers to AI innovation. <ref type="bibr">46</ref> That was followed by an Executive Order that outlined principles such as reducing barriers to the use of AI to promote its use while fostering public trust and confidence in AI and protecting civil liberties, privacy and American values. <ref type="bibr">47</ref> Final guidance was issued in 2020, prioritising the need to encourage innovation and growth in AI. <ref type="bibr" target="#b8">48</ref> The guidance noted the importance of fostering public trust in AI because of its risks to privacy, individual rights, personal choice, civil liberties, public health, safety and security.</p><p>Validation, regulatory and non-regulatory approaches would be crucial in mitigating such risks. <ref type="bibr">49</ref> These efforts have culminated in a proposed nonbinding AI Bill of Rights that includes principles on safety, discrimination, and data privacy. <ref type="bibr" target="#b9">50</ref> While these are non-binding, they are accompanied by a handbook providing suggestions for incorporating the principles into practice.</p><p>In the EU, a political commitment was made to legislate on the human and ethical implications of AI. <ref type="bibr" target="#b10">51</ref> Research was also commissioned by the European Commission outlining ethics guidelines for trustworthy AI. <ref type="bibr" target="#b11">52</ref> A White Paper was published thereafter setting out the policy objectives premised on encouraging the use of AI while mitigating risks on data privacy, non-discrimination and liability. <ref type="bibr" target="#b12">53</ref> The White Paper also examined the limitations of existing legislation in the EU and determined that there should be provisions covering training data, record keeping, robustness and accuracy, and human oversight, amongst others. <ref type="bibr">54</ref> The European Council recommended that concerns surrounding complexity, bias, and the autonomous nature of AI required addressing to ensure the protection of fundamental rights. <ref type="bibr" target="#b13">55</ref> The European Parliament also published several (non-binding) resolutions covering ethics, liability, copyright and criminal matters. <ref type="bibr" target="#b14">56</ref> These developments have trickled down into the health space at a high level. In 2019 the FDA published a discussion paper for AI-based software as a medical device where a 'total product lifecycle regulatory approach' was sought for such devices owing to the ability of AI to adapt and improve from real-world use. <ref type="bibr" target="#b15">57</ref> The FDA then released an Action Plan in 2021 that emphasised its focus on developing a tailored regulatory framework, including supporting regulatory science efforts to evaluate algorithms and eliminating data biases. <ref type="bibr" target="#b16">58</ref> That Action Plan has resulted in clearer (although non-binding) guidance. This included guidance for premarket submission applications for radiological devices that utilise AI. <ref type="bibr">59</ref> The FDA also released guidance on AI-based clinical decision support tools, which broadened the scope of devices that should receive regulatory approval as medical devices. <ref type="bibr">60</ref> In 2021, the World Health Organization (WHO) published guidance on the ethics and governance of AI for health, which outlined relevant laws on human rights and data protection and also outlined key principles that included protecting autonomy and ensuring explainability and transparency. <ref type="bibr" target="#b17">61</ref> In the UK, the NHS set out policies and guidelines for developing a governance framework on AI in health. <ref type="bibr" target="#b18">62</ref> Its report outlined key principles on explainability, effectiveness and commercial strategies that should be considered in a governance framework and outlined considerations on data protection. The non-binding principles were detailed and built upon the relevant literature in the field. <ref type="bibr">63</ref> Again, these are but a small sample of policies and guidelines that exist (albeit the most significant). They serve to elucidate the process that has occurred alongside academic research into the law. In the current void of legal uncertainty, there exists a proliferation of policies and guidelines that seek to identify the relevant issues, create dialogue with stakeholders to decipher them and provide normative and tentative nonbinding recommendations that ought to be followed until recommendations become concretised into a more binding format. At this transient stage, it is hard to ascertain the effectiveness of such guidance It is unclear to what extent developers pay attention to them nor how they determine what to pay attention to. What is clear is that they inform high-level governmental and intergovernmental consultations on developing new laws.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">New Laws: New Solutions</head><p>The culmination of some of these processes through the EU's proposed regulation and directives can now be seen. For the proposed directives, there is the AI Liability Directive (that adapts non-contractual civil liability rules to AI) and the Product Liability Directive (that focuses on strict liability for defective products, including AI products). <ref type="bibr" target="#b19">64</ref> Together, they seek to resolve the challenging distinction between products and services in the AI domain through a rebuttable presumption of causality and introduce a right of access to evidence, among other changes. <ref type="bibr" target="#b20">65</ref> This is a method similar to academic research in the second stage of the process, whereby existing rules are adapted to the challenges of AI. The key difference is that they are adapted into law instead of being the postulation of academic research.</p><p>The most critical development has been the Artificial Intelligence Act (AIA), a proposed regulation that the EU claims is consistent with other Union policies, such as the White Paper on AI. <ref type="bibr">66</ref> The AIA creates a risk classification system for AI systems that either pose an 'unacceptable risk', 'high risk' or 'low risk'. <ref type="bibr">67</ref> The proposed regulation is detailed, setting out prohibited AI practices, classification systems, requirements for compliance, human oversight, and more. The regulation also creates obligations for developers, users, distributors, and others and establishes a governance structure and related institutions. There will also be postmarket monitoring requirements, enforcement mechanisms and penalties.</p><p>The AIA has been criticised as being insufficient. 68 This is particularly the case for its application to the health domain. <ref type="bibr">69</ref> Nevertheless, once enacted, it will represent the culmination of the process highlighted in this paper, through its position as the first major law on AI that brings together considerations from research and guidelines in a bespoke manner (rather than the doctrinal analogical approach that has pervaded so far). Instead of adapting existing laws, the field is shifting toward dealing with AI's specific challenges through novel requirements. As such it is a manifestation of new law to deal with a new challenge that previous paradigms could not anticipate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concluding thoughts</head><p>This four-stage process demarcates more clearly the path that has arisen, which will soon lead to law in the AI and health space. It is hoped that the framework will be a useful reference point for stakeholders interested in this area. From a wider perspective in the legal field, there is also a broader narrative emerging. Technology develops rapidly and is often only subject to appropriate legal and ethical oversight long after it has been deployed, having caused heightened risk and harm to users. Legal researchers must anticipate challenges before they arise and provide pre-emptive solutions that can help mitigate risks rather than working in silos. That requires greater integration of perspectives from the different fields of academia, the private sector and government, and the institutional support necessary for individuals working in those commission-proposes-ai-liability-directive-and-modernised-product-liability-directive accessed 10 May 2023. 66 AIA (n 56) 5. <ref type="bibr">67</ref> ibid 12. 68 Vera Lucia Raposo, 'Ex Machina: Preliminary Critical Assessment of the European Draft Act on Artificial Intelligence' (2022) 30 International Journal of Law and Information Technology 88. 69 Hannah Van Kolfschooten, 'EU Regulation of Artificial Intelligence: Challenges for Patients' Rights (2022) 59 Common Market Law Review 81.</p><p>entities to be given the time and the recognition to participate in such endeavours.</p><p>Such multidisciplinary endeavours already exist between medical lawyers, bioethicists, engineers, computer scientists and the medical profession to some degree, as revealed by the broad range of submissions invited by intergovernmental and governmental entities on developing guidelines and laws. T here are also major research grants at a local and international levels. For example, Horizon Europe has funded a project called CLASSICA to deliver and clinically validate an AI-based clinical decision support system, which rapidly identifies cancerous tumours and maps their distribution. <ref type="bibr">70</ref> That project involves law experts, high-tech SMEs, and hospitals. <ref type="bibr">71</ref> Hamad Bin Khalifa University (HBKU) in Qatar has funded a research grant to develop AI guidelines for healthcare researchers. That grant involves experts in law, science and engineering, health and life sciences, Islamic studies, and biomedicine. <ref type="bibr" target="#b25">72</ref> While promising collaborations have arisen, more can be done to ensure more embedded interdisciplinarity. COVID-19 exaggerated the existing dichotomy of lawyers eager to catch up owing to the extremely rapid deployment of technology in healthcare, but it also highlighted the flaws in that process. By elucidating the process that has arisen from 'AI to law' it can more clearly be seen where research endeavours may best be served.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The Path from AI to Law</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_0"><p>Mount Sinai, 'Mount Sinai Launches Department of Artificial Intelligence and HumanHealth' (11 Oct 2021) available at https://www.mountsinai.org/about/newsroom/2021/mount-sinai-launches-department-ofartificial-intelligence-and-human-health accessed 10 May 2023.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_1"><p>Alan S Young, 'AI in Healthcare Startups and Special Challenges' (2022) 6 Intelligence Based Medicine.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_2"><p>The process is also not unique to healthcare and can likely be illustrated in other subfields where AI is used, but there is a strong body of literature in healthcare that be used to illustrate it.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_3"><p>Information Commissioner's Office (UK), 'Definition of AI', available at https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/explainingdecisions-made-with-artificial-intelligence/part-1-the-basics-of-explaining-ai/ definitions/#:~:text=Artificial%20Intelligence%20(AI) %20can%20be,that%20previously%20required%20human%20thinking accessed 10 May 2023.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_4"><p>For brief historical overview, seeBarry  Solaiman, 'Addressing Access with Artificial Intelligence: Overcoming the Limitations of Deep Learning to Broaden Remote Care Today' (2021) 51 The University of Memphis Law Review 1103, 1108.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">New Innovation Models in Medical AI</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename><surname>Nicholson Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Washington Law Review</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="1121">2022. 1121</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Health AI for Good Rather Than Evil? The Need for a New Regulatory Framework for AI-Based Medical Devices</title>
		<author>
			<persName><forename type="first">Sara</forename><surname>Gerke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Yale Journal of Health Policy, Law, And Ethics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">AI, Explainability, and Safeguarding Patient Safety in Europe: Toward a Science-Focused Regulatory Model</title>
		<idno type="DOI">10.1017/9781108975452.008</idno>
		<ptr target="https://doi.org/10.1017/9781108975452.008" />
	</analytic>
	<monogr>
		<title level="m">The Future of Medical Device Regulation: Innovation and Protection</title>
		<editor>
			<persName><forename type="first">Glenn</forename><surname>Cohen</surname></persName>
		</editor>
		<meeting><address><addrLine>CUP</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="volume">91</biblScope>
		</imprint>
	</monogr>
	<note>Regulation 2017/745 Regulation 2017/746 EU) /Product Liability Directive (1985/374 Vitro Diagnostic Medical Device Regulation (IVDR)</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Toolbox: Dynamics of AI Principles</title>
		<author>
			<persName><forename type="first">Bloom</forename><surname>Solaiman</surname></persName>
		</author>
		<ptr target="https://aiethicslab.com/big-picture/accessed10" />
	</analytic>
	<monogr>
		<title level="j">AI Ethics Lab</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page">102</biblScope>
			<date type="published" when="2023-05">May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">National AI Policies &amp; Strategies</title>
		<author>
			<persName><surname>Oecd</surname></persName>
		</author>
		<author>
			<persName><surname>Ai</surname></persName>
		</author>
		<ptr target="https://oecd.ai/en/dashboards/overviewaccessed10" />
		<imprint>
			<date type="published" when="2023-05">May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Summary of the 2018 White House Summit on Artificial Intelligence for American Industry</title>
		<ptr target="https://trumpwhitehouse.archives.gov/wp-content/uploads/2018/05/Summary-Report-of-White-House-AI-Summit.pdf" />
		<imprint>
			<date type="published" when="2018-05-10">May 10, 2018. 10 May 2023</date>
			<biblScope unit="page" from="2" to="3" />
		</imprint>
		<respStmt>
			<orgName>White House Office of Science and Technology Policy</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Sections</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<ptr target="https://web.archive.org/web/20201130023307/https:/www.whitehouse.gov/presidential-actions/executive-order-maintaining-american-leadership-artificial-intelligence/accessed10" />
		<title level="m">Executive Order on Maintaining American Leadership in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019-02-11">Feb 11, 2019. May 2023</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Guidance for Regulation of Artificial Intelligence Applications</title>
		<author>
			<persName><forename type="first">T</forename><surname>Russel</surname></persName>
		</author>
		<author>
			<persName><surname>Vought</surname></persName>
		</author>
		<idno>M-21-06</idno>
		<ptr target="https://www.whitehouse.gov/wp-content/uploads/2020/11/M-21-06.pdf" />
	</analytic>
	<monogr>
		<title level="m">Executive Office of the President Office of Management and Budget</title>
		<imprint>
			<date type="published" when="2020-11-17">Nov 17, 2020. May 2023. 49 ibid 3</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People</title>
		<author>
			<persName><forename type="first">The</forename><forename type="middle">White</forename><surname>House</surname></persName>
		</author>
		<ptr target="https://www.whitehouse.gov/ostp/ai-bill-of-rights/accessed10" />
		<imprint>
			<date type="published" when="2022-10-04">4 October 2022. May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Union that Strives for More: Agenda for Europe</title>
		<author>
			<persName><surname>Ursula Von Der Leyen</surname></persName>
		</author>
		<ptr target="https://op.europa.eu/en/publication-detail/-/publication/43a17056-ebf1-11e9-9c4" />
	</analytic>
	<monogr>
		<title level="j">European Commission</title>
		<imprint>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2019-07-16">16 July 2019. e-01aa75ed71a1 accessed 10 May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Ethics Guidelines for Trustworthy AI: High Level Expert Group on Artificial Intelligence</title>
		<ptr target="https://ec.europa.eu/futurium/en/ai-alliance-consultation.1.html" />
	</analytic>
	<monogr>
		<title level="j">European Commission</title>
		<imprint>
			<date type="published" when="2019-04-08">8 April 2019. May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">White Paper on Artificial Intelligence -A European Approach to Excellence and Trust</title>
	</analytic>
	<monogr>
		<title level="j">European Commission</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page">54</biblScope>
			<date type="published" when="2020-02-19">19 Feb 2020. 2020</date>
			<publisher>COM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Presidency Conclusions: The Charter of Fundamental Rights in the Context of Artificial Intelligence and Digital Change</title>
		<ptr target="https://www.consilium.europa.eu/media/46496/st11481-en20.pdf" />
		<imprint>
			<date type="published" when="2020-10-21">21 Oct 2020. 10 May 2023</date>
		</imprint>
		<respStmt>
			<orgName>Council of the European Union</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A summary of these can be found here, see</title>
		<ptr target="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A52021PC0206" />
	</analytic>
	<monogr>
		<title level="m">AIA &apos;Proposal For a Regulation Of The European Parliament And Of The Council Laying Down Harmonised Rules On Artificial Intelligence (Artificial Intelligence Act) And Amending Certain Union Legislative Acts&apos; European Commission</title>
		<imprint>
			<date type="published" when="2021-04-21">21 April 2021. 2021/0106. 10 May 2023</date>
		</imprint>
	</monogr>
	<note>COD) SEC(2021) 167 final, p.2</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Proposed Regulatory Framework for Modifications to Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD) -Discussion Paper and Request for Feedback</title>
		<ptr target="https://www.fda.gov/media/122535/downloadaccessed10" />
	</analytic>
	<monogr>
		<title level="j">FDA</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2019-04">April 2019. May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<ptr target="https://www.fda.gov/media/109618/downloadaccessed10" />
		<title level="m">Artificial Intelligence/Machine Learning (AI/ML)-Based Software as a Medical Device (SaMD) Action Plan&apos; US Food &amp; Drug Administration</title>
		<imprint>
			<date type="published" when="2021-01">Jan 2021. May 2023. Sept 28, 2022. May 2023</date>
		</imprint>
	</monogr>
	<note>Clinical Decision Support Software: Guidance for Industry and Food and Drug Administration Staff&apos; FDA</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<ptr target="https://www.who.int/publications/i/item/9789240029200accessed10" />
		<title level="m">Ethics and Governance of Artificial Intelligence for Health: WHO Guidance&apos; WHO</title>
		<meeting><address><addrLine>Geneva</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-05">2021. May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<ptr target="https://transform.england.nhs.uk/media/documents/NHSX_AI_report.pdf" />
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence: How to Get it Right</title>
		<imprint>
			<date type="published" when="2019-01-01">1 Jan 2019. 10 May 2023. 63 ibid 26-41</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Proposal for a Directive Of The European Parliament And Of The Council on adapting non-contractual civil liability rules to artificial intelligence</title>
		<ptr target="https://ec.europa.eu/info/sites/default/files/1_1_197605_prop_dir_ai_en.pdfaccessed10" />
	</analytic>
	<monogr>
		<title level="j">AI Liability Directive</title>
		<imprint>
			<biblScope unit="volume">496</biblScope>
			<date type="published" when="2022">28 Sept 2022. 2022</date>
			<publisher>COM</publisher>
		</imprint>
		<respStmt>
			<orgName>European Commission</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">European Commission Proposes AI Liability Directive and Modernised Product Liability Directive&apos; Allen &amp; Overy</title>
		<author>
			<persName><forename type="first">Anna</forename><surname>Van Der Leeuw-Veiksha</surname></persName>
		</author>
		<ptr target="https://www.allenovery.com/en-gb/global/blogs/digital-hub/european-REFERENCES" />
		<imprint>
			<date type="published" when="2022-10-07">7 Oct 2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><surname>Marr</surname></persName>
		</author>
		<ptr target="https://www.forbes.com/sites/bernardmarr/2022/02/23/the-amazing-possibilities-of-healthcare-in-the-metaverse/?sh=72fe5fc19e5c" />
		<title level="m">The amazing possibilities of healthcare in the metaverse</title>
		<imprint>
			<publisher>Forbes</publisher>
			<date type="published" when="2022-02-23">2022, February 23</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Telemedicine arrives in the U.K.: 10 years of change in one week</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mueller</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/2020/04/04/world/europe/telemedicine-uk-coronavirus.html" />
	</analytic>
	<monogr>
		<title level="j">New York Times</title>
		<imprint>
			<date type="published" when="2020-04-04">2020, April 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Bestsennyy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gilbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rost</surname></persName>
		</author>
		<ptr target="https://www.mckinsey.com/industries/healthcare-systems-and-services/our-insights/telehealth-a-quarter-trillion-dollar-post-covid-19-reality" />
		<title level="m">Telehealth: A quartertrillion-dollar post-COVID-19 reality? McKinsey &amp; Company</title>
		<imprint>
			<date type="published" when="2009">2021, July 9</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The health care benefits of combining wearables and AI</title>
		<author>
			<persName><forename type="first">M</forename><surname>Miyashita</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brady</surname></persName>
		</author>
		<ptr target="https://dickinsonlaw.psu.edu/team-including-dickinson-law-prof-sara-gerke-receives-eu6-million-eu-grant-research" />
	</analytic>
	<monogr>
		<title level="m">Team Including Dickinson Law Prof. Sara Gerke Receives €6 Million Eu Grant To Research Ai And Cancer Surgery</title>
		<imprint>
			<date type="published" when="2019-05-28">2019, May 28. 10 May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<ptr target="https://www.hbku.edu.qa/sites/default/files/trg_projecthighlight_barry.pdf" />
		<title level="m">HBKU Thematic Research Grant 1st Cycle: Artificial Intelligence for Precision Medicine &amp; Health Technologies: Developing a Regulatory Framework for Qatar and the Middle East</title>
		<imprint>
			<date type="published" when="2023-05-10">10 May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Telemedicine and artificial intelligence to support self-isolation of COVID-19 patients: Recent updates and challenges</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Henley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Robinson</surname></persName>
		</author>
		<idno type="DOI">10.1177/20552076221101964</idno>
		<ptr target="https://doi.org/10.1177/20552076221101964" />
	</analytic>
	<monogr>
		<title level="j">Digital Health</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The metaverse in current digital medicine</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nadarajah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ceh.2022.07.001</idno>
		<ptr target="https://doi.org/10.1016/j.ceh.2022.07.001" />
	</analytic>
	<monogr>
		<title level="j">Clinical eHealth</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="52" to="59" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<ptr target="https://www.hee.nhs.uk/news-blogs-events/news/health-education-england-publishes-roadmap-use-ai-nhs" />
		<title level="m">Health Education England publishes roadmap into use of AI in the NHS. NHS</title>
		<meeting><address><addrLine>UK</addrLine></address></meeting>
		<imprint>
			<publisher>NHS Health Education England</publisher>
			<date type="published" when="2022-02-10">2022, February 10</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<ptr target="https://www.gov.uk/government/news/36-million-boost-for-ai-technologies-to-revolutionise-nhs-care" />
		<title level="m">£36 million boost for AI technologies to revolutionise healthcare</title>
		<meeting><address><addrLine>Gov UK</addrLine></address></meeting>
		<imprint>
			<publisher>UK Government</publisher>
			<date type="published" when="2021-06-16">2021, June 16</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">Mount</forename><surname>Sinai</surname></persName>
		</author>
		<ptr target="https://www.mountsinai.org/about/newsroom/2021/mount-sinai-launches-department-of-artificial-intelligence-and-human-health" />
		<title level="m">Mount Sinai launches department of artificial intelligence and human health</title>
		<imprint>
			<date type="published" when="2021-10-11">2021, October 11</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">AI in healthcare startups and special challenges</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Young</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ibmed.2022.100042</idno>
		<ptr target="https://doi.org/10.1016/j.ibmed.2022.100042" />
	</analytic>
	<monogr>
		<title level="j">Intelligence Based Medicine</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<ptr target="https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/explaining-decisions-made-with-artificial-intelligence/part-1-the-basics-of-explaining-ai/definitions/12" />
		<title level="m">Definition of AI</title>
		<imprint>
			<publisher>Information Commissioner&apos;s Office (UK</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Addressing access with artificial intelligence: Overcoming the limitations of deep learning to broaden remote care today</title>
		<author>
			<persName><forename type="first">B</forename><surname>Solaiman</surname></persName>
		</author>
		<idno type="DOI">10.31235/osf.io/s459p</idno>
		<ptr target="https://doi.org/10.31235/osf.io/s459p" />
	</analytic>
	<monogr>
		<title level="j">The University of Memphis Law Review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1103" to="1129" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Ethical and legal challenges of artificial intelligence-driven healthcare</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gerke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1016/B978-0-12-818438-7.00009-1</idno>
		<ptr target="https://doi.org/10.1016/B978-0-12-818438-7.00009-1" />
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence in Healthcare</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Bohr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Memarzadeh</surname></persName>
		</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="295" to="336" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Informed consent and medical artificial intelligence: What to tell the patient?</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.3458726</idno>
		<ptr target="https://doi.org/10.2139/ssrn.3458726" />
	</analytic>
	<monogr>
		<title level="j">The Georgetown Law Journal</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1425" to="1452" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Liability for use of artificial intelligence in medicine</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gerke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.4337/9781785365516.00010</idno>
		<ptr target="https://doi.org/10.4337/9781785365516.00010" />
	</analytic>
	<monogr>
		<title level="m">Research Handbook on Health, AI and the Law</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Solaiman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</editor>
		<imprint>
			<publisher>Edward Elgar Publishing</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="20" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Product liability suits for FDA-regulated AI/ML software</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Pasquale</surname></persName>
		</author>
		<idno type="DOI">10.1017/9781108975452.002</idno>
		<ptr target="https://doi.org/10.1017/9781108975452.002" />
	</analytic>
	<monogr>
		<title level="m">The Future of Medical Device Regulation: Innovation and Protection</title>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="22" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Artificial intelligence and liability in healthcare</title>
		<author>
			<persName><forename type="first">F</forename><surname>Griffin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health Matrix</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="102" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Big data, big tech, and protecting patient privacy</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Mello</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2019.14991</idno>
		<ptr target="https://doi.org/10.1001/jama.2019.14991" />
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">322</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1141" to="1142" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">When AIs outperform doctors: Confronting the challenges of a tort-induced over-reliance on machine learning</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Froomkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Kerr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Arizona Law Review</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="33" to="94" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Medical malpractice and black-box medicine</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><surname>Ii</surname></persName>
		</author>
		<idno type="DOI">10.1017/9781108277648.018</idno>
		<ptr target="https://doi.org/10.1017/9781108277648.018" />
	</analytic>
	<monogr>
		<title level="m">Big Data, Health Law, and Bioethics</title>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="295" to="310" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Who will be liable for medical malpractice in the future? How the use of artificial intelligence in medicine will shape medical tort law</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Schweikart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Minnesota Journal of Law, Science &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="46" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">New innovation models in medical AI</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">N</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName><surname>Ii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gerke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Minssen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Washington Law Review</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1121" to="1189" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Health AI for good rather than evil? The need for a new regulatory framework for AI-based medical devices</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gerke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Yale Journal of Health Policy, Law, And Ethics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="433" to="479" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">AI, explainability, and safeguarding patient safety in Europe: Toward a science-focused regulatory model</title>
		<author>
			<persName><forename type="first">B</forename><surname>Solaiman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Bloom</surname></persName>
		</author>
		<idno type="DOI">10.1017/9781108975452.008</idno>
		<ptr target="https://doi.org/10.1017/9781108975452.008" />
	</analytic>
	<monogr>
		<title level="m">The Future of Medical Device Regulation: Innovation and Protection</title>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">G</forename><surname>Cohen</surname></persName>
		</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="91" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<ptr target="https://aiethicslab.com/big-picture/" />
		<title level="m">Toolbox: Dynamics of AI principles</title>
		<imprint/>
	</monogr>
	<note>AI Ethics Lab</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<ptr target="https://oecd.ai/en/dashboards/overview" />
		<title level="m">National AI policies &amp; strategies</title>
		<editor>
			<persName><forename type="middle">Ai</forename><surname>Oecd</surname></persName>
		</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<ptr target="https://trumpwhitehouse.archives.gov/wp-content/uploads/2018/05/Summary-Report-of-White-House-AI-Summit.pdf?latest" />
		<title level="m">Summary of the 2018 White House summit on artificial intelligence for American industry</title>
		<imprint>
			<date type="published" when="2018-05-10">2018, May 10</date>
		</imprint>
		<respStmt>
			<orgName>White House Office of Science and Technology Policy</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<ptr target="https://web.archive.org/web/20201130023307/https:/www.whitehouse.gov/presidential-actions/executive-order-maintaining-american-leadership-artificial-intelligence/" />
		<title level="m">Executive Order on maintaining American leadership in artificial intelligence</title>
		<imprint>
			<date type="published" when="2019-02-11">2019, February 11</date>
		</imprint>
	</monogr>
	<note>The White House</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Guidance for regulation of artificial intelligence applications</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Vought</surname></persName>
		</author>
		<idno>M-21- 06</idno>
		<ptr target="https://www.whitehouse.gov/wp-content/uploads/2020/11/M-21-06.pdf" />
	</analytic>
	<monogr>
		<title level="j">Executive Office of the President Office of Management and Budget</title>
		<imprint>
			<date type="published" when="2020-11-17">2020, November 17</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<author>
			<persName><forename type="first">The</forename><forename type="middle">White</forename><surname>House</surname></persName>
		</author>
		<ptr target="https://www.whitehouse.gov/ostp/ai-bill-of-rights/" />
		<title level="m">Blueprint for an AI Bill of Rights: Making automated systems work for the American people</title>
		<imprint>
			<date type="published" when="2022-10-04">2022, October 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<author>
			<persName><forename type="first">Von</forename><surname>Der Leyen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename></persName>
		</author>
		<ptr target="https://op.europa.eu/en/publication-detail/-/publication/43a17056-ebf1-11e9-9c4e-01aa75ed" />
	</analytic>
	<monogr>
		<title level="m">A union that strives for more: Agenda for Europe</title>
		<imprint>
			<date type="published" when="2019-07-16">2019, July 16. 71a1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<ptr target="https://ec.europa.eu/futurium/en/ai-alliance-consultation.1.html" />
		<title level="m">Ethics guidelines for trustworthy AI: Highlevel expert group on artificial intelligence</title>
		<imprint>
			<publisher>European Commission</publisher>
			<date type="published" when="2019-04-08">2019, April 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">White paper on artificial intelligence -A European approach to excellence and trust</title>
	</analytic>
	<monogr>
		<title level="j">COM</title>
		<imprint>
			<biblScope unit="page">65</biblScope>
			<date type="published" when="2020-02-19">2020, February 19. 2020</date>
			<publisher>European Commission</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<ptr target="https://www.consilium.europa.eu/media/46496/st11481-en20.pdf" />
		<title level="m">Presidency conclusions: The charter of fundamental rights in the context of artificial intelligence and digital change</title>
		<imprint>
			<publisher>Council of the European Union</publisher>
			<date type="published" when="2020-10-21">2020, October 21</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<ptr target="https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=celex%3A52021PC0206" />
		<title level="m">Proposal for a regulation of the European Parliament and of the Council laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union legislative acts</title>
		<imprint>
			<publisher>European Commission</publisher>
			<date type="published" when="2021-04-21">2021, April 21. 2021/0106. 2021</date>
			<biblScope unit="page">167</biblScope>
		</imprint>
	</monogr>
	<note>COD) SEC</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Proposed regulatory framework for modifications to artificial intelligence/machine learning (AI/ML)-based software as a medical device (SaMD) -Discussion paper and request for feedback</title>
		<author>
			<persName><surname>Fda</surname></persName>
		</author>
		<ptr target="https://www.fda.gov/media/122535/download" />
		<imprint>
			<date type="published" when="2019-04">2019, April</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<author>
			<persName><surname>Fda</surname></persName>
		</author>
		<ptr target="https://www.fda.gov/medical-devices/software-medical-device-samd/artificial-intelligence-and-machine-learning-software-medical-" />
		<title level="m">Artificial intelligence/machine learning (AI/ML)-based software as a medical device (SaMD) action plan</title>
		<imprint>
			<date type="published" when="2021-01">2021, January</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<ptr target="https://www.fda.gov/media/109618/download" />
		<title level="m">Clinical decision support software: Guidance for industry and food and drug administration staff</title>
		<imprint>
			<date type="published" when="2022-09-28">2022, September 28</date>
		</imprint>
		<respStmt>
			<orgName>FDA</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<author>
			<persName><surname>Who</surname></persName>
		</author>
		<ptr target="https://www.who.int/publications/i/item/9789240029200" />
		<title level="m">Ethics and governance of artificial intelligence for health: WHO guidance</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<author>
			<persName><surname>Nhsx</surname></persName>
		</author>
		<ptr target="https://transform.england.nhs.uk/media/documents/NHSX_AI_report.pdf" />
		<title level="m">Artificial intelligence: How to get it right</title>
		<imprint>
			<date type="published" when="2019-01-01">2019, January 1</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<ptr target="https://ec.europa.eu/info/sites/default/files/1_1_197605_prop_dir_ai_en.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proposal for a directive of the European Parliament and of the Council on adapting non-contractual civil liability rules to artificial intelligence (AI Liability Directive)</title>
		<imprint>
			<publisher>European Commission</publisher>
			<date type="published" when="2022-09-28">2022, September 28. 2022</date>
			<biblScope unit="volume">496</biblScope>
		</imprint>
	</monogr>
	<note>Final</note>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der Leeuw-Veiksha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bogdandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Cseres</surname></persName>
		</author>
		<title level="m">European Commission proposes AI liability directive and modernised product liability directive</title>
		<imprint>
			<date type="published" when="2022-10-07">2022, October 7</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Overy</forename><surname>Allen</surname></persName>
		</author>
		<ptr target="https://www.allenovery.com/en-gb/global/blogs/digital-hub/european-commission-proposes-ai-liability-directive-and-modernised-product-liability-directive" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Ex Machina: Preliminary critical assessment of the European Draft Act on Artificial Intelligence</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">L</forename><surname>Raposo</surname></persName>
		</author>
		<idno type="DOI">10.1093/ijlit/eaac002</idno>
		<ptr target="https://doi.org/10.1093/ijlit/eaac002" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Law and Information Technology</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="100" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">EU regulation of artificial intelligence: Challenges for patients&apos; rights</title>
		<author>
			<persName><forename type="first">H</forename><surname>Van Kolfschooten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Common Market Law Review</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="104" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Gerke</surname></persName>
		</author>
		<ptr target="https://dickinsonlaw.psu.edu/team-including-dickinson-law-prof-sara-gerke-receives-eu6-million-eu-grant-research-ai-and-cancer" />
		<title level="m">Team including Dickinson Law Prof. Sara Gerke receives €6 million EU grant to research AI and cancer surgery</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
		<respStmt>
			<orgName>Penn State Dickinson Law</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title/>
		<author>
			<orgName type="collaboration">CLASSICA Project</orgName>
		</author>
		<ptr target="https://classicaproject.eu/team/" />
		<imprint/>
	</monogr>
	<note type="report_type">Team</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">;</forename><surname>Solaiman</surname></persName>
		</author>
		<ptr target="https://www.hbku.edu.qa/sites/default/files/trg_projecthighlight_barry.pdf" />
		<title level="m">HBKU Thematic Research Grant 1st Cycle: Artificial Intelligence for Precision Medicine &amp; Health Technologies: Developing a Regulatory Framework for Qatar and the Middle East</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
