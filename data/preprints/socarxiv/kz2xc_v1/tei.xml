<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Beyond Bias: Studying &apos;culture&apos; in LLMs and AI chatbots</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2024-07">July 2024</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mark</forename><forename type="middle">Friis</forename><surname>Hau</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Christian</forename><surname>Hendriksen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Copenhagen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Beyond Bias: Studying &apos;culture&apos; in LLMs and AI chatbots</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2024-07">July 2024</date>
						</imprint>
					</monogr>
					<idno type="MD5">948BE2506D175E6987FCC6E0A7B1C12F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T02:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper argues for a conceptual shift in the understanding of Large Language Models (LLMs) within ethnographic and organizational studies, proposing a framework that interprets biases in LLMs not as extrinsic flaws, but as intrinsic culture. Drawing from Bruno Latour's Actor-Network Theory (ANT), this study conceptualizes LLMs as actants that participate dynamically within networks of human and nonhuman entities. By recognizing biases as reflective of the training data's cultural imprints, this framework positions LLMs as embedded within the cultural, social, and ideological currents that shape and are shaped by these technologies. The paper argues for a reconceptualization of AI's role in research and practice, urging a methodological and ethical engagement that embraces the constitutive nature of 'AI culture' in shaping organizational and societal dynamics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Since the advent of generative AI (GenAI) and large language models (LLMs), popularized by chatbots like ChatGPT, scholars have challenged the utility and value of AI given their predisposition to give biased or stereotypical answers <ref type="bibr" target="#b14">(Cao et al., 2023;</ref><ref type="bibr" target="#b24">Glazko et al., 2024;</ref><ref type="bibr" target="#b57">Sun et al., 2024)</ref>. From this perspective, bias is a fault in the machine; a mistake that has to be rectified like human prejudices <ref type="bibr" target="#b58">(Talboy and Fuller, 2023)</ref>. The understanding is, that the origin of AI bias lies in the way the systems are trained and the way they work -thus, either they are biased because of skewed training data or they are biased because the underlying algorithm is biased <ref type="bibr" target="#b20">(Fazelpour and Danks, 2021)</ref>, and with enough work this can be completely mitigated, reaching 'ground truth'.</p><p>We suggest that this view is fundamentally limited. 'Bias' is not a mistake or a flaw in the machine that can be fixed; it is the representation of a specific world view embedded in its training data that the model faithfully reproduces. The often overlooked cultural and social dimensions in the operation and design of LLM systems give rise to features that may look like biases but are perhaps more accurately characterized as an 'AI-culture'. These cultural assumptions and values shape the model's responses, which some may perceive as bias. Thus, only viewing AI bias as something that can be mitigated or fixed misses the possibility that it is a feature of the culture that made the AI, and not a bug.</p><p>Generative AI begins to play an ever-larger role in organizations and, indeed, society as a whole <ref type="bibr" target="#b17">(Eloundou et al., 2024)</ref>, questions about bias and culture become more relevant than ever. If we think of bias as something that can be wholly mitigated and solved from a technical perspective, we risk missing the link between the worldview and culture that went into the model and the corresponding outlook and ideas that come out of the model and its effect on the surrounding (human) context. We may talk about algorithmic justice <ref type="bibr">(Lee et al., 2019;</ref><ref type="bibr" target="#b42">Marjanovic, Cecez-Kecmanovic and Vidgen, 2022)</ref>, but perhaps it is also time to talk about algorithmic culture?</p><p>In this article, we develop a novel perspective on large language models and their inherent cultural aspects. We draw on actor-network theory (ANT) <ref type="bibr" target="#b37">(Latour, 2005;</ref><ref type="bibr" target="#b9">Birkbak, 2023;</ref><ref type="bibr" target="#b45">Morton Gutierrez, 2023)</ref> to show how each instance of use of an LLM-powered chatbot activates both visible and hidden networks of actants. From this perspective, LLM biases are neither incidental nor avoidable: they are constitutive of the way these AI models work and enshrine the implicit ideas, norms, values, and takenfor-granted beliefs of their creators and their training data. These elements become part of a mobilized network every time a human asks a chatbot a question. Bias becomes a network effect of the human, the chatbot, and its training data.</p><p>We draw on illustrative examples from our own practices of using chatbots in organizational settings to help understand the visible and hidden networks and how they interact with surrounding social contexts. We do this to show how the ANT-perspective shifts the perspective from a focus on biases to a more general attention to the way hidden network effects act upon human networks of meaning. Most importantly, we highlight how the lack of attention to this hidden network and the culturally embedded structure of the AI can have ramifications for organizations if people do not take a reflexive stance when integrating the chatbot into their organizational processes. This research is particularly relevant considering the 'cultural turn' <ref type="bibr" target="#b47">(Reckwitz, 2002;</ref><ref type="bibr" target="#b61">Ullrich, Daphi and Baumgarten, 2014)</ref>, where culture has been gaining strength and importance in social science research. We find it fitting to emphasize this angle in light of the growing importance of AI in society.</p><p>In this paper, we first provide a theoretical foundation by briefly exploring the concept of culture in anthropology and its relation to bias. We then introduce Actor-Network Theory (ANT) as a framework for understanding LLMs as actants within complex networks. Next, we present our conceptualization of visible and hidden networks in LLM interactions, illustrating these concepts through several ethnographic examples, demonstrating how LLMs operate within organizational contexts. Finally, we discuss the implications of this perspective for human agency, AI-organizational dynamics, and the future role of ethnographers in AI-integrated environments. We argue for a shift in understanding from viewing LLM biases as simple flaws to recognizing them as intrinsic cultural constituents, calling for a more nuanced approach to AI integration and study in organizational settings, as well as drawing attention to the networks -both visible and hidden -in which users of AI chatbots will find themselves enrolled.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theory: AI as Actants</head><p>In Actor-Network Theory (ANT), developed by Bruno Latour and others, agency is not a human privilege, but something that emerges in networks of relations between humans and nonhuman alike, referred to as actors or actants <ref type="bibr" target="#b9">(Birkbak, 2023)</ref>. An actor can be anything that causes an action, such as a person, technology, document, or institution meaning that all actors are fully constituted through their dynamic interactions with other entities in the network <ref type="bibr">(Latour, 2005, p. 5)</ref>.</p><p>One key concept in ANT is the 'black box', where complex sets of relationships and interactions are taken for granted as single entities with their internal workings are no longer questioned by end users <ref type="bibr" target="#b12">(Callon and Latour, 1981)</ref>. When closed, these assemblages are opaque to outsiders, often because their contents are regarded as 'technical'. The goal of opening black boxes is to discover how they are kept opaque; how they structure their 'contexts'; and how those contexts are inscribed within them. Latour uses the example of a diesel engine, "moving objects that are transformed from hand to hand and which are made up by so many different actors, before ending up as a black box safely concealed beneath the bonnet of a car, activated at the turn of a key by a driver who does not have to know anything about Carnot's thermodynamics" <ref type="bibr">(Latour, 1987, p. 5)</ref>.</p><p>Latour argues against privileging human agency over non-human agency, emphasizing that both types of actors are interconnected and mutually influential and hold equal analytical importance <ref type="bibr">(Latour, 2005, p. 76)</ref>. Because of this, ANT provides a useful lens to explore the action opportunities that arise between users and technology, especially with regards to technology that presents itself as human-like, such as AI-chatbots. Particularly, Latour's concept of <ref type="bibr">'actant' (1987; 2005)</ref> provides new opportunities for undertaking ethnographic organizational research that focuses on the network of negotiations taking place between actants <ref type="bibr">(users, managers, developers, chatbots, etc.)</ref>. Challenging the traditional objectactor dichotomy, an 'actant' can be any entity that modifies another in a network <ref type="bibr">(Latour, 1987, p. 84)</ref>, which emphasizes that objects and actors operate together in shaping social and technical activities, each contributing actively to a dynamic process whether they are human agents, technologies, objects, or ideas.</p><p>Under this theory, LLMs influence and are influenced by human and non-human actants within their networks. These multidirectional interactions create a complex network of relationships where the actions of LLMs can shape organizational practices, while simultaneously being molded by the contexts in which they operate. For instance, an LLM used in customer service might alter communication patterns within the organization, while its responses are continually refined based on user feedback and organizational goals. This perspective helps us understand the "social life" of LLMs, focusing on their roles and impacts, shifting our attention from philosophical debates about AI consciousness to the tangible effects these systems have on organizational dynamics, decision-making processes, and relationships in the workplace.</p><p>An ANT perspective allows us to view LLMs not just as tools or passive entities but as active participants influencing and being influenced by other actants, including human users, organizational policies, developer designs, large, multinational tech companies, cultural norms, and other technological systems used alongside or in tandem with them. For example, the output of an LLM is shaped by the 'biases' in its training data (influenced by the tech companies and developers behind it), the specific prompts given by users (influenced by organizational policies and cultural norms), and the integration with other software systems (influenced by technological ecosystems). In turn, the LLM's responses can impact user behavior or drive organizational change, creating dynamic feedback loops within the network.</p><p>ANT is different from a structuralist account, where, as Latour asserts, "nothing happens" <ref type="bibr">(Latour, 2004, p. 73)</ref>. Unlike structuralism, ANT demands that actors actively engage in actions that substantially impact the network. If an actor or actant fails to contribute meaningfully, Latour advocates for its exclusion from the analysis, focusing on the active agency of actors and their consequential roles within the networks they inhabit. This emphasis on active engagement and substantial impact prompts ethnographers to look beyond static organizational charts or predefined roles when studying AI integration, instead focusing on the actual interactions and transformations that occur when AI chatbots are introduced. For instance, how does the presence of an AI writing assistant change the dynamics of a marketing team? How do employees adapt their work practices in response to AI-generated insights? These questions highlight the active and transformative nature of LLMs within organizational networks, and the important role of ethnography in understanding them. The ANT principle of meaningful contribution is likewise highly relevant when studying AI chatbots in organizations, as it encourages researchers to critically evaluate the actual impact of these systems rather than assuming an importance based on AI-hype or potential or dismiss them prematurely due to skepticism. It also highlights the need for longer organizational ethnographies that can capture how the role and influence of AI chatbots may evolve over time in organizational networks. An AI chatbot that initially causes significant disruption might eventually become a seamlessly integrated part of the workflow, or conversely, an AI chatbot initially embraced with enthusiasm might be phased out if it fails to deliver meaningful contributions to the organization. An ANT perspective on AI chatbots encourages ethnographers to remain open to the possibility that LLMs might play a crucial role in some organizational contexts while having minimal impact in others, depending on the specific network of actants and their interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What are AI chatbots and LLMs?</head><p>GenAI refers to advanced AI systems capable of creating original content like images or text <ref type="bibr" target="#b21">(Feuerriegel et al., 2024)</ref>, and in this article we are largely concerned with AI chatbots such as ChatGPT. These tools are built on Large Language Models (LLMs), a type of AI specialized in processing and generating human language that use neural networks to model word sequences, resulting in models capable of handling complex tasks with advanced conversational capabilities, and emergent abilities not foreseen by its developers <ref type="bibr" target="#b10">(Boiko, MacKnight and Gomes, 2023;</ref><ref type="bibr" target="#b11">Bubeck et al., 2023;</ref><ref type="bibr" target="#b31">Ichien, Stamenković and Holyoak, 2023;</ref><ref type="bibr" target="#b46">Noy and Zhang, 2023)</ref>. The neural infrastructure is composed of sets of layers. An Input layer receives information from the external environment, processes it, and passes it to the next layer, the Hidden layer, that further processes input data, potentially through numerous hidden layers, enhancing the network's ability to learn complex patterns. This is followed lastly by an Output layer that produces the final output based on the processed data, which can vary depending on the classification or regression task (Amazon, 2024). AI chatbots, such as ChatGPT, Gemini, or Claude, use LLM technology to engage in natural-sounding conversations <ref type="bibr" target="#b7">(Baldassarre et al., 2023)</ref>. These models have no 'knowledge' and operate probabilistically, predicting responses based on vast training data <ref type="bibr" target="#b6">(Azaria, Azoulay and Reches, 2023)</ref>.</p><p>When receiving user prompts, AI chatbots generate coherent, human-like text. They can perform tasks like editing, condensing, expanding, analyzing, structuring, and rewriting texts-from manuals to essays or poems. However, LLM chatbots are not search engines; they have no repositories of knowledge, working only with probabilities. They often lack the depth needed for academic rigor and may confidently provide incorrect information or hallucinate <ref type="bibr" target="#b32">(Ji et al., 2023)</ref>. As content complexity increases, the accuracy of chatbots decreases, forming a 'knowledge funnel' <ref type="bibr" target="#b28">(Hau, 2024)</ref>).</p><p>ChatGPT matches human experts in providing feedback on academic manuscripts <ref type="bibr" target="#b40">(Liang et al., 2023)</ref> and can effectively simulate and analyze complex topics when interacting with an expert <ref type="bibr" target="#b0">(Adesso, 2023)</ref>. AI chatbots seem to struggle with creating original research <ref type="bibr" target="#b41">(Lozić and Štular, 2023)</ref>. Thus, even if AI chatbots do perform better than around 95 -99 % of humans on creativity tests <ref type="bibr" target="#b25">(Guzik et al., 2023)</ref> they are de-contextualized from their surroundings in a way humans are not. Chatbots are good at specific tasks, not bundles of tasks <ref type="bibr" target="#b17">(Eloundou et al 2024)</ref> and work best when evaluated by domain-specific experts <ref type="bibr" target="#b59">(Tian et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis Bias as culture</head><p>Bias is of course not foreign to ethnographers. Marilyn Strathern has referred to anthropology as a "science built up in the face of prejudice" (1981, p. 667), and Nancy Scheper-Hughes has argued that modern anthropology emerged "with the development of cultural relativism as a mode of objective cross-cultural inquiry and as a response to the problem of ethno-centric bias" <ref type="bibr">(1983, p. 109)</ref>. Bias has been used in anthropology to refer to ethnocentric <ref type="bibr" target="#b18">(Embree, 1950)</ref>, anthropocentric <ref type="bibr" target="#b33">(Kopnina, 2012)</ref>, or androcentric <ref type="bibr" target="#b43">(Milton, 1979;</ref><ref type="bibr" target="#b55">Slocum, 1979)</ref> bias; prioritizing either human, male, or certain cultural, normative viewpoints. Bias is generally thought of as internal to the anthropologist, the impact of researchers' perspectives on their work, with popular college texts discussing how to overcome biases in fieldwork 'by examining cultures as complex, integrated products of specific environmental and historical conditions' <ref type="bibr" target="#b30">(Hylland Eriksen and Sivert Nielsen, 2001;</ref><ref type="bibr" target="#b38">Lavenda and Schultz, 2007;</ref><ref type="bibr" target="#b27">Hasty, Lewis and Snipes, 2022)</ref>. In fields like machine learning however, bias refers to systematic errors that skew a model's results. This understanding has little place in anthropology. Bias implies a privileged, central viewpoint from which other perspectives can be said to diverge, and this anti-relativism is alien to anthropology -but requires a certain knowledge of our discipline for us to mobilize an anthropological understanding of bias to the further study and use of AI-chatbots. To understand bias, we must first understand the more commonly used term in anthropology: Culture.</p><p>Culture is generally understood very broadly in anthropology. Early anthropologists such as Henry Morgan and Herbert Spencer were explicit about the fact that their work involved a search for specific laws of society and culture <ref type="bibr">(Lavenda and Schultz, 2007, p. 200)</ref>, while E.B. Tylor famously referred to culture as 'that complex whole' <ref type="bibr" target="#b60">(Tylor, 1871)</ref>. In the 1920s, structural functionalists like Alfred Radcliffe-Brown understood 'cultures' as monolithic, structural blocks, borrowing from Durkheim's metaphor of society as a biological organism <ref type="bibr" target="#b30">(Hylland Eriksen and Sivert Nielsen, 2001;</ref><ref type="bibr" target="#b26">Hastrup, 2004)</ref>. After the Second World War, Clifford Geertz argued that cultures were like texts, with ethnographers "reading over the shoulders" of those they studied <ref type="bibr">(Geertz, 1973, p. 452)</ref>. The underlying infrastructure of LLMs, neural networks, is eerily similar to Geertz' seminal re-working of Weber's metaphor of humans as "an animal suspended in webs of significance he himself has spun" (Ibid. p. 5). Just as Geertz described culture as a complex, interwoven system of symbols and meanings, LLMs and neural networks create intricate patterns of language understanding and generation. For Geertz, those symbolic webs constituted 'culture', and the analysis of culture was therefore not "an experimental science in search of law, but an interpretive one in search of meaning" (ibid.). In this view of culture as text, they still emerge as somewhat integrated wholes, though Geertz also likened them to an octopus with loose connection over its many tentacles <ref type="bibr">(quoted in Hylland Eriksen and Sivert Nielsen, 2001, p. 148</ref>).</p><p>This has led some anthropologists to eschew the noun culture in favor of cultural, ostensibly devoid of the implications of being a bounded object or substance <ref type="bibr">(Appadurai, 1996, p. 12)</ref>. Rather, we should look at cultural dimensions as "situated difference", or culture as a heuristic device enabling us to talk about differences rather than as a property of individuals or groups (Ibid.:13).</p><p>Heralding the advent of postmodern anthropology, Clifford and Marcus <ref type="bibr" target="#b49">(Rosaldo, 1986)</ref> argued that the concept of culture was something ethnographers wrote up; they did not exist as such in the world but emerged in particular processes of delineation, description, and analysis.</p><p>As Arjun Appadurai has noted, cultural reproduction in today's globalized world is necessarily politiczed and complicated, as both "points of departure and points of arrival are in cultural flux" <ref type="bibr">(1996, p. 44)</ref>. The old 'culture' referring to a more or less tacit and taken-for-granted realm of reproducible practices and dispositions has become an arena of conscious choice and representation (Ibid.). This is even more so, as AI-chatbots act globally, but are built locally, potentially homogenizing cultures worldwide with implicit and unseen assumptions and dispositions. This strikes at the heart of tensions in a globalized world; "the interpenetration of the universalization of particularism and the particularization of universalism" <ref type="bibr">(Robertson, 1992, p. 100)</ref>. This speaks to the increasing interpenetration of culture and economy, which some have seen as a process of American-led homogenization <ref type="bibr">(Wallerstein, 1984, p. 167)</ref>.</p><p>Crucially, knowledge always has a vantage point; any statement about the world involves interpretation <ref type="bibr" target="#b26">(Hastrup, 2004)</ref>, an element of hermeneutics and of radical interpretation rather than an uncovering of facts. Culture is that vantage point. The word bias, in contrast, implies a deviation from an objective standard, and goes against anthropological endeavors to understand and interpret cultural contexts and meanings rather than measure them against an external and privileged viewpoint.</p><p>Any cultural product, including the output of a language model, is deeply embedded in the specific cultural context from which it arises. The central issue then becomes what interpretative framework an AI-chatbot uses, how we can engage with it, and how we can work with and around it.</p><p>When a language model is trained predominantly on American data, it exhibits a US-centric perspective on politics, which is the case for ChatGPT <ref type="bibr" target="#b14">(Cao et al., 2023)</ref>. Conversely, the AI chatbot LlamaChat has a slight preference for pro-European and left-wing political views, although researchers were able to realign the model's political opinion towards specific parties through fine-tuning on political debates <ref type="bibr" target="#b15">(Chalkidis and Brandl, 2024)</ref>. In addition to this, AI chatbots often exhibit emerging properties that transcend their initial design, develop capabilities or tendencies not explicitly programmed or anticipated by their creators. For instance, Elon Musk's AI chatbot Grok, despite being developed by a figure associated with right-wing views, has shown left-leaning tendencies <ref type="bibr" target="#b52">(Rozado, 2023)</ref>. This emergence of unexpected characteristics underscores the complex, somewhat unpredictable nature of LLMs as actants in organizational and social networks. This understanding of bias as constitutive rather than deviant is further reinforced by the fundamental mechanics of how AI chatbots generate language. These models operate on the principle of probability, selecting each word or token based on its likelihood of appearing in a given context. For example, given the prompt "The little girl played with her...", the model might assign higher probabilities to words like "dolls" or "toys" based on patterns in its training data (see Figure <ref type="figure">1</ref>). It might assign a lower, but still significant probability to "colorful" objects, and much lower probabilities to contextually unlikely words like "stocks" or "briefcase".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1 -Playground</head><p>This probabilistic approach is inherently cultural. The likelihood of a word appearing in a given context is not a universal constant, but a reflection of the linguistic and cultural patterns present in the training data. Therefore, culturally non-embedded text generation is, in essence, impossible. An AI model cannot generate text in a vacuum; it will always reflect, to some degree, the cultural context of its training data and the 'biases' inherent in that data. While AI chatbots are often touted for their versatility and broad applicability, they cannot exist independently of the context in which they are created. The very generality of a general purpose technology AI like ChatGPT, paradoxically, achieved through highly specific cultural embeddings. LLM 'bias', therefore reflects a complex interplay of factors: the cultural milieu of the model's training data, the specific organizational guidelines and ethical standards of the developers, and the emergent properties that arise from the model's architecture and training process. The bias of these models are not foreign objects or deviations, like a proverbial fly in a soup. Rather, they are deeply constitutive of the models themselves and their capacity to engage with humans as actants. An LLM with no 'bias' and no underlying web of meaning in which to interpret user input and no parameters for its output, would be, as Geertz put it, "an ethnography of witchcraft as written by a geometer." <ref type="bibr">(Geertz, 1983, p. 55</ref>).</p><p>In the context of Actor-Network Theory, this means that LLMs enter into organizational networks not as neutral tools, but as culturally embedded actants. Their actions and influences within these networks are shaped by their cultural programming, emergent properties, and the specific contexts in which they are deployed. These models are simply following the predominant cultural logics embedded in their training, often reinforcing existing norms and values hidden to the end user. These logics may of course be racist <ref type="bibr" target="#b1">(Alenichev, Kingori and Grietens, 2023)</ref>, ableist <ref type="bibr" target="#b24">(Glazko et al., 2024)</ref>, or sexist <ref type="bibr" target="#b57">(Sun et al., 2024)</ref>, so for questions of both questions of utility and ethics, we should approach AI-integration and study with an understanding of their nature as culturally situated entities. For lack of a better word, LLMs have culture, and we have to find out what it is in order to navigate its answers and output.</p><p>Recognizing this sets the stage for a deeper exploration into how these cultural constructs function within broader networks and are used concretely in organizations and at work. Moving on to understand culture as networks, we can better understand how cultural knowledge and dispositions are propagated, maintained, and transformed within and across various contexts of LLM-use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Culture as networks</head><p>GenAI has reached a level of sophistication where it can potentially take over many work processes and anticipate user needs, but understanding the background and logic driving its operations is still crucial. Particularly, GenAI is deployed within organizations without necessarily grasping the cultural context. While it can certainly eliminate certain routine tasks, it also creates new responsibilities and demands on users. Preliminary studies indicate drastic productivity increases of 20%-70% <ref type="bibr" target="#b13">(Cambon et al., 2023;</ref><ref type="bibr" target="#b16">Dell'Acqua et al., 2023)</ref>, but also find that worker overreliance on AI chatbots actually lead to diminished performance. AI chatbots, in their quest to assist, may reduce user agency by making decisions autonomously, doing so via hidden layers of culture unseen and unknown to end users, and becoming 'adversarially helpful' <ref type="bibr">(Ajwani et al., 2024)</ref>, potentially leading people to trust poor solutions.</p><p>Maintaining human agency as well as some degree of control over these tools will then become a key task in working AI-assisted. To unpack these agency dynamics, we suggest two distinct networks that are formed when end-users interact with the chatbot. The first one is the visible network. This network encompasses the direct, observable interactions and relationships that shape the user's experience with the AI, involving the chatbot itself, other users, AI developers, any linked applications or programs, and various members of the organization in which the use takes place, such as managers. Organizational leaders use LLMs to inform decision-making, AI developers create and update LLMs based on feedback and new data, and users engage with LLMs for various tasks. This network illustrates the explicit relationships and flows of influence in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2 -Visible network</head><p>The second is the unseen network of 'culture' in which the chatbot is embedded and was trained. This hidden network reveals the underlying, often implicit cultural and ideological influences embedded within the interactions and the actants themselves, along with the guidelines, standards, and indeed organizational culture and composition of developers such as Google, Meta, or OpenAI. This network influences the AI's behavior and outputs by structuring the cultural norms, values, and data that the chatbot has learned from. It determines the parameters and weights the AI uses to formulate 'good' answers based on the cultural context inherent in its training data. As discussed above, an AI-chatbot's responses are not just technical outputs -those would be quite less impressive and mostly worthless in many lines of work -but are deeply influenced by the cultural influences from which they derive their knowledge, voice, and parameters. We see that LLM-use is embedded within complex networks of human and cultural interactions that shape and are shaped by their operations, and by forces wholly unknown to end users. This highlights the need to consider both the visible and hidden networks to fully grasp the implications of AI-integration in organizational contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3 -Hidden network</head><p>As chatbots and end-users are embedded in these two networks, the chatbot takes agency in two different ways: First, it becomes an actant in its own right and is be anthropomorphized <ref type="bibr" target="#b19">(Epley, Waytz and Cacioppo, 2007;</ref><ref type="bibr" target="#b54">Shanahan, 2023)</ref> by human actors. Given the proclivity of chatbots to produce human-like output of high quality, humans yield agency to the chatbot. Second, because the background cultural network shapes the fundamental orientation of the chatbot's responses, outputs from the chatbot are shaped in a way that is largely hidden to human users. This hidden network guides the chatbot like an invisible hand, and the end users is not aware that the chatbot reproduces certain worldviews and systems of thought. In this way, human agency is diminished because end users do not realize that they are being enlisted in specific, hidden networks, or subjected to a certain cultural paradigm by their friendly chatbot helper.</p><p>Computational scientists attempt to dissect the algorithms and data structures that drive AI behavior, offering a systematic understanding of their functional mechanisms and explainable AI. However, since AI chatbots and LLMs are such dark black boxes with mechanics based on complex nonlinear interactions in densely connected layers <ref type="bibr" target="#b63">(Wang et al., 2022)</ref>, this interpretability is often infeasible or impossible. For example, it took a whole team of data scientists to understand how the model GPT-2 predicted the next word for the sentence, 'When Mary and John went to the store, John gave a drink to X' (ibid.). However, as <ref type="bibr" target="#b50">Munk et al. (2022)</ref> argue, although the lack of explainability of neural networks is a great issue for computer science, 'Anthropology has developed a methodological repertoire for thinking about and coming to terms with that fact' (2022, p. 13). A core ANT tenet is to study entities before they become black boxes <ref type="bibr">(Latour, 1987, p. 106)</ref>, in order to understand the intricate interactions and relationships of actors (whether human or non-human) in networks before they become simplified or obscured. This would involve mapping out all actors involved, including researchers, programmers, testers, and technological components, examining their interactions and alignments of interests throughout for example ChatGPT's development, in addition to OpenAI organizational workings, frameworks, and guidelines. We foresee a fruitful, yet very delineated field of enquiry here in the future.</p><p>Practical exploration, on the other hand, involves engaging with these chatbots in real-world contexts, observing their interactions, limitations, and the emergent properties that arise from their use across organizations. This will likely be a much wider field, as these tools are increasingly adopted by organizations globally, with AI chatbots being one of the world's fastest growing technologies in number of users <ref type="bibr" target="#b28">(Hau, 2024)</ref>. In the following, we discuss how such organizational ethnographic practical explorations might look.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>AI-networks in organizations-(Mellem)stor -Christian, så Mark</head><p>In this section, we will provide examples that demonstrate the value of the ANT perspective on chatbots and show what the two-network idea looks like in practice and what this means for human agency and human-machine interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Navigating the hidden network through human agency</head><p>In April of 2023, Author B gave a presentation for an audience consisting of university lecturers eager to understand the new technology and its effect on teaching. The core of the presentation was a live demonstration of ChatGPT-4. I 1 provided an example where I pretended to be a master student writing her thesis about sustainability, and gave GPT-4 a simple prompt to suggest good research. It gave a very good -but also quite predictable -answer for a master thesis project. One audience member injected that the chatbot "always gave the average answer", representing a generic answer that constituted the 'average' of its training data. I then asked ChatGPT to provide a tentative research question and overview of a research design for a project about "transnational feminist theory from a poststructuralist perspective", which I chose as an example because it is decidedly not the average master thesis project. Once again, the chatbot happily obliged and it gave a precise research question along with a thorough consideration of some possible research design ideas consistent with poststructuralist thought.</p><p>In this situation, the two networks were mobilized in different ways by the human at the keyboard. The visible network consisted of the presenter (me), the workshop participants, and the ChatGPT interface. The hidden network consisted of the GPT-4 training data, the embedded cultural and academic assumptions and norms in the algorithm, and OpenAI's organizational guidelines and ethical constraints that moderate ChatGPT output. A naïve prompt gave an answer that clearly reproduced the dominant logic in the hidden network, the 'average' representation of the default hidden network. However, changing the prompt to focus on something that was not a dominant logic changed the network configuration so that it no longer simply reproduced the default logic but forced the network to emphasize a more uncommon and niche perspective.</p><p>This simple example demonstrates that if aware of them, a human interlocutor can mediate between visible and hidden networks and direct the AI system to reconfigure itself to accommodate a perspective that navigates its default cultural embeddedness. This is a form of human agency that can be taken back from the AI when the human mediator knows how to steer the model towards a non-default state. Several actants had to mobilize ideas in the visible network for this to take place: A participant needed to point out that the standard output seemed generic, someone needed to understand how to prompt the chatbot in a specific way, and the chatbot itself needed to yield to the human and give an answer that satisfied the prompt. If these things were not in place, the human agency would be diminished, for example by people not realizing that the chatbot gave culturally imposed output and instead took it as the neutral and best possible answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The intersection between chatbot, human expertise, and agency</head><p>In early 2024, Author B gave another live demonstration of ChatGPT in front of the leadership team of a large company. I asked the chatbot to compare the CO2 reporting practices of the company and one of their main competitors as evidenced by their sustainability reports. As I was going through the chatbot's output, one senior leadership member interrupted, stating that the chatbot made a mistake relating to the reporting of emissions in their value chain. I used this as an opportunity to highlight that the chatbots may hallucinate that humans should be skeptical of AI output. However, after the presentation, I received a message from another participant, suggesting that the chatbot had in fact been correct, as it highlighted an obscure part of the reporting where there actually was a meaningful difference between the two companies. Apparently the senior leader from the organization had himself made a mistake, which no one at the demonstration dared to correct.</p><p>Here, the visible network consisted of the presenter (me), the leadership team members, the ChatGPT interface, and the sustainability reports of both companies. The hidden network consisted of ChatGPTs training data on sustainability and corporate reporting, embedded assumptions about report structures and terminology, and the algorithms related to processing and interpretation of the reports, OCR reading etc.</p><p>The actant role of ChatGPT in this situation is clear: it actively contributed to organizational discourse and, in a sense, was allowed to bring its own interpretation to the table to such an extent that it was questionable whether ChatGPT or the organizational leadership team knew their own sustainability reporting. Even in just a demonstrator role, the chatbot directly influenced the discussion of their emission reporting. When the senior leader challenged the output, she reconfigured the network and shifted the focus to the importance of human oversight. This shifted the locus of agency from ChatGPT to humans. Yet, when later it became questionable whether the chatbot was right after all, this cast into doubt the agency of humans once more. As participants at the demonstration were once again in doubt about whether the chatbot or their own leadership members were correct, the network was destabilized, and agency began to shift towards the chatbot.</p><p>When ChatGPT interacted with the organization, it also changed the negotiated order of the organization, where employees may have been reluctant to share their views openly, especially in a situation that could make a manager lose face to a chatbot. Chatbots 'intruding' in established orders may change negotiated orders in a fast and radical way, particularly when it challenges human expertise and authority <ref type="bibr" target="#b51">(Pakarinen and Huising, 2023)</ref>. This example illustrates several dynamics of chatbots and human agency. It highlights the 'black box' nature of chatbots, creating uncertainty about their capabilities and reach. It shows rapid cycles of stabilization and destabilization when chatbot output circulates among humans unfamiliar with the technology. It also demonstrates how chatbots subtly influence social dynamics, challenging human agency and potentially causing conflict when they correct senior management members.</p><p>Discussion: The contours of a future with AI-ethnography AI chatbots are of course not human, being sometimes derisively termed 'stochastic parrots' by computer scientists (see <ref type="bibr" target="#b8">Bender et al., 2021)</ref>. But they reflect certain aspects of human interaction, doing so through a metaphorical curved mirror, where their outputs are shaped by the training data and algorithms underlying their design. What then would it mean to engage ethnographically with such a 'curved mirror'? Some authors have argued that while AI chatbots are decidedly not sentient, they present themselves as an alien co-intelligence <ref type="bibr" target="#b44">(Mollick, 2024)</ref>.</p><p>Geertz famously cautioned against reducing culture to algorithmic predictability. Because current AI chatbots are famously opaque black boxes <ref type="bibr" target="#b64">(Wu et al., 2024)</ref> with emerging capacities unknown to their developers and present as people, we argue ethnographers should adopt a similar stance towards AI chatbots: They should be treated as entities with their own unique characteristics and cultural patterns, and managed as organizational team members rather than the software they actually are. This perspective aligns with our analysis of chatbots as embedded in visible and hidden networks, each with their own set of cultural implications.</p><p>Perhaps 'AI-ethnography' will be the newest step towards what Robert Kozinets calls 'post-analog ethnography' (2021). It requires reflexivity to realize how a hidden network of embedded cultural meaning may structure ideas subtly, and organizational ethnographers are uniquely positioned to navigate and identify the shadow effects of hidden cultural ideas in AI networks <ref type="bibr" target="#b29">(Hauge, 2020;</ref><ref type="bibr" target="#b2">Alshallaqi, 2022;</ref><ref type="bibr" target="#b34">Kristensen, 2023)</ref>. We suggest that a fruitful avenue of research and engagement for ethnographers in the age of AI will be to disentangle and reveal the ways that hidden networks exert influence in ways that are hard to detect.</p><p>However, it does require some understanding of the chatbots (and underlying LLMs or future systems) to exercise this reflexivity. We draw on <ref type="bibr" target="#b44">Mollick's (2024)</ref> point about the centrality of bottom-up technological adoption when it comes to AI chatbot and suggest that academics who combine core ethnographic reflexivity with the ability to interact with and understand AI systems can use this combination to claw back agency from the machine. These will serve important bridging functions in organizations and society in general by showing other humans how the hidden networks shape chatbot output through their understanding and active use of the technology themselves.</p><p>Beyond organizations, it will be important for us all to think critically about the way chatbots, LLMs, and other AI technologies shape our world in unseen ways. As models get better, we would probably expect to get less overtly infused output and more subtle ideas, such as embedded capitalist values or implicit primacy of certain forms of knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this paper, we suggest a fundamental rethinking of how biases in LLMs are understood, moving from a perception of biases as flaws, to viewing them as intrinsic characteristics that reflect the cultural inputs of their training data. This includes redefining what 'bias' means in the context of AI and rethinking how these models are integrated into organizational settings.</p><p>Instead of attempting to 'correct' for bias as if it were an aberration, researchers will need to analyze how these AI-cultures influence interactions within and between organizations. By drawing on Actor-Network Theory (ANT) and anthropological perspectives on culture, we have argued for understanding LLMs not as neutral tools with extrinsic biases, but as culturally embedded actants that actively participate in and shape organizational networks. It compels a move away from simply making AI 'fair' or 'unbiased' towards a more complex engagement with what it means for an AI system to participate in cultural, social, and political networks. By understanding LLMs as actants with their own cultures, organizations are prompted to rethink how they integrate AI into their workflows and decision-making processes.</p><p>Our analysis has revealed the dual nature of LLM interactions: a visible network of direct interactions and a hidden network of cultural influences embedded within the LLM's training data and algorithmic structure. This framework provides a more nuanced understanding of how LLMs operate within organizations, influencing decision-making processes, work practices, and power dynamics, offering a foundation for more nuanced and culturally informed approaches to studying and managing these technologies.</p><p>Through ethnographic examples, we have illustrated how the interplay between visible and hidden networks affects human agency in LLM interactions. We have shown that individuals who can effectively navigate and direct these networks can retain and even enhance human agency in AI-integrated environments. This perspective has several important implications for both research and practice. It challenges the prevailing notion of AI 'bias' as a flaw to be eliminated, recognizing it instead as an intrinsic cultural characteristic that requires careful interpretation and navigation. It emphasizes the need for organizational to develop new methodologies to uncover and analyze the hidden cultural networks embedded in LLMs. It highlights the potential for power shifts within organizations as expertise in LLM interaction becomes increasingly valuable, and it cements the importance of reflexivity and critical thinking in integrating and using AI technologies in organizational settings.</p><p>In conclusion, this paper contributes to the growing body of literature on AI in organizations by providing a novel theoretical framework that includes anthropological perspectives on culture in the study of AI-integration and bias. As organizations become increasingly AI-integrated, such interdisciplinary approaches will be crucial for understanding and shaping the future of work and organizational life.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0"><head></head><label></label><figDesc></figDesc><graphic coords="7,71.76,444.00,468.48,261.60" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We shift to the ethnographic first person for practical purposes.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards the ultimate brain: Exploring scientific discovery with ChatGPT AI</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adesso</surname></persName>
		</author>
		<idno type="DOI">10.1002/aaai.12113</idno>
		<ptr target="https://doi.org/10.1002/aaai.12113" />
	</analytic>
	<monogr>
		<title level="j">AI Magazine</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="342" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reflections before the storm: the AI reproduction of biased imagery in global health visuals</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alenichev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kingori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Grietens</surname></persName>
		</author>
		<idno type="DOI">10.1016/S2214-109X(23)00329-7</idno>
		<ptr target="https://doi.org/10.1016/S2214-109X(23)00329-7" />
	</analytic>
	<monogr>
		<title level="j">The Lancet Global Health</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>pp. e1496-e1498. Available at</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cultural practices and organizational ethnography: implications for fieldwork and research ethics</title>
		<author>
			<persName><forename type="first">M</forename><surname>Alshallaqi</surname></persName>
		</author>
		<idno type="DOI">10.1108/JOE-06-2021-0036</idno>
		<ptr target="https://doi.org/10.1108/JOE-06-2021-0036" />
	</analytic>
	<monogr>
		<title level="j">Journal of Organizational Ethnography</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="259" to="274" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">What Is a Neural Network? -Artificial Neural Network Explained</title>
		<ptr target="https://aws.amazon.com/what-is/neural-network/" />
	</analytic>
	<monogr>
		<title level="j">Aws.Amazon.Com</title>
		<imprint>
			<date type="published" when="2024">2024. 2024</date>
			<publisher>Amazon Web Services</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Disjuncture and Difference in the Global Cultural Economy</title>
		<author>
			<persName><forename type="first">A</forename><surname>Appadurai</surname></persName>
		</author>
		<idno type="DOI">10.1177/026327690007002017</idno>
		<ptr target="https://doi.org/10.1177/026327690007002017" />
	</analytic>
	<monogr>
		<title level="j">Theory, Culture &amp; Society</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="295" to="310" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Modernity at large: Cultural dimensions of globalization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Appadurai</surname></persName>
		</author>
		<ptr target="https://www.google.com/books?hl=en&amp;lr=&amp;id=4LVeJT" />
		<imprint>
			<date type="published" when="1996-06">1996. June 2024</date>
			<publisher>U of Minnesota Press</publisher>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
	<note>gghMC&amp;oi=fnd&amp;pg=PR9&amp;dq=appadurai+1996&amp; ots=6QQNqGZiGi&amp;sig=OQQIQC4W_LK7WTnArg2jPwSG01c</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">ChatGPT is a Remarkable Tool --For Experts</title>
		<author>
			<persName><forename type="first">A</forename><surname>Azaria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Azoulay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reches</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2306.03102" />
		<imprint>
			<date type="published" when="2023-11-15">2023. 15 November 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The Social Impact of Generative AI: An Analysis on ChatGPT</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Baldassarre</surname></persName>
		</author>
		<idno type="DOI">10.1145/3582515.3609555</idno>
		<ptr target="https://doi.org/10.1145/3582515.3609555" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2023 ACM Conference on Information Technology for Social Good. GoodIT &apos;23: ACM International Conference on Information Technology for Social Good</title>
		<meeting>the 2023 ACM Conference on Information Technology for Social Good. GoodIT &apos;23: ACM International Conference on Information Technology for Social Good<address><addrLine>Lisbon Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="363" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Bender</surname></persName>
		</author>
		<idno type="DOI">10.1145/3442188.3445922</idno>
		<ptr target="https://doi.org/10.1145/3442188.3445922" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. FAccT &apos;21: 2021 ACM Conference on Fairness, Accountability, and Transparency, Virtual Event Canada</title>
		<meeting>the 2021 ACM Conference on Fairness, Accountability, and Transparency. FAccT &apos;21: 2021 ACM Conference on Fairness, Accountability, and Transparency, Virtual Event Canada</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="610" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Actor-Network Theory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Birkbak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Oxford Bibliographies in Sociology</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Spillman</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Emergent autonomous scientific research capabilities of large language models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Boiko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Macknight</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Gomes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Sparks of Artificial General Intelligence: Early experiments with GPT-4</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2303.12712" />
		<imprint>
			<date type="published" when="2023-05-23">2023. 23 May 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unscrewing the Big Leviathan; or How Actors Macrostructure Reality, and How Sociologists Help Them To Do So?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Callon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Latour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Social Theory and Methodology</title>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Cetina</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">V</forename><surname>Cicourel</surname></persName>
		</editor>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Early LLM-based Tools for Enterprise Information Workers Likely Provide Meaningful Boosts to Productivity</title>
		<author>
			<persName><forename type="first">A</forename><surname>Cambon</surname></persName>
		</author>
		<ptr target="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/AI-and-Productivity-Report-First-Edition.pdf" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>Microsoft Research</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Assessing Cross-Cultural Alignment between ChatGPT and Human Societies: An Empirical Study</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2303.17466" />
		<imprint>
			<date type="published" when="2023-11-13">2023. 13 November 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Chalkidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Brandl</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2403.13592" />
		<title level="m">Llama meets EU: Investigating the European Political Spectrum through the Lens of LLMs&apos;. arXiv</title>
		<imprint>
			<date type="published" when="2024-06-10">2024. 10 June 2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality</title>
		<author>
			<persName><forename type="first">F</forename><surname>Dell'acqua</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.4573321</idno>
		<ptr target="https://doi.org/10.2139/ssrn.4573321" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="24" to="37" />
		</imprint>
	</monogr>
	<note type="report_type">Harvard Business School Technology &amp; Operations Mgt. Unit Working Paper</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">GPTs are GPTs: Labor market impact potential of LLMs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Eloundou</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.adj0998</idno>
		<ptr target="https://doi.org/10.1126/science.adj0998" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">384</biblScope>
			<biblScope unit="issue">6702</biblScope>
			<biblScope unit="page" from="1306" to="1308" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A Note on Ethnocentrism in Anthropology</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Embree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Anthropologist</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="430" to="432" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On seeing human: A three-factor theory of anthropomorphism</title>
		<author>
			<persName><forename type="first">N</forename><surname>Epley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Waytz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Cacioppo</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.114.4.864</idno>
		<ptr target="https://doi.org/10.1037/0033-295X.114.4.864" />
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="864" to="886" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Algorithmic bias: Senses, sources, solutions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Fazelpour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Danks</surname></persName>
		</author>
		<idno type="DOI">10.1111/phc3.12760</idno>
		<ptr target="https://doi.org/10.1111/phc3.12760" />
	</analytic>
	<monogr>
		<title level="j">Philosophy Compass</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2021">2021. 12760</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generative AI</title>
		<author>
			<persName><forename type="first">S</forename><surname>Feuerriegel</surname></persName>
		</author>
		<idno type="DOI">10.1007/s12599-023-00834-7</idno>
		<ptr target="https://doi.org/10.1007/s12599-023-00834-7" />
	</analytic>
	<monogr>
		<title level="j">Business &amp; Information Systems Engineering</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="111" to="126" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">The Interpretation of Cultures</title>
		<author>
			<persName><forename type="first">C</forename><surname>Geertz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1973">1973</date>
			<publisher>Basic Books</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">From the Native&apos;s Point of View: On the Nature of Anthropological Understanding</title>
		<author>
			<persName><forename type="first">C</forename><surname>Geertz</surname></persName>
		</author>
		<ptr target="http://hypergeertz.jku.at/GeertzTexts/Natives_Point.htm" />
	</analytic>
	<monogr>
		<title level="m">Local Knowledge: Further Essays in Interpretative Anthropology</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Basic Books</publisher>
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Identifying and Improving Disability Bias in GPT-Based Resume Screening</title>
		<author>
			<persName><forename type="first">K</forename><surname>Glazko</surname></persName>
		</author>
		<idno type="DOI">10.1145/3630106.3658933</idno>
		<ptr target="https://doi.org/10.1145/3630106.3658933" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the 2024 ACM Conference on Fairness, Accountability, and Transparency<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="687" to="700" />
		</imprint>
	</monogr>
	<note>FAccT &apos;24</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The Originality of Machines: AI Takes the Torrance Test</title>
		<author>
			<persName><forename type="first">E</forename><surname>Guzik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Byrge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Gilde</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.yjoc.2023.100065</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Creativity</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">100065</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><surname>Hastrup</surname></persName>
		</author>
		<title level="m">En grundbog i antropologisk analyse. Copenhagen: Hans Reitzels Forlag</title>
		<meeting><address><addrLine>Viden om Verden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><surname>Hasty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><surname>Snipes</surname></persName>
		</author>
		<editor>M.M.</editor>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>Introduction to Anthropology. OpenStax</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Hau</surname></persName>
		</author>
		<ptr target="https://faos.ku.dk/pdf/Rapport_200_-_Generativ_kunstig_intelligens_og_fremtidens_arbejdsmarked.pdf" />
		<title level="m">Generativ kunstig intelligens og fremtidens arbejdsmarked</title>
		<imprint>
			<date type="published" when="2024-06">2024. June 2024</date>
			<biblScope unit="page">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">How to take sides: on the challenges of managing positionality</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Hauge</surname></persName>
		</author>
		<idno type="DOI">10.1108/JOE-06-2019-0023</idno>
		<ptr target="https://doi.org/10.1108/JOE-06-2019-0023" />
	</analytic>
	<monogr>
		<title level="j">Journal of Organizational Ethnography</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="111" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Hylland Eriksen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Sivert Nielsen</surname></persName>
		</author>
		<title level="m">A history of anthropology</title>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Pluto Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ichien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Stamenković</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">J</forename><surname>Holyoak</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2308.01497</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2308.01497" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Survey of Hallucination in Natural Language Generation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<idno type="DOI">10.1145/3571730</idno>
		<ptr target="https://doi.org/10.1145/3571730" />
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">55</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Toward conservational anthropology: addressing anthropocentric bias in anthropology</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kopnina</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10624-012-9265-y</idno>
		<ptr target="https://doi.org/10.1007/s10624-012-9265-y" />
	</analytic>
	<monogr>
		<title level="j">Dialectical Anthropology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="146" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Research ethics and organizations: the neglected ethics of organizational ethnography</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Kristensen</surname></persName>
		</author>
		<idno type="DOI">10.1108/JOE-11-2022-0031</idno>
		<ptr target="https://doi.org/10.1108/JOE-11-2022-0031" />
	</analytic>
	<monogr>
		<title level="j">Journal of Organizational Ethnography</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="242" to="253" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Science in action: How to follow scientists and engineers through society</title>
		<author>
			<persName><forename type="first">B</forename><surname>Latour</surname></persName>
		</author>
		<ptr target="https://www.google.com/books" />
	</analytic>
	<monogr>
		<title level="m">books?hl=en&amp;lr=&amp;id=sC4bk4DZXTQC&amp;oi=fnd&amp;pg=PA19&amp;dq=science+in+actio n&amp;ots=WahLxu5fVC&amp;sig=34RuVM4GsO41Oym0FfacRMb-4K0</title>
		<imprint>
			<publisher>Harvard University Press</publisher>
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
	<note>hl=en&amp;lr=&amp;id=sC4bk4DZXTQC&amp;oi=fnd&amp;pg=PA19&amp;dq=latour+1987&amp;ots =WahLCne9UB&amp;sig=z4biyZ10qg1P2</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">On using ANT for studying information systems: a (somewhat) Socratic dialogue</title>
		<author>
			<persName><forename type="first">B</forename><surname>Latour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The social study of information and communication technology: innovation, actors, and contexts</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Avgerou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Ciborra</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Land</surname></persName>
		</editor>
		<meeting><address><addrLine>Oxford</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Reassembling the Social: An Introduction to Actor-Network-Theory</title>
		<author>
			<persName><forename type="first">B</forename><surname>Latour</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Lavenda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schultz</surname></persName>
		</author>
		<title level="m">Core Concepts in Cultural Anthropology</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill Education</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Procedural Justice in Algorithmic Fairness: Leveraging Transparency and Outcome Control for Fair Algorithmic Mediation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1145/3359284</idno>
		<ptr target="https://doi.org/10.1145/3359284" />
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="182" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Can large language models provide useful feedback on research papers? A largescale empirical analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2310.01783" />
		<imprint>
			<date type="published" when="2023-10-09">2023. 9 October 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fluent but Not Factual: A Comparative Analysis of ChatGPT and Other AI Chatbots&apos; Proficiency and Originality in Scientific Writing for Humanities</title>
		<author>
			<persName><forename type="first">E</forename><surname>Lozić</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Štular</surname></persName>
		</author>
		<idno type="DOI">10.3390/fi15100336</idno>
		<ptr target="https://doi.org/10.3390/fi15100336" />
	</analytic>
	<monogr>
		<title level="j">Future Internet</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">336</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Theorising Algorithmic Justice</title>
		<author>
			<persName><forename type="first">O</forename><surname>Marjanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cecez-Kecmanovic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vidgen</surname></persName>
		</author>
		<idno type="DOI">10.1080/0960085X.2021.1934130</idno>
		<ptr target="https://doi.org/10.1080/0960085X.2021.1934130" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Information Systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="269" to="287" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Male Bias in Anthropology</title>
		<author>
			<persName><forename type="first">K</forename><surname>Milton</surname></persName>
		</author>
		<idno type="DOI">10.2307/2801639</idno>
		<ptr target="https://doi.org/10.2307/2801639" />
	</analytic>
	<monogr>
		<title level="j">Man</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="54" />
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Co-Intelligence: Living and Working with AI</title>
		<author>
			<persName><forename type="first">E</forename><surname>Mollick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>Random House</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On actor-network theory and algorithms: ChatGPT and the new power relationships in the age of AI</title>
		<author>
			<persName><forename type="first">Morton</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename></persName>
		</author>
		<idno type="DOI">10.1007/s43681-023-00314-4</idno>
		<ptr target="https://doi.org/10.1007/s43681-023-00314-4" />
	</analytic>
	<monogr>
		<title level="j">AI and Ethics</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence</title>
		<author>
			<persName><forename type="first">S</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.4375283</idno>
		<ptr target="https://doi.org/10.2139/ssrn.4375283" />
		<imprint>
			<date type="published" when="2023">2023</date>
			<pubPlace>Rochester, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Toward a Theory of Social Practices: A Development in Culturalist Theorizing</title>
		<author>
			<persName><forename type="first">A</forename><surname>Reckwitz</surname></persName>
		</author>
		<idno type="DOI">10.1177/13684310222225432</idno>
		<ptr target="https://doi.org/10.1177/13684310222225432" />
	</analytic>
	<monogr>
		<title level="j">European Journal of Social Theory</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="243" to="263" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Globalization: Social Theory and Global Culture</title>
		<author>
			<persName><forename type="first">R</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SAGE</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">From the Door of His Tent: The Fieldworker and the Inquisitor</title>
		<author>
			<persName><forename type="first">R</forename><surname>Rosaldo</surname></persName>
		</author>
		<idno type="DOI">10.1525/9780520946286-006</idno>
		<ptr target="https://doi.org/10.1525/9780520946286-006" />
		<editor>J. Clifford and G.E. Marcus</editor>
		<imprint>
			<date type="published" when="1986">1986</date>
			<publisher>University of California Press</publisher>
			<biblScope unit="page" from="77" to="97" />
		</imprint>
	</monogr>
	<note>Writing Culture</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">The Thick Machine: Anthropological AI between Explanation and Explication</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Munk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gehrt Olesen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jacomy</surname></persName>
		</author>
		<idno type="DOI">10.1177/20539517211069891</idno>
		<ptr target="https://doi.org/10.1177/20539517211069891" />
	</analytic>
	<monogr>
		<title level="j">Big Data &amp; Society</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Relational Expertise: What Machines Can&apos;t Know</title>
		<author>
			<persName><forename type="first">P</forename><surname>Pakarinen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Huising</surname></persName>
		</author>
		<idno type="DOI">10.1111/joms.12915</idno>
		<ptr target="https://doi.org/10.1111/joms.12915" />
	</analytic>
	<monogr>
		<title level="j">Journal of Management Studies</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">The political preferences of Grok&apos;, Rozado&apos;s Visual Analytics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Rozado</surname></persName>
		</author>
		<ptr target="https://davidrozado.substack.com/p/the-political-preferences-of-grok" />
		<imprint>
			<date type="published" when="2023-06">2023. June 2024</date>
			<biblScope unit="page">24</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Introduction: The problem of bias in androcentric and feminist anthropology</title>
		<author>
			<persName><forename type="first">N</forename><surname>Scheper-Hughes</surname></persName>
		</author>
		<idno type="DOI">10.1080/00497878.1983.9978584</idno>
		<ptr target="https://doi.org/10.1080/00497878.1983.9978584" />
	</analytic>
	<monogr>
		<title level="j">Women&apos;s Studies</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="109" to="116" />
			<date type="published" when="1983">1983</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Talking About Large Language Models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Shanahan</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2212.03551</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2212.03551" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Woman the Gatherer: Male bias in anthropology</title>
		<author>
			<persName><forename type="first">S</forename><surname>Slocum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science, Sex, and Society. Women&apos;s Educational Equity Act Program</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Kammer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Granrose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Sloan</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1979">1979</date>
		</imprint>
		<respStmt>
			<orgName>U. S. Department of Health, Education, and Welfare</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Culture in a Netbag: The Manufacture of a Subdiscipline in Anthropology</title>
		<author>
			<persName><forename type="first">M</forename><surname>Strathern</surname></persName>
		</author>
		<idno type="DOI">10.2307/2801494</idno>
		<ptr target="https://doi.org/10.2307/2801494" />
	</analytic>
	<monogr>
		<title level="j">Man</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="665" to="688" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Smiling women pitching down: auditing representational and presentational gender biases in image-generative AI</title>
		<author>
			<persName><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1093/jcmc/zmad045</idno>
		<ptr target="https://doi.org/10.1093/jcmc/zmad045" />
	</analytic>
	<monogr>
		<title level="j">Journal of Computer-Mediated Communication</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Challenging the appearance of machine intelligence: Cognitive bias in LLMs and Best Practices for Adoption</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Talboy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Fuller</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2304.01358</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2304.01358" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Is ChatGPT the Ultimate Programming Assistant</title>
		<author>
			<persName><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2304.11938</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2304.11938" />
	</analytic>
	<monogr>
		<title level="m">How far is it?&apos; arXiv</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Primitive Culture: Researches Into the Development of Mythology, Philosophy, Religion, Art, and Custom</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Tylor</surname></persName>
		</author>
		<editor>J. Murray</editor>
		<imprint>
			<date type="published" when="1871">1871</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Protest and Culture: Concepts and Approaches in Social Movement Research -An Introduction</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ullrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Daphi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Baumgarten</surname></persName>
		</author>
		<idno type="DOI">10.1057/9781137385796</idno>
		<ptr target="https://doi.org/10.1057/9781137385796" />
	</analytic>
	<monogr>
		<title level="s">Conceptualizing Culture in Social Movement Research</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Baumgarten</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Daphi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Ullrich</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Palgrave Macmillan</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<author>
			<persName><forename type="first">I</forename><surname>Wallerstein</surname></persName>
		</author>
		<title level="m">The Politics of the World-Economy: The States, the Movements and the Civilizations</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 small</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2211.00593</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2211.00593" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note>arXiv. Available at</note>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2403.08946" />
		<imprint>
			<date type="published" when="2024-06-20">2024. 20 June 2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
