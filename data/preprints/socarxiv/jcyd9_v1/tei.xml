<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Monitoring Attitudes Over Time -Real Change or the Result of Repeated Interviewing?</title>
				<funder>
					<orgName type="full">&quot;German Research Foundation&quot; (DFG)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Fabienne</forename><surname>Kraemer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Survey Design and Methodology</orgName>
								<orgName type="department" key="dep2">GESIS -Leibniz Institute for the Social Sciences</orgName>
								<address>
									<settlement>Mannheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Peter</forename><surname>Lugtig</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Methodology and Statistics</orgName>
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<settlement>Utrecht</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bella</forename><surname>Struminskaya</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Methodology and Statistics</orgName>
								<orgName type="institution">Utrecht University</orgName>
								<address>
									<settlement>Utrecht</settlement>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Henning</forename><surname>Silber</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Survey Design and Methodology</orgName>
								<orgName type="department" key="dep2">GESIS -Leibniz Institute for the Social Sciences</orgName>
								<address>
									<settlement>Mannheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bernd</forename><surname>Weiß</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Survey Design and Methodology</orgName>
								<orgName type="department" key="dep2">GESIS -Leibniz Institute for the Social Sciences</orgName>
								<address>
									<settlement>Mannheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Michael</forename><surname>Bosnjak</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Psychological Research Methods</orgName>
								<orgName type="institution">Trier University</orgName>
								<address>
									<settlement>Trier</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Socarxiv</surname></persName>
						</author>
						<title level="a" type="main">Monitoring Attitudes Over Time -Real Change or the Result of Repeated Interviewing?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1024D26C89D4155AE76BF9820C2C9D3D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-22T06:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>panel conditioning</term>
					<term>cognitive stimulus hypothesis</term>
					<term>attitude change</term>
					<term>structural equation modeling</term>
					<term>panel studies</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Researchers often use panel data to study change and stability of social patterns. However, repeated interviewing can affect respondents' attitudes in a panel study by raising awareness and triggering reflection processes on surveyed topics (cognitive stimulus hypothesis). We investigated change in respondents' attitudes about abortion and the underlying mechanisms of attitude change across six waves using data from a survey experiment administered within a probability-based and a non-probability panel in Germany. We manipulated the frequency of receiving identical attitude questions on the same issue. We estimated multiple-group and longitudinal structural equation models to differentiate change in the measurement of reported attitudes from "real" attitude change. We show that repeatedly asking about abortion increases the reliability of respondents' reported abortion attitudes, providing support for the cognitive stimulus hypothesis. Our results also suggest that improved response behavior due to general survey experience further enhances attitude reliability when answering identical attitude questions repeatedly.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Panel surveys are widely used due to their possibility to track attitudes and subjective beliefs of individuals over time and thus to study change and stability of social patterns.</p><p>However, previous research indicates that shifts in respondents' attitudes over the course of a longitudinal study do not solely reflect individual or social change but instead, might result from repeated interviewing <ref type="bibr" target="#b4">(Bergmann &amp; Barth, 2018;</ref><ref type="bibr" target="#b40">Sturgis et al., 2009;</ref><ref type="bibr">Waterton &amp; Lievesley, 1989)</ref>. This potential bias inherent to panel studies is generally referred to as panel conditioning and describes the impact of repeated interviews on respondents' behaviors and attitudes or the way in which they are reported in subsequent waves of the study <ref type="bibr" target="#b21">(Kalton et al., 1989;</ref><ref type="bibr" target="#b29">Lazarsfeld, 1940)</ref>.</p><p>Recent studies have explored the existence and magnitude of panel conditioning (e.g., <ref type="bibr" target="#b12">Cornesse et al., 2023;</ref><ref type="bibr" target="#b13">Eckman &amp; Bach, 2021;</ref><ref type="bibr">Kraemer et al., 2023;</ref><ref type="bibr" target="#b37">Silber et al., 2019)</ref>.</p><p>Research that specifically investigate the effects of panel conditioning on respondents' attitudes over time suggest that repeated surveying on the same issue raises respondents' awareness and stimulates further reflection processes on surveyed topicsa process which has been referred to as the cognitive stimulus model <ref type="bibr" target="#b40">(Sturgis et al., 2009)</ref>. Studies have provided some evidence on the assumptions of the cognitive stimulus model by documenting more stable and reliable survey responses and an increased opinionation, that is, reporting attitudes instead of saying 'don't know,' among experienced panelists <ref type="bibr" target="#b4">(Bergmann &amp; Barth, 2018;</ref><ref type="bibr" target="#b5">Binswanger et al., 2013;</ref><ref type="bibr" target="#b27">Kroh et al., 2016;</ref><ref type="bibr" target="#b40">Sturgis et al., 2009)</ref>.</p><p>Previous studies typically used non-experimental designs <ref type="bibr" target="#b4">(Bergmann &amp; Barth, 2018;</ref><ref type="bibr" target="#b5">Binswanger et al., 2013;</ref><ref type="bibr" target="#b40">Sturgis et al., 2009)</ref> which are susceptible to other types of bias affecting change rates, such as maturation effects or selective dropout from panel studies.</p><p>Such effects are very difficult to control for in observational data and might induce systematic bias of unknown magnitude into change estimates. But, more importantly, most studies have not investigated the reasons why attitudinal responses in panel studies become more stable and reliable over time. Are these panel conditioning effects the result of increased reflection by the respondent on the survey topics or do panel respondents simply become more consistent in their responses over time due to an increased experience with answering surveys in general, that is, gain experience with typical response tasks?</p><p>In this paper, we aim to address these research gaps by examining the following research questions: (1) Does repeatedly asking the same attitude question lead to panel conditioning in form of more consistent answers and an increased opinionation over time? <ref type="bibr">(2)</ref> Can conditioning effects best be explained as a result of increased reflection by the respondent on the topic of the question, or simply by the fact they become a 'better respondent' due to increases in general survey experience?</p><p>Our study is unique as it uses data of a longitudinal survey experiment comprising six survey waves carried out both within a probability-based and a non-probability panel. The experimental design manipulates the frequency of receiving identical attitude questions over the course of the study and allows us to investigate the impact of different levels of exposure to identical attitude questions on the existence and magnitude of attitude changes.</p><p>Additionally, this design enables us to study attitude change not only between different respondent groups but also across the six survey waves to further examine the underlying mechanisms of changes in respondents' attitudes. Additionally, we included measures of attitude certainty and knowledgeability to gain further insights on the mechanisms and relevance of reflection processes for changes in respondents' (reported) attitudes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>Research addressing the effects of panel conditioning on attitudes and subjective beliefs is scarce. While most panel conditioning studies have focused on identifying and estimating bias in overall response quality or behavioral outcomes such as voter turnout (e.g., <ref type="bibr" target="#b3">Battaglia et al., 1996;</ref><ref type="bibr" target="#b10">Clausen, 1968;</ref><ref type="bibr" target="#b17">Halpern-Manners et al., 2017;</ref><ref type="bibr" target="#b41">Sun et al., 2019;</ref><ref type="bibr" target="#b44">Yalch, 1976)</ref>, only few studies have investigated how repeated interviewing changes respondents' attitudes over the course of a panel study (e.g., <ref type="bibr" target="#b5">Binswanger et al., 2013;</ref><ref type="bibr" target="#b20">Jagodzinski et al., 1987;</ref><ref type="bibr" target="#b40">Sturgis et al., 2009)</ref>.</p><p>Despite the variety in research designs, the existing studies mainly provide consistent findings regarding attitude change in panel studies and document more stable, reliable answers to attitudinal questions and an increased opinionation on surveyed topics across waves.</p><p>In one of the earlier studies that investigated attitudinal responses over the course of a panel study, <ref type="bibr" target="#b20">Jagodzinski et al. (1987)</ref> differentiated between changes in the latent attitudes and changes in the reported attitudes and showed that the reliability of attitude reports regarding immigrant workers in Germany increased between the first and second survey wave. <ref type="bibr">Waterton and Lievesley (1989)</ref> compared the political attitudes of members of the British Social Attitudes Panel over the course of three survey waves to fresh cross-sections and found an increase in politization due to repeated interviewing with panelists reporting more often to support a political party. Similarly, <ref type="bibr">Sturgis and colleagues (2009)</ref> found that panelists of the British Household Panel Study provided fewer "don't know" responses to a left-right political orientation question over the course of 11 panel wavesa finding which they attributed to an increase in (political) opinionation. Additionally, Sturgis et al.'s study found that respondents' answers to attitudinal questions became more reliable and stable over time.</p><p>Subsequent studies have provided further evidence on an increase in stability and reliability of attitudinal survey responses over time. <ref type="bibr" target="#b28">Kruse (2009)</ref> showed an increase in interwave stabilities of environmental attitudes. <ref type="bibr" target="#b27">Kroh et al. (2016)</ref> tested the consistency of individual response patterns in 17 multi-item scales which were administered in 30 subsequent panel waves within the German Socio-Economic Panel (GSOEP) and found that repeated interviewing increased the reliability of individual survey responses over time.</p><p>Research by <ref type="bibr" target="#b41">Sun et al. (2019)</ref> who investigated the effect of panel conditioning on overall response quality using several response quality indicators documented an increase in reliability of selected attitude scales over time for members of two probability-based panel studies in the USA providing further evidence on an increase of reliability of attitudinal responses over the course of a panel study. Previous findings that hint at an increased opinionation of experienced panelists on surveyed topics were supported by <ref type="bibr" target="#b4">Bergmann and Barth (2018)</ref>, who used data from the German Longitudinal Election Study (GLES) and showed that repeated interviewing decreased respondents' political indecision by affecting attitude strength. This effect was especially prominent for respondents who initially held weak attitudes regarding party vote intentions.</p><p>Most of the existing studies on panel conditioning and its effect on attitudinal responses explain their findings based on the notion that repeated interviewing increases awareness and prompts respondents to reflect intensively on the surveyed topics which leads them to form opinions where none existed prior to the survey or to change existing attitudes.</p><p>The assumption of triggered reflection processes due to the repeated interviewing on specific topics was extended to a general theoretical frameworkthe cognitive stimulus model <ref type="bibr" target="#b40">(Sturgis et al., 2009)</ref>.</p><p>The cognitive stimulus model assumes that respondentsinstead of forming opinions "on the spot," base their opinions on information and intensive cognitive engagement with an issue at hand: Being repeatedly exposed to and asked about the same issues might stimulate respondents to intensively reflect on the surveyed topics and their stance towards them.</p><p>Respondents might even discuss the issues with others or obtain further information, for example, by paying closer attention to the news <ref type="bibr" target="#b40">(Sturgis et al., 2009)</ref>. <ref type="bibr">Sturgis et al. (2005)</ref> argue that even if respondents do not change their existing views, the triggered reflection processes lead them to hold more consistent attitudes and to show an increased attitude strength (attitude crystallization) than without any intensified deliberation due to repeated interviewing. The three main empirical implications of the cognitive stimulus model are: (a) attitudes become more reliable over time, (b) attitudes become more stable over time, (c) and opinionation on surveyed issues increases.</p><p>Following the assumptions of the cognitive stimulus model <ref type="bibr" target="#b40">(Sturgis et al., 2009)</ref>, respondents' learning effects over the course of a panel study are topic-or question-specific.</p><p>Changes in respondents' answers are due to a repeated exposure to similar or identical question content and the thereby prompted reflection processes. <ref type="bibr">Waterton and Lievesley (1989)</ref> have provided initial evidence for the mechanism of content-specific reflection processes by conducting follow-up in-depth interviews with panel members. They showed that the survey evoked discussions among the panelists and their friends and family <ref type="bibr">(Waterton &amp; Lievesley, 1989)</ref>. On the contrary, <ref type="bibr" target="#b11">Clinton (2001)</ref> found that long-term members of an online panel reported lower levels of news consumption compared to respondents who had been in the panel for a shorter period of timean assumed consequence of topic-specific reflection besides discussions with others. In any case, the present evidence regarding the mechanisms underlying observed attitude crystallization is at best suggestive.</p><p>In contrast to the cognitive stimulus model, some studies have argued that observed attitude change and increases in the reliability of attitudinal responses over time might simply be the result of an increased experience with answering surveys in general and, consequently, "better" response behavior leading to more accurate self-reports <ref type="bibr" target="#b27">(Kroh et al., 2016;</ref><ref type="bibr" target="#b42">Warren &amp; Halpern-Manners, 2012;</ref><ref type="bibr">Waterton &amp; Lievesley, 1989)</ref>. It is argued that repeatedly answering surveys may increase respondents' familiarity with the overall survey procedure and improve their understanding of the rules and requirements of an interview <ref type="bibr" target="#b39">(Struminskaya, 2016;</ref><ref type="bibr">Waterton &amp; Lievesley, 1989)</ref>. Consequently, respondents might learn about the relevance of reporting their true opinions and behaviors to the researcher and learn to use different survey instruments as well as to map their answers to different response scales <ref type="bibr" target="#b31">(Nancarrow &amp; Cartwright, 2007;</ref><ref type="bibr">Waterton &amp; Lievesley, 1989)</ref>. In fact, research suggests respondents becoming familiar with the response task and their experience with different survey instruments might decrease initial complexities of question comprehension tasks <ref type="bibr">(Waterton &amp; Lievesley, 1989)</ref>, facilitate less error-prone retrieval of relevant information <ref type="bibr" target="#b1">(Bailar, 1989)</ref>, and might decrease error in mapping the retrieved information to the response scale as respondents' familiarity in dealing with different response scales increases <ref type="bibr" target="#b2">(Basso et al., 2001)</ref>.</p><p>Respondents might even prepare for subsequent interviews by looking up relevant information beforehand: studies using external validation data showed increases in the accuracy of respondents' income reports and reports regarding the receipt of unemployment benefits with higher panel experience <ref type="bibr" target="#b15">(Frick et al., 2006;</ref><ref type="bibr" target="#b45">Yan &amp; Eckman, 2012)</ref>. We refer to this mechanism as the "better respondents" model <ref type="bibr" target="#b45">(Yan &amp; Eckman, 2012)</ref>.</p><p>Findings from the German GESIS Panel provide further support for the "better respondents" model by documenting shorter response times for more experienced panelists which cannot be attributed to satisficing response behavior <ref type="bibr" target="#b23">(Kartsounidou et al., 2023;</ref><ref type="bibr">Kraemer et al., 2023)</ref>. Similarly, it has been observed that experienced members of the LISS Panel in the Netherlands more often did their task "on time" compared to novice respondents <ref type="bibr" target="#b35">(Scherpenzeel &amp; Zandvliet, 2011)</ref>, indicating "better" response behavior with an increased survey experience.</p><p>Both models, the cognitive stimulus and the "better respondents" model can lead to the same outcome but are based on different mechanisms. While <ref type="bibr" target="#b40">Sturgis et al. (2009)</ref> attribute fewer "don't know" responses of more experienced panelists to an increased opinionation on the subject matter, <ref type="bibr">Waterton and Lievesley (1989)</ref> explain their finding of a decrease in "don't know" responses with respondents learning the "rules that govern the interview process," arguing that respondents learn about the importance of their survey responses to researchers and therefore, provide more often substantial answers.</p><p>Altogether, the existing empirical findings are only suggestive of the mechanisms underlying observed changes in attitude reports and there is no direct evidence on the role of content-specific reflection processes versus familiarity with the response task. To contribute to the literature, we aim to investigate the mechanisms of observed attitude changes in repeated measurement settings by testing the following four hypotheses. Two of the expected findings (H1 and H2) could be due to either the cognitive stimulus or the "better respondents" model, while Hypothesis 3 is based on the assumptions of the cognitive stimulus model, and Hypothesis 4 is based on the "better respondents" model.</p><p>According to the cognitive stimulus model <ref type="bibr" target="#b40">(Sturgis et al., 2009)</ref>, repeatedly being asked about a specific issue increases awareness and prompts respondents to intensively reflect on the subject matter. In the case of non-existent opinions toward the issue, this might lead to the formation of new opinions and, therefore, an increase in opinionation reflected in fewer "don't know" answers. The "better respondents" model <ref type="bibr" target="#b45">(Yan &amp; Eckman, 2012)</ref> however, would assume that fewer "don't know" answers simply indicate an increased familiarity with the response task and the survey procedure increasing respondents' willingness to report their attitudes. Based on both models, we hypothesize:</p><p>Hypothesis 1: Respondents who repeatedly answer identical attitude questions will give fewer "don't know" answers compared to respondents who do not repeatedly receive identical attitude questions.</p><p>Similarly, attitude crystallization due to repeated interviewing is the core assumption of the cognitive stimulus model suggesting that the triggered increase in cognitive engagement with the surveyed topics leads to more consistent and crystallized attitudes which are less susceptible to change. Following the "better respondents" model on the other hand, more consistent and reliable attitudes would not reflect internal attitude change but respondents simply becoming better at answering (multi-item) scales, leading to more accurate attitude reports in which "noise" and random errors have been canceled out due to experience with the response tasks. Using either model, we expect: Hypothesis 2: Respondents who repeatedly answer identical attitude questions show a crystallization of attitudes (i.e., increases in attitude reliability and/or stability) compared to respondents who do not repeatedly receive identical attitude questions.</p><p>The next hypothesis is only in line with the assumptions of the cognitive stimulus model and not the "better respondent" model as it addresses the underlying mechanism of the cognitive stimulus model: Hypothesis 3: Respondents who are repeatedly exposed to identical attitude questions show an increased attitude strength and knowledgeability on the subject matter compared to respondents who do not repeatedly receive identical attitude questions.</p><p>In addition, we derived one expectation that can be explained by the "better respondents" model, but not the cognitive stimulus model. Following <ref type="bibr" target="#b27">Kroh et al. (2016)</ref> who discuss the possibility that the increased familiarity with a response task could have an impact on increases in reliability of individual survey responses over time, we hypothesize: Hypothesis 4: Respondents, who have high levels of general survey experience, show more reliable attitudes than respondents with low levels of general survey experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Design</head><p>To test our hypotheses, we use data collected in a longitudinal survey experiment which was carried out both within a probability-based mixed-mode panel study and a nonprobability online access panel in Germany. The survey experiment comprised six panel waves and manipulated the frequency of answering identical questions (i.e., target questions) over six consecutive waves. Respondents were randomly assigned to one of three experimental groups: one experimental group received the identical target questions in each of the six waves (i.e., fully conditioned), another experimental group received the target question only from Wave 4 onwards (i.e., medium conditioned), and the control group received the target questions only once in the final wave (i.e., unconditioned)<ref type="foot" target="#foot_0">1</ref> (for an illustration of the experimental design, see Figure <ref type="figure" target="#fig_0">1</ref>). In the non-probability panel study, respondents were randomly assigned to three groups of equal sample size (n fully conditioned = 647; n medium conditioned = 651; n unconditioned = 648). Respondents of the probability-based panel study have been randomly assigned to three experimental groups of unequal sample size with 50% of the respondents being assigned to the fully conditioned group, whereas 25% of respondents were assigned to the medium conditioned and the unconditioned groups, respectively (n fully conditioned = 2,337; n medium conditioned = 1,165; n unconditioned = 1,158)<ref type="foot" target="#foot_1">2</ref> . Sample members were selected using cross-quotas on gender (female; male), age (18-35 years; 36-65 years; 66 years and older), and level of education measured as the highest general school leaving certificate (below secondary school certificate; secondary school certificate; higher education entrance qualification). Data was collected exclusively online via web-based surveys with each survey wave taking about 15 minutes to complete, except for the first wave that took about 35 minutes due to the inclusion of additional background measures on socio-demographics, political attitudes, and personality.</p><p>Selected panel members were explicitly invited to participate in the study via a personalized email by the panel provider. However, every panel member could also participate via the panel's online user interface. Only respondents who completed the first wave were able to participate in the following survey wave. The invited panel members received up to four email reminders. Each reminder was sent after three to four days following the invitation or the preceding reminder email. Respondents received a postpaid incentive after each completed survey wave. The amount of the paid incentive varied by wave from €0.60 to €2.50, depending on the average survey duration. Furthermore, respondents received an additional bonus payment of €2 if they successfully participated in all six panel waves.</p><p>Across the six waves of the panel study, the completion rates (COMR) <ref type="bibr" target="#b8">(Callegaro &amp; DiSogra, 2008)</ref>  In this paper, we use the data of six consecutive survey waves of the GESIS Panel (waves 41 to 46), which were fielded between October 2020 and January 2022. Since 2021, survey waves of the GESIS Panel are administered every three months but until 2020, data collection was conducted bimonthly. Accordingly, while the experimental study was fielded, the interval between survey waves changed from two to three months. The questionnaire of the experimental study took up around 5 minutes to complete.</p><p>In the first wave of the experimental study, completion rates (COMR) varied from 93.2% for the first panel cohort to 93.7% and 89.7% for the second and third cohort, respectively<ref type="foot" target="#foot_2">3</ref> . In the last wave, they ranged from 92.2% for the first and second panel cohort to 90.3% for the third panel cohort. Cumulative response rates (CUMR) in the first wave of the experimental study ranged from 11.5% for the first panel cohort to 9.7% for the second and 9.6% for the third panel cohort. In the last wave of the experimental study, cumulative response rates ranged from 10.7% for the first panel cohort to 8.8% and 8.8% for the second and third panel cohort, respectively. In the final wave of our experimental study, attrition rates ranged from 49.6% for the first cohort to 41.0% for the second and 31.6% for the third cohort <ref type="bibr" target="#b36">(Schulz et al. 2021;</ref><ref type="bibr" target="#b38">Stadtmüller et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measures</head><p>Attitudes toward abortion. To investigate change in respondents' (reported) attitudes, we used 4-items measuring attitudes toward abortion which have been used within the US General Social Survey (GSS) <ref type="bibr" target="#b0">(Adamczyk &amp; Valdimarsdóttir, 2018;</ref><ref type="bibr" target="#b9">Carter et al., 2009)</ref>.</p><p>Respondents were presented with the four statements on different circumstances under which a woman should be able to obtain a legal abortion, and then asked to indicate to which extent they agree or disagree with each statement on a scale ranging from 1 "strongly disagree" to 7 "strongly agree." As a further response alternative, each item included a "don't know" category. The stated reasons for an abortion were (a) a woman simply not wanting more children, (b) a family which cannot afford any more children, (c) a high probability of serious birth defects, and (d) the endangerment of the woman's health due to the pregnancy (for question wording and implementation, see Online Appendix A). The items were presented in an item-by-item format with each of the four items shown on a separate screen with a vertical response scale. <ref type="foot" target="#foot_3">4</ref>Attitude certainty. To gain further insights on the relevance of reflection processes for attitude change, we used follow-up measures which were administered both in the first and last wave of the study directly after respondents answered the 4-items assessing abortion attitudes. The first measure assessed the certainty of respondents' abortion attitudes. After responding to the four items on abortion, respondents were asked to indicate whether they have a clear opinion on the issue of abortion on a 7-point Likert-scale ranging from 1 "I do not have a clear opinion on that." to 7 "I have a clear opinion on that.". Response options additionally included a "don't know"category.</p><p>Knowledgeability. The second measure captured respondents' level of knowledgeability on the issue. Respondents were asked to rate their familiarity with the topic of legal abortion on a 7-point Likert-scale ranging from 1 "Not familiar at all" to 7 "Very familiar" with the option to choose "don't know" as an explicit response category.</p><p>Conditioning frequency. To investigate whether topic-specific reflection processes are responsible for changes in respondents' (reported) attitudes, we use the study's experimental design and compare respondents with three different levels of exposure to identical attitude questions over the course of the six survey waves. We compare respondents who received identical attitude questions in every wave (i.e., fully conditioned) with respondents who received identical questions only three times from the second half of the study onwards (i.e., medium conditioned) and those who received the target attitude questions only once in the final wave of the study (i.e., unconditioned).</p><p>Survey experience. To explore the possible impact of experience with the general response task on answers to attitude questions, we use two different operationalization of survey experience. First, we compare the respondents across the probability and nonprobability panels. We argue that respondents of non-probability panels, on average, have much more experience in participating in many different surveys compared to respondents of probability-based panel studies, who only participate, for instance, every two or three months.</p><p>Administrative data obtained by the panel provider, indeed, shows that respondents of the non-probability panel had a median of 74 completed surveys in the last 12 months prior to our study, whereas respondents of the probability-based panel had participated in a maximum of 6 survey waves in the same period. Some nonprobability online panelists might even be a member of one or multiple other online panels <ref type="bibr" target="#b7">(Callegaro et al., 2014)</ref>. As a second operationalization of survey experience, we focus on respondents' experience within a panel and differentiate our experimental groups within the probability-based panel by panel cohort.</p><p>We compare respondents of the initial panel cohort (recruited in 2013 and highly experienced) with respondent of the second (medium experienced) and third cohort (lowest experienced), which have been incorporated into the panel 3 (in 2016) and 5 years (in 2018) later, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analytic strategy</head><p>The overall goal of our analyses is to test the mechanisms responsible for observed changes in attitude answers in panel studies. For this, we first investigate differences in the proportion of "don't know" answers to the target abortion measure between the experimental groups by conducting χ 2 -and Fisher's exact tests (if the number of observations was not sufficiently high) to answer Hypothesis 1.</p><p>Subsequently, we conduct a between-group comparison across the six experimental groups regarding their observed abortion attitudes in the last wave of the study to answer Hypothesis 2. To compare the groups, we use multiple-group confirmatory factor analysis (MG-CFA) testing measurement invariance of the target abortion measures across the differently conditioned respondent groups (i.e., different exposure to identical abortion questions and general experience in survey participation) in Wave 6. For this and subsequent analyses based on structural equation modeling, we use the R-package lavaan <ref type="bibr" target="#b34">(Rosseel, 2012)</ref>.</p><p>By conducting a MG-CFA, we can disentangle the effect of repeated interviewing on the measurement component of responses to the abortion questions (i.e., how respondents report their attitudes on abortion) from the effect of repeated interviewing on the actual underlying latent abortion attitudes. Testing measurement invariance consists of a series of pre-defined model comparisons that successively impose more stringent equality constraints on the parameters of a measurement model <ref type="bibr" target="#b6">(Byrne, 1989)</ref>.</p><p>The baseline measurement model that we compare across the groups in Wave 6 is a two-factor model distinguishing between abortion sought for elective reasons and abortion sought for trauma-or health-related reasons<ref type="foot" target="#foot_4">5</ref> . In particular, the first two abortion items (i.e., the woman does not want more children and the family cannot afford any more children) load on a latent factor representing elective reasons, whereas the last two items (i.e., high probability of birth defects and serious endangerment of the woman's health) load on a second latent factor capturing the traumatic reasons for seeking out an abortion (for an illustration of the two-factor model, see Figure <ref type="figure" target="#fig_2">2</ref>). The two-factor model has been validated in several previous studies <ref type="bibr" target="#b18">(Hoffmann &amp; Johnson, 2005;</ref><ref type="bibr" target="#b33">Osborne et al., 2022)</ref> and in various country contexts <ref type="bibr" target="#b19">(Huang et al., 2016;</ref><ref type="bibr" target="#b22">Karpov &amp; Kääriäinen, 2005;</ref><ref type="bibr" target="#b32">Osborne &amp; Davies, 2012)</ref> against a model with only one latent factor. Following the pre-defined model comparisons of a MG-CFA, we first test the overall factor structure and pattern of factor loadings of our measurement model (i.e., testing of configural invariance) across the six respondent groups (i.e., the three experimental groups in each panel study). Configural invariance exists if the two-factor structure as well as the loading patterns of the four abortion items are the same in every of the six experimental groups. If configural invariance can be established, we will proceed to test whether the magnitude of factor loadings is equal across the groups (i.e., metric invariance), and whether the intercepts of the items are equal across groups (i.e., scalar invariance). Finally, we will test whether residual variances of the indicators are equal across the six respondent groups (i.e., strict invariance).</p><p>As a sensitivity analysis, we additionally investigate answers to the target abortion measure across the six survey waves to test Hypothesis 2 further. We conduct this withingroup comparison for fully conditioned respondents who received the abortion measure in each survey wave and estimate a longitudinal factor analysis that tests the measurement invariance of abortion attitudes over time differentiating between changes in reported attitudes and underlying latent attitudes. Again, we follow the pre-defined series of model comparisons testing differences in the measurement components (i.e., factor loadings, item intercepts, residual variances). Testing our baseline model over the six survey waves, we allow the residual variance of an item to correlate across the six waves. If scalar invariance as a minimum requirement can be established, we will then further employ the longitudinal design of our study and use the within-group comparison to investigate the stability of the latent abortion attitudes over time by estimating an autoregressive first-order model (simplex model; see Figure <ref type="figure" target="#fig_3">3</ref>). While the outlined analyses so far address the question of whether panel conditioning takes place, such a finding would be consistent with both theoretical models (i.e., cognitive stimulus and "better respondents" model).</p><p>In order to test Hypothesis 3, which specifically relates to the assumptions of the cognitive stimulus model, we incorporate (self-reported) attitude certainty and knowledgeability on the issue of abortion into the between-group comparison of the baseline measurement model in the last wave of the study. By doing so, we estimate a structural equation model including these external covariates, which affect both latent factors of the abortion items. We test whether the means of respondents' attitude certainty and knowledgeability are significantly different across groups and how their impact on the latent abortion factors differs across groups.</p><p>Finally, to test Hypothesis 4, we compare the differently conditioned respondents of the probability and non-probability panels. Additionally, we differentiate the experimental groups of the probability-based panel by cohort and conduct multiple-group confirmatory factor analyses across the three different cohorts of the panel for each conditioning level (i.e., fully conditioned, medium conditioned, and unconditioned) separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Hypothesis 1: Differences in the proportion of "don't know" answers Before investigating change in respondents' abortion attitudes and its underlying mechanisms, we first compared the dropout rates in the last wave of the study across the experimental groups to exclude the possibility of bias due to differential non-response possibly affecting differences in observed abortion attitudes across groups. In both the probabilistic and non-probabilistic panel study, we only find marginal differences in dropout rates (with a maximum difference of about 6 percentage points), indicating that nonresponse is not significantly different across the experimental groups (for the detailed dropout rates per experimental group, see Table <ref type="table" target="#tab_9">B</ref>.6 and B.7 in the Online Appendix). To test Hypothesis 1, Table <ref type="table" target="#tab_1">1</ref> displays the proportion of "don't know" responses across the six experimental groups.</p><p>The results show that the three respondent groups of the probabilistic panel significantly differ in their amount of given "don't know" answers regarding two out of the four abortion items.</p><p>The respondent groups of the non-probabilistic panel only differ significantly in their proportion of "don't know" answers for one of the four abortion items. Nevertheless, fully conditioned respondents (i.e., respondents who were surveyed on abortion in each wave) in both the probabilistic and non-probabilistic panel consistently show a smaller proportion in "don't know" responses compared to the unconditioned respondents across all items, which is in line with the hypothesis. The magnitude of differences is greater among the groups of the non-probabilistic panel with differences amounting up to 4 percentage points (p.p.) on average, whereas differences across the respondent groups of the probabilistic panel are only 2 p.p. on average. For the last two abortion items (abortion due to birth defect and due to pregnancy endangering the woman's health), the amount of "don't know" responses did not differ across the respondent groups of the probabilistic panel, indicating that repeatedly being surveyed on these issues does not influence whether those respondents form a substantive opinion or report that they do not know. When excluding "don't know" and "skips" as a non-substantial answer for the further analyses below, we have complete data on all four abortion items for 4,370 respondents and partly missing data for 430 respondents, who are included in the between-group comparison analyses. For the within-group comparisons (on fully conditioned respondents of the probabilistic panel), we can include complete data on all abortion items and all six measurement points for 1,289 respondents and partly missing data for 1,031 respondents. To account for the missing patterns in the data, we use Full Information Maximum Likelihood (FIML) to estimate the model coefficients <ref type="bibr" target="#b14">(Enders &amp; Bandalos, 2001)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Testing measurement invariance across the six experimental groups</head><p>We first test configural invariance of the measurement model. For this, we fit the twofactor structure of the measurement model on abortion attitudes to the six different respondent groups while freely estimating the model's parameters (i.e., factor loadings, item intercepts, residual variances). The results provided in Table <ref type="table" target="#tab_2">2</ref> show that the two-factor model fits the data in each group (χ 2 (6) = 5.98, p = .43, root mean square error of approximation (RMSEA) = .000, Comparative Fit Index (CFI) &gt;.999, Akaike Information Criterion (AIC) = 60,539), according to the rules of thumb for model fit <ref type="bibr" target="#b24">(Kline, 2023)</ref>.</p><p>Next, we test for metric invariance by constraining all factor loadings to be equal across the six respondent groups but allowing for variation in item intercepts and residual variances. The results show that the metric invariance model does not significantly fit worse than the configural invariance model (∆χ 2 (10) = 11.80, p = .30) and additionally has a smaller value for the AIC (AIC = 60531), indicating that the factor loadings do not differ between the six respondent groups.</p><p>Consequently, we test for scalar invariance by constraining all factor loadings and additionally, the item intercepts to be equal across the experimental groups but freely estimating residual variances of the items across groups. Again, results show that the more restrictive model fits the data better than the less restrictive metric invariance model (∆χ 2 (10) = 11.85, p = .30; AIC = 60523), and accordingly that both factor loadings and item intercepts are equal across the six experimental group.</p><p>Lastly, we test for strict invariance and constrain all parameters (i.e., factor loadings, item intercepts, and residual variances) of the measurement model to be equal across the six experimental groups. The results indicate that equal residual variances across groups are not supported in the data by showing that the strict invariance model fits the data significantly worse than the less restrictive scalar invariance model (∆χ 2 (20) = 89.73, p &lt; .001; AIC = 60572). Thus, while there is no difference in the factor loadings and the item intercepts of the abortion measurement model, we find that residual variances of the abortion items differ significantly across our six experimental groups. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hypothesis 2: Attitude crystallization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Between-group analyses</head><p>Reliability. To test Hypothesis 2 on the crystallization of attitudes due to repeated interviewing, we first investigate changes in attitude reliability. For this, we inspect the residual variances of the four abortion itemswhich have been shown to be unequal across the six respondent groupsin more detail. Similar to <ref type="bibr" target="#b20">Jagodzinski et al. (1987)</ref>, we infer a higher degree of attitude reliability from smaller residual item variances. Although residual variances do not consistently decrease across the extent of exposure to the identical abortion questions (i.e., conditioning frequency) for all items, the fully conditioned respondent groups show the smallest residual variances for three out of the four abortion items. We calculated an average residual variance (see </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Within-group analyses</head><p>As a sensitivity analysis, we additionally investigate within-group changes in respondents' attitudes toward abortion over time. We focus on the analysis of fully conditioned respondents (who received the identical abortion measure in each of the six waves) from both the probability-based and the non-probability panel and first examine measurement invariance of the abortion items across the six measurement points. Our analysis of measurement invariance over time for respondents of the probability-based panel shows that only partial scalar invariance can be established (i.e., equal factor loadings and equal item intercepts except from the fourth abortion item in Wave 1), and that similar to the betweengroup analyses residual variances are not equal across the six waves. For fully conditioned respondents of the non-probability panel, measurement invariance analyses show similarly that only scalar invariance is supported in the data and that residual variances of the four 6 Besides investigating changes in the measurement component of respondents' abortion attitudes, we also examined whether repeated interviewing on the identical issues leads to changes in respondent's latent attitudes and found no differences in the latent factor means between the experimental groups. This indicates, that repeatedly answering identical questions on abortion does not change respondents' attitudes toward the subject (for detailed results, see The model fits the data sufficiently well (χ 2 (30) = 33.50, p = .30, RMSEA = .012, CFI = &lt;.</p><p>999, AIC = 95,522). We then compare this model to a structural equation model that includes equality constraints on the means of attitude certainty and knowledgeability across groups.</p><p>We find that the model with equality constraints on the covariates' means does not fit the data significantly worse than the less restrictive model (∆χ 2 (10) = 15.08, p = .13; AIC = 95,517;</p><p>for detailed model fit statistics, see Table <ref type="table">F</ref>.1 in the Online Appendix). This indicates that respondents do not hold their abortion attitudes more strongly or show higher levels of knowledgeability when they are repeatedly asked on the issue of abortion compared to those respondents who are not repeatedly surveyed on abortion.</p><p>After testing the covariates' means across the respondent groups, we then estimate a model with equality constraints regarding the covariates' impact on the latent abortion attitudes (i.e., equal regression slopes between the covariates and the latent factors). We find that the model with equal regression slopes fits the data better than the model with unequal regression slopes (∆χ 2 (20) = 30.89, p = .06; AIC = 95508, see Table <ref type="table">F</ref>.1. in the Online Appendix for detailed results), suggesting that the impact of attitude certainty and knowledgeability on latent abortion attitudes also does not differ across the experimental groups. Altogether, these results do not provide support for Hypothesis 3, as we do neither observe an increase in certainty or knowledgeability nor an increase in their impact on underlying abortion attitudes.</p><p>Hypothesis 4: Survey experience and increased attitude reliability ("better respondent" model)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probability-based vs. non-probability panel respondents</head><p>To test our fourth hypothesis regarding the impact of survey experience (i.e., experience with the response task in general) on the reliability of reported abortion attitudes, we first compare residual variances as an indicator of attitude reliability between fully conditioned respondents of the probability-based against respondents of the non-probability panel. To do so, we first constrain the residual variances of the abortion items to be equal between respondents of the probabilistic and the non-probabilistic panel. The results show that the model with equal residual variances among respondents of the probabilistic and nonprobabilistic panel fits the data significantly worse than the scalar invariance model with unequal residual variances (∆χ 2 (12) = 45.27, p &lt; .001; AIC = 60544; for detailed results, see Table <ref type="table">G</ref>.1 in the Online Appendix), indicating that respondents from the probability-based and the non-probability panel significantly differ from each other.</p><p>When comparing the standardized residual variances between the two panels (see parameter estimates of the scalar invariance model in Table <ref type="table" target="#tab_3">3</ref>), the residual variances of the fully conditioned respondents are larger among probability-based compared to nonprobabilistic panel members, which is line with Hypothesis 4. With respect to the reliability coefficients (see Table <ref type="table" target="#tab_15">C</ref>.2 in Online Appendix), we observe a similar pattern with fully conditioned respondents of the non-probabilistic panel showing (slightly) higher reliability coefficients compared to fully conditioned members of the probability-based panel. Because the observed differences are of small magnitude, our analyses provide tentative evidence for Hypothesis 4, assuming that higher levels of survey experience lead to increased attitude reliability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison of panel cohorts within the probability-based panel</head><p>We additionally differentiated the respondent groups of the probability-based panel by panel cohort to test Hypothesis 4 further. For every conditioning level, we tested differences in our measurement model between respondents of the three cohorts who have different tenure within the panel. Results of the MG-CFA across the panel cohorts show no significant differences in model parameters (for detailed results, see Online Appendix H). Consequently, factor loadings, item intercepts, and the residual variances of the abortion items are equal across cohort, indicating that experience within a panel does not change respondents' reported abortion attitudes. Overall, results imply that respondents' abortion attitudes are not affected by the amount of experience, so that Hypothesis 4 is not supported for this comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Previous research suggests that repeated interviewing on the same issues stimulates reflection processes within respondents which can lead to the crystallization of attitudes, that is, more reliable and stable attitudes (cognitive stimulus hypothesis; see <ref type="bibr" target="#b40">Sturgis et al., 2009)</ref>.</p><p>In this paper, we tested the cognitive stimulus hypothesis against the better respondents model <ref type="bibr" target="#b45">(Yan &amp; Eckman, 2012)</ref> which explains changes in attitude answers over time with respondents' increased experience with the general response task and more accurate self-reports. As the empirical base, we investigated changes in respondents' abortion attitudes and the underlying mechanisms of those changes over the course of six consecutive panel waves.</p><p>Our study used data from a longitudinal survey experiment conducted within both a German probabilistic and non-probabilistic panel. In this experiment, we manipulated the frequency of receiving identical attitude questions (1 time vs. 3 times vs. 6 times). We estimated structural equation models to further differentiate between changes in the measurement of respondents' reported abortion attitudes and changes in their latent attitudes toward abortion.</p><p>Overall, our study provides evidence for panel conditioning effects that result from repeatedly asking respondents questions on the same issues. Respondents who received the identical abortion questions in each wave of the study provided significantly fewer "don't know" answers to most items of the abortion battery compared to respondents who received the attitudinal target questions less often (Hypothesis 1). Following previous literature, this decrease in "don't know" responses could either be attributed to improved response behavior <ref type="bibr">(Waterton &amp; Lievesley, 1989)</ref> or an increased opinionation on the topic <ref type="bibr" target="#b40">(Sturgis et al., 2009)</ref>.</p><p>Moreover, the results show that attitude reliability is significantly different across the experimental groups and is highest for those respondents who received the identical abortion questions in each survey wave (i.e., fully conditioned respondents). Increases in attitude reliability, could be due to both better response behavior leading to more accurate self-reports as well as triggered reflection processes on surveyed topics. However, the observed differences in attitude reliability between the groups who differ in their survey intensity on identical topics, point to the attitude crystallization assumption of the cognitive stimulus hypothesis. Within-group comparisons of fully conditioned respondents provide further evidence in line with the findings of the between-group comparisons: Respondents' attitude reports on abortion become more reliable over time compared to the first wave of the study which can in this case be due to, both the increasing exposure to the identical issue of abortion or respondents simply becoming better at answering multi-item scales.</p><p>The results of the first-order autoregressive model, investigating change in the latent traits further show that respondents' latent abortion attitudes become more stable in subsequent waves of the study following the second interview. Although the results of the autoregressive model should be interpreted with caution given its model fit statistics, this implies that the attitude reliability we observe is at least partially due to a change in respondents' latent abortion attitudes rather than only the result from a change in how they report their attitudes. Therefore, the findings of the longitudinal factor analysis further support the assumption of crystallized abortion attitudes due to repeated interviewing on an identical issue (Hypothesis 2). Altogether, our findings on increased attitude reliability and stability are consistent with previous studies which document more reliable and stable attitudes among more experienced panelists <ref type="bibr" target="#b4">(Bergmann &amp; Barth, 2018;</ref><ref type="bibr" target="#b27">Kroh et al., 2016;</ref><ref type="bibr" target="#b40">Sturgis et al., 2009;</ref><ref type="bibr" target="#b41">Sun et al., 2019)</ref>.</p><p>Whereas both the findings of the between-and within-group comparisons point toward the cognitive stimulus hypothesis as an explanation for observed changes, we did not find evidence on increased attitude certainty and knowledgeability on abortion after respondents answered the identical abortion question multiple times (Hypothesis 3). This finding contradicts the assumptions of the cognitive stimulus hypothesis <ref type="bibr" target="#b40">(Sturgis et al., 2009)</ref> which argues that repeated survey participation triggers reflection processes and further information search, possibly leading to an increased attitude strength and increased knowledge levels.</p><p>Noteworthy, however, we used self-reported measures of attitude strength and knowledgeability which could have impacted this result.</p><p>We further tested the assumptions of triggered reflection processes against the theory of better response behavior by comparing respondents from the probability-based panel to the respondents of the non-probabilistic panel as well as comparing different panel cohorts of the probability-based panel. Whereas we do not find any evidence for differences in reported abortion attitudes across the three cohorts of the probabilistic panel, we find that fully conditioned respondents of the non-probabilistic panel show smaller residual variances and somewhat higher reliability coefficients compared to fully conditioned respondents of the probability-based panel. This finding indicates that general experience with responding to surveys might further enhance the reliability of reported attitudes (Hypothesis 4). In addition, as we did not only find changes in reliability of the measured attitudes but also an increased stability of the underlying abortion attitudes, we can assume that reflection processes on the survey topic might be triggered after repeatedly answering the same attitude question and that these processes are responsible for changes in the "true" underlying attitudes and not only for changes in their measurement component. This further supports the cognitive stimulus hypothesis <ref type="bibr" target="#b40">(Sturgis et al., 2009)</ref>.</p><p>Our study is not without limitations and opportunities for future research. In addition, future research could experimentally vary the topic and task difficulty while still manipulating the frequency of receiving identical question content to shed further light on which mechanism (triggered reflection processes vs. improved response behavior) is most likely responsible for observed changes in respondents' (attitude) answers over time.</p><p>Overall, our study provides valuable insights into the validity of attitudinal responses in longitudinal studies. By using an experimental study design and distinguishing between changes in the measurement of respondents' attitudes and their latent traits, we showed that repeated interviewing increases the reliability of reported attitudes and increases how stable latent attitudes are being held by respondents, both supporting the cognitive stimulus hypothesis. In addition, we found that experience with the overall response task further enhances attitude reliability when answering identical attitude questions repeatedly.</p><p>Consequently, our study suggests that repeated measurement can improve the accuracy of attitude answers in panel studies, which allows researchers a valid analysis of change and stability over time.</p><p>Appendix B: Outcome rates       The results for the elective factor show that reliability consistently rises with the level of conditioning for both groups of respondents: probabilistic and non-probabilistic panelists.</p><p>Fully conditioned respondents show the highest reliability coefficients. For the traumatic factor, we only observe this pattern for respondents of the non-probability panel. For respondents of the probability-based panel, we observe a less consistent pattern with unconditioned respondents showing the highest reliability coefficient and only an increased reliability of the fully conditioned respondent group compared to medium conditioned respondents. Similar to the residual variances of the abortion items, fully conditioned respondents of the non-probability panel show even higher reliability than those of the probability-based study. time are supported in the data (∆χ 2 (10) = 9.98, p = .44; AIC = 140,984). As a next step, we test for scalar invariance over time by constraining all factor loadings and the item intercepts to be equal across the survey waves. Our results show that the longitudinal scalar invariance model does fit the data significantly worse than the longitudinal metric invariance model (∆χ 2 (10) = 22.51, p = .01; AIC = 140,987), so that only partial scalar invariance can be established across the six measurement points (∆χ 2 (9) = 13.29, p = .15; AIC = 140,980). In the partial scalar invariance model, we freely estimated the intercept of the fourth abortion item (abortion due to endangerment of the woman's health by the pregnancy) in Wave 1, while we restricted the remaining item intercepts to be equal across time (for detailed results, see Table <ref type="table" target="#tab_19">E</ref>.2). After establishing equal factor loadings and equal item intercepts (except from the fourth item in Wave 1), we test for strict invariance over time. Similar to the MG-CFA, the results of the longitudinal CFA show that strict invariance is not supported in the data (∆χ 2 (19) = 128.33, p &lt; .001; AIC = 141,070) and that the residual variances of the abortion items are significantly different across the six measurement points.  ). However, estimates of the model's parameters show negative residual covariances for the third abortion item across selected measurement points (i.e., 𝛤 6,2 , 𝛤 6,3 , 𝛤 6,4 ). A possible reason for this might be the small sample size (n = 449) combined with the complexity of our fitted model (n parameter = 218), affecting the estimation of parameters. We, therefore, did not proceed to test relationships in the latent factors over time for the respondents of the non-probability panel.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Experimental design: Manipulation of exposure to identical target questions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>varied from 93.9% in the first wave to 92.9% in the last wave of the study. Up to the last wave of the study, 42.0% of the respondents dropped out of the study (see Online Appendix B, Tables B.1 and B.2 for detailed completion and attrition rates for each wave separated by the different respondent groups; Callegaro &amp; DiSogra, 2008). Probability-based panel study. The longitudinal survey experiment was additionally fielded within the GESIS Panela German probability-based mixed-mode access panel comprising about 5,200 panelists that are surveyed on topics such as subjective well-being, personality and personal values, media usage, and work and leisure (GESIS, 2023). The GESIS Panel was initially recruited in 2013, based on a random sample drawn from municipalities' population registers targeting German-speaking persons aged 18-70 years who were permanently residing in private households in Germany. The recruitment process followed a multi-stage procedure which initially included a face-to-face interview, whose response rate (AAPOR RR1) was 35.5% (Bosnjak et al., 2018). In 2016 and 2018, two refreshment samples (n = 1,710; n = 1,607) were recruited to counter the effects of panel attrition. Data collection in the GESIS Panel is administered in two modes, via web-based surveys (online mode) or mailed paper questionnaires (offline mode). By 2021, a majority of respondents (about 75%) complete the surveys online, whereas the remaining 25% of panelists participate in the offline mode. Irrespective of the participation mode, each panelist receives a survey invitation by mail that contains a prepaid cash incentive of €5. Panelists participating in the online mode additionally receive an email survey invitation and up to two email reminders: one week and two weeks after the invitation. Offline respondents do not receive reminders.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Two-factor measurement model on attitudes toward abortion.</figDesc><graphic coords="19,70.85,70.85,352.90,341.69" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Autoregressive first-order model (simplex model); for reasons of conciseness, only</figDesc><graphic coords="21,70.85,70.85,494.46,392.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>First, for the operationalization of general survey experienceto test its effect on changes in respondents' reported attitudes -, we compare different panel cohorts of the probabilistic panel. However, even the most recent cohort included in our analysis and in comparison, the least experienced cohort of the probabilistic panel has been part of the panel for about two years and respondents have already participated in up to 16 survey waves at the beginning of our study, which might have impacted our results. Second, we used subjective measures on attitude certainty and knowledgeability on the issue of abortion to test the cognitive stimulus hypothesis, possibly affecting conclusions on the relevance of reflection processes for attitude change in panel studies. Future research could use objective measures (e.g., response latency) and test alternative measures of peer discussions and media attention on surveyed topics to deepen the understanding of the underlying mechanism of attitude change.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Note. AIC = Akaike's Information Criterion; RMSEA = root mean square error of approximation; CFI = Comparative-Fit Index; *** p&lt;0.001 ** p&lt;0.01 * p&lt;0.05, a in comparison to the configural invariance model.We also investigated measurement invariance of abortion attitudes over time for the fully conditioned respondents of the non-probability panel. Following the pre-defined series of model comparisons, we first fitted our two-factor measurement model to the longitudinal data of the non-probability panel to test configural invariance over time. Fit statistics of the configural invariance model are sufficiently good (χ 2 (126) = 214.23, p &lt; .001, (RMSEA) = .039, (CFI) = .987, (AIC) = 21,570). Further tests on metric invariance show that only partial metric invariance over time can be established in the non-probability panel with factor loadings being equal over time except for the factor loading of abortion item 3 at Wave 6 (∆χ 2 (9) = 9.53, p = .39; AIC = 21,561). We further find that item intercepts are significantly equal across the six survey waves, establishing scalar invariance over time (∆χ 2 (10) = 12.80, p = .24; AIC = 21,554). Similar to our analysis of the fully conditioned respondents in the probabilistic panel, model fit statistics further show that a more restricted model with equal residual variances across the six measurement points fits the data significantly worse (∆χ 2 (19) = 78.10, p &lt; .001; AIC = 21,594). Accordingly, strict invariance over time is not supported in the data and the items' residual variances are significantly different across the six survey waves. The detailed parameter estimates of the scalar invariance model (see TableE.5) show in line with the analysis of respondents from the probability-based panel and our postulated Hypothesis 2 an overall decrease in residual variances and smaller residual variances in subsequent waves compared to the first wave of the study (see Column 𝜽 𝜹 ̅̅̅</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Percentage of "don't know" answers for the abortion items per experimental group Note. The estimated p-values for significance of the differences across groups are based on Pearson's χ 2 -test and Fisher's exact test for count data if observations of "don't know" were n = &lt;5 in single cells of the contingency table.</figDesc><table><row><cell>Experimental</cell><cell>Abortion item</cell><cell>Abortion item</cell><cell>Abortion item</cell><cell>Abortion item</cell></row><row><cell>group</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell></row><row><cell></cell><cell></cell><cell>Probability panel</cell><cell></cell><cell></cell></row><row><cell>Fully conditioned</cell><cell>6.41</cell><cell>6.29</cell><cell>5.08</cell><cell>4.36</cell></row><row><cell>Medium conditioned</cell><cell>9.13</cell><cell>8.78</cell><cell>6.30</cell><cell>3.72</cell></row><row><cell>Unconditioned</cell><cell>9.20</cell><cell>9.03</cell><cell>5.77</cell><cell>4.51</cell></row><row><cell>χ 2</cell><cell>11.10</cell><cell>10.23</cell><cell>2.10</cell><cell>.97</cell></row><row><cell>p-value</cell><cell>.004</cell><cell>.006</cell><cell>.349</cell><cell>.617</cell></row><row><cell></cell><cell cols="2">Nonprobability panel</cell><cell></cell><cell></cell></row><row><cell>Fully conditioned</cell><cell>3.63</cell><cell>2.82</cell><cell>0.81</cell><cell>1.21</cell></row><row><cell>Medium conditioned</cell><cell>7.34</cell><cell>6.62</cell><cell>5.45</cell><cell>3.10</cell></row><row><cell>Unconditioned</cell><cell>7.76</cell><cell>6.93</cell><cell>4.33</cell><cell>4.76</cell></row><row><cell>χ 2</cell><cell>4.35</cell><cell>4.99</cell><cell>-</cell><cell>-</cell></row><row><cell>p-value</cell><cell>.114</cell><cell>.083</cell><cell>.007</cell><cell>.066</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Model fit statistics for measurement invariance across the experimental groups</figDesc><table><row><cell>Model/Test</cell><cell>𝝌𝟐</cell><cell>df</cell><cell>CFI</cell><cell>RMSEA</cell><cell>AIC</cell><cell>∆𝝌𝟐</cell><cell>∆𝒅𝒇</cell></row><row><cell>Configural invariance</cell><cell>5.98</cell><cell>6</cell><cell>&gt;.999</cell><cell>.000</cell><cell>60539</cell><cell>-</cell><cell>-</cell></row><row><cell>Metric invariance</cell><cell>17.77</cell><cell>16</cell><cell>&gt;.999</cell><cell>.011</cell><cell>60531</cell><cell>11.80</cell><cell>10</cell></row><row><cell>Scalar invariance</cell><cell>29.62</cell><cell>26</cell><cell>&gt;.999</cell><cell>.013</cell><cell>60523</cell><cell>11.85</cell><cell>10</cell></row><row><cell>Strict invariance</cell><cell>119.35***</cell><cell>46</cell><cell>.992</cell><cell>.045</cell><cell>60572</cell><cell>89.73***</cell><cell>20</cell></row></table><note><p>Note. AIC = Akaike's Information Criterion; RMSEA = root mean square error of approximation; CFI = Comparative-Fit Index; *** p&lt;0.001 ** p&lt;0.01 * p&lt;0.05.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>shows the standardized estimates for the residual variances of each of the four abortion items (Columns 𝜽 𝟏 𝜹 -𝜽 𝟒 𝜹 ; for unstandardized estimates, see TableC.1 in Appendix).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 ,</head><label>3</label><figDesc>Column 𝜽 𝜹 ̅̅̅ ) over the four abortion items for reasons of conciseness, which shows similar results compared to the patterns we observe for the four individual items. Specifically, fully conditioned respondents show the smallest residual variances, which is in line with Hypothesis 2.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 .</head><label>3</label><figDesc>Standardized parameter estimates of the scalar invariance model across the experimental groups</figDesc><table><row><cell>Experimental</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>group/ parameter</cell><cell>𝝀 𝟏 𝒙</cell><cell>𝝀 𝟐 𝒙</cell><cell>𝝀 𝟑 𝒙</cell><cell>𝝀 𝟒 𝒙</cell><cell>𝝉 𝒙𝟏 𝝉 𝒙𝟐 𝝉 𝒙𝟑</cell><cell>𝝉 𝒙𝟒</cell><cell>𝜽 𝟏 𝜹</cell><cell>𝜽 𝟐 𝜹</cell><cell>𝜽 𝟑 𝜹</cell><cell>𝜽 𝟒 𝜹</cell><cell>𝜽 𝜹 ̅̅̅</cell></row><row><cell>estimates</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Probability panel</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fully conditioned</cell><cell cols="11">0.88 0.92 0.94 0.76 2.29 2.30 4.70 6.39 0.22 0.16 0.13 0.43 0.24</cell></row><row><cell>Medium conditioned</cell><cell cols="11">0.88 0.90 0.89 0.77 2.43 2.41 4.58 6.72 0.23 0.18 0.22 0.41 0.26</cell></row><row><cell cols="12">Unconditioned 0.86 0.88 0.93 0.77 2.36 2.35 4.31 5.99 0.27 0.22 0.13 0.41 0.26</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Non-probability panel</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fully conditioned</cell><cell cols="11">0.93 0.89 0.97 0.79 2.42 2.25 4.59 6.31 0.14 0.20 0.07 0.38 0.20</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>Table D.1 and D.2 in the Online Appendix).abortion items are significantly different across the six measurement points (for detailed results, see TableE.1 for probability-based panel respondents and TableE.4 for nonprobability panel respondents in the Online Appendix). Standardized parameter estimates for the longitudinal partial scalar invariance model Turning to the fully conditioned respondents of the non-probability panel, we similarly observe an overall pattern of decrease in residual variances across waves and smaller residual variances in subsequent waves compared to Wave 1 of the study (for detailed results, see TableE.5 and E.6 in the Online Appendix). The longitudinal patterns of the items' residual variances in both panels provide additional tentative support for Hypothesis 2, which expects an increase in attitude reliability due to repeated interviewing on the identical issue. For this, we use within-group comparison across the six survey waves and focus on fully conditioned respondents of the probabilistic panel 7 . As the data does support partial scalar invariance of our measurement model over time, we can investigate change patterns in respondents' latent abortion attitudes over the course of the six waves. We estimate indicate the stability of respondents' latent abortion attitudes over time. We compared a first-order model with unequal autoregression coefficients to a first-order model in which we restricted the autoregression coefficients to be equal over time (i.e., stability of respondents' latent abortion attitudes is equal over time). Model fit statistics show that the model with equal autoregression coefficients fits the data significantly worse than the model with unequal autoregression coefficients over time (∆χ 2 (8) = 61.89, p &lt; .001; AIC = 142699; for detailed model fit statistics, see TableE.8 in the Online Appendix), suggesting that the stability of respondents' abortion attitudes changes over time.To investigate the pattern of the autoregression coefficients over time, we inspect the coefficients' estimates provided in Table5(for the unstandardized estimates, see TableE.9 in patterns in our data that cannot be fully captured by the simplex model alone. Nevertheless, the increase in stability over time provides further tentative evidence in line with our Hypothesis 2, which assumes that repeatedly answering identical attitude questions leads to the crystallization of attitudes.</figDesc><table><row><cell cols="10">Reliability. The initial screening of the items' residual variances over time (Table 4,</cell><cell></cell></row><row><cell cols="9">Columns 𝜽 𝟏 𝜹 -𝜽 𝟒 𝜹 , for unstandardized estimates, see Table E.2 in the Online Appendix) for</cell><cell></cell><cell></cell></row><row><cell cols="10">respondents of the probability-based panel, shows a pattern of decreasing error variances</cell><cell></cell></row><row><cell cols="9">across the six survey waves. We calculated an average residual variance over the four</cell><cell></cell><cell></cell></row><row><cell cols="9">individual items (see Table 4, Column 𝜽 𝜹 ̅̅̅ ). The average residual variance across the six</cell><cell></cell><cell></cell></row><row><cell cols="10">measurement points supports the general pattern we observe across the four individual items,</cell><cell></cell></row><row><cell cols="9">showing a somewhat consistent decrease across waves (until Wave 6) and smaller error</cell><cell></cell><cell></cell></row><row><cell cols="6">variances in the subsequent waves compared to Wave 1.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Survey</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wave/ parameter</cell><cell>𝝀 𝟏 𝒙</cell><cell>𝝀 𝟐 𝒙</cell><cell>𝝀 𝟑 𝒙</cell><cell>𝝀 𝟒 𝒙</cell><cell>𝝉 𝒙𝟏 𝝉 𝒙𝟐 𝝉 𝒙𝟑 𝝉 𝒙𝟒</cell><cell>𝜽 𝟏 𝜹</cell><cell>𝜽 𝟐 𝜹</cell><cell>𝜽 𝟑 𝜹</cell><cell>𝜽 𝟒 𝜹</cell><cell>𝜽 𝜹 ̅̅̅</cell></row><row><cell>estimates</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wave 1</cell><cell cols="10">0.88 0.88 0.88 0.77 2.29 2.28 3.91 5.48 0.24 0.22 0.23 0.41 0.28</cell></row><row><cell>Wave 2</cell><cell cols="10">0.90 0.89 0.91 0.79 2.34 2.27 4.14 5.73 0.20 0.22 0.17 0.38 0.24</cell></row><row><cell>Wave 3</cell><cell cols="10">0.88 0.88 0.93 0.79 2.30 2.28 4.33 5.82 0.23 0.22 0.13 0.38 0.24</cell></row><row><cell>Wave 4</cell><cell cols="10">0.90 0.90 0.93 0.79 2.37 2.34 4.34 5.84 0.20 0.20 0.13 0.39 0.23</cell></row><row><cell>Wave 5</cell><cell cols="10">0.90 0.91 0.94 0.78 2.32 2.30 4.38 5.81 0.18 0.18 0.12 0.39 0.22</cell></row></table><note><p><p><p><p><p><p><p><p><p><p>Additional analyses comparing McDonald's third coefficient omega across the six measurement points for both fully conditioned respondents of the probability-based and the non-probability panel provide further tentative evidence on an increase in reliability supporting Hypothesis 2 (for detailed results, see Table</p>E</p>.3 and Table</p>E</p>.7 in the Online Appendix).</p>Stability. We further examine the crystallization of attitudes due to repeated interviewing (Hypothesis 2) by investigating changes in the stability of respondents' abortion attitudes over time.</p>7 </p>Parameter estimates of the longitudinal measurement model for fully conditioned respondents of the nonprobability panel have shown negative residual covariances for the third abortion item across selected measurement points. Due to the possibility of model misspecification and overfitting, we did not test relationships in the underlying abortion attitudes for respondents of the non-probability panel (for detailed results, see Table</p>E</p>.4 in the Online Appendix). thus the Online Appendix). The results show that autoregression coefficients between Wave 1 and Wave 2 are lowest compared to subsequent waves, indicating that the stability of respondents' latent abortion attitudes does increase after the second interview. Consequently, observed changes over time are not restricted to changes in the measurement component of the reported abortion attitudes but are also reflected in respondents' latent abortion attitudes, which become more stable over time. It should be noted that the results on changes in autoregression coefficients over time should be interpreted cautiously as the simplex model fit the data worse than the previously established partial scalar invariance model, possibly due to model complexity or complex</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 .</head><label>5</label><figDesc>Standardized estimates of first-order model with unequal autoregression coefficients</figDesc><table><row><cell></cell><cell>𝜷W2, W1</cell><cell>𝜷W3, W2</cell><cell>𝜷W4, W3</cell><cell>𝜷W5, W4</cell><cell>𝜷W6, W5</cell></row><row><cell>Elective factor</cell><cell>0.83</cell><cell>0.91</cell><cell>0.93</cell><cell>0.93</cell><cell>0.91</cell></row><row><cell>Traumatic factor</cell><cell>0.83</cell><cell>0.89</cell><cell>0.88</cell><cell>0.89</cell><cell>0.86</cell></row><row><cell>Hypothesis 3:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Increase in attitude certainty and knowledgeability as a result of reflection processes</head><label></label><figDesc></figDesc><table /><note><p>To test Hypothesis 3, we investigate the role of respondents' attitude certainty and knowledgeability. We first fit a structural model with attitude certainty and knowledgeability as external covariates that influence both latent factors across the six experimental groups.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table B .1</head><label>B</label><figDesc>Completion rates (COMR) per wave in the non-probability panel (in percent)All attrition rates refer to those respondents who completed the first wave.</figDesc><table><row><cell>Wave 1</cell><cell>93.90</cell></row><row><cell>Wave 2</cell><cell>80.70</cell></row><row><cell>Wave 3</cell><cell>90.42</cell></row><row><cell>Wave 4</cell><cell>92.57</cell></row><row><cell>Wave 5</cell><cell>93.16</cell></row><row><cell>Wave 6</cell><cell>92.87</cell></row><row><cell>Table B.2</cell><cell></cell></row><row><cell cols="2">Attrition rates (ATTR) per wave and respondent group in the non-probability panel (in</cell></row><row><cell>percent)</cell><cell></cell></row><row><cell>Wave 1</cell><cell>-</cell></row><row><cell>Wave 2</cell><cell>19.30</cell></row><row><cell>Wave 3</cell><cell>27.16</cell></row><row><cell>Wave 4</cell><cell>32.80</cell></row><row><cell>Wave 5</cell><cell>37.43</cell></row><row><cell>Wave 6</cell><cell>42.00</cell></row></table><note><p>Note.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table B .3</head><label>B</label><figDesc></figDesc><table><row><cell cols="4">Completion rates (COMR) per wave and panel cohort in the probability-based panel (in</cell></row><row><cell>percent)</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>First cohort</cell><cell>Second cohort</cell><cell>Third cohort</cell></row><row><cell>Wave 1</cell><cell>93.17</cell><cell>93.73</cell><cell>89.72</cell></row><row><cell>Wave 2</cell><cell>94.82</cell><cell>94.00</cell><cell>91.11</cell></row><row><cell>Wave 3</cell><cell>94.00</cell><cell>93.42</cell><cell>91.82</cell></row><row><cell>Wave 4</cell><cell>93.03</cell><cell>92.44</cell><cell>91.26</cell></row><row><cell>Wave 5</cell><cell>93.06</cell><cell>93.27</cell><cell>91.48</cell></row><row><cell>Wave 6</cell><cell>92.24</cell><cell>92.16</cell><cell>90.26</cell></row></table><note><p>Note. Completion rates are provided for each panel cohort, separately.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table B .4</head><label>B</label><figDesc>Note. The cumulative response rates provided by the GESIS Panel are dependent on recruitment and profile rates which are specific for each recruited panel cohort. CUMR is therefore, provided for each panel cohort, separately.</figDesc><table><row><cell cols="4">Cumulative response rates (CUMR) per wave and panel cohort in the probability-based panel</cell></row><row><cell>(in percent)</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>First cohort</cell><cell>Second cohort</cell><cell>Third cohort</cell></row><row><cell>Wave 1</cell><cell>11.45</cell><cell>9.68</cell><cell>9.62</cell></row><row><cell>Wave 2</cell><cell>11.51</cell><cell>9.54</cell><cell>9.58</cell></row><row><cell>Wave 3</cell><cell>11.24</cell><cell>9.32</cell><cell>9.41</cell></row><row><cell>Wave 4</cell><cell>11.01</cell><cell>9.08</cell><cell>9.12</cell></row><row><cell>Wave 5</cell><cell>10.93</cell><cell>9.10</cell><cell>8.99</cell></row><row><cell>Wave 6</cell><cell>10.69</cell><cell>8.84</cell><cell>8.75</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table B .5</head><label>B</label><figDesc>Attrition rates per wave of our experimental study and per panel cohort in the probabilitybased panel (in percent)As the GESIS Panel is an already established panel infrastructure comprising more than 50 waves, all attrition rates refer to those respondents who completed the first survey wave after recruitment. Consequently, attrition rates are differentiated for each recruited panel cohort.</figDesc><table><row><cell></cell><cell>First cohort</cell><cell>Second cohort</cell><cell>Third cohort</cell></row><row><cell>Wave 1</cell><cell>46.60</cell><cell>36.55</cell><cell>24.33</cell></row><row><cell>Wave 2</cell><cell>47.25</cell><cell>37.66</cell><cell>25.82</cell></row><row><cell>Wave 3</cell><cell>48.04</cell><cell>38.71</cell><cell>27.69</cell></row><row><cell>Wave 4</cell><cell>48.60</cell><cell>39.65</cell><cell>29.50</cell></row><row><cell>Wave 5</cell><cell>48.97</cell><cell>40.06</cell><cell>30.62</cell></row><row><cell>Wave 6</cell><cell>49.64</cell><cell>41.05</cell><cell>31.61</cell></row></table><note><p>Note.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table B</head><label>B</label><figDesc></figDesc><table><row><cell>.6</cell><cell></cell><cell></cell></row><row><cell cols="3">Attrition rates in Wave 6 of the experimental study per respondent group in the non-</cell></row><row><cell>probability panel (in percent)</cell><cell></cell><cell></cell></row><row><cell>Fully conditioned group</cell><cell>Medium conditioned group</cell><cell>Unconditioned group</cell></row><row><cell>44.12</cell><cell>41.32</cell><cell>47.15</cell></row></table><note><p>Note. The attrition rates refer to those respondents who completed the first wave.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table B .7</head><label>B</label><figDesc>Attrition rates in Wave 6 of the experimental study per respondent group in the probabilitybased panel (in percent)Note. As the GESIS Panel is an already established panel infrastructure comprising more than 50 waves, we calculated specific attrition rates for Wave 6 of our experimental study, referring to the respondents who completed the first wave of our study. We additionally differentiated for the different respondent groups. The rates are calculated based on the procedure for the calculation of attrition rates per panel cohort, which are provided by the GESIS Panel (GESIS, 2023).</figDesc><table><row><cell>Fully conditioned group</cell><cell>Medium conditioned group</cell><cell>Unconditioned group</cell></row><row><cell>1.41</cell><cell>1.29</cell><cell>1.55</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table C .2</head><label>C</label><figDesc>Reliability coefficients for both factors across the experimental groups</figDesc><table><row><cell>Experimental group</cell><cell>Reliability 𝝎 𝟑</cell><cell></cell></row><row><cell></cell><cell>Elective factor</cell><cell>Traumatic factor</cell></row><row><cell></cell><cell>Probability-based panel</cell><cell></cell></row><row><cell>Fully conditioned</cell><cell>0.90</cell><cell>0.85</cell></row><row><cell>Medium conditioned</cell><cell>0.88</cell><cell>0.83</cell></row><row><cell>Unconditioned</cell><cell>0.86</cell><cell>0.87</cell></row><row><cell></cell><cell>Non-probability panel</cell><cell></cell></row><row><cell>Fully conditioned</cell><cell>0.91</cell><cell>0.90</cell></row><row><cell>Medium conditioned</cell><cell>0.85</cell><cell>0.85</cell></row><row><cell>Unconditioned</cell><cell>0.82</cell><cell>0.80</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table D .2</head><label>D</label><figDesc>Standardized differences in latent factor means across the six experimental groups</figDesc><table><row><cell></cell><cell>Elective factor</cell><cell>Traumatic factor</cell></row><row><cell></cell><cell>Mean</cell><cell>Mean difference</cell></row><row><cell></cell><cell>difference</cell><cell></cell></row><row><cell>Fully conditioned (prob) vs.</cell><cell>-.233</cell><cell>-.021</cell></row><row><cell>medium conditioned (prob)</cell><cell>(.041)</cell><cell>(.043)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Fully conditioned (prob) vs. unconditioned (prob)</head><label></label><figDesc></figDesc><table><row><cell>-.208</cell><cell>-.627</cell></row><row><cell>(.042)</cell><cell>(.046)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Fully conditioned (prob) vs. fully conditioned (non-prob)</head><label></label><figDesc></figDesc><table><row><cell>Medium conditioned (prob) vs.</cell><cell>.054</cell><cell>-.518</cell></row><row><cell>unconditioned (non-prob)</cell><cell>(.080)</cell><cell>(.080)</cell></row><row><cell>Unconditioned (prob) vs. fully</cell><cell>.152</cell><cell>-.267</cell></row><row><cell>conditioned (non-prob)</cell><cell>(.076)</cell><cell>(.082)</cell></row><row><cell>Unconditioned (prob) vs.</cell><cell>-.232</cell><cell>-.375</cell></row><row><cell>medium conditioned (non-prob)</cell><cell>(.072)</cell><cell>(.084)</cell></row><row><cell>Unconditioned (prob) vs.</cell><cell>.029</cell><cell>-1.166</cell></row><row><cell>unconditioned (non-prob)</cell><cell>(.081)</cell><cell>(.082)</cell></row><row><cell>Fully conditioned (non-prob) vs.</cell><cell>-.384</cell><cell>-.108</cell></row><row><cell>medium conditioned (non-prob)</cell><cell>(.093)</cell><cell>(.104)</cell></row><row><cell>Fully conditioned (non-prob) vs.</cell><cell>-.123</cell><cell>-.899</cell></row><row><cell>unconditioned (non-prob)</cell><cell>(.100)</cell><cell>(.102)</cell></row><row><cell>Medium conditioned (non-prob)</cell><cell>.261</cell><cell>-.792</cell></row><row><cell>vs. unconditioned (non-prob)</cell><cell>(.097)</cell><cell>(.103)</cell></row><row><cell></cell><cell>-.056</cell><cell>.360</cell></row><row><cell></cell><cell>(.073)</cell><cell>(.077)</cell></row><row><cell>Fully conditioned (prob) vs.</cell><cell>-.440</cell><cell>.252</cell></row><row><cell>medium conditioned (non-prob)</cell><cell>(.068)</cell><cell>(.078)</cell></row><row><cell>Fully conditioned (prob) vs.</cell><cell>-.179</cell><cell>-.539</cell></row><row><cell>unconditioned (non-prob)</cell><cell>(.077)</cell><cell>(.076)</cell></row><row><cell>Medium conditioned (prob) vs.</cell><cell>.025</cell><cell>.648</cell></row><row><cell>Unconditioned (prob)</cell><cell>(.047)</cell><cell>(.053)</cell></row><row><cell>Medium conditioned (prob) vs.</cell><cell>.178</cell><cell>.381</cell></row><row><cell>fully conditioned (non-prob)</cell><cell>(.076)</cell><cell>(.081)</cell></row><row><cell>Medium conditioned (prob) vs.</cell><cell>-.206</cell><cell>.273</cell></row><row><cell>medium conditioned (non-prob)</cell><cell>(.071)</cell><cell>(.082)</cell></row></table><note><p>Note. Standard errors in parentheses.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table E .2</head><label>E</label><figDesc>Unstandardized parameter estimates for longitudinal partial scalar invariance model for fully conditioned respondents from the probability-based panel Reliability coefficients for both factors across the six survey waves for fully conditioned respondents from the probability-based panel Model fit statistics for tested models across the six survey waves for fully conditioned respondents from the non-probability panel</figDesc><table><row><cell>Scalar</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wave 3 model invariance</cell><cell cols="9">1.93 1.92 1.36 .90 5.05 5.0 6.03 6.37 1.08 1.05 .25 .46 236.57*** 145 .987 .038 21554 12.80</cell><cell>10</cell></row><row><cell>Strict</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>invariance</cell><cell></cell><cell cols="3">314.67*** 164</cell><cell>.979</cell><cell>.045</cell><cell>21594</cell><cell cols="2">78.10***</cell><cell>19</cell></row><row><cell>Wave 4 model</cell><cell cols="9">1.93 1.92 1.36 .90 5.05 6.03 6.37 .90 .88 .26 .46</cell></row><row><cell>Wave 5</cell><cell cols="9">1.93 1.92 1.36 .90 5.05 5.0 6.03 6.37 .88 .82 .24 .47</cell></row><row><cell>Wave 6</cell><cell cols="9">1.93 1.92 1.36 .90 5.05 5.0 6.03 6.37 .97 .86 .27 .44</cell></row><row><cell>Table E.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Reliability 𝝎 𝟑</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Elective factor</cell><cell></cell><cell cols="3">Traumatic factor</cell></row><row><cell>Wave 1</cell><cell></cell><cell></cell><cell>0.87</cell><cell></cell><cell></cell><cell></cell><cell>0.82</cell><cell></cell></row><row><cell>Wave 2</cell><cell></cell><cell></cell><cell>0.88</cell><cell></cell><cell></cell><cell></cell><cell>0.86</cell><cell></cell></row><row><cell>Wave 3</cell><cell></cell><cell></cell><cell>0.87</cell><cell></cell><cell></cell><cell></cell><cell>0.87</cell><cell></cell></row><row><cell>Wave 4</cell><cell></cell><cell></cell><cell>0.89</cell><cell></cell><cell></cell><cell></cell><cell>0.86</cell><cell></cell></row><row><cell>Wave 5</cell><cell></cell><cell></cell><cell>0.90</cell><cell></cell><cell></cell><cell></cell><cell>0.86</cell><cell></cell></row><row><cell>Wave 6</cell><cell></cell><cell></cell><cell>0.90</cell><cell></cell><cell></cell><cell></cell><cell>0.85</cell><cell></cell></row><row><cell>Table E.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Survey wave/</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>parameter</cell><cell>𝝀 𝟏 𝒙</cell><cell>𝝀 𝟐 𝒙</cell><cell>𝟑 𝒙</cell><cell>𝝀 𝟒 𝒙</cell><cell cols="3">𝝉 𝒙𝟏 𝝉 𝒙𝟐 𝝉 𝒙𝟑 𝝉 𝒙𝟒 𝜽 𝟏 𝜹</cell><cell>𝜽 𝟐 𝜹</cell><cell>𝜽 𝟑 𝜹</cell><cell>𝜽 𝟒 𝜹</cell></row><row><cell>estimates Model/Test</cell><cell></cell><cell>χ 2</cell><cell cols="2">df</cell><cell>CFI</cell><cell>RMSEA</cell><cell>AIC</cell><cell cols="2">∆𝝌𝟐</cell><cell>∆𝒅𝒇</cell></row><row><cell>Configural</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>invariance</cell><cell></cell><cell cols="3">214.23*** 126</cell><cell>.987</cell><cell>.039</cell><cell>21570</cell><cell>-</cell><cell>-</cell></row><row><cell>Wave 1 model</cell><cell cols="9">1.93 1.92 1.36 .90 5.05 5.0 6.03 6.42 1.14 1.03 .54 .56</cell></row><row><cell>Metric</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>invariance</cell><cell></cell><cell cols="3">240.37*** 136</cell><cell>.985</cell><cell>.041</cell><cell>21576</cell><cell cols="2">26.14**</cell><cell>10</cell></row><row><cell>Wave 2 model Partial metric</cell><cell cols="9">1.93 1.92 1.36 .90 5.05 5.0 6.03 6.37 .91 1.03 .37 .47</cell></row><row><cell>invariance</cell><cell></cell><cell cols="3">223.77*** 135</cell><cell>.987</cell><cell>.038</cell><cell>21561</cell><cell cols="2">9.53</cell><cell>9</cell></row><row><cell>model a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table E .5</head><label>E</label><figDesc>Standardized parameter estimates for longitudinal scalar invariance model for fully conditioned respondents from the non-probability panel Unstandardized parameter estimates for longitudinal scalar invariance model for fully conditioned respondents from the non-probability panel Reliability coefficients for both factors across the six survey waves for fully conditioned respondents from the non-probability panel Model fit statistics of first-order autoregressive models Note. AIC = Akaike's Information Criterion; RMSEA = root mean square error of approximation; CFI = Comparative-Fit Index; *** p&lt;0.001 ** p&lt;0.01 * p&lt;0.05.</figDesc><table><row><cell>Table E.6 Table E.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model/Test</cell><cell></cell><cell>χ 2</cell><cell>df</cell><cell></cell><cell></cell><cell>CFI</cell><cell>RMSEA</cell><cell>AIC</cell><cell></cell><cell>∆𝝌𝟐</cell><cell>∆𝒅𝒇</cell></row><row><cell>Simplex</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>model w/ Survey wave/ parameter coefficients estimates autoregressive unequal</cell><cell cols="2">𝝀 𝟏 𝒙 2033.48 𝝀 𝟐 𝒙</cell><cell cols="2">𝝀 𝟑 𝒙 195</cell><cell>𝝀 𝟒 𝒙</cell><cell cols="4">𝝉 𝒙𝟏 𝝉 𝒙𝟐 𝝉 𝒙𝟑 𝝉 𝒙𝟒 𝜽 𝟏 𝜹 .960 .064 142653</cell><cell>𝜽 𝟐 𝜹</cell><cell>𝜽 𝟑 𝜹 -</cell><cell>𝜽 𝟒 𝜹</cell><cell>-</cell></row><row><cell>Simplex</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>model w/</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wave 1 autoregressive equal</cell><cell cols="10">1.90 1.86 1.28 .94 5.01 4.96 6.10 6.40 1.18 1.14 .52 .54 2095.37 203 .959 .063 142699 61.89***</cell><cell>8</cell></row><row><cell>coefficients</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wave 2</cell><cell cols="10">1.90 1.86 1.28 .94 5.01 4.96 6.10 6.40 1.06 .85 .45 .44</cell></row><row><cell>Survey wave/ parameter</cell><cell>𝝀 𝟏 𝒙</cell><cell>𝝀 𝟐 𝒙</cell><cell>𝝀 𝟑 𝒙</cell><cell cols="2">𝝀 𝟒 𝒙</cell><cell cols="3">𝝉 𝒙𝟏 𝝉 𝒙𝟐 𝝉 𝒙𝟑 𝝉 𝒙𝟒 𝜽 𝟏 𝜹</cell><cell cols="2">𝜽 𝟐 𝜹</cell><cell>𝜽 𝟑 𝜹</cell><cell>𝜽 𝟒 𝜹</cell><cell>𝜽 𝜹 ̅̅̅</cell></row><row><cell>estimates</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wave 3</cell><cell cols="10">1.90 1.86 1.28 .94 5.01 4.96 6.10 6.40 .96 1.13 .37 .37</cell></row><row><cell>Wave 1 Wave 4</cell><cell cols="10">.87 .87 .87 .79 2.29 2.31 4.15 5.37 .25 .25 .24 .38 .28 1.90 1.86 1.28 .94 5.01 4.96 6.10 6.40 .67 .55 .36 .48</cell></row><row><cell>Wave 2</cell><cell cols="10">.88 .90 .88 .81 2.31 2.38 4.37 5.72 .23 .19 .23 .35 .25</cell></row><row><cell>Wave 5</cell><cell cols="10">1.90 1.86 1.28 .94 5.01 4.96 6.10 6.40 .72 .90 .51 .56</cell></row><row><cell>Wave 3</cell><cell cols="10">.90 .88 .90 .84 2.28 2.25 4.34 5.77 .20 .23 .19 .30 .23</cell></row><row><cell>Wave 6</cell><cell cols="10">1.90 1.86 1.60 .94 5.01 4.96 6.10 6.40 .56 1.16 .09 .43</cell></row><row><cell>Wave 4</cell><cell cols="10">.93 .94 .91 .80 2.30 2.35 4.34 5.50 .14 .12 .18 .36 .20</cell></row><row><cell>Table E.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wave 5</cell><cell cols="10">.92 .90 .88 .80 2.28 2.25 4.02 5.18 .15 .19 .22 .37 .23</cell></row><row><cell>Wave 6</cell><cell cols="10">.94 .88 .98 .78 2.33 2.20 4.26 6.06 .12 .23 .04 .39 .20 Reliability 𝝎 𝟑</cell></row><row><cell></cell><cell></cell><cell cols="4">Elective factor</cell><cell></cell><cell cols="4">Traumatic factor</cell></row><row><cell>Wave 1</cell><cell></cell><cell></cell><cell>0.85</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.83</cell><cell></cell></row><row><cell>Wave 2</cell><cell></cell><cell></cell><cell>0.89</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.84</cell><cell></cell></row><row><cell>Wave 3</cell><cell></cell><cell></cell><cell>0.89</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.86</cell><cell></cell></row><row><cell>Wave 4</cell><cell></cell><cell></cell><cell>0.93</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.85</cell><cell></cell></row><row><cell>Wave 5</cell><cell></cell><cell></cell><cell>0.91</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.83</cell><cell></cell></row><row><cell>Wave 6</cell><cell></cell><cell></cell><cell>0.91</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.90</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table E .9</head><label>E</label><figDesc>Unstandardized estimates of first-order model with unequal autoregression coefficientsModel fit statistics of tested models across the cohorts of the probability-based panel (unconditioned respondents)Note. AIC = Akaike's Information Criterion; RMSEA = root mean square error of approximation; CFI = Comparative-Fit Index; *** p&lt;0.001 ** p&lt;0.01 * p&lt;0.05.</figDesc><table><row><cell>Table H.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Model/Test</cell><cell>χ 2</cell><cell>df</cell><cell>CFI</cell><cell>RMSEA</cell><cell>AIC</cell><cell>∆𝝌𝟐</cell><cell>∆𝒅𝒇</cell></row><row><cell>Configural</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>invariance</cell><cell>6.01</cell><cell>3</cell><cell>.998</cell><cell>.055</cell><cell>12887</cell><cell>-</cell><cell>-</cell></row><row><cell>model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Metric</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>invariance</cell><cell>9.41</cell><cell>7</cell><cell>.999</cell><cell>.032</cell><cell>12883</cell><cell>3.40</cell><cell>4</cell></row><row><cell>model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Scalar</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>invariance</cell><cell>13.19</cell><cell>11</cell><cell>.999</cell><cell>.024</cell><cell>12878</cell><cell>3.78</cell><cell>4</cell></row><row><cell>model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Strict</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>invariance</cell><cell>23.96</cell><cell>19</cell><cell>.997</cell><cell>.028</cell><cell>12873</cell><cell>10.77</cell><cell>8</cell></row><row><cell>model</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>𝜷W2, W1</cell><cell></cell><cell>𝜷W3, W2</cell><cell>𝜷W4, W3</cell><cell>𝜷W5, W4</cell><cell>𝜷W6, W5</cell><cell></cell></row><row><cell>Elective factor</cell><cell>.82</cell><cell></cell><cell>.89</cell><cell>.92</cell><cell>.96</cell><cell>.92</cell><cell></cell></row><row><cell>Traumatic</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>.80</cell><cell></cell><cell>.86</cell><cell>.88</cell><cell>.91</cell><cell>.84</cell><cell></cell></row><row><cell>factor</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0"><p>We refer to the three experimental groups as "fully conditioned", "medium conditioned", and "unconditioned" group dependent on their frequency of exposure to identical attitude questions. The used terminology, however, does not indicate whether respondent conditioning has actually happened due to our experimental setup.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1"><p>The unequal sample size of the three experimental groups resulted from subsequent changes in the survey design during the fieldwork period. The unconditioned control group was equally split to introduce an additional manipulation of conditioning frequency in which respondents received the attitudinal (target) questions three out of six times (i.e., medium conditioned).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2"><p>The outcome rates provided by the GESIS Panel are specified for each recruited panel cohort, separately.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3"><p>In the offline mode of the GESIS Panel, the abortion items were not displayed on different pages of the paper questionnaire.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4"><p>Using this terminology (i.e., 'elective' and 'traumatic'), we follow previous literature that investigates a twofactor measurement model of abortion attitudes in various country contexts<ref type="bibr" target="#b33">(Osborne et al., 2022;</ref><ref type="bibr" target="#b32">Osborne &amp; Davies, 2012)</ref>. We distinguish between elective and traumatic abortion to capture the differences in the circumstances that lead to abortion. However, we are not suggesting that having an elective abortion is free from trauma or that traumatic abortion does not offer any choice to a woman.</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>This work was supported by the <rs type="funder">"German Research Foundation" (DFG)</rs> [Grant Number: 418316085].</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Online Appendix</head><p>Appendix A: Question wordings and implementation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attitudes toward abortion</head><p>Below you will find statements about potential reasons for a legal abortion. In Germany, an abortion is considered legal until the 12th week of pregnancy. We are interested in your personal opinion on this topic and to what extent you agree or disagree with the following statements.</p><p>• It should be possible for a pregnant woman to have a legal abortion if she is married and no longer wants children. • It should be possible for a pregnant woman to have a legal abortion if the woman's health is seriously endangered by the pregnancy.</p><p>1 Strongly disagree -7 Strongly agree; 99 Don't know</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attitude certainty</head><p>The previous questions were about potential reasons that might lead a pregnant woman into having a legal abortion.</p><p>Do you have a clear opinion on legal abortions or not?</p><p>1 I do not have a clear opinion on that -7 I have a clear opinion on that; 99 Don't know</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Knowledgeability</head><p>In the following, we would like to ask you one more question about the reasons that may lead a pregnant woman into having a legal abortion.</p><p>How familiar are you with this topic?</p><p>1 Not familiar at all -7 Very familiar; 99 Don't know</p><p>Appendix C: Multiple-group confirmatory factor analysis  <ref type="bibr" target="#b24">(Kline, 2023)</ref>.</p><p>After establishing the two-factor structure of the measurement model over time we then test for metric invariance over time, restricting all factor loadings to be equal across the six measurement points. We find that metric invariance holds and equal factor loading over   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix F: Structural equation model including subjective attitude certainty and knowledgeability</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix G: Comparison of respondents from the probability-based panel and the non-probability panel</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Understanding Americans&apos; abortion attitudes: The role of the local religious context</title>
		<author>
			<persName><forename type="first">A</forename><surname>Adamczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Valdimarsdóttir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Social Science Research</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="129" to="144" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Information needs, surveys, and measurement errors. Panel surveys</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Bailar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="1" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Practice effects on the Wisconsin Card Sorting Test-64 card version across 12 months</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Basso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lowery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ghormley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Bornstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Clinical Neuropsychologist</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="471" to="478" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">R</forename><surname>Zell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Y H</forename><surname>Ching</surname></persName>
		</author>
		<title level="m">Can Participating in a Panel Sample introduce Bias into Trend Estiamtes? Proceedings of Survey Research Methods Section of the American Statistical Association</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="1010" to="1013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">What was I thinking? A theoretical framework for analysing panel conditioning in attitudes and (response) behaviour</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Barth</surname></persName>
		</author>
		<idno type="DOI">10.1080/13645579.2017.1399622</idno>
		<ptr target="https://doi.org/10.1080/13645579.2017.1399622" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Research Methodology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="333" to="345" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Panel Conditioning in Difficult Attitudinal Questions</title>
		<author>
			<persName><forename type="first">J</forename><surname>Binswanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Schunk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Toepoel</surname></persName>
		</author>
		<idno type="DOI">10.1093/poq/nft030</idno>
		<ptr target="https://doi.org/10.1093/poq/nft030" />
	</analytic>
	<monogr>
		<title level="j">Public Opinion Quarterly</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="783" to="797" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multigroup Comparisons and the Assumption of Equivalent Construct Validity Across Groups: Methodological and Substantive Issues</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Byrne</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15327906mbr2404_7</idno>
		<ptr target="https://doi.org/10.1207/s15327906mbr2404_7" />
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Research</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="503" to="523" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Online panel research</title>
		<author>
			<persName><forename type="first">M</forename><surname>Callegaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bethlehem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Göritz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Krosnick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lavrakas</surname></persName>
		</author>
		<idno type="DOI">10.1002/9781118763520.ch1</idno>
		<ptr target="https://doi.org/10.1002/9781118763520.ch1" />
	</analytic>
	<monogr>
		<title level="m">Online Panel Research</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Callegaro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Baker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Bethlehem</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Göritz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Krosnick</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lavrakas</surname></persName>
		</editor>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Computing response metrics for online panels</title>
		<author>
			<persName><forename type="first">M</forename><surname>Callegaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Disogra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public opinion quarterly</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1008" to="1032" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Trends in abortion attitudes by race and gender: A reassessment over a four-decade period</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Sociological Research</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Clausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Response Validity: Vote Report</title>
		<imprint>
			<date type="published" when="1968">1968</date>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="588" to="606" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Panel Bias from Attrition and Conditioning: A Case Study of the Knowledge Networks Panel</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Clinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Experimental evidence on panel conditioning effects when increasing the surveying frequency in a probability-based online panel</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cornesse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Blom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M.-L</forename><surname>Sohnius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gonzalez Ocanto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Rettig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ungefucht</surname></persName>
		</author>
		<ptr target="https://madoc.bib.uni-mannheim.de/66055/1/7990_artcl.pdf" />
	</analytic>
	<monogr>
		<title level="j">Survey Research Methods: SRM</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="323" to="339" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Panel Conditioning in the US Consumer Expenditure Survey</title>
		<author>
			<persName><forename type="first">S</forename><surname>Eckman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Official Statistics (JOS)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Relative Performance of Full Information Maximum Likelihood Estimation for Missing Data in Structural Equation Models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Enders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bandalos</surname></persName>
		</author>
		<idno type="DOI">10.1207/S15328007SEM0803_5</idno>
		<ptr target="https://doi.org/10.1207/S15328007SEM0803_5" />
	</analytic>
	<monogr>
		<title level="j">Structural Equation Modeling: A Multidisciplinary Journal</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="430" to="457" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Using Analysis of Gini (ANOGI) for Detecting Whether Two Subsamples Represent the Same Universe: The German Socio-Economic Panel Study (SOEP) Experience</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Frick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goebel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Schechtman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yitzhaki</surname></persName>
		</author>
		<idno type="DOI">10.1177/0049124105283109</idno>
		<ptr target="https://doi.org/10.1177/0049124105283109" />
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="427" to="468" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">GESIS Panel Standard Edition. GESIS Data Archive, Cologne</title>
		<author>
			<persName><surname>Gesis</surname></persName>
		</author>
		<idno type="DOI">10.4232/1.14007</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Panel conditioning in the general social survey</title>
		<author>
			<persName><forename type="first">A</forename><surname>Halpern-Manners</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Torche</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="124" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Attitudes toward abortion among religious traditions in the United States: Change or continuity?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociology of Religion</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="182" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Benevolent sexism, attitudes toward motherhood, and reproductive rights: A multi-study longitudinal examination of abortion attitudes</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Sibley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Osborne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Personality and Social Psychology Bulletin</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="970" to="984" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Is there a &quot;Socratic Effect</title>
		<author>
			<persName><forename type="first">W</forename><surname>Jagodzinski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Kühnel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Schmidt</surname></persName>
		</author>
		<idno type="DOI">10.1177/0049124187015003004</idno>
		<ptr target="https://doi.org/10.1177/0049124187015003004" />
	</analytic>
	<monogr>
		<title level="m">Nonexperimental Panel Studies?: Consistency of an Attitude toward Guestworkers</title>
		<imprint>
			<date type="published" when="1987">1987</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="259" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">G</forename><surname>Kalton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kasprzyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mcmillen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>Panel surveys</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Abortion culture&quot; in Russia: Its origins, scope, and challenge to social development</title>
		<author>
			<persName><forename type="first">V</forename><surname>Karpov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kääriäinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Sociology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="13" to="33" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Survey experience and its positive impact on response behavior in longitudinal surveys: Evidence from the probability-based GESIS Panel</title>
		<author>
			<persName><forename type="first">E</forename><surname>Kartsounidou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kluge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Silber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gummer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Social Research Methodology</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Principles and practice of structural equation modeling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Kline</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023">2023</date>
			<publisher>Guilford publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Panel Conditioning in A Probability-based Longitudinal study: A Comparison of Respondents with Different Levels of Survey Experience</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kraemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Silber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Struminskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosnjak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koßmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Weiß</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Survey Statistics and Methodology</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note>smad004</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Satisficing Response Behavior Across Time: Assessing Negative Panel Conditioning Using an Experimental Design with Six Repetitions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Kraemer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Silber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Struminskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Weiß</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosnjak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Koßmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sand</surname></persName>
		</author>
		<ptr target="https://ojs.ub.uni-konstanz.de/srm/article/view/7986" />
	</analytic>
	<monogr>
		<title level="j">Survey Research Methods</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="269" to="300" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Using Person-Fit Measures to Assess the Impact of Panel Conditioning on Reliability</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kroh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schupp</surname></persName>
		</author>
		<idno type="DOI">10.1093/poq/nfw025</idno>
		<ptr target="https://doi.org/10.1093/poq/nfw025" />
	</analytic>
	<monogr>
		<title level="j">Public Opinion Quarterly</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="914" to="942" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Y</forename><surname>Kruse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Callegaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Dennis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Subias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Disogra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Tompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Methodological Research on Web Panel Conditioning and Attrition. Accuracy&apos;s Impact on Research. A Knowledge Networks Newsletter</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Lazarsfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Panel&quot; studies. The Public Opinion Quarterly</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="122" to="128" />
			<date type="published" when="1940">1940</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Test theory: A unified treatment</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcdonald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>psychology press</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Online access panels and tracking research. The conditioning issue</title>
		<author>
			<persName><forename type="first">C</forename><surname>Nancarrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Cartwright</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Market Research</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="573" to="594" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">When Benevolence Backfires: Benevolent Sexists&apos; Opposition to Elective and Traumatic Abortion 1</title>
		<author>
			<persName><forename type="first">D</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Davies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Social Psychology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="291" to="307" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Abortion attitudes: An overview of demographic and ideological differences</title>
		<author>
			<persName><forename type="first">D</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">C</forename><surname>Overall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Petterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Sibley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Political Psychology</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="29" to="76" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">lavaan: An R package for structural equation modeling</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Rosseel</surname></persName>
		</author>
		<ptr target="https://www.jstatsoft.org/article/view/v048i02" />
	</analytic>
	<monogr>
		<title level="j">Journal of statistical software</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Slapers en inactieven binnen online panels</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Scherpenzeel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zandvliet</surname></persName>
		</author>
		<ptr target="https://ideas.repec.org/p/tiu/tiutis/" />
		<imprint>
			<date type="published" when="2011">2011. 0eb1dc85-8b8c-4802-ace1-496499154ee4.html</date>
		</imprint>
		<respStmt>
			<orgName>Tilburg University, School of Economics and Management</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Minderop</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weyandt</surname></persName>
		</author>
		<title level="m">GESIS Panel Wave Report: Wave he (GESIS Panel Wave Report)</title>
		<imprint>
			<publisher>GESIS -Leibniz Institute for the Social Sciences</publisher>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Does panel conditioning affect data quality in ego-centered social network questions? Social Networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Silber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schröder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Struminskaya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Stocké</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bosnjak</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.socnet.2018.08.003</idno>
		<ptr target="https://doi.org/10.1016/j.socnet.2018.08.003" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="45" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Stadtmüller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Schwerdtfeger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Weyandt</surname></persName>
		</author>
		<title level="m">GESIS Panel Wave Report: Wave id (GESIS Panel Wave Report)</title>
		<imprint>
			<publisher>GESIS -Leibniz Institute for the Social Sciences</publisher>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Respondent Conditioning in Online Panel Surveys: Results of Two Field Experiments</title>
		<author>
			<persName><forename type="first">B</forename><surname>Struminskaya</surname></persName>
		</author>
		<idno type="DOI">10.1177/0894439315574022</idno>
		<ptr target="https://doi.org/10.1177/0894439315574022" />
	</analytic>
	<monogr>
		<title level="j">Social Science Computer Review</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="115" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Attitudes over time: The psychology of panel conditioning. Methodology of longitudinal surveys</title>
		<author>
			<persName><forename type="first">P</forename><surname>Sturgis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Allum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Brunton-Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page">126</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Panel Effects: Do the Reports of Panel Respondents Get Better or Worse over Time</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Tourangeau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Presser</surname></persName>
		</author>
		<idno type="DOI">10.1093/jssam/smy021</idno>
		<ptr target="https://doi.org/10.1093/jssam/smy021" />
	</analytic>
	<monogr>
		<title level="j">Journal of Survey Statistics and Methodology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="572" to="588" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Panel Conditioning in Longitudinal</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Halpern-Manners</surname></persName>
		</author>
		<idno type="DOI">10.1177/0049124112460374</idno>
		<ptr target="https://doi.org/10.1177/0049124112460374" />
	</analytic>
	<monogr>
		<title level="j">Social Science Surveys. Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="491" to="534" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Evidence of conditioning effects in the British Social Attitudes Panel</title>
		<author>
			<persName><forename type="first">J</forename><surname>Waterton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Livesley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Panel Surveys</title>
		<editor>
			<persName><forename type="first">D</forename><surname>Kasprzyk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Duncan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Kalton</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Singh</surname></persName>
		</editor>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="319" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Pre-election Interview Effects on Voter Turnout</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">F</forename><surname>Yalch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Public Opinion Quarterly</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="331" to="336" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Panel Conditioning: Change in True Value versus Change in Self</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eckman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="4726" to="4736" />
		</imprint>
		<respStmt>
			<orgName>Survey Research Methods</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
