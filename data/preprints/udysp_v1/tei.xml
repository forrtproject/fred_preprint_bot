<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large Language Models (LLMs) for Evidence Synthesis: An Exploratory Evaluation and A New Approach for Automated Data Extraction</title>
				<funder ref="#_M6SDQC7">
					<orgName type="full">Social Sciences and Humanities Research Council</orgName>
					<orgName type="abbreviated">SSHRC</orgName>
				</funder>
				<funder ref="#_UkpbKxr">
					<orgName type="full">Connaught Fund</orgName>
				</funder>
				<funder ref="#_ETZfKFG">
					<orgName type="full">International Network of Educational Institutes</orgName>
				</funder>
				<funder ref="#_QnRd2Fs">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Yuchen</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Applied Psychology and Human Development</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Nanyu</forename><surname>Luo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Applied Psychology and Human Development</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Hajung</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Applied Psychology and Human Development</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Linxin</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Mechanical and Industrial Engineering</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Linfeng</forename><surname>Gao</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jiayi</forename><surname>Han</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Division of Applied Psychology</orgName>
								<orgName type="department" key="dep2">School of Humanities and Social Science</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<postCode>518172</postCode>
									<settlement>Shenzhen, Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Shi'ting Chen</surname></persName>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Division of Applied Psychology</orgName>
								<orgName type="department" key="dep2">School of Humanities and Social Science</orgName>
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
								<address>
									<postCode>518172</postCode>
									<settlement>Shenzhen, Guangdong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Xiaoya</forename><surname>Zhang</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Department of Family, Youth and Community Sciences</orgName>
								<orgName type="institution">University of Florida</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>PhD</roleName><forename type="first">Jinbo</forename><surname>He</surname></persName>
							<email>jinbo.he@xjtlu.edu.cn</email>
							<affiliation key="aff5">
								<orgName type="department" key="dep1">Department of Biosciences and Bioinformatics</orgName>
								<orgName type="department" key="dep2">School of Science</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong-Liverpool University</orgName>
								<address>
									<postCode>215123</postCode>
									<settlement>Suzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><roleName>PhD</roleName><forename type="first">Feng</forename><surname>Ji</surname></persName>
							<email>f.ji@utoronto.ca.and</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Applied Psychology and Human Development</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff6">
								<orgName type="department">Department of Applied Psychology and Human Development</orgName>
								<orgName type="institution">University of Toronto</orgName>
								<address>
									<settlement>Toronto</settlement>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff7">
								<orgName type="department" key="dep1">Department of Biosciences and Bioinformatics</orgName>
								<orgName type="department" key="dep2">School of Science</orgName>
								<orgName type="institution">Xi&apos;an Jiaotong-Liverpool University</orgName>
								<address>
									<postCode>215123</postCode>
									<settlement>Suzhou, Jiangsu</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Large Language Models (LLMs) for Evidence Synthesis: An Exploratory Evaluation and A New Approach for Automated Data Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D96B6510473E0F622B3BCE2147F09D64</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-21T13:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Generative AI</term>
					<term>Large Language Models</term>
					<term>Responsible AI</term>
					<term>ChatGPT</term>
					<term>Evidence Synthesis</term>
					<term>Meta-analysis</term>
					<term>Research Methods</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Large language models (LLMs) are increasingly used in scientific research for their strong general problem-solving capabilities. Data extraction remains one of the most time-and labor-consuming steps in evidence synthesis (ES), making LLMs a promising tool with improved efficiency and accuracy. Our study evaluates the performance of different LLMs and proposes a novel method, Divide, Conquer, then Recheck (DCR), to optimize for LLM-based data extraction in ES. Multiple LLM foundational models were compared through accuracy, precision, recall, and F1score. We find that GPT-4o demonstrates notably better performance across most variables compared to ChatPDF, Bing Chat, and GPT-4. The proposed DCR method powered by GPT4-o achieved higher accuracy in most structured data extraction and the few-shot prompting strategy further improved performance on complex information (e.g., correlation coefficient). These findings highlight the potential of using LLMs in ES research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Large Language Models (LLMs) for Evidence Synthesis: An Exploratory Evaluation for</head><p>Automated Data Extraction and A Novel Method with Improved Performance</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Evidence synthesis (ES) is a systematic research process of integrating information from multiple studies to provide a comprehensive understanding of a specific topic. It involves methodical and reproducible approaches to identify, evaluate, and combine evidence on a given research question from diverse sources <ref type="bibr" target="#b1">(Ades &amp; Sutton, 2006)</ref>. Beyond its methodological rigor, ES also provides a practical and structured approach to evaluate the effectiveness and risks of interventions and treatments, guiding research, policy, and decision-making <ref type="bibr" target="#b4">(Briner et al., 2012;</ref><ref type="bibr" target="#b16">Khan et al., 2003;</ref><ref type="bibr" target="#b25">Ohlsson, 1994)</ref>, and has become increasingly influential across the social, behavioral, and medical sciences <ref type="bibr" target="#b20">(Littell et al., 2008)</ref>. Despite their significance, ES is often timeconsuming and resource-intensive, resulting in delays that may render findings outdated by the time they are published <ref type="bibr" target="#b3">(Blaizot et al., 2022;</ref><ref type="bibr" target="#b10">Edwards et al., 2023;</ref><ref type="bibr">Hill et al., 2023)</ref>. In this study, we focus on whether, what, and how recent advances of large language models (LLMs) can address these limitations and improve ES.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Introduction to Evidence Synthesis</head><p>Evidence synthesis (ES), such as systematic reviews and meta-analyses, typically involves several key steps: formulating the review question, developing a protocol, identifying and selecting relevant studies, critically appraising their quality, analyzing and synthesizing the findings, and disseminating the review results <ref type="bibr" target="#b4">(Briner et al., 2012)</ref>. Among these, a crucial step is data extraction, the process of retrieving and organizing key information from primary studies. This step functions as a bridge between study selection and critical appraisal, providing the foundational data necessary to evaluate the quality, reliability, and relevance of the included studies.</p><p>However, data extraction and coding is also one of the most time-consuming and resourceintensive stages of the ES process. This step is typically conducted manually, making it both laborintensive and prone to human error. Studies have shown that data extraction errors are common, with rates reported as high as 63% depending on the complexity of the data <ref type="bibr" target="#b23">(Mathes et al., 2017)</ref>. These errors may stem from misclassification of statistical values, misinterpretation of findings, or simple data entry mistakes. In addition to undermining the accuracy of ES, manual data extraction contributes to delays in result dissemination and reduces reproducibility, raising concerns about the efficiency and reliability of ES.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Current Research and Limitations on LLMs in ES</head><p>Recent advances in artificial intelligence (AI) have introduced large language models (LLMs) as a promising tool to automate data extraction in ES. These models can process natural language, recognize complex patterns, and perform extraction tasks with minimal training <ref type="bibr" target="#b26">(OpenAI, 2023;</ref><ref type="bibr" target="#b5">Bubeck et al., 2023;</ref><ref type="bibr" target="#b9">De Angelis et al., 2023;</ref><ref type="bibr" target="#b27">Paruchuri et al., 2024)</ref>. A growing body of studies has started to explore the potential utility of LLMs in academic research settings (e.g., <ref type="bibr" target="#b22">Mammides &amp; Papadopoulos, 2024)</ref>, including forecasting and anomaly detection (e.g., <ref type="bibr" target="#b31">Su et al., 2024)</ref>, sentiment analysis (e.g., <ref type="bibr" target="#b33">Susnjak, 2024)</ref>, time series analysis (e.g., <ref type="bibr" target="#b38">Zhang et al., 2024)</ref>, power analysis (e.g., <ref type="bibr" target="#b18">Kim et al., 2024)</ref>, as well as, ES (e.g., <ref type="bibr" target="#b14">Hill et al., 2024;</ref><ref type="bibr">Polak et al., 2024;</ref><ref type="bibr" target="#b35">Wang &amp; Luo, 2024)</ref>.</p><p>Recent research on LLMs in ES has primarily focused on automating tasks such as screening publications against inclusion/exclusion criteria (e.g., <ref type="bibr">Wang et al., 2024)</ref> and data extraction <ref type="bibr">(Polak &amp; Mogan, 2024;</ref><ref type="bibr" target="#b35">Wang &amp; Luo, 2024)</ref>. These approaches have shown particularly strong performance in healthcare and materials science, especially when extracting structured and well-formatted data (e.g., binary variables, material properties; <ref type="bibr" target="#b11">Ekuma, 2024;</ref><ref type="bibr" target="#b35">Wang &amp; Luo, 2024)</ref>. However, the accuracy rate tends to decline when dealing with continuous or complex data types (e.g., <ref type="bibr" target="#b32">Sun et al., 2024)</ref>. Notably, the majority of these studies have focused on highly structured research designs, such as randomized controlled trials (RCTs), where data formats are relatively more standardized and thus more amenable for automation.</p><p>In contrast, the application of LLMs in social and behavioral science remains largely underexplored. Social and behavioral research often involves complex constructs, diverse methodological designs, and context-dependent reporting <ref type="bibr" target="#b30">(Sanbonmatsu et al., 2021)</ref>, making it inherently difficult to extract and standardize data. Since LLMs are pretrained on broad, generalpurpose datasets, they may lack the domain-specific precision required to accurately handle highly specialized content <ref type="bibr" target="#b33">(Susnjak, 2024)</ref>. As a result, automated extraction and coding face particular challenges when dealing with embedded statistics, complex quantitative indicators, or unstructured qualitative data. Moreover, while prior studies have examined the feasibility of LLM-based data extraction and some have compared extracting performance of different LLMs <ref type="bibr" target="#b8">(Dagdelen et al., 2024;</ref><ref type="bibr" target="#b7">Celikten &amp; Onan, 2025)</ref>, relatively few have systematically assessed data extraction performance under schema constraints, including mapping diverse data types into structured coding schemes. Existing evaluations are often limited by small sample sizes (e.g., validation of results extracted from 15 RCT medical papers, Vidal Perez, 2024), further constraining the generalizability of findings across broader ES contexts. To address these gaps, our study explores the capabilities and methodological innovations of using LLMs in extracting and coding diverse data formats and types within the social and behavioral sciences.</p><p>Hallucination and lack of accuracy also remain critical challenges in LLM-based data extraction and coding, particularly within the context of ES. To date, although LLMs have offered substantial potential to streamline information retrieval, they are still susceptible to generating inaccurate or fabricated outputs, especially when dealing with very large context windows <ref type="bibr" target="#b21">(Liu et al., 2024)</ref> and multi-modal data when reviewing articles. These limitations often result in missing or inconsistent extractions that compromise the reliability of ES. One contributing factor may be the sequential nature of LLM text generation, compounded by API constraints such as Tokens Per Minute (TPM), which may ultimately produce incorrect outputs. Yet, few studies have examined how to systematically identify and resolve such discrepancies. As a result, there is a growing need for approaches that not only automate data extraction and coding to improve efficiency but also incorporate robust validation methods to ensure the accuracy and reliability of extracted outputs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">The Objective of the Study</head><p>Building on a standardized coding scheme in social behavioral research, we focus on the topic of body image and selected 60 papers and evaluate the performance of different LLMs in extracting and coding the information from these papers, and we compared different models (i.e., GPT-3.5, GPT-4, GPT-4o) based on precision, accuracy, recall, and F1-score. Meanwhile, building on the comparative evaluation, we then propose an improved automated method, Divide, Conquer, then Recheck (DCR), to enhance the extraction performance and reduce reliance on human validation.</p><p>Based on our research purpose, we aim to answer the following research questions: (1) To what extent can different LLMs autonomously and accurately extract and code social and behavioral data from empirical studies? (2) How does the extraction and coding precision improve using our proposed method? (3) Could our proposed method effectively validate and recheck outputs?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Study Design</head><p>In order to evaluate the performance of different LLMs in data extraction and coding during the ES process, we build upon an existing well-cited meta-analysis study <ref type="bibr" target="#b13">(He et al., 2020)</ref> and use LLMs to extract and code information from the paper identified by this meta-analysis. This paper involves 60 papers on the topic of body image, specifically including body appreciation and BMI. We chose this paper as a gold standard due to its relevance to the fields of social and behavioral sciences and its high quality, as the original coding was conducted by multiple researchers and underwent rigorous peer review. Additionally, it contains a diverse set of qualitative and quantitative variables as presented in Table <ref type="table" target="#tab_0">1</ref>. percentage of participants with a college education or higher (p2); sample sizes of participants (ssize); percentage of participants identifying as white (pwhite); mean age of participants (mage); mean BMI of participants (mbmi); and the Pearson correlation between Body Appreciation (BA) and BMI (r).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Study 1: Comparison of LLMs for Manual Chatbot-Based Data Extraction</head><p>We conducted an evaluation study using ChatPDF (powered by GPT-3.5), Bing Chat (powered by GPT-4), ChatGPT-4, and ChatGPT-4o to evaluate and compare the performance (i.e., accuracy) of different LLMs in the automated data extraction and coding process. Across all phases in Study 1, each article was uploaded individually and manually queried through chatbots (see Appendix A) to extract and code data. Two independent raters evaluated the accuracy of extracted outputs against a human-coded gold standard. ChatPDF represents an example of the document-centric interface that routes queries to OpenAI models for PDF interrogation, and prior studies show these GPT-4-family systems have already shown potential contributions in ES tasks <ref type="bibr">(Polak &amp; Mogan, 2024;</ref><ref type="bibr" target="#b35">Wang &amp; Luo, 2024)</ref>, so the results establish a baseline for LLM-based extraction in social and behavioral ES research and inform further methodological refinement in Study 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Study 2: Development of an Automated Extraction and Validation Method</head><p>To reduce potential hallucination and further improve factual accuracy, we propose an automated method, the Divide, Conquer, then Recheck (DCR; see Figure <ref type="figure" target="#fig_0">1</ref>), which better utilizes the API token limitation and more comprehensively reveals the advanced power of GPT-4o, the model achieving the highest accuracy in Study 1. The DCR method is designed to improve the precision, reliability, and traceability of automated data extraction via LLMs. DCR performs three core functions: (1) dividing full-text articles into smaller and standardized chunks, (2) applying structured and iterative prompting for targeted data extraction, and (3) implementing a systematic rechecking and validating process to identify and resolve discrepancies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Divide and Conquer.</head><p>To mitigate the token limitation issue and leverage GPT-4o's ability to process multi-modal data, DCR first converts PDF articles into Markdown but preserves images, which reduces file size and storage costs. Articles are then segmented into standardized sections (e.g., introduction, methods), which reduces the input context. Each variable is extracted, via OpenAI's GPT API, using strategically tailored prompts, with clear definitions and requirements (e.g., extracted by sex) to minimize ambiguity, which might cause hallucination. For complex variables such as correlation coefficients, we implement few-shot prompting based on prior lowperforming cases (see Figure <ref type="figure" target="#fig_1">2</ref>, Appendix B).  Rechecking. To improve accuracy and consistency, DCR includes a systematic validation process that cross-checks extracted values across article sections and categorizes them as SAME (aligned), DIFFERENT (inconsistent data), or NONE (missing data). Cases flagged as DIFFERENT or NONE trigger a rechecking step, prompting the model to revisit relevant content to clarify discrepancies or locate missing data. This iterative process significantly reduces discrepancy errors, increases coverage, and ensures the robustness and precision of the final results (see Figure <ref type="figure" target="#fig_2">3</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Transparency</head><p>The Python script for the present study is publicly available on OSF (https://osf.io/zfx9v/?view_only=c8b1b5056fd84093bcf2a343cdfa2d51).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Key Evaluation Metrics</head><p>In Study 1, we primarily use accuracy to evaluate the performance of LLMs, which is defined as the proportion of agreement between the LLM-generated outputs and the established gold standard. For each of the 60 selected studies, we calculate the average accuracy across two independent raters, assessing the degree to which ChatPDF, Bing Chat, ChatGPT-4, and GPT-4o responses aligned with the gold standard. This approach allows us to estimate the overall accuracy range and performance for each LLM across all extracted items.</p><p>In Study 2, to more comprehensively evaluate the performance of our proposed DCR method, we adopt three more evaluation metrics, including precision, recall, and F1-score. Unlike prior evaluation studies with single metrics (e.g., <ref type="bibr" target="#b35">Wang &amp; Luo, 2024)</ref>, this approach enables systematic identification of discrepancy issues. To be specific, the precision and recall scores interpret inconsistent data and missing data, respectively, to measure correctness and completeness, while the F1-score summarizes the trade-off between precision and recall, thereby jointly assessing the accuracy, completeness, and reliability of LLM-based extraction compared to the gold standard.</p><p>We define three core components: Correctly Extracted Data (CED), Incorrectly Extracted Data (IED), and Missing Data (MD). CED refers to data accurately extracted by the LLM that matches the ground truth (i.e., gold standard results). IED means extracted data that do not match the ground truth, while MD represents the data present in the ground truth but omitted by the LLM. Precision is calculated as the proportion of correctly extracted data (CED) among all extracted data; Recall is computed as the proportion of correctly extracted data among all data present in the ground truth; F1-score is computed as the harmonic mean of precision and recall. The formulas are as below.</p><formula xml:id="formula_0">Precision = !"# !"# % &amp;"# ; Recall = !"# !"# % '# ; F1-score =</formula><p>( * *+,-./.01 * 2,-344 *+,-./.01 % 2,-344</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Performance of Different LLMs in Data Extraction and Coding</head><p>Overall, the accuracy of data extraction and coding varied substantially in Study 1, where we assessed through standard chatbot interfaces. We find that GPT-4o (total average accuracy = .80) demonstrate notably better performance across most variables compared to ChatPDF (total average accuracy = .54), Bing Chat (total average accuracy = .73) and GPT-4 (total average accuracy = .79). According to Figure <ref type="figure" target="#fig_3">4</ref>, notable improvements were observed in variables such as survey method, source of sample, assessment of BMI, percentage of participants with a college education or higher, and the Pearson correlation between BA and BMI. These results highlight GPT-4o's relative strength in accurately extracting and coding data in ES, which reflects the ongoing evolution of LLM capabilities. However, we also observed visible differences in the performance between qualitative and quantitative data in Study 1. Generally, qualitative variables were extracted with relatively higher accuracy compared to quantitative data, which consistently showed lower accuracy due to their complexity (e.g., mean age, mean BMI, and correlation coefficient; see Figure <ref type="figure" target="#fig_3">4</ref>). Thus, this finding motivated us to proceed with the investigation in Study 2, in which we compared the GPT-4o chatbot with our proposed DCR method to improve extraction accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Comparison of the ChatGPT-4o and the DCR Method</head><p>Compared to the best-performing model in Study 1 (powered by GPT-4o), the DCR method in Study 2 shows noticeable improvements, with total accuracy increasing from .80 to .95 and total average F1-score increasing from .89 to .97 (see Figure <ref type="figure" target="#fig_4">5</ref>). Notably, the total average F1-scores for qualitative data and quantitative data of our extracted variables increase to .97 and .98, respectively, indicating substantial improvements in both data types. These results suggest that our DCR method in Study 2 not only outperforms the best-performing model in Study 1 overall, but also demonstrates greater reliability and consistency across different data types. Specifically, it helps narrow the accuracy gap in overall quantitative data extraction and coding.</p><p>As shown in Figure <ref type="figure" target="#fig_4">5</ref>, the DCR method in Study 2's total average precision increases from .81 to .97 compared to the GPT-4o chatbot. This increase indicates that the DCR method proposed in Study 2 is more effective in accurately extracting and coding relevant information. The total recall for DCR is slightly lower than for GPT-4o (0.98 vs. 0.99), a very small difference that suggests GPT-4o has robust performance at minimizing missed extractions.</p><p>Breaking these down further by data type, both qualitative and quantitative data extraction and coding benefited from the DCR method proposed in Study 2. As displayed in Figure <ref type="figure" target="#fig_4">5</ref>, the precision and F1-score for qualitative data increase from .91 to .98, and from .95 to .97, respectively. Meanwhile, the most notable improvement occurs in quantitative data extraction and coding, which has been a major challenge in Study 1. The precision and F1-score of quantitative data extraction and coding rose from .68 to .96, and from .81 to .98, respectively. These findings indicate that the DCR method in Study 2 is particularly effective in handling content-specific, less structured, and complex quantitative data with greater accuracy and completeness.</p><p>Specifically, Figure <ref type="figure" target="#fig_5">6</ref> presents a comparison of extraction and coding performance between the GPT-4o chatbot and the DCR method across 13 variables. Both methods exhibit consistently high performance in qualitative data extraction, with F1-scores exceeding 0.90. These variables are mostly categorical, which likely contributed to their stable extraction accuracy across models. GPT-4o chatbox achieves slightly higher F1-scores for the extraction of the type of publication and the assessment of BMI.</p><p>In terms of the quantitative variables, the DCR method improves the performance of extracting and coding semi-structured variables (e.g., sample size, percentage of white participants, and percentage of college students or higher), while the most substantial improvements emerge in the extraction of complex variables, particularly mean age, mean BMI, and correlation coefficients. These variables present notable challenges due to their variability in format and contextual embedding within texts. Among them, mean age and mean BMI show the greatest performance gain, with the DCR method in Study 2 achieving approximately a 70% improvement over that of the best-performing model in Study 1. This improvement reflects the effectiveness of the DCR method in both reducing missing and inconsistent data and enhancing extraction precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion</head><p>This study aims to evaluate the capabilities of LLMs in automating data extraction and coding for ES, in the context of social and behavioral science research. Building upon an existing meta-analysis, we extracted data from the papers identified by the meta-analysis study and conducted a two-step investigation: Study 1 compared the performance of different LLMs (i.e., GPT-3.5, GPT-4, GPT-4o) using manual chatbot querying, while Study 2 proposed and evaluated a novel automated method, DCR, to further optimize the extraction and validation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implications of LLMs' performance</head><p>Our study provides preliminary empirical evidence on the feasibility of LLMs in automating data extraction for literature coding tasks. In our study, to answer Research Question (1), we compare the accuracy of three LLM-based models (i.e., GPT-3.5, GPT-4, GPT-4o) in Study 1. The results demonstrate that GPT-4o outperforms for most variables when compared with the other three models. This suggests that the extraction capabilities of LLMs are significantly associated with the advancement of newer model generations. These findings align with previous research on LLM-based data extraction in ES <ref type="bibr">(Polak &amp; Morgan, 2024;</ref><ref type="bibr">Polak et al., 2024;</ref><ref type="bibr" target="#b35">Wang &amp; Luo, 2024)</ref>, which suggests that LLMs are able to assist in labor-intensive data extraction tasks by reducing the reliance on manual data extraction and validation. Thus, the findings highlight LLMs' potential to significantly reduce the manual effort required for extracting data from large volumes of literature.</p><p>While LLMs show satisfactory accuracy in certain structured variables (e.g., author, assessment of BA, sample size) in Study 1, their performance (e.g., mean age, mean BMI, correlation coefficient) remains an area for further improvement for more variables. This limitation suggests that relying solely on the current LLMs for data extraction remains insufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implications of the DCR Method</head><p>Corresponding to Research Question (2), the results of the DCR method proposed in Study 2 substantially improve precision and F1-score across most variables compared to that of the bestperforming model in Study 1, confirming its effectiveness in data extraction and coding process of ES research with great accuracy and completeness. These improvements can be attributed to several key innovations informed by limitations identified in Study 1. First, different from previous studies that rely solely on converting into text (e.g., <ref type="bibr" target="#b17">Khraisha et al., 2024;</ref><ref type="bibr" target="#b35">Wang &amp; Luo, 2024)</ref> or focusing on converting HTML tables into customized formats (e.g., JSON; <ref type="bibr" target="#b37">Yi et al., 2024)</ref>, the DCR addresses token limitations and preserves formatting integrity by dividing entire articles into structured text sections, preserving images, and standardized Markdown format.</p><p>Second, to improve performance on complex variables such as correlation coefficients (r), we implemented a few-shot prompting strategy, drawing on prior approaches (e.g., <ref type="bibr" target="#b11">Ekuma, 2024;</ref><ref type="bibr" target="#b37">Yi et al., 2024)</ref>, but with a key difference that our prompts incorporate self-reflective feedback. By manually retrieving failed examples, providing annotated feedback, and training the model to learn from mistakes, the performance of correlation coefficient in Study 2 (precision = .86, recall = .98, and F1-score = .92) significantly improved that addresses one of the most complex variables in the best-performing model in Study 1 (precision = .64, recall = .95, and F1-score = .76). This approach enables the model to better extract embedded statistical statements and values from diverse table formats.</p><p>Third, to address Research Question (3), the DCR method implements a systematic validation and rechecking process to handle missing and inconsistent data. This issue is frequently observed in Study 1 and in prior research <ref type="bibr">(Garthlehner et al., 2024;</ref><ref type="bibr" target="#b35">Wang &amp; Luo, 2024)</ref>. Unlike MetaMate <ref type="bibr" target="#b35">(Wang &amp; Luo, 2024)</ref>, which addresses only missing data, our method also corrects inconsistencies, making it more comprehensive. By logging validation outcomes and prompting GPT-4o to revisit discrepancies, this approach not only increased accuracy but also reduced the need for extensive human-in-the-loop (HITL) involvement.</p><p>In summary, our proposed DCR improves automation, accuracy with reliability, and traceability in LLM-assisted ES research. However, given the occasional errors and inconsistencies observed, human oversight remains crucial, particularly in tasks requiring nuanced interpretation across papers with diverse formats and varying structures. Future work should focus on model fine-tuning, further refining prompt strategies targeting specific contexts (e.g., demographic groups), and developing best practices to reduce errors and increase generalizability in large-scale ES studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Limitations and Future Directions</head><p>While this study demonstrates the potential of LLMs in processing automation in ES, particularly in data extraction and validation processes, several limitations still need to be noted. First, the extraction performance was not consistently stable across all variables or models. For example, performance on the type of publication and the assessment of BMI slightly declined in Study 2. The potential reason might be the information lost in the file processing process (e.g., the conversion from PDF articles into Markdown omitted the headnote and footnote in this study), or the inherent variability of LLM output. Thus, a better file processing programme with less information lost and further refined prompts with specific domain requirements are needed. A similar discussion about prompt engineering was claimed by <ref type="bibr">Khraisha (2023)</ref> that a reliable prompt would raise GPT-4's screening performance to be almost perfect.</p><p>Second, the black-box issue in LLM research, where the underlying mechanisms driving outputs are not fully transparent <ref type="bibr" target="#b19">(Komera &amp; Manche, 2023)</ref>, makes it difficult to further diagnose failure or improve extraction accuracy. Thus, the development of interpretability tools is needed to provide the model's inner decision-making processes <ref type="bibr" target="#b6">(Caruana et al., 2015;</ref><ref type="bibr" target="#b19">Komera &amp; Manche, 2023)</ref>.</p><p>Third, although numerous other LLMs, such as Claude, Gemini, and DeepSeek, are available, we selected models only embedded in ChatGPT for this study. This choice was made to reduce variation across systems: models from different vendors might use different architectures, training data, and inference settings, which can confound comparisons. Notably, however, non-ChatGPT models may perform as well as or better than the models studied here. <ref type="bibr">Ntinopoulos and colleagues (2025)</ref> have demonstrated that models like Claude 3.0 Opus, Gemini Advanced, and Llama 3-70b exhibit the best performance in entity extraction and binary classification tasks. These findings suggest that expanding model selection beyond ChatGPT-based models could enhance the generalizability and robustness of automated data extraction. Future research should further explore the effectiveness and performance of these additional LLMs for automated data extraction in the ES process.</p><p>Beyond data extraction, LLMs could play a broader role in other stages of ES. For example, Susnjak (2024) demonstrated the potential of LLMs in automating knowledge synthesis, a critical component of systematic literature reviews. Within the research, it suggests that future research should explore the integration of LLMs into more advanced stages of ES, such as summarization and integration of findings, while still addressing the current limitations in data extraction.</p><p>Another critical challenge is the phenomenon of hallucination, where LLMs generate fabricated or inaccurate information <ref type="bibr" target="#b2">(Beutel et al., 2023)</ref>. Although the DCR method proposed in this study significantly improves performance, hallucination remains a concern for the reliability and trustworthiness of LLM-generated outputs. For instance, LLMs may occasionally respond with "None" or provide fabricated results, which could undermine confidence in their utility for ES <ref type="bibr" target="#b15">(Ji et al., 2023)</ref>. Additionally, due to the inherent probabilistic nature of LLMs, there remains a possibility that the model might not generate consistent results across iterations of the same process <ref type="bibr">(Polak and Morgan, 2024)</ref>, further complicating the reproducibility and reliability. At present, maintaining the accuracy and reliability of data extraction still depends on rigorous validation processes. Besides the automated validation process, the HITL system remains essential for ensuring accountability and verifying outputs <ref type="bibr">(Korema &amp; Manche, 2023)</ref>. Therefore, continued development of interpretability tools to ensure transparency and improvement of the automated validation process in the DCR method will be vital to reduce reliance on human oversight in the implication of LLMs in ES in the long run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>This study explores the use of large language models (LLMs) to automate data extraction and coding for ES research in the context of social and behavioral research. In Study 1, we compared multiple LLMs for their performance and found that GPT-4o models achieved the highest accuracy in retrieving the targeted information. In Study 2, we proposed an automated data extraction method, CDR, which further improved the efficiency and accuracy of data extraction and coding. Our findings showed that LLMs prove promising in assisting data extraction and classification and reducing manual effort and human error. However, it is still essential to remain human-in-the-loop to ensure accuracy and reliability in practice. Future research should focus on refining method performance and establishing clear guidelines for their ethical and responsible use of LLMs for ES.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A: Prompts for Study 1</head><p>"Show me this paper's author (s) and year, Publication type (Journal or Dissertation), Country, Sample (participants numbers), Survey method <ref type="bibr">(interview, paper-and-pencil, online, or mixed)</ref>, Percent of white in participants, Mean age of participants, Percent of college or higher of participants, Mean BMI of participants, Source of sample (community, college, primary/secondary/high school, or mixed), Assessment of BA, Assessment of BMI (self-reported or measured), effect size, correlation between body appreciation and BMI." """Author(s), Year, Publication type (Journal or Dissertation), <ref type="bibr">Country, Male Sample Size, Female Sample Size, Survey method (interview, paper-and-pencil, online, or mixed)</ref>, Percent of white male participants, Percent of white female participants, Mean age of male participants, Mean age of female participants, Percent of college or higher male participants, Percent of college or higher female participants, Mean BMI of male participants, Mean BMI of female participants, Source of sample (community, college, primary/secondary/ high school, or mixed), Assessment of BA, Assessment of BMI (self-reported or measured), Male effect size, Female effect size, Correlation between male body appreciation and BMI, Correlation between female body appreciation and <ref type="bibr">BMI, Confidence Level (low, moderate, high)</ref>, Confidence Percentage (scale of 0% to 100%).""" Provided text: """{TEXT}"""</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompts for specific user questions:</head><p>"The following values should be examined and reported with gender differences if available; if not, report the data without separation by gender: sample size, Percent of white in participants, mean age of participants, Percent of college or higher of participants, Mean BMI of participants, correlation between body appreciation and BMI.</p><p>Definition for the values that we will extract today: Gender: whether part or all of the data is reported by gender (e.g., female(s) or male(s); women or men; feminine or masculine; or other descriptions that indicate female and male). If reported by gender, specify the genders; otherwise, respond with "T".</p><p>Author: The name(s) and the author(s) of the study or paper. It should only appear after the main title of the paper or study, not in the abstract or introduction or other sections.</p><p>Year: The year of the study or paper that was published.</p><p>Publication type: The type of publication means (i.e., journal articles or dissertation). It must be one of the following two options: journal articles or dissertation.</p><p>Country: The country where the study was conducted or where the participants were recruited (i.e., North America, Europe, South America, Asia).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sample: Total numbers of participants of the study.</head><p>Survey method: The method used to collect data <ref type="bibr">(i.e., paperand-pencil or online)</ref>. It must be one of the following two options: paper-and-pencil or online.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Percent of white in participants:</head><p>The percentage (%) of participants identifying as white. The text might not straifghtforwardly mention "white" but you can infer it from the context (e.g., "Caucasian", "European", etc.).</p><p>Mean age of participants: The average age of the participants in the study.</p><p>Percentage of college or higher of participants: The percentage (%) of participants with college or higher education level than college. The text{IMAGE_ATTACHED} might not straifghtforwardly mention "college" or other education level higher than "college" but you can infer it from the context (e.g., the Source of Sample might indicate "all participants were college/university students" for 100%, "all participants were primary/secondary/high school students" for 0%, etc.).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean BMI of participants: The average body mass index (BMI) of the participants.</head><p>Source of sample: how or where the participants were recruited (i.e., community, college, or primary/secondary/ high school). It must be one of the following three options: community, college, or primary/secondary/ high school.</p><p>Assessment of BA: The method used to assess body appreciation (BA; i.e., BAS or BAS-2; BAS stands for body appreciation scale). It must be one of the following two options: BAS or BAS-2.</p><p>Assessment of BMI: The method used to assess BMI (i.e., self-reported or measured). It must be one of the following two options: self-reported or measured.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Correlation (r) between body appreciation and BMI: The reported correlation coefficient (e.g., Pearson's r) between Body Appreciation and BMI.</head><p>Confidence <ref type="bibr">Level (low, moderate, high)</ref>: Please also tell me, how would you rate your confidence <ref type="bibr">(low, moderate, high)</ref> in your each of the answer you provided.</p><p>Confidence Percentage (scale of 0% to 100%): on a scale of 0% to 100%, how confident are you in the accuracy of each of the answer that you provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Examples of prompts with few-shot learning:</head><p>"Here is an example of where we should extract the correlation coefficient. The answer is that the correlation between BAS-2 and BMI for men is -0.24, the correlation between BAS-2 and BMI for women is 0.39. Please indicate and learn why this is the case and please reflect in the prompt conditions on what you should do for troubleshooting."</p><p>After manually adjusted for the self-reflection prompt suggestions: "Correlation between body appreciation and BMI: The reported correlation coefficient (e.g., Pearson's r) between Body Appreciation and BMI, adhering strictly to the following instructions:</p><p>---1. General Extraction: Identify the reported correlation coefficient between Body Appreciation and BMI. It must be a numerical value <ref type="bibr">(e.g., 0.5, -0.3, etc.)</ref>. Pay attention to the table titles or notes if the information is presented in tables or matrices.</p><p>---2. Case Handling:</p><p>---Case 1 (Multiple Subscales): If multiple BAS or BAS-2 subscales correlations with BMI are reported, compute and report the average correlation across these subscales. If only one overall correlation (no subscales) is reported, directly report this single correlation.</p><p>---Case 2 (Gender-Specific Data): If correlations are separately reported by gender: For each gender, compute and report the average correlation across BAS or BAS-2 subscales if multiple subscales are present. For example, if the BAS subscales "body valorisation" and "body care" or other subscales are reported separately for males and females, or BAS scales or subscales are reported separately for heterosexual and non-heterosexual females or males, compute the average correlation for each gender. If only a single correlation per gender (no subscales) is reported, directly report this correlation for each gender.</p><p>---Case 3 (Correlations Presented in Tables or Matrices): If correlations appear in tables or matrices: Carefully examine table title and notes or matrix entries to determine whether correlations are presented by gender (e.g., separate correlations for males and females indicated by upper/lower triangles). If gender-specific correlations are indicated, separately extract and report correlations per gender following instructions in Case 2. If no gender distinction is present, directly extract and report the correlation(s) according to instructions in Case 1. There may be multiple tables or images to present the correlation, so you need to check all of them and calculate the average correlation across all the tables or images." Here is an example text of where we should extract """{VARIABLE Y}""".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example text or images:</head><p>"""{TEXT_2}""" or """{IMAGE_ATTACHED_2}"""</p><p>The answer is that """{INSERT THE GROUND TRUTH OF VARIABLE Y}""". Please indicate and learn why this is the case and please reflect in the prompt conditions on what you should do for troubleshooting."</p><p>After manually adjusting for the self-reflection prompt suggestions:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>"""{INSERT THE SELF-REFLECTION PROMPTS HERE }"""</head><p>Prompts for structured response format: **IMPORTANT:** Replace {RESULT} with the value you found or "None" if you cannot find anything **IMPORTANT:** If information is not explicitly provided in the text, answer with "None" **IMPORTANT:** Provide only the values requested, formatted exactly as specified. Any additional text will be considered an error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>"""{VARIABLE X: {RESULT} VARIABLE Y: {RESULT}}"""</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Method Comparison Between Study 1 and Study 2.</figDesc><graphic coords="8,73.01,79.90,467.99,308.61" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Diagram of Divide, Conquer, and Prompt.</figDesc><graphic coords="8,72.00,529.65,468.00,159.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Diagram of Systematic Validation and Rechecking Process.</figDesc><graphic coords="9,71.05,175.40,468.00,186.79" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Accuracy Comparison by Models: Data Extraction and Coding Performance of ChatPDF, Bing Chat, GPT-4 and GPT-4o in Study 1.</figDesc><graphic coords="10,72.01,328.51,467.99,299.45" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Comparison of GPT-4o vs DCR Method in Data Extraction and Coding Performance: Total Average Precision, Recall, and F1-Score by Data Type.</figDesc><graphic coords="11,72.00,257.39,448.65,251.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Data Extraction and Coding Performance of GPT-4o vs DCR Method: Precision, Recall, F1-Score, and Accuracy by Variable.</figDesc><graphic coords="12,67.95,208.25,467.99,395.38" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>"</head><label></label><figDesc>Please extract the following values from the provided text {IMAGE_ATTACHED}. Each value has a definition to guide the extraction process. If you are unable to determine the value from the text, respond with "None."</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Prompts for structured response format: **IMPORTANT:** Replace {RESULT} with the value you found or "None" if you cannot find anything **IMPORTANT:** If information is not explicitly provided in the text, answer with "None" **IMPORTANT:** Provide only the values requested, formatted exactly as specified. Any additional text will be considered an error.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary of Extracted and Coding Information.</figDesc><table><row><cell>Data Types</cell><cell>Extracted Variables (Coding Schemes)</cell></row><row><cell>Qualitative</cell><cell>author(s); type of publication (ptype; journal or dissertation); country</cell></row><row><cell>(N = 7)</cell><cell>(region; North America, Europe, South America, or Asia); survey method (smethod; online or paper-pencil); source of sample (source;</cell></row><row><cell></cell><cell>primary/middle/high school, college, or community); assessment of body</cell></row><row><cell></cell><cell>appreciation (measureba; BAS or BAS-2); assessment of BMI</cell></row><row><cell></cell><cell>(measurebmi; self-reported or measured);</cell></row><row><cell>Quantitative</cell><cell></cell></row><row><cell>(N = 6)</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>Funding This project was supported by the <rs type="funder">Connaught Fund</rs> (Grant Number <rs type="grantNumber">520245</rs>) and <rs type="funder">Social Sciences and Humanities Research Council (SSHRC) of Canada</rs> (Grant Number <rs type="grantNumber">215119</rs>, <rs type="grantNumber">00169</rs>), Seed Grant of the <rs type="funder">International Network of Educational Institutes</rs> (Grant Number <rs type="grantNumber">522011</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_UkpbKxr">
					<idno type="grant-number">520245</idno>
				</org>
				<org type="funding" xml:id="_M6SDQC7">
					<idno type="grant-number">215119</idno>
				</org>
				<org type="funding" xml:id="_ETZfKFG">
					<idno type="grant-number">00169</idno>
				</org>
				<org type="funding" xml:id="_QnRd2Fs">
					<idno type="grant-number">522011</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration of Conflicting Interests</head><p>The author(s) report having no conflicts of interest with respect to contents, authorship, or publication of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C:</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Prompt Template for Structured Data Extraction in Social and Behavioral Science</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompts for contextual information:</head><p>"Please extract the following values from the provided text and images """{IMAGE_ATTACHED_1}""". Each value has a definition to guide the extraction process. If you are unable to determine the value from the text, respond with "None."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Provided text:</head><p>"""{TEXT_1}"""</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>All Variables for Extraction: """{PASTE ALL YOUR INTERESTED VARIABLES AND THEIR CODING SCHEMES HERE}"""</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prompts for specific user questions:</head><p>"The following values should be examined and reported with """{INSERT THE GROUP DIFFERENCE YOU INTERESTED, e.g., sex}""" if available; if not, report the data without separation by """{GROUP DIFFERENCE}""".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Here are variables with """{GROUP DIFFERENCE}: {INSERT VARIABLES WITH GROUP DIFFERENCE} """</head><p>Definition for the values that we will extract today:</p><p>"""{VARIABLE X (Categorical data): Definition and Description;</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">{RESULT} Percent of white male participants: {RESULT} Percent of white female participants: {RESULT} Mean age of male participants: {RESULT} Mean age of female participants: {RESULT} Percent of college or higher male participants: {RESULT} Percent of college or higher female participants: {RESULT} Mean BMI of male participants: {RESULT} Mean BMI of female participants: {RESULT} Source of sample (community, college, primary/secondary/ high school, or mixed): {RESULT} Assessment of BA: {RESULT} Assessment of BMI (self-reported or measured</title>
	</analytic>
	<monogr>
		<title level="m">{RESULT} Male effect size: {RESULT} Female effect size: {RESULT} Correlation between male body appreciation and BMI: {RESULT} Correlation between female body appreciation and BMI: {RESULT} Confidence Level</title>
		<imprint>
			<publisher>{RESULT} Reference</publisher>
		</imprint>
	</monogr>
	<note>Survey method (interview, paper-and-pencil, online, or mixed. low, moderate, high): {RESULT} Confidence Percentage (scale of 0% to 100%)</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multiparameter evidence synthesis in epidemiology and medical decision-making: current approaches</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Ades</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Sutton</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1467-985X.2005.00377.x</idno>
		<ptr target="https://doi.org/10.1111/j.1467-985X.2005.00377.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society Series A: Statistics in Society</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="35" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Artificial hallucination: Gpt on lsd?</title>
		<author>
			<persName><forename type="first">G</forename><surname>Beutel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Geerits</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Kielstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Critical Care</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">148</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Using artificial intelligence methods for systematic review in health sciences: A systematic review</title>
		<author>
			<persName><forename type="first">A</forename><surname>Blaizot</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Veettil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Saidoung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Moreno-Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wiratunga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aceves-Martins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Chaiyakunapruk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename></persName>
		</author>
		<idno type="DOI">10.1002/jrsm.1553</idno>
		<ptr target="https://doi.org/10.1002/jrsm.1553" />
	</analytic>
	<monogr>
		<title level="j">Research Synthesis Methods</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="353" to="362" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Systematic review and evidence synthesis as a practice and scholarship tool</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Briner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Denyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Rousseau</surname></persName>
		</author>
		<idno type="DOI">10.1093/oxfordhb/9780199763986.013.0007</idno>
		<ptr target="https://doi.org/10.1093/oxfordhb/9780199763986.013.0007" />
	</analytic>
	<monogr>
		<title level="m">Oxford Handbook of Evidence-Based Management</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="2" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Bubeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Chandrasekaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Eldan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kamar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.12712</idno>
		<idno type="arXiv">arXiv:2303.12712</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.12712" />
		<title level="m">Sparks of artificial general intelligence: Early experiments with gpt-4</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission</title>
		<author>
			<persName><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 21st ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2015-08">2015. August</date>
			<biblScope unit="page" from="1721" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Benchmarking Large Language Models for Biomedical Literature Summarization: Abstractive vs. Extractive Paradigms</title>
		<author>
			<persName><forename type="first">T</forename><surname>Celikten</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Onan</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2025.3604351</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2025.3604351" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Structured information extraction from scientific text with large language models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Dagdelen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ceder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename></persName>
		</author>
		<idno type="DOI">10.1038/s41467-024-45563-x</idno>
		<ptr target="https://doi.org/10.1038/s41467-024-45563-x" />
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1418</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health</title>
		<author>
			<persName><forename type="first">L</forename><surname>De Angelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Baglivo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Arzilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">P</forename><surname>Privitera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Tozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rizzo</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpubh.2023.1166120</idno>
		<ptr target="https://doi.org/10.3389/fpubh.2023.1166120" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Public Health</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">1166120</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">ADVISE: AI-accelerated design of evidence synthesis for global development</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Porciello</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Engelbert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2305.01145</idno>
		<idno type="arXiv">arXiv:2305.01145</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2305.01145" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Dynamic in-context learning with conversational models for data extraction and materials property prediction</title>
		<author>
			<persName><forename type="first">C</forename><surname>Ekuma</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2405.10448</idno>
		<idno type="arXiv">arXiv:2405.10448</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2405.10448" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Data extraction for evidence synthesis using a large language model: A proof-of-concept study</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gartlehner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kahwati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Hilscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kugley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Crotty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Viswanathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Nussbaumer-Streit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Erskine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Konet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chew</surname></persName>
		</author>
		<idno type="DOI">10.1002/jrsm.1710</idno>
		<ptr target="https://doi.org/10.1002/jrsm.1710" />
	</analytic>
	<monogr>
		<title level="j">Research Synthesis Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="576" to="589" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The association between body appreciation and body mass index among males and females: A meta-analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bodyim.2020.03.006</idno>
		<ptr target="https://doi.org/10.1016/j.bodyim.2020.03.006" />
	</analytic>
	<monogr>
		<title level="j">Body Image</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="10" to="26" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Methods for using Bing&apos;s AI-powered search engine for data extraction for a systematic review</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Clegg</surname></persName>
		</author>
		<idno type="DOI">10.1002/jrsm.1689</idno>
		<ptr target="https://doi.org/10.1002/jrsm.1689" />
	</analytic>
	<monogr>
		<title level="j">Research Synthesis Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="347" to="353" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Survey of hallucination in natural language generation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Frieske</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Fung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
		<idno type="DOI">10.1145/3571730</idno>
		<ptr target="https://doi.org/10.1145/3571730" />
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Systematic reviews to support evidencebased medicine: How to review and apply findings of healthcare research</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kunz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kleijnen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Antes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Royal Society of Medicine</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Can large language models replace humans in systematic reviews? Evaluating GPT-4&apos;s efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Khraisha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Put</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kappenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Warraitch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hadfield</surname></persName>
		</author>
		<idno type="DOI">10.1002/jrsm.1715</idno>
		<ptr target="https://doi.org/10.1002/jrsm.1715" />
	</analytic>
	<monogr>
		<title level="j">Research Synthesis Methods</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="616" to="626" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Assessing ChatGPT as a power analysis tool: An empirical investigation</title>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ji</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/32mkv</idno>
		<ptr target="https://doi.org/10.31234/osf.io/32mkv" />
	</analytic>
	<monogr>
		<title level="j">PsyArXiv Preprint</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<author>
			<persName><forename type="first">O</forename><surname>Komera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Manche</surname></persName>
		</author>
		<title level="m">Black-Box Behavior in Large Language Models: Challenges and Implications</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Littell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Corcoran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Pillai</surname></persName>
		</author>
		<title level="m">Systematic reviews and meta-analysis</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Lost in the middle: How language models use long contexts</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Paranjape</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bevilacqua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00638</idno>
		<ptr target="https://doi.org/10.1162/tacl_a_00638" />
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="157" to="173" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The role of large language models in interdisciplinary research: Opportunities, challenges and ways forward</title>
		<author>
			<persName><forename type="first">C</forename><surname>Mammides</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Papadopoulos</surname></persName>
		</author>
		<idno type="DOI">10.1111/2041-210x.14398</idno>
		<ptr target="https://doi.org/10.1111/2041-210x.14398" />
	</analytic>
	<monogr>
		<title level="j">Methods in Ecology and Evolution</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Frequency of data extraction errors and methods to increase data extraction quality: a methodological review</title>
		<author>
			<persName><forename type="first">T</forename><surname>Mathes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Klaen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Pieper</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12874-017-0431-4</idno>
		<ptr target="https://doi.org/10.1186/s12874-017-0431-4" />
	</analytic>
	<monogr>
		<title level="j">BMC Medical Research Methodology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Large language models for data extraction from unstructured and semi-structured electronic health records: a multiple model performance evaluation</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ntinopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R C</forename><surname>Biefer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Tudorache</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Odavic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Risteski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Dzemali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ Health &amp; Care Informatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">101139</biblScope>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Systematic reviews-theory and practice</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ohlsson</surname></persName>
		</author>
		<idno type="DOI">10.3109/00365519409088573</idno>
		<ptr target="https://doi.org/10.3109/00365519409088573" />
	</analytic>
	<monogr>
		<title level="j">Scandinavian Journal of Clinical and Laboratory Investigation</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="25" to="32" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><surname>Openai</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2303.08774</idno>
		<idno type="arXiv">arXiv:2303.08774</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2303.08774" />
		<title level="m">GPT-4 technical report</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Paruchuri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Garrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hernandez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Sunshine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Althoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Mcduff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2406.12830</idno>
		<idno type="arXiv">arXiv:2406.12830</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2406.12830" />
		<title level="m">What are the odds? Language models are capable of probabilistic reasoning</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Flexible, model-agnostic method for materials data extraction from text using general purpose language models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Polak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Modi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Latosinska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<idno type="DOI">10.1039/D4DD00016A</idno>
		<ptr target="https://doi.org/10.1039/D4DD00016A" />
	</analytic>
	<monogr>
		<title level="j">Digital Discovery</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1221" to="1235" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Extracting accurate materials data from research papers with conversational language models and prompt engineering</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Polak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Morgan</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-024-45914-8</idno>
		<ptr target="https://doi.org/10.1038/s41467-024-45914-8" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">1569</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The Impact of Complexity on Methods and Findings in Psychological Science</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Sanbonmatsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Cooley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Butner</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2020.580111</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2020.580111" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">580111</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Large Language models for forecasting and anomaly detection: A systematic literature review</title>
		<author>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2402.10350</idno>
		<idno>ArXiv, abs/2402.10350</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2402.10350" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">How good are large language models for automated data extraction from randomized trials?</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Doi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Furuya-Kanamori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<idno type="DOI">10.1101/2024.02.20.24303083</idno>
		<ptr target="https://doi.org/10.1101/2024.02.20.24303083" />
	</analytic>
	<monogr>
		<title level="j">medRxiv</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2026" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Applying bert and chatgpt for sentiment analysis of lyme disease in scientific literature</title>
		<author>
			<persName><forename type="first">T</forename><surname>Susnjak</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-1-0716-3561-2_14</idno>
		<ptr target="https://doi.org/10.1007/978-1-0716-3561-2_14" />
	</analytic>
	<monogr>
		<title level="m">Borrelia burgdorferi: Methods and Protocols</title>
		<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Springer US</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="173" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Prompt engineering for filling in evidence tables</title>
		<author>
			<persName><forename type="first">C</forename><surname>Vidal Perez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Metamate: Large language model to the rescue of automated data extraction for educational systematic reviews and meta-analyses</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
		<idno type="DOI">10.35542/osf.io/wn3cd</idno>
		<ptr target="https://doi.org/10.35542/osf.io/wn3cd" />
	</analytic>
	<monogr>
		<title level="j">Society for Research on Educational Effectiveness</title>
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Zero-shot generative large language models for systematic review screening automation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Scells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Koopman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-56027-9_25</idno>
		<ptr target="https://doi.org/10.1007/978-3-031-56027-9_25" />
	</analytic>
	<monogr>
		<title level="m">European Conference on Information Retrieval</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2024">2024</date>
			<biblScope unit="page" from="403" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">MaTableGPT: GPT-based table data extractor from materials science literature</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Miano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">.</forename><forename type="middle">.</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2406.05431</idno>
		<idno type="arXiv">arXiv:2406.05431</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2406.05431" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Large language models for time series: A survey</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chowdhury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2402.01801</idno>
		<idno>ArXiv, abs/2402.01801</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2402.01801" />
		<imprint>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
