<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Exploring Academic Perspectives: A Survey-Based Study on the Impact of Artificial Intelligence in Education</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Donna</forename><surname>Johnson</surname></persName>
							<email>donna.johnson@leedsbeckett.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Biomedical Science</orgName>
								<orgName type="department" key="dep2">School of Health</orgName>
								<orgName type="institution">Leeds Beckett University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Exploring Academic Perspectives: A Survey-Based Study on the Impact of Artificial Intelligence in Education</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">20156C11D6E542A4E5E6204B8895BE82</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2" ident="GROBID" when="2025-10-23T06:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<label type="revision">a91ee48</label>
					<label type="parameters">startPage=-1, endPage=-1, consolidateCitations=0, consolidateHeader=1, consolidateFunders=0, includeRawAffiliations=false, includeRawCitations=false, includeRawCopyrights=false, generateTeiIds=false, generateTeiCoordinates=[], sentenceSegmentation=false, flavor=null</label>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>With the current interest in the role of AI within education, there remains a lack of understanding regarding the perspectives of academic staff. This study addresses this gap, serving as a preliminary inquiry into the attitudes and perceived impacts of AI on education. Employing a survey-based approach, this study gathered data from a diverse cohort of academic staff across various disciplines. Overall, staff were positive about the impact of AI on their role but less so on the impact on student learning. Academic staff's opinions on AI in education can be influenced by a variety of factors, including their understanding of AI, their beliefs about the role of technology in education, and their experiences with using AI tools. If academic staff have negative attitudes towards AI, they may resist its implementation, which can hinder its potential benefits. Academic staff's opinions can provide valuable insights into the potential barriers and facilitators to the successful implementation of AI in education. For example, if academic staff believe that AI tools are difficult to use, this suggests a need for more training and support in the use of these tools. Therefore, gauging academic staff's opinion on AI in education is crucial for understanding how to effectively implement AI in education and maximise its benefits for students. This paper aims to give an overview of staff opinions around AI in education and will discuss the potential barriers to AI adoption in education as well as recommendations for its successful implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>This study used a survey approach. The questionnaire was created using Microsoft forms and included multiplechoice questions to gather structured responses and free-text questions to allow for more open-ended responses. It covered various aspects of AI in education, including the perceived benefits and challenges, the level of comfort with using AI tools, and the perceived impact of AI on teaching and learning.</p><p>An email request was sent to all academic staff at Leeds Beckett University, inviting them to participate in the study. The email included a link to the online questionnaire and information about the purpose of the study, the voluntary nature of participation, and the confidentiality of responses.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Artificial intelligence (AI) has rapidly emerged as a disruptive force in various industries, and education is no exception <ref type="bibr" target="#b11">(Girasa, 2020)</ref>. The potential of AI to transform the way we teach and learn has garnered significant interest from educators, policymakers, and researchers alike <ref type="bibr" target="#b10">(Gejendhiran et al., 2020)</ref>. The hype around AI in education has been fueled by a combination of technological advancements, increasing investment, and high expectations for the potential benefits. <ref type="bibr" target="#b15">(Luckin &amp; Holmes, 2016)</ref>. AI-driven technologies have been integrated into various aspects of education, from personalised learning and intelligent tutoring systems to administrative task automation and learning analytics <ref type="bibr" target="#b0">(Alam, 2022;</ref><ref type="bibr" target="#b7">Chen et al., 2020)</ref>. These advancements have the potential to revolutionize educational experiences, making them more efficient, engaging, and accessible. However, the integration of AI also presents several challenges and raises important ethical considerations <ref type="bibr" target="#b4">(Borenstein &amp; Howard, 2021;</ref><ref type="bibr" target="#b17">Selwyn, 2019)</ref>. Data privacy concerns are among the most pressing issues, as the use of AI-driven technologies often involves the collection and analysis of sensitive student data <ref type="bibr" target="#b14">(Lobera et al., 2020)</ref>. Algorithmic biases can also lead to unfair treatment of certain student populations, exacerbating existing inequalities in the educational landscape. The digital divide is another challenge, as students from underprivileged backgrounds may lack the resources to fully benefit from AI-driven learning experiences <ref type="bibr" target="#b5">(Božić, 2023)</ref>.</p><p>One of the key challenges, often overlooked, is the need for buy-in from academic staff. Educators will play a crucial role in the successful implementation of AI in education. They are the ones who will use AI tools in their teaching, and their attitudes and beliefs about AI can significantly influence how effectively these tools are used.</p><p>Responses were analyzed using a combination of thematic analysis and quantitative methods. Thematic analysis was conducted using NVivo to identify common themes and patterns in the free-text responses. Two sample Kolmogorov-Smirnov testing was performed to estimate statistically significant associations between demographic parameters (age, sex, role, and use of AI) and patterns of response and Chi 2 Goodness of Fit test was used to assess any significant associations between responses to questions about the impact of AI on their practice, teaching and learning and on students.</p><p>This study was conducted in accordance with institutional ethical guidelines for research involving human participants and was approved by the Local Ethics Review Co-ordinator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Demographics</head><p>Responses were collected from academic staff at Leeds Beckett University. There was a response rate of approximately 10% of academic staff (125/1200). Age was spread over a wide range of groups, with the most frequent group being 41-45 (18.1%), and relatively smaller numbers for 21-25 and above 65 with 3 (2.4%) respondents per group. We received a slightly increased number of female respondents (52%) compared to male respondents (43.3%), with 4.7% either giving no answer or other. Most respondents reported their role as Senior lecturer (39.4%) or Lecturer (27.6%). There were no significant associations seen between demographic characteristics and responses to questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Use of AI within role</head><p>While most respondents reported having never used AI in their work (68.5% total), most respondents were open to it (50.4%). Of the 31.4% that reported using AI in their role (yes, regularly: 10.2%, yes occasionally: 21.3%) most had used it for teaching-or research-related tasks (figure <ref type="figure" target="#fig_0">1</ref>), with the most common AI used being ChatGPT. Most of those using AI reported that their academic productivity somewhat or significantly increased (65%), and the remainder felt there was no difference; no respondents reported a decrease in their productivity. When asked to evaluate their knowledge of AI in education 8.7% of respondents rated themselves as excellent, 32.3% as good, 41.7% as average, 15.7% as below average and 1.6% as poor. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact on self</head><p>Part of the questionnaire was concerned with staff opinions on how AI would impact their role. While opinions on the overall impact of AI on education in general was evenly split (negative: 35.%, neutral: 32.3, positive: 31.5%, no answer: 0.8%), most felt that AI will either have no impact on the importance of their role or make it more important (figure <ref type="figure" target="#fig_1">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a b c</head><p>Staff also believed that AI had the potential to replace/assist with some aspects of their role (figure <ref type="figure" target="#fig_2">3</ref>), with most listing creation of teaching materials or research preparation. They also felt it could reduce the time spent on such tasks as well as increasing their creativity and innovation. Staff, however, highlighted concerns around inaccuracy and a need to better understand the output as negative aspects in this regard along with it having no impact on their work-life balance.</p><p>Overall, while there were those that considered AI to have negative impacts on their role, most were cautiously positive about its impact on their role.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact on teaching and learning</head><p>Several questions were asked about the impact of AI on aspects of teaching and learning. Respondents were overwhelmingly positive about AI's ability to help them create more interesting and engaging teaching materials but less certain of its ability to close the achievement gap or enhance the diversity of learning experiences. Respondents were also largely skeptical of the accuracy of AI in assessing student work or its ability to stimulate or replace human interaction in a learning environment and felt that it was likely to negatively impact academic integrity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Impact on students</head><p>The final category of questions concerned the perceived impact on students. Answers in this group reflected greater concerns for negative impacts of AI. While there were those that responded positively, many respondents felt AI would reduce student autonomy, decrease engagement, motivation to learn, critical thinking skills, self-directed learning, focus and concentration and hinder their ability to develop transferrable skills. It was also felt that there was a significant potential for it to weaken the staff-student relationship. Despite these more negative opinions here, most respondents felt we should be training students in the use of AI (figure <ref type="figure">4</ref>) and that it should be used as a tool rather than something to be punished.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>a b</head><p>Figure <ref type="figure">4</ref>. Despite concerns about the impact of AI on students, most felt we should be providing training in its use (a), and it should be considered as a tool rather than something to be penalised (b).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Associations</head><p>We were interested in determining if there were any associations between respondent's use of AI and whether they had more positive/negative opinions about the impact of AI. While we saw no associations between those that had or were willing to try AI and whether they gave more positive/negative responses, there were significant associations between those that answered, 'No and not interested' in response to 'Have you used AI in your role' and answers that suggested a negative impact of AI across most questions asked (Table <ref type="table">1</ref>). Most effect sizes were small to moderate as assessed using Cramer's V, but there was a strong association between those that had no interest in using AI and those that considered its use to be something to be penalised.</p><p>Table <ref type="table">1</ref>. Associations between those that had no interest in using AI in their role and negative opinions about its impact on various educational factors.</p><p>Question Adjusted Residual* P value (Chi 2 ) Cramer's V** Do you believe AI can contribute to a more inclusive educational environment? 3.5 0.027 0.233 Do you believe AI can effectively aid in student assessment and marking? 4.9 &lt;0.001 0.351 Do you believe AI can effectively assist in creating more engaging and interactive content for your students? 5.6 &lt;0.001 0.366 Do you believe AI can effectively assist in research-related tasks? 4.0 &lt;0.001 0.386 Do you believe AI can effectively assist in teaching-related tasks? 5.4 &lt;0.001 0.480 Do you believe AI has the potential to replace certain aspects of your role as an educator? 4.4 0.002 0.275 Do you believe that AI can help students develop necessary skills like critical thinking, creativity, communication, and collaboration? 3.4 0.002 0.274 Do you think we should train students to effectively use AI for academic purposes? 4.3 &lt;0.001 0.411 How do you feel about the accuracy of AI in assessing student performance? 5.6 &lt;0.001 0.359 How do you feel AI will impact the future of your role as an educator? 3.8 &lt;0.001 0.297 How do you feel AI will impact the staff-student relationship? 3.2 &lt;0.001 0.279 How do you perceive the impact of AI on creativity and innovation in your teaching or research? 3.6 &lt;0.001 0.325 How do you perceive the impact of AI on the creativity and critical thinking of students? 5.8 &lt;0.001 0.354 How do you perceive the impact of AI on the time spent on teachingrelated tasks? 4.2 0.003 0.292 How do you see AI impacting students' self-directed learning skills? 6.1 &lt;0.001 0.390 How do you think AI will affect students' motivation to learn? 5.3 &lt;0.001 0.323 How do you think AI will impact student engagement in learning? 6.1 &lt;0.001 0.377 How do you think AI will impact students' ability to focus and concentrate on their studies? 5.9 &lt;0.001 0.356 How do you think we should deal with the use of AI by students? 7.8 &lt;0.001 0.545 How would you rate the overall impact of AI on the education sector? 7.1 &lt;0.001 0.492 * Positive residuals show there are more observed than expected and a value above 3 is considered significant. ** Cramer's V denotes the effect size with values around 0.1 considered small, 0.3 moderate and 0.5 or above is considered a large effect size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Free text answers</head><p>The free text section allowed respondents to expand on their thoughts about AI in education and 45.7% left additional answers. Answers were coded in NVIVO using an inductive approach to identify key themes and facilitate thematic analysis <ref type="bibr" target="#b9">(Elliott-Mainwaring, 2021)</ref>. Coding was an iterative process where larger themes were identified and then divided into focused groups as patterns emerged. Answers could be grouped into comments relating to uncertainty, caution, need for guidance/training, positive impacts, negative impacts and then overall opinions.</p><p>A significant portion of the comments show optimism about integrating AI into educational settings.</p><p>Respondents in this group see AI as a resource that can make learning more efficient and engaging. Specifically, they point out that AI can guide student learning by helping them sift through vast amounts of information, making study time more productive. There's also the idea that AI can prepare students for a workforce that increasingly relies on automated systems. While many see the benefits, there's a noticeable sense of caution.</p><p>Respondents argue for a carefully planned strategy for implementing AI in education. The emphasis is on thoughtful integration-ensuring that AI tools are used in a way that complements rather than replaces traditional teaching methods. They suggest that before jumping into AI adoption, educators should first establish clear guidelines on how these tools should be used.</p><p>Some comments reflect uncertainty, primarily stemming from a lack of understanding about the full scope of AI's capabilities. This group is concerned that educational institutions are not adequately prepared to integrate AI technologies in a meaningful way. They question whether institutions have the resources and knowledge needed for successful implementation.</p><p>Lastly, there are those who express reservations about the negative impact AI could have on education. One worry is that if students misuse AI, the technology's negative aspects could outweigh the positives. There is also concern that students who are not exposed to AI might face disadvantages in their future careers.</p><p>The overarching sentiment is one of cautious optimism. While there's a general agreement on the potential advantages of using AI in educational settings, these positive views are balanced by calls for careful planning and implementation. The need for a clear strategy that involves not just the adoption but also the ethical use of AI tools is emphasized. This reflects a collective understanding that while AI offers promising possibilities for enhancing education, it also presents challenges that must be thoughtfully addressed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>This survey was carried out to assess the opinions of AI in education from academic staff. There is little literature regarding the opinions of academic staff on AI and these results provide a starting point for understanding these for the background to implementing AI successfully. We do, however, acknowledge the shortcomings of the survey approach used in this study. In distributing this voluntary and anonymous survey by the methods described, it resulted in a low response rate (approximately 10%). However, the topic can be a contentious one and the possibility that respondents are more likely than non-respondents to hold strong opinions or emotions on this issue is a real one and should be considered. As a further limitation, all respondents came from Leeds Beckett University, and opinions from staff at other types of institution may differ.</p><p>How are staff currently using AI?</p><p>The study indicates that ChatGPT (ChatGPT, n.d.) is the most frequently used AI tool among those who have adopted AI for their work, especially for tasks related to teaching and research. ChatGPT's natural language processing capabilities make it well-suited for these functions. For instance, it can be used to automatically answer frequently asked questions from students, freeing up time for the teaching staff. In research, it can assist in text analysis or even help generate written content, making it a useful tool for academic writing or data interpretation. Use for these tasks may indicate that staff see AI as a complementary tool.</p><p>The ease of use is a significant factor. ChatGPT is relatively straightforward to implement and doesn't require extensive technical skills. This is particularly appealing in an academic environment where not everyone might be tech-savvy. The less daunting a tool appears, the more likely staff are to try it out, even if they initially had reservations about using AI. The immediate benefits that ChatGPT offers can also make it an attractive option.</p><p>If staff can quickly see positive results, like saved time or improved efficiency, they are more likely to continue using it and even become advocates for it. This can influence the wider staff community. If a respected colleague reports having a positive experience with ChatGPT, it serves as a strong endorsement and could encourage others who are on the fence about AI to give it a try.</p><p>However, it's worth noting that the specific choice of ChatGPT could also point to limitations in how AI is perceived. If ChatGPT is primarily used for communication and data analysis, it suggests that academic staff</p><p>might not yet see AI as being applicable for more complex tasks. This could be because they are unaware of the capabilities, or it might reflect reservations about the effectiveness of AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Barriers to adoption</head><p>The data presents a curious paradox: while 68.5% of academic staff have not used AI in their professional capacity, a slightly smaller but still significant portion (50.4%) expressed an openness to doing so. One obvious explanation for this difference could be the technical barriers that academic staff face. In a sector where expertise is often concentrated in specific disciplines, the skills to understand and implement AI may not be universally distributed <ref type="bibr" target="#b13">(Liu et al., 2020)</ref>. Some staff might feel daunted by the complexity or are uncertain about how to integrate AI into their existing practices. If staff opinion leans towards viewing AI as a specialist tool requiring a steep learning curve, this can act as a significant deterrent to broader adoption. Another factor could be the institution's policies or lack of resources dedicated to technological advancement. For instance, if an institution does not actively promote or invest in AI tools, or if it fails to provide training programmes, the staff-even if willing-may find it challenging to incorporate AI. In this scenario, the opinion of administrative staff and decision-makers becomes an important variable. Their endorsement or lack thereof can either catalyze or inhibit technological adoption across the board. There is also the cultural aspect of academic settings, which are often steeped in tradition and established methods. Staff who have long-standing practices may be resistant to incorporating what they may see as disruptive technologies. The influence of key opinion leaders among staff in perpetuating or mitigating this cultural resistance cannot be overstated. If senior staff express skepticism or concern about the practicality or efficacy of AI, their opinions can have a cascading effect. Such sentiments can be particularly influential if they are echoed in departmental meetings or even casual conversations, thereby shaping the collective attitude towards AI.</p><p>Psychological factors like fear of the unknown or fear of failure can also contribute to the hesitancy <ref type="bibr" target="#b2">(Apostolidis et al., 2022)</ref>. The prospect of integrating AI into one's workflow could induce anxiety related to job security, effectiveness, or ethical considerations. Staff opinions can either alleviate or exacerbate these concerns. Open discussions, testimonials, or pilot projects showcasing successful AI adoption could help mitigate these fears.</p><p>The finding that 65% of AI users experienced an increase in productivity is a strong point in favor of wider AI adoption in academic settings. The immediate, visible benefits, such as time saved, can serve as a persuasive factor for others to adopt AI tools. However, the low number of reported negative impacts deserves attention.</p><p>The fact that no one reported a decrease in productivity could be due to several reasons. It might be that the sample size is not large enough to capture a full range of experiences, or maybe the timeframe of AI usage hasn't been long enough to see any negative impacts. Alternatively, it could indicate a form of reporting bias where people are less likely to report negative experiences in a survey. This low frequency of negative impacts could also result from the type of tasks that AI is being used for. If AI is primarily used for tasks like communication and data analysis, the risk of negative impact might be lower than if it were applied to more complex aspects of teaching and research.</p><p>Ethical dilemmas are another aspect that might not immediately impact productivity but are crucial for longterm sustainable AI adoption. Issues around data privacy, especially in the context of student information, could pose challenges. Similarly, the use of AI in research raises questions about intellectual property and research integrity. If AI tools are generating content or analysing data, who owns that output? And how transparent are the algorithms driving these tools?</p><p>The gap between the willingness to adopt AI and the actual use of these technologies in academic roles is a complex issue influenced by a wide range of factors. Staff opinions serve as both a mirror and a lens-reflecting existing attitudes and shaping future behaviors. Understanding the interplay of these variables is important for institutions aiming to bridge the divide between willingness and action in AI adoption. Therefore, it's not just a question of encouraging openness towards AI but also addressing the tangible and intangible barriers that keep such willingness from translating into action.</p><p>One primary concern from respondents is regarding quality of education. Given that most respondents haven't yet employed AI in their roles, reservations about automated marking systems lacking the nuance of human evaluation could be a significant barrier. This is particularly relevant for subjects that hinge on subjective analysis and critical thinking, where human expertise is often considered irreplaceable. Another aspect that resonates with the study's findings is the issue of student engagement. With more than half of the respondents open to AI adoption, yet a significant majority not having used it, there might be underlying worries that automated lectures or tutorials could dilute the richness of in-person interactions. Staff might fear that students would lose out on immediate feedback and the spontaneous discussion that traditional classroom settings offer.</p><p>The issue of accessibility and inclusivity is particularly salient. Despite the apparent openness to AI technology, there may be substantial reservations about how universally accessible these tools are for all students. The concern isn't merely hypothetical; it touches on the ethical commitment of educational institutions to provide equitable opportunities for all students, irrespective of their socio-economic background or physical abilities.</p><p>For students with disabilities, AI-driven platforms might pose a series of challenges, such as compatibility with assistive technologies or the availability of content in accessible formats. While AI has the potential to offer personalised learning experiences, if these technologies are not designed with accessibility in mind from the ground up, they could inadvertently exclude a segment of the student population. Therefore, the reluctance among most academic staff to incorporate AI could stem from a conscientious standpoint, prioritising inclusivity over technological advancement.</p><p>Economic disparities can exacerbate existing inequalities in access to educational resources. Students from disadvantaged backgrounds may not have access to high-speed internet or the necessary hardware to engage with AI-driven educational platforms effectively <ref type="bibr" target="#b8">(Coleman, 2021)</ref>. This digital divide could lead to a situation where only a subset of students can fully benefit from AI's capabilities, which might be anathema to the inclusive ethos that educational institutions strive to uphold. The issue of accessibility and inclusivity also has implications for an institution's reputation and regulatory compliance. Failing to provide equitable access to educational resources could attract legal ramifications and negatively affect an institution's standing in rankings, which often consider inclusivity as a key metric.</p><p>Given that few negative impacts were reported, it could suggest that there is an underlying caution against rushing into adoption without adequately addressing ethical considerations. Handling sensitive student data is an inherently ethical act, associated with responsibilities around confidentiality, informed consent, and the right to privacy. The introduction of AI systems, which often require the collection and analysis of large datasets to function effectively, could pose new challenges in ensuring that this data is handled securely and ethically. This is particularly pertinent given the increasing prevalence of data breaches and cyber-attacks targeting educational institutions.</p><p>The algorithms that power AI systems often operate as 'black boxes,' making it difficult to fully understand how decisions are made. This lack of transparency can be a significant concern when it comes to ethical considerations. For instance, if an AI system were used to automatically mark student assessments, questions about the fairness and bias of the algorithm could arise, particularly if the criteria aren't clear or if the AI has been trained on unrepresentative data <ref type="bibr" target="#b3">(Baker &amp; Hawn, 2022)</ref>.</p><p>While AI's ability to offer personalized learning experiences is often touted as a significant advantage, this same may be viewed as a potential disadvantage when considering the importance of a standardised curriculum. AI's capability for personalization allows for tailored learning paths, customised feedback, and adaptive resource allocation, all of which can significantly benefit individual students by meeting them at their level of understanding and learning pace. However, the flip side of this is the potential for educational experiences to become too fragmented. If each student is following a highly individualized learning path, there's a risk that the cohesive structure of a standard curriculum could be eroded. Curricula are often designed not just to impart knowledge but also offer a shared foundation upon which more advanced concepts are built. The concern, then, is that excessive personalization could cause students to miss out on this essential, shared knowledge, affecting the integrity of the educational programme. This issue isn't just academic; it has social implications as well. Shared educational experiences contribute to a sense of community and shared understanding among students. Too much personalization could risk isolating students, each absorbed in their individualised educational journey, diminishing the collective learning experience. The potential for a fragmented curriculum could also have long-term consequences for students as they move into the workforce. Employers often have set expectations regarding the foundational knowledge that students should possess, and excessive personalization could jeopardise this.</p><p>The consideration of students' long-term readiness for the workforce adds another layer of complexity to the debate on AI adoption in education. There's a growing concern that over-reliance on these tools could inadvertently hamper the development of skills that are inherently human and highly valued in the workforce. These 'soft skills' are often cultivated through human interaction that can be diminished if AI takes on a more dominant role in the educational setting. For instance, while an AI-driven system might efficiently handle the marking of assessments, it cannot replicate the nuanced feedback and mentorship that a human educator can provide. Such interpersonal skills are not just supplemental but often central to many professions, especially those in healthcare, social work, management, and more.</p><p>Another aspect that could be influencing the rate of AI adoption is the potential added costs for students.</p><p>Educational institutions are already grappling with issues around tuition fees and the affordability of higher education. The introduction of AI tools, particularly more sophisticated ones, might necessitate additional financial outlay, either from the institution itself or passed down to students as added fees or subscriptions to access the tools. Such financial barriers could exacerbate existing inequalities in access to higher education, contradicting the inclusive ethos that educational institutions strive to maintain.</p><p>The cognitive and psychological impacts of constant interaction with AI could be a latent but substantive concern, particularly for younger or more impressionable students. While AI has the potential to offer highly engaging and interactive learning experiences, the long-term effects of such constant digital interaction on cognitive development are not yet fully understood. Issues such as shortened attention spans, reduced critical thinking abilities, or even potential addiction to digital interfaces could be serious considerations that academic staff are considering. The low number of negative impacts reported in the study might be indicative of a cautious approach, waiting for more conclusive evidence on these fronts before fully embracing AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>How do staff opinions influence AI adoption?</head><p>The study shows that most respondents hold the positions of senior lecturers/lecturers. These roles generally come with a level of autonomy in teaching methods and often have sway over departmental decisions. Their opinions, therefore, have the potential to significantly influence the broader academic community within an institution. When staff have positive experiences with AI, it can create a ripple effect. Their endorsement can serve as a form of 'social proof,' making other staff more comfortable with the idea of adopting AI in their own roles. For instance, if a senior lecturer successfully integrates AI tools into their research methods or teaching approach and shares these positive outcomes with colleagues, it could encourage others to explore these tools <ref type="bibr" target="#b16">(McConnell et al., 2020)</ref>. This is particularly important for those who may be hesitant or lack the confidence to try out new technologies without some form of validation from trusted peers.</p><p>However, the influence of this group can also act as a double-edged sword. If they express skepticism about AI, it can impede its broader adoption. This is especially true if these views are vocalised in formal settings like department meetings or even informally during discussions among colleagues. The influence of such staff extends beyond their immediate colleagues. They often sit on committees within the institution, thereby having the ability to influence policy and resource allocation. Their views could thus shape not just departmental but institutional approaches to AI, either opening doors for investment in new technologies or keeping the status quo. In addition, these staff members are often deeply involved in student education and mentorship. Their adoption or rejection of AI tools could directly impact the next generation of professionals, affecting not just current but also future attitudes towards technology in academia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implications</head><p>The staff opinions gathered in this study carry several significant implications for the future adoption of AI in academic settings. First and foremost, the notable gap between the number of staff willing to use AI and those who have done so suggests that mere openness to the technology isn't enough to guarantee its adoption. This disparity indicates that even if staff are willing, there may be various barriers, such as lack of resources or training, preventing them from using AI. The preference for specific AI tools like ChatGPT also suggests that staff may currently see AI as beneficial for particular tasks, perhaps due to a limited understanding of the technology's broader capabilities.</p><p>The reported increase in productivity among AI users is promising and implies that when AI is adopted, it tends to be used successfully, at least in the short term. However, the low number of reported negative impacts warrants caution. It raises the question of whether staff are sufficiently considering the longer-term and more complex challenges that come with AI integration. One possibility is that the short-term gains in productivity are overshadowing potential long-term issues. For instance, while automating routine tasks might improve efficiency now, there could be future concerns about job displacement as AI capabilities expand. The initial boost in productivity might also lead to higher workloads and expectations, ultimately affecting staff well-being in the long run.</p><p>Ethical considerations are another critical aspect that seems to be missing from the reported experiences. For instance, the use of AI in data analysis or student evaluations brings up important questions about data privacy.</p><p>How is student or research data being stored and used, and who has access to it? There's also the issue of algorithmic bias, which could inadvertently introduce discrimination into research findings or student assessments. The low number of negative reports might also be due to a honeymoon period with the technology, where the novelty and immediate benefits have not yet given way to a more nuanced understanding of long-term implications. Alternatively, it could reflect reporting bias where staff are less likely to report challenges or failures, either due to the stigma associated with it or because they haven't yet encountered these issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Recommendations</head><p>Addressing the technical barriers is a crucial first step to bridge the existing gap between staff's willingness to use AI and their actual adoption of the technology. Institutions can facilitate this by offering a range of training and resources tailored to various skill levels. Workshops aimed at beginners could offer a hands-on introduction to AI tools, covering the basics and demystifying the technology. These could be both in-person sessions and virtual webinars, allowing for broader participation. Such workshops would serve as an entry point, giving staff the essential skills and confidence to start exploring AI tools in their professional activities. For those who prefer a self-paced learning environment, online courses could be an invaluable resource. These courses could range from beginner to advanced levels, allowing staff to progress at their own pace and comfort. With the advantage of asynchronous learning, academic staff could fit these educational modules around their existing commitments, thereby removing one of the potential barriers to upskilling.</p><p>Institutions could invest in dedicated technical support teams well-versed in AI applications. These teams could offer real-time assistance for specific challenges that staff may encounter while using AI tools, from troubleshooting technical issues to providing guidance on optimal usage for teaching and research tasks. Providing a safety net of expert support can significantly reduce the perceived risk associated with adopting new technologies, making staff more willing to integrate AI into their daily work.</p><p>Importantly, these training and support initiatives should be designed to serve dual purposes. First, they should aim to enable those staff members who are interested in AI but unsure of how to take the first step, offering them the tools and knowledge to begin their journey. Second, they should cater to those who have already dipped their toes in the AI waters but are keen to expand their skill set and explore more advanced applications.</p><p>The popularity of ChatGPT among the academic staff who participated in the study serves as a telling indication of how AI is currently perceived in educational settings. While ChatGPT and similar tools are highly versatile, their primary usage appears to be confined to specific tasks such as communication and perhaps rudimentary data analysis. This could signify a limited awareness among academic staff of the broader capabilities that AI can offer, especially in more complex educational contexts. Broadening this awareness is crucial for several reasons. First, a limited perception of AI's utility could inhibit innovation and the adoption of potentially transformative educational technologies. For instance, AI can not only facilitate communication but also offer advanced data analytics for educational research, automate administrative tasks, provide adaptive learning experiences, and even assist in curriculum development. The narrow focus on specific tasks such as communication might be a missed opportunity to leverage AI's full potential, thereby affecting the educational institution's competitiveness and efficacy.</p><p>Given that the majority of the study's respondents are in roles that wield considerable influence over departmental and possibly institutional decisions, their perception of AI's capabilities is particularly significant.</p><p>Awareness-raising sessions could serve a dual purpose here. On one hand, they could educate academic staff about the various ways AI can be integrated into their teaching and research activities, thereby possibly catalysing more widespread adoption. On the other hand, these sessions could also act as a forum for staff to voice their concerns or reservations, which could be invaluable for institutions in addressing the barriers to AI adoption effectively.</p><p>The reported increase in productivity among AI users is undeniably a compelling argument for the broader adoption of AI in educational settings. However, the low number of reported negative impacts raises questions about the long-term consequences that might not yet be fully understood. This underscores the need for a more comprehensive long-term impact assessment, which could significantly influence the pace and nature of AI adoption within academic circles. The prospect of job displacement is a pressing concern that goes beyond immediate productivity gains. While AI can automate various tasks, thereby freeing up time for academic staff, there is the looming question of whether these technologies might eventually supplant roles traditionally held by humans <ref type="bibr" target="#b18">(Tschang &amp; Almirall, 2021)</ref>. This is not merely an issue of job security for academic staff but also raises questions about the quality of education. If certain roles become automated, we may lose the humancentric qualities in education that machines cannot replicate, such as mentorship, nuanced understanding, and ethical decision-making. Given that the study's respondents predominantly comprise senior lecturers and lecturers, who often have an influential say in policy and curriculum matters, the long-term employment implications could be a significant determinant in their cautious approach to AI adoption.</p><p>The ethical concerns are not to be underestimated either <ref type="bibr" target="#b4">(Borenstein &amp; Howard, 2021)</ref>. As AI systems become more integrated into educational infrastructures, the ethical implications could grow exponentially. These may include issues of data privacy, algorithmic bias, and equitable access, among others. This is particularly important given that academic institutions are often held to high ethical standards, both in research and teaching, and any missteps in this regard could have far-reaching reputational consequences. A deeper long-term impact assessment is therefore required. It could take multiple forms, including longitudinal studies tracking both the benefits and drawbacks of AI adoption over extended periods, cost-benefit analyses that factor in not just financial but also social and ethical costs, and scenario planning exercises that consider various future trajectories of AI development and adoption.</p><p>The role of influential voices within academic settings cannot be overstated, especially when it comes to the adoption of new technologies like AI. Leveraging these influential voices could serve as a strategic approach to accelerating AI adoption, as well as addressing any concerns or roadblocks that may exist. Involving such staff in pilot programmes for AI adoption can serve multiple objectives. Their participation would likely lend credibility and weight to these initiatives, making it more likely that other staff members will consider engaging with AI tools. Such pilot programmes offer a hands-on experience that allows these key stakeholders to understand the practical benefits and challenges of AI, thereby forming opinions based on direct interaction rather than abstract considerations. This nuanced understanding can be invaluable when it comes to refining the AI tools to better suit educational needs.</p><p>Conversely, any concerns or reservations these influential figures have could act as substantial roadblocks to AI adoption. Given their role in shaping academic culture and policies, their skepticism could have a ripple effect, influencing not just their immediate colleagues but also shaping departmental attitudes and possibly even institutional policies. Therefore, actively involving them in the decision-making process and addressing their concerns could significantly accelerate the rate of AI adoption. This could take the form of dedicated forums for discussion, workshops to address specific concerns, or even consulting them in the initial stages of developing an AI strategy for the department or institution. Their insights could also be essential in identifying any potential pitfalls or ethical considerations that might not be immediately obvious. Given the complex nature of AI and its far-reaching implications, these perspectives are not just desirable but crucial for responsible and effective implementation.</p><p>The establishment of clear ethical guidelines for AI usage within educational settings is a critical measure <ref type="bibr" target="#b12">(Holmes et al., 2022)</ref>. The issue of data privacy is paramount; AI systems often require access to vast amounts of data to function effectively, and in an educational context, this could include sensitive information ranging from student marks to personal identifiers. Without robust ethical guidelines, the risk of data breaches or misuse becomes a significant concern. Clear policies can establish what kinds of data can be collected, how it should be stored, and who has access to it, thereby offering a level of assurance to staff members who may have reservations about AI adoption on data privacy grounds.</p><p>Research integrity is another area where ethical guidelines are crucial. AI has the potential to significantly influence research methodologies and outcomes, especially in data-driven disciplines. Guidelines can help ensure that AI is used responsibly in research contexts, providing a framework for its deployment that respects academic integrity, offers transparency, and ensures replicability. Given the central role that research plays in the professional lives of academic staff addressing these concerns could remove a significant barrier to AI adoption.</p><p>Establishing ethical guidelines isn't just about risk mitigation though, it's also about creating a culture of responsible AI usage that aligns with broader institutional values. Given the influential roles that senior lecturers and lecturers often hold, their input into the creation of these guidelines could be invaluable, ensuring that the policies are both practical and aligned with the educational mission of the institution. Such guidelines could serve as a reference point for ongoing education and training, forming the basis of professional development activities aimed at promoting responsible AI adoption. The establishment of an ethical review board focused on AI could also provide a structured framework for oversight and accountability. This board would not only review ongoing and proposed AI initiatives but also offer guidelines on ethical data management.</p><p>Mitigating the perceived negative impact of AI on students' learning and skills development requires a multipronged approach that aligns with the concerns of academic staff. One potentially effective strategy is to adopt a collaborative human-AI model, where technology serves as a complement to human instruction rather than a replacement. This ensures that the educational experience remains holistic, preserving the essential elements of mentorship and ethical guidance that only human educators can provide. To tackle concerns related to accessibility and inclusivity, regular equity audits could be conducted to evaluate how AI technologies are affecting various student demographics. This would enable educational institutions to make necessary adjustments to ensure that all students have equitable access to learning resources.</p><p>Curriculum integration is another critical aspect; AI should be deployed in a way that supplements rather than fragments the existing curriculum. By doing so, institutions can mitigate fears about the erosion of shared foundational knowledge among students. To address worries that students may lose out on developing human skills like empathy and teamwork, specific programmes focused on soft skills training could be introduced. These could range from team-based projects to ethical discussions and community engagement activities <ref type="bibr" target="#b19">(Wood et al., 2021;</ref><ref type="bibr" target="#b20">Yang, 2022)</ref>.</p><p>Longitudinal studies that track the long-term cognitive and psychological impacts of AI on students can also offer invaluable insights. These studies would inform ongoing and future AI strategies, ensuring that they align with the broader educational goals and the well-being of students. Finally, transparency and regular communication between administrators, academic staff, and students are crucial. Providing updates on AI initiatives and the outcomes of impact assessments can help build institutional trust.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>This survey reveals a complex interplay of factors that influence staff opinions, ranging from the perceived impact on student learning and skills development to ethical considerations and practical barriers to AI adoption. It suggests that while there is interest and willingness among academic staff, there's also caution and hesitance. This caution is not only rooted in a resistance to new technology but is a nuanced response to the multifaceted challenges that AI adoption presents. These range from ethical considerations like data privacy and research integrity to more pedagogical concerns such as the quality of education and accessibility. It underscores the need for a multi-dimensional approach to AI adoption in educational settings. It calls for clear ethical guidelines, comprehensive long-term impact assessments, and strategic involvement of influential voices within the academic community to facilitate responsible and effective AI integration. It also emphasises the need for further research, especially longitudinal studies, to fully grasp the long-term impacts and ethical implications of AI in education. Given the influential roles that academic staff play in shaping educational policies and practices, their insights and concerns offer a crucial roadmap for the responsible and effective implementation of AI in education.</p><p>References</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Have you used AI for research-related tasks (a), teaching-related tasks (b) or admin-related tasks (c).Teaching and research-related tasks were the most reported use of AI from respondents.</figDesc><graphic coords="4,72.00,465.92,321.32,189.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Most respondents felt there would be no impact or positive impact on the importance of their role.</figDesc><graphic coords="5,72.00,458.10,389.93,229.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Many staff felt that AI has the potential to replace aspects of their role.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="6,72.00,292.62,387.04,227.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0"><graphic coords="6,72.00,521.53,402.00,236.45" type="bitmap" /></figure>
		</body>
		<back>

			<div type="funding">
<div><head>Funding</head><p>No funding was received for this work, it was performed as part of the employment of the authors, <rs type="institution">Leeds Beckett University</rs>.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The author has no relevant financial or non-financial interests to disclose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Biographical note</head><p>Donna is the Course Director for the Taught Postgraduate courses in Biomedical Science at Leeds Beckett University. Within this role she has led IBMS and RSB accreditation for the masters courses. She has extensive experience teaching genetics and statistics at undergraduate and postgraduate levels. Her current interest is student support, in particular supporting the transition to masters level study. More recently, she has been investigating staff opinions on the impact of artificial intelligence in education and how AI can be integrated as a tool for student learning. She is a senior fellow of the HEA and a Chartered Science Teacher.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Employing Adaptive Learning and Intelligent Tutoring Robots for Virtual Classrooms and Smart Campuses: Reforming Education in the Age of Artificial Intelligence</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advanced Computing and Intelligent Technologies</title>
		<imprint>
			<biblScope unit="page" from="395" to="406" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Possibilities and Apprehensions in the Landscape of Artificial Intelligence in Education</title>
		<author>
			<persName><forename type="first">A</forename><surname>Alam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computational Intelligence and Computing Applications (ICCICA)</title>
		<imprint>
			<date type="published" when="2021">2021. 2021</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">From chalk to clicks -The impact of (rapid) technology adoption on employee emotions in the higher education sector</title>
		<author>
			<persName><forename type="first">C</forename><surname>Apostolidis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Devine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Jabbar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technological Forecasting and Social Change</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="issue">121860</biblScope>
			<biblScope unit="page">121860</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Algorithmic bias in education</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hawn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Artificial Intelligence in Education</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1052" to="1092" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Emerging challenges in AI and the need for AI ethics education</title>
		<author>
			<persName><forename type="first">J</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI and Ethics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="65" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Artifical Intelligence as the Reason and the Solution of Digital Divide</title>
		<author>
			<persName><forename type="first">V</forename><surname>Božić</surname></persName>
		</author>
		<ptr target="https://langedutech.com/letjournal/index.php/let/article/view/53" />
	</analytic>
	<monogr>
		<title level="j">Language Education and Technology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName><surname>Chatgpt</surname></persName>
		</author>
		<ptr target="https://chat.openai.com/" />
		<imprint>
			<date type="published" when="2023-09-22">September 22, 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Artificial Intelligence in Education: A Review</title>
		<author>
			<persName><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="75264" to="75278" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Digital divide in UK education during COVID-19 pandemic: Literature review</title>
		<author>
			<persName><forename type="first">V</forename><surname>Coleman</surname></persName>
		</author>
		<ptr target="http://files.eric.ed.gov/fulltext/ED616296.pdf" />
	</analytic>
	<monogr>
		<title level="s">Cambridge Assessment</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">Research report</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Exploring using NVivo software to facilitate inductive coding for thematic narrative synthesis</title>
		<author>
			<persName><forename type="first">H</forename><surname>Elliott-Mainwaring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British Journal of Midwifery</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="628" to="632" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Disruptive Technologies -A promising key for Sustainable Future Education</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gejendhiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">A</forename><surname>Anicia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vignesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kalaimani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="page" from="843" to="847" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">AI as a Disruptive Technology</title>
		<author>
			<persName><forename type="first">R</forename><surname>Girasa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence as a Disruptive Technology</title>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="3" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Ethics of AI in Education: Towards a Community-Wide Framework</title>
		<author>
			<persName><forename type="first">W</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Porayska-Pomsta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Holstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">B</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">C</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cukurova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">I</forename><surname>Bittencourt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Koedinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Artificial Intelligence in Education</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="504" to="526" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Understanding academics&apos; adoption of learning technologies: A systematic review</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Geertshuis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grainger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Education</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page">103857</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Privacy, values and machines: Predicting opposition to artificial intelligence</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lobera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J F</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Torres-Albero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Communicating Artificial Intelligence (AI)</title>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="80" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Intelligence Unleashed: An argument for AI in Education</title>
		<author>
			<persName><forename type="first">R</forename><surname>Luckin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Holmes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">60</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A model of peer effects on instructor innovation adoption</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mcconnell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Montplaisir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Offerdahl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of STEM Education</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Should Robots Replace Teachers?: AI and the Future of Education</title>
		<author>
			<persName><forename type="first">N</forename><surname>Selwyn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Artificial Intelligence as Augmenting Automation: Implications for Employment</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">T</forename><surname>Tschang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Almirall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Academy of Management Perspectives</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="642" to="659" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Are We Ready to Integrate Artificial Intelligence Literacy into Medical School Curriculum: Students and Faculty Survey</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Ange</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Education and Curricular Development</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">23821205211024080</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Artificial Intelligence education for young children: Why, what, and how in curriculum design and implementation</title>
		<author>
			<persName><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Education: Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">100061</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
