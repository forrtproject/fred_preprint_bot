<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Children, Ethics, and Generative Video: Educational Reflections on Sora 2</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2025-10-15">15 October 2025</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Andrew</forename><surname>Firr</surname></persName>
							<email>a.firr@chester.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Chester</orgName>
								<address>
									<settlement>Chester</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Children, Ethics, and Generative Video: Educational Reflections on Sora 2</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2025-10-15">15 October 2025</date>
						</imprint>
					</monogr>
					<idno type="MD5">782A59E3F9545010FC6D55753AA817F7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-10-21T14:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Generative AI</term>
					<term>AI literacy</term>
					<term>children&apos;s rights</term>
					<term>media ethics</term>
					<term>educational policy</term>
					<term>digital pedagogy</term>
					<term>child safeguarding Ethical approval: Not applicable</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The release of OpenAI's Sora 2 marks a turning point in the relationship between generative AI and education. For the first time, text-to-video systems can produce coherent and photorealistic scenes that blur the boundary between what is filmed and what is fabricated. This commentary examines the ethical, pedagogical, and policy implications of this shift in children's learning and safeguarding. Drawing on emerging research, international frameworks, and ethical theory, it argues that AI literacy must extend beyond functional competence to civic and moral capacity. Teachers require sustained professional learning to design reflective, human-centred practices that help young people navigate synthetic media critically and compassionately. The commentary concludes that education should not retreat from generative technologies but humanise them, cultivating discernment, empathy, and responsibility as essential literacies for the age of synthetic video.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Main Text</head><p>The release of OpenAI's Sora 2 in late 2025 marked a new stage in the evolution of generative artificial intelligence. For the first time, text-to-video models can create extended photorealistic scenes with synchronised dialogue, ambient sound, and narrative coherence. This leap from still to moving images represents not merely a technical advance but a transformation in the nature of visual media. Within days of its launch, Sora 2 was used to generate deepfakes of deceased public figures and insert individuals into fabricated or defamatory situations. The Safe AI for Children Alliance (2025), a non-profit child safeguarding coalition, warned that such misuse exposes young people to new forms of identity theft, reputational harm and emotional manipulation. For educators, parents, and policymakers, the question is no longer whether children will encounter generative videos but whether they will be equipped to interpret and navigate them safely, creatively, and ethically. <ref type="bibr" target="#b6">Floridi (2014)</ref> describes as an infosphere, a shared environment where human and artificial agents co-produce information and meaning. In this hybrid space, the epistemic stability of an image-and thus its capacity to testify to reality-becomes increasingly fragile. For adults, contextual literacy and critical reasoning can mitigate this instability. For children, whose cognitive and moral frameworks are still forming, the effect is more profound and long-lasting. The traditional pedagogical distinction between fact and fiction becomes blurred, while the ethical challenge of authenticity moves from philosophy to everyday experience. The question of 'What is real?' becomes a literacy problem as much as it is a philosophical one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Generative video collapses the distinction between what is filmed and what is fabricated, creating what</head><p>Empirical evidence shows that teachers are already encountering this frontier in education. <ref type="bibr" target="#b25">Xu et al. (2024)</ref> experimentally compared 76 undergraduate and graduate students assigned to human-made instructional videos versus AI-generated videos and found comparable learning outcomes but lower perceived authenticity for AI-generated content than for human-made content. Student comprehension levels were similar, but learners described AI videos as less authentic and emotionally engaging, suggesting that authenticity now demands explicit discussion rather than tacit assumptions. In a related preprint, <ref type="bibr" target="#b12">Lee et al. (2025)</ref> conducted interviews with ten K-12 teachers on their early use of generative video AI; teachers celebrated its creative potential but raised concerns about data provenance, bias, and consent, calling for institutional frameworks and support. These findings reveal a profession eager to innovate, yet aware of the social and moral weight that innovation carries.</p><p>According to the UN Committee on the Rights of the Child (2021), children's rights in the digital environment extend beyond protection to encompass participation, agency, and access to information and expression. However, the rapid emergence of generative AI poses risks that could undermine all three, compromising privacy, consent, and meaningful involvement in shaping digital experiences. Publicly available photographs and classroom recordings can be scraped into training datasets, repurposed, and redistributed without consent. The practice of 'likeness insertion', highlighted in the Safe AI for Children Alliance (2025), a non-peer-reviewed policy briefing for schools and parents, destabilises identity ownership and privacy. <ref type="bibr" target="#b13">Livingstone et al. (2019)</ref> argue that digital-literacy education must extend beyond content to include algorithmic literacy, understanding how data and algorithms curate what children encounter, and the commercial purposes that shape these systems. This direction is reinforced by the UNICEF Innocenti review's call to equip children for datafication and automation <ref type="bibr" target="#b22">(Stoilova et al., 2021)</ref>. For young people, developing such literacy is not optional; it is essential to civic competence in the digital age.</p><p>The reconceptualisation of AI literacy as more than mere functional competence is well-aligned with educational frameworks that expand technical fluency into critical and civic capacities, for example, <ref type="bibr" target="#b14">Long and Magerko's (2020)</ref> triadic model of tool use, human-AI collaboration, and critical evaluation, and more recent proposals to embed AI literacy in citizenship and data justice activities <ref type="bibr" target="#b20">(Picasso et al. 2024;</ref><ref type="bibr" target="#b4">DiPaola et al. 2024)</ref>. In this enriched framework, students are taught to not only prompt, generate, and edit responsibly, but also to interrogate the power dynamics, representation effects, and governance implications of algorithmic systems. Pedagogical design should shift from avoidance to guided engagement. Recent studies indicate that classroom engagement with both AI-generated and human-produced materials can deepen reflections on creativity and authorship <ref type="bibr" target="#b0">(Amirjalili et al., 2024;</ref><ref type="bibr" target="#b16">Marrone et al., 2022)</ref>. Similarly, when generative tools are integrated reflectively, students develop stronger ethical awareness of multimodal composition <ref type="bibr">(Burriss et al., 2024)</ref>. Sustaining such reflective practices depends on teachers' readiness and ongoing professional development.</p><p>To implement such approaches, teachers require sustained professional learning. <ref type="bibr">UNESCO (2023a</ref><ref type="bibr">UNESCO ( , 2023b) )</ref> stresses that capacity building is foundational to responsible AI integration, highlighting that human capacity and collective action, not technology, are the determining factors in ensuring that AI benefits teaching and learning. However, most teacher-training programmes remain focused on generic digital competence, leaving algorithmic systems unexplored. <ref type="bibr" target="#b15">Luckin et al. (2016)</ref> argue that educators should become designers of learning ecosystems in which human judgment and AI systems are blended thoughtfully; hence, she calls for collaboration among developers, researchers, and teachers to co-construct these environments. In more recent scholarship, Luckin and colleagues proposed that transparency in educational AI must be co-designed with educators, technologists, and domain experts, pointing to the value of formal partnerships and collaborative networks to ensure AI aligns with pedagogical goals <ref type="bibr" target="#b3">(Chaudhry et al., 2022)</ref>. These initiatives should not only explain how tools function but also address their epistemological consequences and how they change what it means to know, create, and witness. Without such preparation, schools risk adopting generative systems as novelties rather than as critical pedagogy subjects.</p><p>Although the policy landscape is expanding, it remains fragmented. The OECD (2024a, 2024b) and European Commission (2025) have issued frameworks promoting trustworthy AI. In the United Kingdom, the Online Safety Act (2023) and ICO's Age-Appropriate Design Code (n.d.) provide a partial foundation for the safeguarding of minors. However, none of these approaches directly address the unique challenges of generative videos. Effective governance requires broad ethical principles to be operationalised through mechanisms of transparency and accountability. Many scholars have proposed that developers publish model cards <ref type="bibr" target="#b17">(Mitchell et al., 2019)</ref> and datasheets for datasets <ref type="bibr" target="#b8">(Gebru et al., 2021)</ref> that document training data provenance, known biases, intended use, and limitations, making hidden technical choices legible to users and regulators. Platforms accessible to minors should disable likeness insertion by default and activate it only with verified parental consent. Independent audits and accessible redress systems are essential for upholding accountability. These mechanisms, far from hindering innovation, reinforce public trust and align technological progress with democratic norms.</p><p>Although policy frameworks are necessary, they are not sufficient to ensure responsible innovation in generative systems. In How to Create Your AI School Guidance, <ref type="bibr" target="#b1">Bauschard and Quidwai (2024)</ref> underscore that investment in human capacity through continuous professional development, institutional alignment, and capacity building is as crucial as technical capabilities. In the spirit of large-scale mission-driven initiatives, one might envision a moonshot for digital safety, a coordinated public-private research effort that integrates ethical education and participatory design throughout the lifecycle of generative tools, thereby bridging the gaps between innovation, accountability, and societal alignment. <ref type="bibr" target="#b23">Thorn (2024)</ref> formed a cross-sector initiative with major technology companies to establish safety-by-design principles aimed at preventing AI-generated child sexual abuse material and related harms, such as non-consensual imagery. Their collaborative approach, which combines technology firms, civil society, and regulatory concerns, illustrates how shared governance can operationalise safety in generative AI.</p><p>Although not yet specific to educational contexts, the essence of co-design and accountability suggests that educational AI governance would benefit from a similar ethos: one that positions children not just as users or recipients, but as co-creators of policy insights and design choices.</p><p>Ethical philosophy, particularly Noddings' (2013) ethic of care, provides a conceptual foundation for this approach. In an AI context, this suggests the need to design systems and curricula that acknowledge children's lived experiences, fears, and aspirations, and support their inclusion not merely as users but as active participants in shaping the technologies that affect them. The growing literature on ethical AI for children points to participatory and co-creative approaches as necessary for safeguarding children's agency and ensuring relevance. <ref type="bibr" target="#b11">James and Prout (2015)</ref> argue that children are active social actors, capable of shaping their own lives and influencing their social worlds. Extending from their theory, one can argue that involving children in discussions of AI imagery, privacy, and consent transforms protection from a paternalistic exercise into a shared moral practice that fosters resilience, empathy, and moral imagination.</p><p>The pedagogical implications are significant. Rather than confining AI ethics to standalone digital safety modules, schools should consider embedding media ethics and AI literacy across subjects such as art, citizenship, and computing. For instance, students could analyse how generative systems encode emotional affect, bias, or power, compare AI-generated imagery with documentary footage, or debate when manipulation becomes deceptive. Such integrative strategies resonate with UNESCO (2023a) guidance, which frames AI literacy as a cross-cutting dimension of education and calls for curricular innovation based on human-centred validation and ethical frameworks. Although the UK Department for Education (2023a, 2023b) has begun publishing leadership toolkits that encourage educators to explore AI's ethical and social implications of AI, the formalisation of "ethical AI readiness" across subjects remains aspirational. When children are invited to interrogate the algorithms and systems shaping their perceptions, they engage not only their critical thinking but also their capacity for civic reflection and agency in a technologised world.</p><p>Generative videos also challenge cultural institutions and parents to reconsider their roles. Media-literacy efforts that once centred on recognising misinformation must now evolve to include synthetic literacy, the ability to decode content that is neither wholly true nor wholly false but is computationally constructed. Families and schools share the responsibility of nurturing this interpretive capacity. By modelling critical curiosity rather than fear, adults can help children approach AI with wonder and discernment. Education has become an act of ethical stewardship, guiding the next generation to navigate complexity without cynicism.</p><p>Ultimately, Sora 2 exemplifies both the promise and the peril of the generative turn. It expands creative possibilities while testing society's capacity to preserve authenticity, privacy, and moral coherence. For children, whose lives are increasingly mediated by screens, the stakes are high. A coordinated response linking pedagogy, governance, and technological design can transform anxiety into agency. Education should not retreat from innovation but humanise it, cultivating discernment, empathy, and responsibility as the essential literacies of the twenty-first century. The challenge is to ensure that generative systems serve learning rather than exploit attention and that children's creative participation coexists with robust ethical guardrails. As <ref type="bibr" target="#b7">Floridi (2024)</ref> argues, the aim of artificial intelligence is not to halt technological progress but to ensure that it advances human flourishing and the quality of meaning in our shared digital environments. Equipping young people to live wisely and compassionately amid synthetic media is one of the defining moral projects of the current age.</p></div>		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Data availability statement: Not applicable. No empirical data were generated or analysed in this commentary.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declarations</head><p>Funding: This research received no specific grant from any funding agency in the public, commercial, or not-for-profit sector.</p><p>The author declares no conflicts of interest.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Exploring the boundaries of authorship: a comparative analysis of AI-generated text and human academic writing in English literature</title>
		<author>
			<persName><forename type="first">F</forename><surname>Amirjalili</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Neysani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Nikbakht</surname></persName>
		</author>
		<idno type="DOI">10.3389/feduc.2024.1347421</idno>
		<ptr target="https://doi.org/10.3389/feduc.2024.1347421" />
	</analytic>
	<monogr>
		<title level="j">Front. Educ</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">1347421</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<author>
			<persName><forename type="first">S</forename><surname>Bauschard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Quidwai</surname></persName>
		</author>
		<idno type="DOI">10.2139/ssrn.4784207</idno>
		<ptr target="https://doi.org/10.2139/ssrn.4784207" />
	</analytic>
	<monogr>
		<title level="m">From Insight to Implementation: How to Create Your AI School Guidance</title>
		<title level="s">SSRN Scholarly Paper</title>
		<imprint>
			<date type="published" when="2024-04-04">2024, April 4</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Exploring the ethics of multimodal composition with AI: Student and educator perspectives on evaluating and using generative models in the classroom</title>
		<author>
			<persName><forename type="first">S</forename><surname>Burriss</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hundley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pendergrass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Molvig</surname></persName>
		</author>
		<ptr target="https://citejournal.org/volume-25/issue-2-25/english-language-arts/exploring-the-ethics-of-multimodal-composition-with-ai-student-and-educator-perspectives-on-evaluating-and-using-generative-models-in-the-classroom/" />
	</analytic>
	<monogr>
		<title level="m">Contemporary Issues in Technology and Teacher Education</title>
		<imprint>
			<date type="published" when="2025">2025</date>
			<biblScope unit="volume">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">generative-artificial-intelligence-ai-in-education Department for Education [DfE]. (2023b). The safe and effective use of AI in education Leadership toolkit video transcipts</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Chaudhry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Cukurova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Luckin</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-031-11647-6_33</idno>
		<ptr target="https://assets.publishing.service.gov.uk/media/6842" />
	</analytic>
	<monogr>
		<title level="m">Artificial Intelligence in Education: Posters, Workshops, Tutorials, Industry &amp; Innovation Tracks, Practitioners&apos; and Doctoral Consortium</title>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Rodrigo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Matsuda</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">I</forename><surname>Cristea</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Dimitrova</surname></persName>
		</editor>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>UK Government</publisher>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="195" to="198" />
		</imprint>
	</monogr>
	<note>A Transparency Index Framework for AI in Education. e04ee5a089417c8060c5/Leadersh ip_Toolkit_-_Transcript.pdf</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">AI literacy as civic literacy: A case study of the &quot;AI and human rights&quot; curriculum for middle school students</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dipaola</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aidinoff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Marzilli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Champigny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Gundy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yezzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Breazeal</surname></persName>
		</author>
		<idno type="DOI">10.5210/fm.v29i12.13869</idno>
		<ptr target="https://doi.org/10.5210/fm.v29i12.13869" />
	</analytic>
	<monogr>
		<title level="j">First Monday</title>
		<imprint>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<author>
			<orgName type="collaboration">European Commission.</orgName>
		</author>
		<ptr target="https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai" />
		<title level="m">AI Act: Shaping Europe&apos;s digital future</title>
		<imprint>
			<date type="published" when="2025-10-08">2025, October 8</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The fourth revolution: How the infosphere is reshaping human reality</title>
		<author>
			<persName><forename type="first">L</forename><surname>Floridi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On the future of content in the age of artificial intelligence: Some implications and directions</title>
		<author>
			<persName><forename type="first">L</forename><surname>Floridi</surname></persName>
		</author>
		<idno type="DOI">10.1007/s13347-024-00806-z</idno>
		<ptr target="https://doi.org/10.1007/s13347-024-00806-z" />
	</analytic>
	<monogr>
		<title level="j">Philosophy &amp; Technology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">112</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Datasheets for datasets</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Morgenstern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Vecchione</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Vaughan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Iii</forename><surname>Daum√©</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename></persName>
		</author>
		<idno type="DOI">10.1145/3458723</idno>
		<ptr target="https://doi.org/10.1145/3458723" />
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="86" to="92" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<ptr target="https://www.legislation.gov.uk/ukpga/2023/50" />
		<title level="m">Online Safety Act 2023 (c. 50). London: The National Archives</title>
		<imprint>
			<publisher>Government of the United Kingdom</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Age appropriate design: a code of practice for online services</title>
		<author>
			<orgName type="collaboration">Information Commissioner&apos;s Office</orgName>
		</author>
		<ptr target="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/childrens-information/childrens-code-guidance-and-resources/age-appropriate-design-a-code-of-practice-for-online-services/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Prout</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315745008</idno>
		<ptr target="https://doi.org/10.4324/9781315745008" />
		<title level="m">Constructing and Reconstructing Childhood: Contemporary issues in the sociological study of childhood</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>rd ed.).. Routledge.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">How Can Video Generative AI Transform K-12 Education? Examining Teachers&apos; Perspectives through TPACK and TAM</title>
		<author>
			<persName><forename type="first">U</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Son</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Byun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lim</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2503.08003</idno>
		<idno type="arXiv">arXiv:2503.08003</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2503.08003" />
		<imprint>
			<date type="published" when="2025">2025</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Children&apos;s data and privacy online: Growing up in a digital age</title>
		<author>
			<persName><forename type="first">S</forename><surname>Livingstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Stoilova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Nandagiri</surname></persName>
		</author>
		<ptr target="https://eprints.lse.ac.uk/101283/1/Livingstone_childrens_data_and_privacy_online_evidence_review_published.pdf" />
	</analytic>
	<monogr>
		<title level="j">An evidence review. London School of Economics and Political Science</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">What Is AI Literacy? Competencies and Design Considerations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Magerko</surname></persName>
		</author>
		<idno type="DOI">10.1145/3313831.3376727</idno>
		<ptr target="https://doi.org/10.1145/3313831.3376727" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (CHI &apos;20)</title>
		<meeting>the 2020 CHI Conference on Human Factors in Computing Systems (CHI &apos;20)</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Luckin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">B</forename><surname>Forcier</surname></persName>
		</author>
		<ptr target="https://oro.open.ac.uk/50104/1/" />
		<title level="m">Intelligence Unleashed: An argument for AI in Education. Pearson / Open Ideas</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note>Luckin%20et%20al.%20-%202016%20-%20Intelligence%20Unleashed.%20An%20argument%20for%20AI%20in%20Educ.pdf</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Creativity and Artificial Intelligence -A Student Perspective</title>
		<author>
			<persName><forename type="first">R</forename><surname>Marrone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Taddeo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hill</surname></persName>
		</author>
		<idno type="DOI">10.3390/jintelligence10030065</idno>
		<ptr target="https://doi.org/10.3390/jintelligence10030065" />
	</analytic>
	<monogr>
		<title level="j">Journal of Intelligence</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">65</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Model cards for model reporting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zaldivar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Barnes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Vasserman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Raji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
		<idno type="DOI">10.1145/3287560.3287596</idno>
		<ptr target="https://doi.org/10.1145/3287560.3287596" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Conference on Fairness, Accountability, and Transparency</title>
		<meeting>the Conference on Fairness, Accountability, and Transparency</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="220" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Caring: A relational approach to ethics and moral education</title>
		<author>
			<persName><forename type="first">N</forename><surname>Noddings</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>University of California Press</publisher>
			<pubPlace>Berkeley, CA</pubPlace>
		</imprint>
	</monogr>
	<note>nd ed.</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<ptr target="https://www.oecd.org/en/topics/sub-issues/ai-principles.html" />
		<title level="m">OECD updates AI Principles to stay abreast of rapid technological developments</title>
		<imprint>
			<publisher>AI Principles -OECD</publisher>
			<date type="published" when="2024-05-03">2024a, May 3. 2024b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Advancing Critical Data and AI Literacies Through Authentic and Real-World Assessment Design Using a Data Justice Approach</title>
		<author>
			<persName><forename type="first">F</forename><surname>Picasso</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Atenas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Havemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Serbati</surname></persName>
		</author>
		<idno type="DOI">10.55982/openpraxis.16.3.667</idno>
		<ptr target="https://doi.org/10.55982/openpraxis.16.3.667" />
	</analytic>
	<monogr>
		<title level="j">Open Praxis</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="291" to="310" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sora 2 and AI-generated video: An initial briefing for schools and parents</title>
		<ptr target="https://www.safeaiforchildren.org/sora-2-initial-briefing-for-schools-and-parents/" />
	</analytic>
	<monogr>
		<title level="m">Safe AI for Children Alliance</title>
		<imprint>
			<date type="published" when="2009">2025, October 9</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Investigating risks and opportunities for children in a digital world: A rapid review of evidence on children&apos;s internet use and outcomes</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stoilova</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Livingstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Khazbak</surname></persName>
		</author>
		<ptr target="https://www.unicef.org/innocenti/media/5621/file/UNICEF-Investigating-Risks-Opportunities-Children-Digital-World-2021.pdf" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>UNICEF Office of Research -Innocenti</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<author>
			<persName><surname>Thorn</surname></persName>
		</author>
		<ptr target="https://unesdoc.unesco.org/ark:/48223/pf0000386693" />
	</analytic>
	<monogr>
		<title level="m">General comment No. 25 (2021) on children&apos;s rights in relation to the digital environment</title>
		<title level="s">Thorn / All Tech Is Human</title>
		<imprint>
			<publisher>By F. Miao &amp; W. Holmes</publisher>
			<date type="published" when="2021-03-02">2024. 2021, March 2</date>
		</imprint>
	</monogr>
	<note>Guidance for generative AI in education and research</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<ptr target="https://unesdoc.unesco.org/ark:/48223/pf0000385723" />
		<title level="m">Global Education Monitoring Report 2023: Technology in education: A tool on whose terms? UNESCO</title>
		<imprint>
			<publisher>UNESCO</publisher>
			<date type="published" when="2023">2023b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">From recorded to AIgenerated instructional videos: A comparison of learning performance and experience</title>
		<author>
			<persName><forename type="first">T</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1111/bjet.13530</idno>
		<ptr target="https://doi.org/10.1111/bjet.13530" />
	</analytic>
	<monogr>
		<title level="j">British Journal of Educational Technology</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
